[[reference-shared-types]]
== Shared types


[discrete]
=== AcknowledgedResponseBase

[pass]
++++
<pre>
++++
interface AcknowledgedResponseBase {
  pass:[/**] @property acknowledged For a successful response, this value is always true. On failure, an exception is returned instead. */
  acknowledged: boolean
}
[pass]
++++
</pre>
++++

[discrete]
=== AggregateName

[pass]
++++
<pre>
++++
type AggregateName = string
[pass]
++++
</pre>
++++

[discrete]
=== BulkIndexByScrollFailure

[pass]
++++
<pre>
++++
interface BulkIndexByScrollFailure {
  cause: <<ErrorCause>>
  id: <<Id>>
  index: <<IndexName>>
  status: <<_integer, integer>>
  type: string
}
[pass]
++++
</pre>
++++

[discrete]
=== BulkStats

[pass]
++++
<pre>
++++
interface BulkStats {
  total_operations: <<_long, long>>
  total_time?: <<Duration>>
  total_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  total_size?: <<ByteSize>>
  total_size_in_bytes: <<_long, long>>
  avg_time?: <<Duration>>
  avg_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  avg_size?: <<ByteSize>>
  avg_size_in_bytes: <<_long, long>>
}
[pass]
++++
</pre>
++++

[discrete]
=== ByteSize

[pass]
++++
<pre>
++++
type ByteSize = <<_long, long>> | string
[pass]
++++
</pre>
++++

[discrete]
=== Bytes

[pass]
++++
<pre>
++++
type Bytes = 'b' | 'kb' | 'mb' | 'gb' | 'tb' | 'pb'
[pass]
++++
</pre>
++++

[discrete]
=== CategoryId

[pass]
++++
<pre>
++++
type CategoryId = string
[pass]
++++
</pre>
++++

[discrete]
=== ClusterAlias

[pass]
++++
<pre>
++++
type ClusterAlias = string
[pass]
++++
</pre>
++++

[discrete]
=== ClusterDetails

[pass]
++++
<pre>
++++
interface ClusterDetails {
  status: <<ClusterSearchStatus>>
  indices: string
  took?: <<DurationValue>><<<UnitMillis>>>
  timed_out: boolean
  _shards?: <<ShardStatistics>>
  failures?: <<ShardFailure>>[]
}
[pass]
++++
</pre>
++++

[discrete]
=== ClusterInfoTarget

[pass]
++++
<pre>
++++
type ClusterInfoTarget = '_all' | 'http' | 'ingest' | 'thread_pool' | 'script'
[pass]
++++
</pre>
++++

[discrete]
=== ClusterInfoTargets

[pass]
++++
<pre>
++++
type ClusterInfoTargets = <<ClusterInfoTarget>> | <<ClusterInfoTarget>>[]
[pass]
++++
</pre>
++++

[discrete]
=== ClusterSearchStatus

[pass]
++++
<pre>
++++
type ClusterSearchStatus = 'running' | 'successful' | 'partial' | 'skipped' | 'failed'
[pass]
++++
</pre>
++++

[discrete]
=== ClusterStatistics

[pass]
++++
<pre>
++++
interface ClusterStatistics {
  skipped: <<_integer, integer>>
  successful: <<_integer, integer>>
  total: <<_integer, integer>>
  running: <<_integer, integer>>
  partial: <<_integer, integer>>
  failed: <<_integer, integer>>
  details?: Record<<<ClusterAlias>>, <<ClusterDetails>>>
}
[pass]
++++
</pre>
++++

[discrete]
=== CompletionStats

[pass]
++++
<pre>
++++
interface CompletionStats {
  pass:[/**] @property size_in_bytes Total amount, in bytes, of memory used for completion across all shards assigned to selected nodes. */
  size_in_bytes: <<_long, long>>
  pass:[/**] @property size Total amount of memory used for completion across all shards assigned to selected nodes. */
  size?: <<ByteSize>>
  fields?: Record<<<Field>>, <<FieldSizeUsage>>>
}
[pass]
++++
</pre>
++++

[discrete]
=== Conflicts

[pass]
++++
<pre>
++++
type Conflicts = 'abort' | 'proceed'
[pass]
++++
</pre>
++++

[discrete]
=== CoordsGeoBounds

[pass]
++++
<pre>
++++
interface CoordsGeoBounds {
  top: <<_double, double>>
  bottom: <<_double, double>>
  left: <<_double, double>>
  right: <<_double, double>>
}
[pass]
++++
</pre>
++++

[discrete]
=== DFIIndependenceMeasure

[pass]
++++
<pre>
++++
type DFIIndependenceMeasure = 'standardized' | 'saturated' | 'chisquared'
[pass]
++++
</pre>
++++

[discrete]
=== DFRAfterEffect

[pass]
++++
<pre>
++++
type DFRAfterEffect = 'no' | 'b' | 'l'
[pass]
++++
</pre>
++++

[discrete]
=== DFRBasicModel

[pass]
++++
<pre>
++++
type DFRBasicModel = 'be' | 'd' | 'g' | 'if' | 'in' | 'ine' | 'p'
[pass]
++++
</pre>
++++

[discrete]
=== DataStreamName

[pass]
++++
<pre>
++++
type DataStreamName = string
[pass]
++++
</pre>
++++

[discrete]
=== DataStreamNames

[pass]
++++
<pre>
++++
type DataStreamNames = <<DataStreamName>> | <<DataStreamName>>[]
[pass]
++++
</pre>
++++

[discrete]
=== DateFormat

[pass]
++++
<pre>
++++
type DateFormat = string
[pass]
++++
</pre>
++++

[discrete]
=== DateMath

[pass]
++++
<pre>
++++
type DateMath = string | Date
[pass]
++++
</pre>
++++

[discrete]
=== DateTime

[pass]
++++
<pre>
++++
type DateTime = string | <<EpochTime>><<<UnitMillis>>> | Date
[pass]
++++
</pre>
++++

[discrete]
=== Distance

[pass]
++++
<pre>
++++
type Distance = string
[pass]
++++
</pre>
++++

[discrete]
=== DistanceUnit

[pass]
++++
<pre>
++++
type DistanceUnit = 'in' | 'ft' | 'yd' | 'mi' | 'nmi' | 'km' | 'm' | 'cm' | 'mm'
[pass]
++++
</pre>
++++

[discrete]
=== DocStats

[pass]
++++
<pre>
++++
interface DocStats {
  pass:[/**] @property count Total number of non-deleted documents across all primary shards assigned to selected nodes. This number is based on documents in Lucene segments and may include documents from nested fields. */
  count: <<_long, long>>
  pass:[/**] @property deleted Total number of deleted documents across all primary shards assigned to selected nodes. This number is based on documents in Lucene segments. Elasticsearch reclaims the disk space of deleted Lucene documents when a segment is merged. */
  deleted?: <<_long, long>>
}
[pass]
++++
</pre>
++++

[discrete]
=== Duration

[pass]
++++
<pre>
++++
type Duration = string | -1 | 0
[pass]
++++
</pre>
++++

[discrete]
=== DurationLarge

[pass]
++++
<pre>
++++
type DurationLarge = string
[pass]
++++
</pre>
++++

[discrete]
=== DurationValue

[pass]
++++
<pre>
++++
type DurationValue<Unit = unknown> = Unit
[pass]
++++
</pre>
++++

[discrete]
=== ElasticsearchVersionInfo

[pass]
++++
<pre>
++++
interface ElasticsearchVersionInfo {
  build_date: <<DateTime>>
  build_flavor: string
  build_hash: string
  build_snapshot: boolean
  build_type: string
  lucene_version: <<VersionString>>
  minimum_index_compatibility_version: <<VersionString>>
  minimum_wire_compatibility_version: <<VersionString>>
  number: string
}
[pass]
++++
</pre>
++++

[discrete]
=== ElasticsearchVersionMinInfo

[pass]
++++
<pre>
++++
interface ElasticsearchVersionMinInfo {
  build_flavor: string
  minimum_index_compatibility_version: <<VersionString>>
  minimum_wire_compatibility_version: <<VersionString>>
  number: string
}
[pass]
++++
</pre>
++++

[discrete]
=== EmptyObject

[pass]
++++
<pre>
++++
interface EmptyObject {
}
[pass]
++++
</pre>
++++

[discrete]
=== EpochTime

[pass]
++++
<pre>
++++
type EpochTime<Unit = unknown> = Unit
[pass]
++++
</pre>
++++

[discrete]
=== ErrorCause

[pass]
++++
<pre>
++++
interface ErrorCauseKeys {
  type: string
  reason?: string
  stack_trace?: string
  caused_by?: <<ErrorCause>>
  root_cause?: <<ErrorCause>>[]
  suppressed?: <<ErrorCause>>[]
}
type ErrorCause = ErrorCauseKeys
  & { [property: string]: any }
[pass]
++++
</pre>
++++

[discrete]
=== ErrorResponseBase

[pass]
++++
<pre>
++++
interface ErrorResponseBase {
  error: <<ErrorCause>>
  status: <<_integer, integer>>
}
[pass]
++++
</pre>
++++

[discrete]
=== EsqlColumns

[pass]
++++
<pre>
++++
type EsqlColumns = ArrayBuffer
[pass]
++++
</pre>
++++

[discrete]
=== ExpandWildcard

[pass]
++++
<pre>
++++
type ExpandWildcard = 'all' | 'open' | 'closed' | 'hidden' | 'none'
[pass]
++++
</pre>
++++

[discrete]
=== ExpandWildcards

[pass]
++++
<pre>
++++
type ExpandWildcards = <<ExpandWildcard>> | <<ExpandWildcard>>[]
[pass]
++++
</pre>
++++

[discrete]
=== Field

[pass]
++++
<pre>
++++
type Field = string
[pass]
++++
</pre>
++++

[discrete]
=== FieldMemoryUsage

[pass]
++++
<pre>
++++
interface FieldMemoryUsage {
  memory_size?: <<ByteSize>>
  memory_size_in_bytes: <<_long, long>>
}
[pass]
++++
</pre>
++++

[discrete]
=== FieldSizeUsage

[pass]
++++
<pre>
++++
interface FieldSizeUsage {
  size?: <<ByteSize>>
  size_in_bytes: <<_long, long>>
}
[pass]
++++
</pre>
++++

[discrete]
=== FieldSort

[pass]
++++
<pre>
++++
interface FieldSort {
  missing?: AggregationsMissing
  mode?: <<SortMode>>
  nested?: <<NestedSortValue>>
  order?: <<SortOrder>>
  unmapped_type?: MappingFieldType
  numeric_type?: <<FieldSortNumericType>>
  format?: string
}
[pass]
++++
</pre>
++++

[discrete]
=== FieldSortNumericType

[pass]
++++
<pre>
++++
type FieldSortNumericType = '<<_long, long>>' | '<<_double, double>>' | 'date' | 'date_nanos'
[pass]
++++
</pre>
++++

[discrete]
=== FieldValue

[pass]
++++
<pre>
++++
type FieldValue = <<_long, long>> | <<_double, double>> | string | boolean | null | any
[pass]
++++
</pre>
++++

[discrete]
=== FielddataStats

[pass]
++++
<pre>
++++
interface FielddataStats {
  evictions?: <<_long, long>>
  memory_size?: <<ByteSize>>
  memory_size_in_bytes: <<_long, long>>
  fields?: Record<<<Field>>, <<FieldMemoryUsage>>>
}
[pass]
++++
</pre>
++++

[discrete]
=== Fields

[pass]
++++
<pre>
++++
type Fields = <<Field>> | <<Field>>[]
[pass]
++++
</pre>
++++

[discrete]
=== FlushStats

[pass]
++++
<pre>
++++
interface FlushStats {
  periodic: <<_long, long>>
  total: <<_long, long>>
  total_time?: <<Duration>>
  total_time_in_millis: <<DurationValue>><<<UnitMillis>>>
}
[pass]
++++
</pre>
++++

[discrete]
=== Fuzziness

[pass]
++++
<pre>
++++
type Fuzziness = string | <<_integer, integer>>
[pass]
++++
</pre>
++++

[discrete]
=== GeoBounds

[pass]
++++
<pre>
++++
type GeoBounds = <<CoordsGeoBounds>> | <<TopLeftBottomRightGeoBounds>> | <<TopRightBottomLeftGeoBounds>> | <<WktGeoBounds>>
[pass]
++++
</pre>
++++

[discrete]
=== GeoDistanceSort

[pass]
++++
<pre>
++++
interface GeoDistanceSortKeys {
  mode?: <<SortMode>>
  distance_type?: <<GeoDistanceType>>
  ignore_unmapped?: boolean
  order?: <<SortOrder>>
  unit?: <<DistanceUnit>>
  nested?: <<NestedSortValue>>
}
type GeoDistanceSort = GeoDistanceSortKeys
  & { [property: string]: <<GeoLocation>> | <<GeoLocation>>[] | <<SortMode>> | <<GeoDistanceType>> | boolean | <<SortOrder>> | <<DistanceUnit>> | <<NestedSortValue>> }
[pass]
++++
</pre>
++++

[discrete]
=== GeoDistanceType

[pass]
++++
<pre>
++++
type GeoDistanceType = 'arc' | 'plane'
[pass]
++++
</pre>
++++

[discrete]
=== GeoHash

[pass]
++++
<pre>
++++
type GeoHash = string
[pass]
++++
</pre>
++++

[discrete]
=== GeoHashLocation

[pass]
++++
<pre>
++++
interface GeoHashLocation {
  geohash: <<GeoHash>>
}
[pass]
++++
</pre>
++++

[discrete]
=== GeoHashPrecision

[pass]
++++
<pre>
++++
type GeoHashPrecision = number | string
[pass]
++++
</pre>
++++

[discrete]
=== GeoHexCell

[pass]
++++
<pre>
++++
type GeoHexCell = string
[pass]
++++
</pre>
++++

[discrete]
=== GeoLine

[pass]
++++
<pre>
++++
interface GeoLine {
  pass:[/**] @property type Always `"LineString"` */
  type: string
  pass:[/**] @property coordinates Array of `[lon, lat]` coordinates */
  coordinates: <<_double, double>>[][]
}
[pass]
++++
</pre>
++++

[discrete]
=== GeoLocation

[pass]
++++
<pre>
++++
type GeoLocation = <<LatLonGeoLocation>> | <<GeoHashLocation>> | <<_double, double>>[] | string
[pass]
++++
</pre>
++++

[discrete]
=== GeoShape

[pass]
++++
<pre>
++++
type GeoShape = any
[pass]
++++
</pre>
++++

[discrete]
=== GeoShapeRelation

[pass]
++++
<pre>
++++
type GeoShapeRelation = 'intersects' | 'disjoint' | 'within' | 'contains'
[pass]
++++
</pre>
++++

[discrete]
=== GeoTile

[pass]
++++
<pre>
++++
type GeoTile = string
[pass]
++++
</pre>
++++

[discrete]
=== GeoTilePrecision

[pass]
++++
<pre>
++++
type GeoTilePrecision = number
[pass]
++++
</pre>
++++

[discrete]
=== GetStats

[pass]
++++
<pre>
++++
interface GetStats {
  current: <<_long, long>>
  exists_time?: <<Duration>>
  exists_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  exists_total: <<_long, long>>
  missing_time?: <<Duration>>
  missing_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  missing_total: <<_long, long>>
  time?: <<Duration>>
  time_in_millis: <<DurationValue>><<<UnitMillis>>>
  total: <<_long, long>>
}
[pass]
++++
</pre>
++++

[discrete]
=== GrokPattern

[pass]
++++
<pre>
++++
type GrokPattern = string
[pass]
++++
</pre>
++++

[discrete]
=== HealthStatus

[pass]
++++
<pre>
++++
type HealthStatus = 'green' | 'GREEN' | 'yellow' | 'YELLOW' | 'red' | 'RED'
[pass]
++++
</pre>
++++

[discrete]
=== Host

[pass]
++++
<pre>
++++
type Host = string
[pass]
++++
</pre>
++++

[discrete]
=== HttpHeaders

[pass]
++++
<pre>
++++
type HttpHeaders = Record<string, string | string[]>
[pass]
++++
</pre>
++++

[discrete]
=== IBDistribution

[pass]
++++
<pre>
++++
type IBDistribution = 'll' | 'spl'
[pass]
++++
</pre>
++++

[discrete]
=== IBLambda

[pass]
++++
<pre>
++++
type IBLambda = 'df' | 'ttf'
[pass]
++++
</pre>
++++

[discrete]
=== Id

[pass]
++++
<pre>
++++
type Id = string
[pass]
++++
</pre>
++++

[discrete]
=== Ids

[pass]
++++
<pre>
++++
type Ids = <<Id>> | <<Id>>[]
[pass]
++++
</pre>
++++

[discrete]
=== IndexAlias

[pass]
++++
<pre>
++++
type IndexAlias = string
[pass]
++++
</pre>
++++

[discrete]
=== IndexName

[pass]
++++
<pre>
++++
type IndexName = string
[pass]
++++
</pre>
++++

[discrete]
=== IndexPattern

[pass]
++++
<pre>
++++
type IndexPattern = string
[pass]
++++
</pre>
++++

[discrete]
=== IndexPatterns

[pass]
++++
<pre>
++++
type IndexPatterns = <<IndexPattern>>[]
[pass]
++++
</pre>
++++

[discrete]
=== IndexingStats

[pass]
++++
<pre>
++++
interface IndexingStats {
  index_current: <<_long, long>>
  delete_current: <<_long, long>>
  delete_time?: <<Duration>>
  delete_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  delete_total: <<_long, long>>
  is_throttled: boolean
  noop_update_total: <<_long, long>>
  throttle_time?: <<Duration>>
  throttle_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  index_time?: <<Duration>>
  index_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  index_total: <<_long, long>>
  index_failed: <<_long, long>>
  types?: Record<string, <<IndexingStats>>>
  write_load?: <<_double, double>>
}
[pass]
++++
</pre>
++++

[discrete]
=== Indices

[pass]
++++
<pre>
++++
type Indices = <<IndexName>> | <<IndexName>>[]
[pass]
++++
</pre>
++++

[discrete]
=== IndicesOptions

[pass]
++++
<pre>
++++
interface IndicesOptions {
  pass:[/**] @property allow_no_indices If false, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. */
  allow_no_indices?: boolean
  pass:[/**] @property expand_wildcards Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. */
  expand_wildcards?: <<ExpandWildcards>>
  pass:[/**] @property ignore_unavailable If true, missing or closed indices are not included in the response. */
  ignore_unavailable?: boolean
  pass:[/**] @property ignore_throttled If true, concrete, expanded or aliased indices are ignored when frozen. */
  ignore_throttled?: boolean
}
[pass]
++++
</pre>
++++

[discrete]
=== IndicesResponseBase

[pass]
++++
<pre>
++++
interface IndicesResponseBase extends <<AcknowledgedResponseBase>> {
  _shards?: <<ShardStatistics>>
}
[pass]
++++
</pre>
++++

[discrete]
=== InlineGet

[pass]
++++
<pre>
++++
interface InlineGetKeys<TDocument = unknown> {
  fields?: Record<string, any>
  found: boolean
  _seq_no?: <<SequenceNumber>>
  _primary_term?: <<_long, long>>
  _routing?: <<Routing>>
  _source?: TDocument
}
type InlineGet<TDocument = unknown> = InlineGetKeys<TDocument>
  & { [property: string]: any }
[pass]
++++
</pre>
++++

[discrete]
=== Ip

[pass]
++++
<pre>
++++
type Ip = string
[pass]
++++
</pre>
++++

[discrete]
=== KnnQuery

[pass]
++++
<pre>
++++
interface KnnQuery extends QueryDslQueryBase {
  pass:[/**] @property field The name of the vector field to search against */
  field: <<Field>>
  pass:[/**] @property query_vector The query vector */
  query_vector?: <<QueryVector>>
  pass:[/**] @property query_vector_builder The query vector builder. You must provide a query_vector_builder or query_vector, but not both. */
  query_vector_builder?: <<QueryVectorBuilder>>
  pass:[/**] @property num_candidates The number of nearest neighbor candidates to consider per shard */
  num_candidates?: <<_integer, integer>>
  pass:[/**] @property k The final number of nearest neighbors to return as top hits */
  k?: <<_integer, integer>>
  pass:[/**] @property filter Filters for the kNN search query */
  filter?: QueryDslQueryContainer | QueryDslQueryContainer[]
  pass:[/**] @property similarity The minimum similarity for a vector to be considered a match */
  similarity?: <<_float, float>>
}
[pass]
++++
</pre>
++++

[discrete]
=== KnnRetriever

[pass]
++++
<pre>
++++
interface KnnRetriever extends <<RetrieverBase>> {
  pass:[/**] @property field The name of the vector field to search against. */
  field: string
  pass:[/**] @property query_vector Query vector. Must have the same number of dimensions as the vector field you are searching against. You must provide a query_vector_builder or query_vector, but not both. */
  query_vector?: <<QueryVector>>
  pass:[/**] @property query_vector_builder Defines a model to build a query vector. */
  query_vector_builder?: <<QueryVectorBuilder>>
  pass:[/**] @property k Number of nearest neighbors to return as top hits. */
  k: <<_integer, integer>>
  pass:[/**] @property num_candidates Number of nearest neighbor candidates to consider per shard. */
  num_candidates: <<_integer, integer>>
  pass:[/**] @property similarity The minimum similarity required for a document to be considered a match. */
  similarity?: <<_float, float>>
}
[pass]
++++
</pre>
++++

[discrete]
=== KnnSearch

[pass]
++++
<pre>
++++
interface KnnSearch {
  pass:[/**] @property field The name of the vector field to search against */
  field: <<Field>>
  pass:[/**] @property query_vector The query vector */
  query_vector?: <<QueryVector>>
  pass:[/**] @property query_vector_builder The query vector builder. You must provide a query_vector_builder or query_vector, but not both. */
  query_vector_builder?: <<QueryVectorBuilder>>
  pass:[/**] @property k The final number of nearest neighbors to return as top hits */
  k?: <<_integer, integer>>
  pass:[/**] @property num_candidates The number of nearest neighbor candidates to consider per shard */
  num_candidates?: <<_integer, integer>>
  pass:[/**] @property boost Boost value to apply to kNN scores */
  boost?: <<_float, float>>
  pass:[/**] @property filter Filters for the kNN search query */
  filter?: QueryDslQueryContainer | QueryDslQueryContainer[]
  pass:[/**] @property similarity The minimum similarity for a vector to be considered a match */
  similarity?: <<_float, float>>
  pass:[/**] @property inner_hits If defined, each search hit will contain inner hits. */
  inner_hits?: SearchInnerHits
}
[pass]
++++
</pre>
++++

[discrete]
=== LatLonGeoLocation

[pass]
++++
<pre>
++++
interface LatLonGeoLocation {
  pass:[/**] @property lat Latitude */
  lat: <<_double, double>>
  pass:[/**] @property lon Longitude */
  lon: <<_double, double>>
}
[pass]
++++
</pre>
++++

[discrete]
=== Level

[pass]
++++
<pre>
++++
type Level = 'cluster' | 'indices' | 'shards'
[pass]
++++
</pre>
++++

[discrete]
=== LifecycleOperationMode

[pass]
++++
<pre>
++++
type LifecycleOperationMode = 'RUNNING' | 'STOPPING' | 'STOPPED'
[pass]
++++
</pre>
++++

[discrete]
=== MapboxVectorTiles

[pass]
++++
<pre>
++++
type MapboxVectorTiles = ArrayBuffer
[pass]
++++
</pre>
++++

[discrete]
=== MergesStats

[pass]
++++
<pre>
++++
interface MergesStats {
  current: <<_long, long>>
  current_docs: <<_long, long>>
  current_size?: string
  current_size_in_bytes: <<_long, long>>
  total: <<_long, long>>
  total_auto_throttle?: string
  total_auto_throttle_in_bytes: <<_long, long>>
  total_docs: <<_long, long>>
  total_size?: string
  total_size_in_bytes: <<_long, long>>
  total_stopped_time?: <<Duration>>
  total_stopped_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  total_throttled_time?: <<Duration>>
  total_throttled_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  total_time?: <<Duration>>
  total_time_in_millis: <<DurationValue>><<<UnitMillis>>>
}
[pass]
++++
</pre>
++++

[discrete]
=== Metadata

[pass]
++++
<pre>
++++
type Metadata = Record<string, any>
[pass]
++++
</pre>
++++

[discrete]
=== Metrics

[pass]
++++
<pre>
++++
type Metrics = string | string[]
[pass]
++++
</pre>
++++

[discrete]
=== MinimumShouldMatch

[pass]
++++
<pre>
++++
type MinimumShouldMatch = <<_integer, integer>> | string
[pass]
++++
</pre>
++++

[discrete]
=== MultiTermQueryRewrite

[pass]
++++
<pre>
++++
type MultiTermQueryRewrite = string
[pass]
++++
</pre>
++++

[discrete]
=== Name

[pass]
++++
<pre>
++++
type Name = string
[pass]
++++
</pre>
++++

[discrete]
=== Names

[pass]
++++
<pre>
++++
type Names = <<Name>> | <<Name>>[]
[pass]
++++
</pre>
++++

[discrete]
=== Namespace

[pass]
++++
<pre>
++++
type Namespace = string
[pass]
++++
</pre>
++++

[discrete]
=== NestedSortValue

[pass]
++++
<pre>
++++
interface NestedSortValue {
  filter?: QueryDslQueryContainer
  max_children?: <<_integer, integer>>
  nested?: <<NestedSortValue>>
  path: <<Field>>
}
[pass]
++++
</pre>
++++

[discrete]
=== NodeAttributes

[pass]
++++
<pre>
++++
interface NodeAttributes {
  pass:[/**] @property attributes Lists node attributes. */
  attributes: Record<string, string>
  pass:[/**] @property ephemeral_id The ephemeral ID of the node. */
  ephemeral_id: <<Id>>
  pass:[/**] @property id The unique identifier of the node. */
  id?: <<NodeId>>
  pass:[/**] @property name The unique identifier of the node. */
  name: <<NodeName>>
  pass:[/**] @property transport_address The host and port where transport HTTP connections are accepted. */
  transport_address: <<TransportAddress>>
}
[pass]
++++
</pre>
++++

[discrete]
=== NodeId

[pass]
++++
<pre>
++++
type NodeId = string
[pass]
++++
</pre>
++++

[discrete]
=== NodeIds

[pass]
++++
<pre>
++++
type NodeIds = <<NodeId>> | <<NodeId>>[]
[pass]
++++
</pre>
++++

[discrete]
=== NodeName

[pass]
++++
<pre>
++++
type NodeName = string
[pass]
++++
</pre>
++++

[discrete]
=== NodeRole

[pass]
++++
<pre>
++++
type NodeRole = 'master' | 'data' | 'data_cold' | 'data_content' | 'data_frozen' | 'data_hot' | 'data_warm' | 'client' | 'ingest' | 'ml' | 'voting_only' | 'transform' | 'remote_cluster_client' | 'coordinating_only'
[pass]
++++
</pre>
++++

[discrete]
=== NodeRoles

[pass]
++++
<pre>
++++
type NodeRoles = <<NodeRole>>[]
[pass]
++++
</pre>
++++

[discrete]
=== NodeShard

[pass]
++++
<pre>
++++
interface NodeShard {
  state: IndicesStatsShardRoutingState
  primary: boolean
  node?: <<NodeName>>
  shard: <<_integer, integer>>
  index: <<IndexName>>
  allocation_id?: Record<string, <<Id>>>
  recovery_source?: Record<string, <<Id>>>
  unassigned_info?: ClusterAllocationExplainUnassignedInformation
  relocating_node?: <<NodeId>> | null
  relocation_failure_info?: <<RelocationFailureInfo>>
}
[pass]
++++
</pre>
++++

[discrete]
=== NodeStatistics

[pass]
++++
<pre>
++++
interface NodeStatistics {
  failures?: <<ErrorCause>>[]
  pass:[/**] @property total Total number of nodes selected by the request. */
  total: <<_integer, integer>>
  pass:[/**] @property successful Number of nodes that responded successfully to the request. */
  successful: <<_integer, integer>>
  pass:[/**] @property failed Number of nodes that rejected the request or failed to respond. If this value is not 0, a reason for the rejection or failure is included in the response. */
  failed: <<_integer, integer>>
}
[pass]
++++
</pre>
++++

[discrete]
=== Normalization

[pass]
++++
<pre>
++++
type Normalization = 'no' | 'h1' | 'h2' | 'h3' | 'z'
[pass]
++++
</pre>
++++

[discrete]
=== OpType

[pass]
++++
<pre>
++++
type OpType = 'index' | 'create'
[pass]
++++
</pre>
++++

[discrete]
=== Password

[pass]
++++
<pre>
++++
type Password = string
[pass]
++++
</pre>
++++

[discrete]
=== Percentage

[pass]
++++
<pre>
++++
type Percentage = string | <<_float, float>>
[pass]
++++
</pre>
++++

[discrete]
=== PipelineName

[pass]
++++
<pre>
++++
type PipelineName = string
[pass]
++++
</pre>
++++

[discrete]
=== PluginStats

[pass]
++++
<pre>
++++
interface PluginStats {
  classname: string
  description: string
  elasticsearch_version: <<VersionString>>
  extended_plugins: string[]
  has_native_controller: boolean
  java_version: <<VersionString>>
  name: <<Name>>
  version: <<VersionString>>
  licensed: boolean
}
[pass]
++++
</pre>
++++

[discrete]
=== PropertyName

[pass]
++++
<pre>
++++
type PropertyName = string
[pass]
++++
</pre>
++++

[discrete]
=== QueryCacheStats

[pass]
++++
<pre>
++++
interface QueryCacheStats {
  pass:[/**] @property cache_count Total number of entries added to the query cache across all shards assigned to selected nodes. This number includes current and evicted entries. */
  cache_count: <<_long, long>>
  pass:[/**] @property cache_size Total number of entries currently in the query cache across all shards assigned to selected nodes. */
  cache_size: <<_long, long>>
  pass:[/**] @property evictions Total number of query cache evictions across all shards assigned to selected nodes. */
  evictions: <<_long, long>>
  pass:[/**] @property hit_count Total count of query cache hits across all shards assigned to selected nodes. */
  hit_count: <<_long, long>>
  pass:[/**] @property memory_size Total amount of memory used for the query cache across all shards assigned to selected nodes. */
  memory_size?: <<ByteSize>>
  pass:[/**] @property memory_size_in_bytes Total amount, in bytes, of memory used for the query cache across all shards assigned to selected nodes. */
  memory_size_in_bytes: <<_long, long>>
  pass:[/**] @property miss_count Total count of query cache misses across all shards assigned to selected nodes. */
  miss_count: <<_long, long>>
  pass:[/**] @property total_count Total count of hits and misses in the query cache across all shards assigned to selected nodes. */
  total_count: <<_long, long>>
}
[pass]
++++
</pre>
++++

[discrete]
=== QueryVector

[pass]
++++
<pre>
++++
type QueryVector = <<_float, float>>[]
[pass]
++++
</pre>
++++

[discrete]
=== QueryVectorBuilder

[pass]
++++
<pre>
++++
interface QueryVectorBuilder {
  text_embedding?: <<TextEmbedding>>
}
[pass]
++++
</pre>
++++

[discrete]
=== RRFRetriever

[pass]
++++
<pre>
++++
interface RRFRetriever extends <<RetrieverBase>> {
  pass:[/**] @property retrievers A list of child retrievers to specify which sets of returned top documents will have the RRF formula applied to them. */
  retrievers: <<RetrieverContainer>>[]
  pass:[/**] @property rank_constant This value determines how much influence documents in individual result sets per query have over the final ranked result set. */
  rank_constant?: <<_integer, integer>>
  pass:[/**] @property rank_window_size This value determines the size of the individual result sets per query. */
  rank_window_size?: <<_integer, integer>>
}
[pass]
++++
</pre>
++++

[discrete]
=== RankBase

[pass]
++++
<pre>
++++
interface RankBase {
}
[pass]
++++
</pre>
++++

[discrete]
=== RankContainer

[pass]
++++
<pre>
++++
interface RankContainer {
  pass:[/**] @property rrf The reciprocal rank fusion parameters */
  rrf?: <<RrfRank>>
}
[pass]
++++
</pre>
++++

[discrete]
=== RecoveryStats

[pass]
++++
<pre>
++++
interface RecoveryStats {
  current_as_source: <<_long, long>>
  current_as_target: <<_long, long>>
  throttle_time?: <<Duration>>
  throttle_time_in_millis: <<DurationValue>><<<UnitMillis>>>
}
[pass]
++++
</pre>
++++

[discrete]
=== Refresh

[pass]
++++
<pre>
++++
type Refresh = boolean | 'true' | 'false' | 'wait_for'
[pass]
++++
</pre>
++++

[discrete]
=== RefreshStats

[pass]
++++
<pre>
++++
interface RefreshStats {
  external_total: <<_long, long>>
  external_total_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  listeners: <<_long, long>>
  total: <<_long, long>>
  total_time?: <<Duration>>
  total_time_in_millis: <<DurationValue>><<<UnitMillis>>>
}
[pass]
++++
</pre>
++++

[discrete]
=== RelationName

[pass]
++++
<pre>
++++
type RelationName = string
[pass]
++++
</pre>
++++

[discrete]
=== RelocationFailureInfo

[pass]
++++
<pre>
++++
interface RelocationFailureInfo {
  failed_attempts: <<_integer, integer>>
}
[pass]
++++
</pre>
++++

[discrete]
=== RequestBase

[pass]
++++
<pre>
++++
interface RequestBase extends <<SpecUtilsCommonQueryParameters>> {
}
[pass]
++++
</pre>
++++

[discrete]
=== RequestCacheStats

[pass]
++++
<pre>
++++
interface RequestCacheStats {
  evictions: <<_long, long>>
  hit_count: <<_long, long>>
  memory_size?: string
  memory_size_in_bytes: <<_long, long>>
  miss_count: <<_long, long>>
}
[pass]
++++
</pre>
++++

[discrete]
=== Result

[pass]
++++
<pre>
++++
type Result = 'created' | 'updated' | 'deleted' | 'not_found' | 'noop'
[pass]
++++
</pre>
++++

[discrete]
=== Retries

[pass]
++++
<pre>
++++
interface Retries {
  bulk: <<_long, long>>
  search: <<_long, long>>
}
[pass]
++++
</pre>
++++

[discrete]
=== RetrieverBase

[pass]
++++
<pre>
++++
interface RetrieverBase {
  pass:[/**] @property filter Query to filter the documents that can match. */
  filter?: QueryDslQueryContainer | QueryDslQueryContainer[]
  pass:[/**] @property min_score Minimum _score for matching documents. Documents with a lower _score are not included in the top documents. */
  min_score?: <<_float, float>>
}
[pass]
++++
</pre>
++++

[discrete]
=== RetrieverContainer

[pass]
++++
<pre>
++++
interface RetrieverContainer {
  pass:[/**] @property standard A retriever that replaces the functionality of a traditional query. */
  standard?: <<StandardRetriever>>
  pass:[/**] @property knn A retriever that replaces the functionality of a knn search. */
  knn?: <<KnnRetriever>>
  pass:[/**] @property rrf A retriever that produces top documents from reciprocal rank fusion (RRF). */
  rrf?: <<RRFRetriever>>
  pass:[/**] @property text_similarity_reranker A retriever that reranks the top documents based on a reranking model using the InferenceAPI */
  text_similarity_reranker?: <<TextSimilarityReranker>>
}
[pass]
++++
</pre>
++++

[discrete]
=== Routing

[pass]
++++
<pre>
++++
type Routing = string
[pass]
++++
</pre>
++++

[discrete]
=== RrfRank

[pass]
++++
<pre>
++++
interface RrfRank {
  pass:[/**] @property rank_constant How much influence documents in individual result sets per query have over the final ranked result set */
  rank_constant?: <<_long, long>>
  pass:[/**] @property rank_window_size Size of the individual result sets per query */
  rank_window_size?: <<_long, long>>
}
[pass]
++++
</pre>
++++

[discrete]
=== ScalarValue

[pass]
++++
<pre>
++++
type ScalarValue = <<_long, long>> | <<_double, double>> | string | boolean | null
[pass]
++++
</pre>
++++

[discrete]
=== ScoreSort

[pass]
++++
<pre>
++++
interface ScoreSort {
  order?: <<SortOrder>>
}
[pass]
++++
</pre>
++++

[discrete]
=== Script

[pass]
++++
<pre>
++++
interface Script {
  pass:[/**] @property source The script source. */
  source?: string
  pass:[/**] @property id The `id` for a stored script. */
  id?: <<Id>>
  pass:[/**] @property params Specifies any named parameters that are passed into the script as variables. Use parameters instead of hard-coded values to decrease compile time. */
  params?: Record<string, any>
  pass:[/**] @property lang Specifies the language the script is written in. */
  lang?: <<ScriptLanguage>>
  options?: Record<string, string>
}
[pass]
++++
</pre>
++++

[discrete]
=== ScriptField

[pass]
++++
<pre>
++++
interface ScriptField {
  script: <<Script>> | string
  ignore_failure?: boolean
}
[pass]
++++
</pre>
++++

[discrete]
=== ScriptLanguage

[pass]
++++
<pre>
++++
type ScriptLanguage = 'painless' | 'expression' | 'mustache' | 'java' | string
[pass]
++++
</pre>
++++

[discrete]
=== ScriptSort

[pass]
++++
<pre>
++++
interface ScriptSort {
  order?: <<SortOrder>>
  script: <<Script>> | string
  type?: <<ScriptSortType>>
  mode?: <<SortMode>>
  nested?: <<NestedSortValue>>
}
[pass]
++++
</pre>
++++

[discrete]
=== ScriptSortType

[pass]
++++
<pre>
++++
type ScriptSortType = 'string' | 'number' | 'version'
[pass]
++++
</pre>
++++

[discrete]
=== ScriptTransform

[pass]
++++
<pre>
++++
interface ScriptTransform {
  lang?: string
  params?: Record<string, any>
  source?: string
  id?: string
}
[pass]
++++
</pre>
++++

[discrete]
=== ScrollId

[pass]
++++
<pre>
++++
type ScrollId = string
[pass]
++++
</pre>
++++

[discrete]
=== ScrollIds

[pass]
++++
<pre>
++++
type ScrollIds = <<ScrollId>> | <<ScrollId>>[]
[pass]
++++
</pre>
++++

[discrete]
=== SearchStats

[pass]
++++
<pre>
++++
interface SearchStats {
  fetch_current: <<_long, long>>
  fetch_time?: <<Duration>>
  fetch_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  fetch_total: <<_long, long>>
  open_contexts?: <<_long, long>>
  query_current: <<_long, long>>
  query_time?: <<Duration>>
  query_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  query_total: <<_long, long>>
  scroll_current: <<_long, long>>
  scroll_time?: <<Duration>>
  scroll_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  scroll_total: <<_long, long>>
  suggest_current: <<_long, long>>
  suggest_time?: <<Duration>>
  suggest_time_in_millis: <<DurationValue>><<<UnitMillis>>>
  suggest_total: <<_long, long>>
  groups?: Record<string, <<SearchStats>>>
}
[pass]
++++
</pre>
++++

[discrete]
=== SearchTransform

[pass]
++++
<pre>
++++
interface SearchTransform {
  request: WatcherSearchInputRequestDefinition
  timeout: <<Duration>>
}
[pass]
++++
</pre>
++++

[discrete]
=== SearchType

[pass]
++++
<pre>
++++
type SearchType = 'query_then_fetch' | 'dfs_query_then_fetch'
[pass]
++++
</pre>
++++

[discrete]
=== SegmentsStats

[pass]
++++
<pre>
++++
interface SegmentsStats {
  pass:[/**] @property count Total number of segments across all shards assigned to selected nodes. */
  count: <<_integer, integer>>
  pass:[/**] @property doc_values_memory Total amount of memory used for doc values across all shards assigned to selected nodes. */
  doc_values_memory?: <<ByteSize>>
  pass:[/**] @property doc_values_memory_in_bytes Total amount, in bytes, of memory used for doc values across all shards assigned to selected nodes. */
  doc_values_memory_in_bytes: <<_long, long>>
  pass:[/**] @property file_sizes This object is not populated by the cluster stats API. To get information on segment files, use the node stats API. */
  file_sizes: Record<string, IndicesStatsShardFileSizeInfo>
  pass:[/**] @property fixed_bit_set Total amount of memory used by fixed bit sets across all shards assigned to selected nodes. Fixed bit sets are used for nested object field types and type filters for join fields. */
  fixed_bit_set?: <<ByteSize>>
  pass:[/**] @property fixed_bit_set_memory_in_bytes Total amount of memory, in bytes, used by fixed bit sets across all shards assigned to selected nodes. */
  fixed_bit_set_memory_in_bytes: <<_long, long>>
  pass:[/**] @property index_writer_memory Total amount of memory used by all index writers across all shards assigned to selected nodes. */
  index_writer_memory?: <<ByteSize>>
  index_writer_max_memory_in_bytes?: <<_long, long>>
  pass:[/**] @property index_writer_memory_in_bytes Total amount, in bytes, of memory used by all index writers across all shards assigned to selected nodes. */
  index_writer_memory_in_bytes: <<_long, long>>
  pass:[/**] @property max_unsafe_auto_id_timestamp Unix timestamp, in milliseconds, of the most recently retried indexing request. */
  max_unsafe_auto_id_timestamp: <<_long, long>>
  pass:[/**] @property memory Total amount of memory used for segments across all shards assigned to selected nodes. */
  memory?: <<ByteSize>>
  pass:[/**] @property memory_in_bytes Total amount, in bytes, of memory used for segments across all shards assigned to selected nodes. */
  memory_in_bytes: <<_long, long>>
  pass:[/**] @property norms_memory Total amount of memory used for normalization factors across all shards assigned to selected nodes. */
  norms_memory?: <<ByteSize>>
  pass:[/**] @property norms_memory_in_bytes Total amount, in bytes, of memory used for normalization factors across all shards assigned to selected nodes. */
  norms_memory_in_bytes: <<_long, long>>
  pass:[/**] @property points_memory Total amount of memory used for points across all shards assigned to selected nodes. */
  points_memory?: <<ByteSize>>
  pass:[/**] @property points_memory_in_bytes Total amount, in bytes, of memory used for points across all shards assigned to selected nodes. */
  points_memory_in_bytes: <<_long, long>>
  stored_memory?: <<ByteSize>>
  pass:[/**] @property stored_fields_memory_in_bytes Total amount, in bytes, of memory used for stored fields across all shards assigned to selected nodes. */
  stored_fields_memory_in_bytes: <<_long, long>>
  pass:[/**] @property terms_memory_in_bytes Total amount, in bytes, of memory used for terms across all shards assigned to selected nodes. */
  terms_memory_in_bytes: <<_long, long>>
  pass:[/**] @property terms_memory Total amount of memory used for terms across all shards assigned to selected nodes. */
  terms_memory?: <<ByteSize>>
  pass:[/**] @property term_vectory_memory Total amount of memory used for term vectors across all shards assigned to selected nodes. */
  term_vectory_memory?: <<ByteSize>>
  pass:[/**] @property term_vectors_memory_in_bytes Total amount, in bytes, of memory used for term vectors across all shards assigned to selected nodes. */
  term_vectors_memory_in_bytes: <<_long, long>>
  pass:[/**] @property version_map_memory Total amount of memory used by all version maps across all shards assigned to selected nodes. */
  version_map_memory?: <<ByteSize>>
  pass:[/**] @property version_map_memory_in_bytes Total amount, in bytes, of memory used by all version maps across all shards assigned to selected nodes. */
  version_map_memory_in_bytes: <<_long, long>>
}
[pass]
++++
</pre>
++++

[discrete]
=== SequenceNumber

[pass]
++++
<pre>
++++
type SequenceNumber = <<_long, long>>
[pass]
++++
</pre>
++++

[discrete]
=== Service

[pass]
++++
<pre>
++++
type Service = string
[pass]
++++
</pre>
++++

[discrete]
=== ShardFailure

[pass]
++++
<pre>
++++
interface ShardFailure {
  index?: <<IndexName>>
  node?: string
  reason: <<ErrorCause>>
  shard: <<_integer, integer>>
  status?: string
}
[pass]
++++
</pre>
++++

[discrete]
=== ShardStatistics

[pass]
++++
<pre>
++++
interface ShardStatistics {
  failed: <<_uint, uint>>
  pass:[/**] @property successful Indicates how many shards have successfully run the search. */
  successful: <<_uint, uint>>
  pass:[/**] @property total Indicates how many shards the search will run on overall. */
  total: <<_uint, uint>>
  failures?: <<ShardFailure>>[]
  skipped?: <<_uint, uint>>
}
[pass]
++++
</pre>
++++

[discrete]
=== ShardsOperationResponseBase

[pass]
++++
<pre>
++++
interface ShardsOperationResponseBase {
  _shards?: <<ShardStatistics>>
}
[pass]
++++
</pre>
++++

[discrete]
=== SlicedScroll

[pass]
++++
<pre>
++++
interface SlicedScroll {
  field?: <<Field>>
  id: <<Id>>
  max: <<_integer, integer>>
}
[pass]
++++
</pre>
++++

[discrete]
=== Slices

[pass]
++++
<pre>
++++
type Slices = <<_integer, integer>> | <<SlicesCalculation>>
[pass]
++++
</pre>
++++

[discrete]
=== SlicesCalculation

[pass]
++++
<pre>
++++
type SlicesCalculation = 'auto'
[pass]
++++
</pre>
++++

[discrete]
=== Sort

[pass]
++++
<pre>
++++
type Sort = <<SortCombinations>> | <<SortCombinations>>[]
[pass]
++++
</pre>
++++

[discrete]
=== SortCombinations

[pass]
++++
<pre>
++++
type SortCombinations = <<Field>> | <<SortOptions>>
[pass]
++++
</pre>
++++

[discrete]
=== SortMode

[pass]
++++
<pre>
++++
type SortMode = 'min' | 'max' | 'sum' | 'avg' | 'median'
[pass]
++++
</pre>
++++

[discrete]
=== SortOptions

[pass]
++++
<pre>
++++
interface SortOptionsKeys {
  _score?: <<ScoreSort>>
  _doc?: <<ScoreSort>>
  _geo_distance?: <<GeoDistanceSort>>
  _script?: <<ScriptSort>>
}
type SortOptions = SortOptionsKeys
  & { [property: string]: <<FieldSort>> | <<SortOrder>> | <<ScoreSort>> | <<GeoDistanceSort>> | <<ScriptSort>> }
[pass]
++++
</pre>
++++

[discrete]
=== SortOrder

[pass]
++++
<pre>
++++
type SortOrder = 'asc' | 'desc'
[pass]
++++
</pre>
++++

[discrete]
=== SortResults

[pass]
++++
<pre>
++++
type SortResults = <<FieldValue>>[]
[pass]
++++
</pre>
++++

[discrete]
=== StandardRetriever

[pass]
++++
<pre>
++++
interface StandardRetriever extends <<RetrieverBase>> {
  pass:[/**] @property query Defines a query to retrieve a set of top documents. */
  query?: QueryDslQueryContainer
  pass:[/**] @property search_after Defines a search after object parameter used for pagination. */
  search_after?: <<SortResults>>
  pass:[/**] @property terminate_after Maximum number of documents to collect for each shard. */
  terminate_after?: <<_integer, integer>>
  pass:[/**] @property sort A sort object that that specifies the order of matching documents. */
  sort?: <<Sort>>
  pass:[/**] @property collapse Collapses the top documents by a specified key into a single top document per key. */
  collapse?: SearchFieldCollapse
}
[pass]
++++
</pre>
++++

[discrete]
=== StoreStats

[pass]
++++
<pre>
++++
interface StoreStats {
  pass:[/**] @property size Total size of all shards assigned to selected nodes. */
  size?: <<ByteSize>>
  pass:[/**] @property size_in_bytes Total size, in bytes, of all shards assigned to selected nodes. */
  size_in_bytes: <<_long, long>>
  pass:[/**] @property reserved A prediction of how much larger the shard stores will eventually grow due to ongoing peer recoveries, restoring snapshots, and similar activities. */
  reserved?: <<ByteSize>>
  pass:[/**] @property reserved_in_bytes A prediction, in bytes, of how much larger the shard stores will eventually grow due to ongoing peer recoveries, restoring snapshots, and similar activities. */
  reserved_in_bytes: <<_long, long>>
  pass:[/**] @property total_data_set_size Total data set size of all shards assigned to selected nodes. This includes the size of shards not stored fully on the nodes, such as the cache for partially mounted indices. */
  total_data_set_size?: <<ByteSize>>
  pass:[/**] @property total_data_set_size_in_bytes Total data set size, in bytes, of all shards assigned to selected nodes. This includes the size of shards not stored fully on the nodes, such as the cache for partially mounted indices. */
  total_data_set_size_in_bytes?: <<_long, long>>
}
[pass]
++++
</pre>
++++

[discrete]
=== StoredScript

[pass]
++++
<pre>
++++
interface StoredScript {
  pass:[/**] @property lang Specifies the language the script is written in. */
  lang: <<ScriptLanguage>>
  options?: Record<string, string>
  pass:[/**] @property source The script source. */
  source: string
}
[pass]
++++
</pre>
++++

[discrete]
=== SuggestMode

[pass]
++++
<pre>
++++
type SuggestMode = 'missing' | 'popular' | 'always'
[pass]
++++
</pre>
++++

[discrete]
=== SuggestionName

[pass]
++++
<pre>
++++
type SuggestionName = string
[pass]
++++
</pre>
++++

[discrete]
=== TaskFailure

[pass]
++++
<pre>
++++
interface TaskFailure {
  task_id: <<_long, long>>
  node_id: <<NodeId>>
  status: string
  reason: <<ErrorCause>>
}
[pass]
++++
</pre>
++++

[discrete]
=== TaskId

[pass]
++++
<pre>
++++
type TaskId = string | <<_integer, integer>>
[pass]
++++
</pre>
++++

[discrete]
=== TextEmbedding

[pass]
++++
<pre>
++++
interface TextEmbedding {
  model_id: string
  model_text: string
}
[pass]
++++
</pre>
++++

[discrete]
=== TextSimilarityReranker

[pass]
++++
<pre>
++++
interface TextSimilarityReranker extends <<RetrieverBase>> {
  pass:[/**] @property retriever The nested retriever which will produce the first-level results, that will later be used for reranking. */
  retriever: <<RetrieverContainer>>
  pass:[/**] @property rank_window_size This value determines how many documents we will consider from the nested retriever. */
  rank_window_size?: <<_integer, integer>>
  pass:[/**] @property inference_id Unique identifier of the inference endpoint created using the inference API. */
  inference_id?: string
  pass:[/**] @property inference_text The text snippet used as the basis for similarity comparison */
  inference_text?: string
  pass:[/**] @property field The document field to be used for text similarity comparisons. This field should contain the text that will be evaluated against the inference_text */
  field?: string
}
[pass]
++++
</pre>
++++

[discrete]
=== ThreadType

[pass]
++++
<pre>
++++
type ThreadType = 'cpu' | 'wait' | 'block' | 'gpu' | 'mem'
[pass]
++++
</pre>
++++

[discrete]
=== TimeOfDay

[pass]
++++
<pre>
++++
type TimeOfDay = string
[pass]
++++
</pre>
++++

[discrete]
=== TimeUnit

[pass]
++++
<pre>
++++
type TimeUnit = 'nanos' | 'micros' | 'ms' | 's' | 'm' | 'h' | 'd'
[pass]
++++
</pre>
++++

[discrete]
=== TimeZone

[pass]
++++
<pre>
++++
type TimeZone = string
[pass]
++++
</pre>
++++

[discrete]
=== TopLeftBottomRightGeoBounds

[pass]
++++
<pre>
++++
interface TopLeftBottomRightGeoBounds {
  top_left: <<GeoLocation>>
  bottom_right: <<GeoLocation>>
}
[pass]
++++
</pre>
++++

[discrete]
=== TopRightBottomLeftGeoBounds

[pass]
++++
<pre>
++++
interface TopRightBottomLeftGeoBounds {
  top_right: <<GeoLocation>>
  bottom_left: <<GeoLocation>>
}
[pass]
++++
</pre>
++++

[discrete]
=== TransformContainer

[pass]
++++
<pre>
++++
interface TransformContainer {
  chain?: <<TransformContainer>>[]
  script?: <<ScriptTransform>>
  search?: <<SearchTransform>>
}
[pass]
++++
</pre>
++++

[discrete]
=== TranslogStats

[pass]
++++
<pre>
++++
interface TranslogStats {
  earliest_last_modified_age: <<_long, long>>
  operations: <<_long, long>>
  size?: string
  size_in_bytes: <<_long, long>>
  uncommitted_operations: <<_integer, integer>>
  uncommitted_size?: string
  uncommitted_size_in_bytes: <<_long, long>>
}
[pass]
++++
</pre>
++++

[discrete]
=== TransportAddress

[pass]
++++
<pre>
++++
type TransportAddress = string
[pass]
++++
</pre>
++++

[discrete]
=== UnitFloatMillis

[pass]
++++
<pre>
++++
type UnitFloatMillis = <<_double, double>>
[pass]
++++
</pre>
++++

[discrete]
=== UnitMillis

[pass]
++++
<pre>
++++
type UnitMillis = <<_long, long>>
[pass]
++++
</pre>
++++

[discrete]
=== UnitNanos

[pass]
++++
<pre>
++++
type UnitNanos = <<_long, long>>
[pass]
++++
</pre>
++++

[discrete]
=== UnitSeconds

[pass]
++++
<pre>
++++
type UnitSeconds = <<_long, long>>
[pass]
++++
</pre>
++++

[discrete]
=== Username

[pass]
++++
<pre>
++++
type Username = string
[pass]
++++
</pre>
++++

[discrete]
=== Uuid

[pass]
++++
<pre>
++++
type Uuid = string
[pass]
++++
</pre>
++++

[discrete]
=== VersionNumber

[pass]
++++
<pre>
++++
type VersionNumber = <<_long, long>>
[pass]
++++
</pre>
++++

[discrete]
=== VersionString

[pass]
++++
<pre>
++++
type VersionString = string
[pass]
++++
</pre>
++++

[discrete]
=== VersionType

[pass]
++++
<pre>
++++
type VersionType = 'internal' | 'external' | 'external_gte' | 'force'
[pass]
++++
</pre>
++++

[discrete]
=== WaitForActiveShardOptions

[pass]
++++
<pre>
++++
type WaitForActiveShardOptions = 'all' | 'index-setting'
[pass]
++++
</pre>
++++

[discrete]
=== WaitForActiveShards

[pass]
++++
<pre>
++++
type WaitForActiveShards = <<_integer, integer>> | <<WaitForActiveShardOptions>>
[pass]
++++
</pre>
++++

[discrete]
=== WaitForEvents

[pass]
++++
<pre>
++++
type WaitForEvents = 'immediate' | 'urgent' | 'high' | 'normal' | 'low' | 'languid'
[pass]
++++
</pre>
++++

[discrete]
=== WarmerStats

[pass]
++++
<pre>
++++
interface WarmerStats {
  current: <<_long, long>>
  total: <<_long, long>>
  total_time?: <<Duration>>
  total_time_in_millis: <<DurationValue>><<<UnitMillis>>>
}
[pass]
++++
</pre>
++++

[discrete]
=== WktGeoBounds

[pass]
++++
<pre>
++++
interface WktGeoBounds {
  wkt: string
}
[pass]
++++
</pre>
++++

[discrete]
=== WriteResponseBase

[pass]
++++
<pre>
++++
interface WriteResponseBase {
  _id: <<Id>>
  _index: <<IndexName>>
  _primary_term?: <<_long, long>>
  result: <<Result>>
  _seq_no?: <<SequenceNumber>>
  _shards: <<ShardStatistics>>
  _version: <<VersionNumber>>
  forced_refresh?: boolean
}
[pass]
++++
</pre>
++++

[discrete]
=== byte

[pass]
++++
<pre>
++++
type byte = number
[pass]
++++
</pre>
++++

[discrete]
=== double

[pass]
++++
<pre>
++++
type double = number
[pass]
++++
</pre>
++++

[discrete]
=== float

[pass]
++++
<pre>
++++
type float = number
[pass]
++++
</pre>
++++

[discrete]
=== integer

[pass]
++++
<pre>
++++
type integer = number
[pass]
++++
</pre>
++++

[discrete]
=== long

[pass]
++++
<pre>
++++
type long = number
[pass]
++++
</pre>
++++

[discrete]
=== short

[pass]
++++
<pre>
++++
type short = number
[pass]
++++
</pre>
++++

[discrete]
=== uint

[pass]
++++
<pre>
++++
type uint = number
[pass]
++++
</pre>
++++

[discrete]
=== ulong

[pass]
++++
<pre>
++++
type ulong = number
[pass]
++++
</pre>
++++

[discrete]
=== SpecUtilsBaseNode

[pass]
++++
<pre>
++++
interface SpecUtilsBaseNode {
  attributes: Record<string, string>
  host: <<Host>>
  ip: <<Ip>>
  name: <<Name>>
  roles?: <<NodeRoles>>
  transport_address: <<TransportAddress>>
}
[pass]
++++
</pre>
++++

[discrete]
=== SpecUtilsNullValue

[pass]
++++
<pre>
++++
type SpecUtilsNullValue = null
[pass]
++++
</pre>
++++

[discrete]
=== SpecUtilsPipeSeparatedFlags

[pass]
++++
<pre>
++++
type SpecUtilsPipeSeparatedFlags<T = unknown> = T | string
[pass]
++++
</pre>
++++

[discrete]
=== SpecUtilsStringified

[pass]
++++
<pre>
++++
type SpecUtilsStringified<T = unknown> = T | string
[pass]
++++
</pre>
++++

[discrete]
=== SpecUtilsVoid

[pass]
++++
<pre>
++++

[pass]
++++
</pre>
++++

[discrete]
=== SpecUtilsWithNullValue

[pass]
++++
<pre>
++++
type SpecUtilsWithNullValue<T = unknown> = T | <<SpecUtilsNullValue>>
[pass]
++++
</pre>
++++

[discrete]
=== SpecUtilsAdditionalProperties

[pass]
++++
<pre>
++++
interface SpecUtilsAdditionalProperties<TKey = unknown, TValue = unknown> {
}
[pass]
++++
</pre>
++++

[discrete]
=== SpecUtilsAdditionalProperty

[pass]
++++
<pre>
++++
interface SpecUtilsAdditionalProperty<TKey = unknown, TValue = unknown> {
}
[pass]
++++
</pre>
++++

[discrete]
=== SpecUtilsCommonQueryParameters

[pass]
++++
<pre>
++++
interface SpecUtilsCommonQueryParameters {
  pass:[/**] @property error_trace When set to `true` Elasticsearch will include the full stack trace of errors when they occur. */
  error_trace?: boolean
  pass:[/**] @property filter_path Comma-separated list of filters in dot notation which reduce the response returned by Elasticsearch. */
  filter_path?: string | string[]
  pass:[/**] @property human When set to `true` will return statistics in a format suitable for humans. For example `"exists_time": "1h"` for humans and `"eixsts_time_in_millis": 3600000` for computers. When disabled the human readable values will be omitted. This makes sense for responses being consumed only by machines. */
  human?: boolean
  pass:[/**] @property pretty If set to `true` the returned JSON will be "pretty-formatted". Only use this option for debugging only. */
  pretty?: boolean
}
[pass]
++++
</pre>
++++

[discrete]
=== SpecUtilsCommonCatQueryParameters

[pass]
++++
<pre>
++++
interface SpecUtilsCommonCatQueryParameters {
  pass:[/**] @property format Specifies the format to return the columnar data in, can be set to `text`, `json`, `cbor`, `yaml`, or `smile`. */
  format?: string
  pass:[/**] @property h List of columns to appear in the response. Supports simple wildcards. */
  h?: <<Names>>
  pass:[/**] @property help When set to `true` will output available columns. This option can't be combined with any other query string option. */
  help?: boolean
  pass:[/**] @property local If `true`, the request computes the list of selected nodes from the local cluster state. If `false` the list of selected nodes are computed from the cluster state of the master node. In both cases the coordinating node will send requests for further information to each selected node. */
  local?: boolean
  pass:[/**] @property master_timeout Period to wait for a connection to the master node. */
  master_timeout?: <<Duration>>
  pass:[/**] @property s List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: <<Names>>
  pass:[/**] @property v When set to `true` will enable verbose output. */
  v?: boolean
}
[pass]
++++
</pre>
++++

[discrete]
=== SpecUtilsOverloadOf

[pass]
++++
<pre>
++++
interface SpecUtilsOverloadOf<TDefinition = unknown> {
}
[pass]
++++
</pre>
++++
