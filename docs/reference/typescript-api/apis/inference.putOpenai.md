# Client.inference.putOpenai

Create an OpenAI inference endpoint. Create an inference endpoint to perform an inference task with the `openai` service or `openai` compatible APIs.

## Method Signature

```typescript
client.inference.putOpenai(this: That, params: T.InferencePutOpenaiRequest, options?: TransportRequestOptionsWithOutMeta): Promise<T.InferencePutOpenaiResponse>
```

### Parameters

| Parameter | Type | Description |
|-----------|------|-------------|
| `this` | `That` | - |
| `params` | [`InferencePutOpenaiRequest`](../types/InferencePutOpenaiRequest.md) | - |
| `options?` | `TransportRequestOptionsWithOutMeta` | - |

### Returns

`Promise<T.InferencePutOpenaiResponse>`

## See Also

- [Client](../client.md)
- [All APIs](../index.md)
