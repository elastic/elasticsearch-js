[[reference-shared-types-global-search-types]]

=== `Search` types

////////
===========================================================================================================================
||                                                                                                                       ||
||                                                                                                                       ||
||                                                                                                                       ||
||        ██████╗ ███████╗ █████╗ ██████╗ ███╗   ███╗███████╗                                                            ||
||        ██╔══██╗██╔════╝██╔══██╗██╔══██╗████╗ ████║██╔════╝                                                            ||
||        ██████╔╝█████╗  ███████║██║  ██║██╔████╔██║█████╗                                                              ||
||        ██╔══██╗██╔══╝  ██╔══██║██║  ██║██║╚██╔╝██║██╔══╝                                                              ||
||        ██║  ██║███████╗██║  ██║██████╔╝██║ ╚═╝ ██║███████╗                                                            ||
||        ╚═╝  ╚═╝╚══════╝╚═╝  ╚═╝╚═════╝ ╚═╝     ╚═╝╚══════╝                                                            ||
||                                                                                                                       ||
||                                                                                                                       ||
||    This file is autogenerated, DO NOT send pull requests that changes this file directly.                             ||
||    You should update the script that does the generation, which can be found in:                                      ||
||    https://github.com/elastic/elastic-client-generator-js                                                             ||
||                                                                                                                       ||
||    You can run the script with the following command:                                                                 ||
||       npm run elasticsearch -- --version <version>                                                                    ||
||                                                                                                                       ||
||                                                                                                                       ||
||                                                                                                                       ||
===========================================================================================================================
////////
++++
<style>
.lang-ts a.xref {
  text-decoration: underline !important;
}
</style>
++++


[discrete]
[[SearchAggregationBreakdown]]
=== SearchAggregationBreakdown

[source,ts,subs=+macros]
----
interface SearchAggregationBreakdown {
  build_aggregation: <<long>>
  build_aggregation_count: <<long>>
  build_leaf_collector: <<long>>
  build_leaf_collector_count: <<long>>
  collect: <<long>>
  collect_count: <<long>>
  initialize: <<long>>
  initialize_count: <<long>>
  post_collection?: <<long>>
  post_collection_count?: <<long>>
  reduce: <<long>>
  reduce_count: <<long>>
}
----


[discrete]
[[SearchAggregationProfile]]
=== SearchAggregationProfile

[source,ts,subs=+macros]
----
interface SearchAggregationProfile {
  breakdown: <<SearchAggregationBreakdown>>
  description: string
  time_in_nanos: <<DurationValue>><<<UnitNanos>>>
  type: string
  debug?: <<SearchAggregationProfileDebug>>
  children?: <<SearchAggregationProfile>>[]
}
----


[discrete]
[[SearchAggregationProfileDebug]]
=== SearchAggregationProfileDebug

[source,ts,subs=+macros]
----
interface SearchAggregationProfileDebug {
  segments_with_multi_valued_ords?: <<integer>>
  collection_strategy?: string
  segments_with_single_valued_ords?: <<integer>>
  total_buckets?: <<integer>>
  built_buckets?: <<integer>>
  result_strategy?: string
  has_filter?: boolean
  delegate?: string
  delegate_debug?: <<SearchAggregationProfileDebug>>
  chars_fetched?: <<integer>>
  extract_count?: <<integer>>
  extract_ns?: <<integer>>
  values_fetched?: <<integer>>
  collect_analyzed_ns?: <<integer>>
  collect_analyzed_count?: <<integer>>
  surviving_buckets?: <<integer>>
  ordinals_collectors_used?: <<integer>>
  ordinals_collectors_overhead_too_high?: <<integer>>
  string_hashing_collectors_used?: <<integer>>
  numeric_collectors_used?: <<integer>>
  empty_collectors_used?: <<integer>>
  deferred_aggregators?: string[]
  segments_with_doc_count_field?: <<integer>>
  segments_with_deleted_docs?: <<integer>>
  filters?: <<SearchAggregationProfileDelegateDebugFilter>>[]
  segments_counted?: <<integer>>
  segments_collected?: <<integer>>
  map_reducer?: string
  brute_force_used?: <<integer>>
  dynamic_pruning_attempted?: <<integer>>
  dynamic_pruning_used?: <<integer>>
  skipped_due_to_no_data?: <<integer>>
}
----


[discrete]
[[SearchAggregationProfileDelegateDebugFilter]]
=== SearchAggregationProfileDelegateDebugFilter

[source,ts,subs=+macros]
----
interface SearchAggregationProfileDelegateDebugFilter {
  results_from_metadata?: <<integer>>
  query?: string
  specialized_for?: string
  segments_counted_in_constant_time?: <<integer>>
}
----


[discrete]
[[SearchBoundaryScanner]]
=== SearchBoundaryScanner

[source,ts,subs=+macros]
----
type SearchBoundaryScanner = 'chars' | 'sentence' | 'word'
----


[discrete]
[[SearchCollector]]
=== SearchCollector

[source,ts,subs=+macros]
----
interface SearchCollector {
  name: string
  reason: string
  time_in_nanos: <<DurationValue>><<<UnitNanos>>>
  children?: <<SearchCollector>>[]
}
----


[discrete]
[[SearchCompletionContext]]
=== SearchCompletionContext

[source,ts,subs=+macros]
----
interface SearchCompletionContext {
  pass:[/**] @property boost The factor by which the score of the suggestion should be boosted. The score is computed by multiplying the boost with the suggestion weight. */
  boost?: <<double>>
  pass:[/**] @property context The value of the category to filter/boost on. */
  context: <<SearchContext>>
  pass:[/**] @property neighbours An array of precision values at which neighboring geohashes should be taken into account. Precision value can be a distance value (`5m`, `10km`, etc.) or a raw geohash precision (`1`..`12`). Defaults to generating neighbors for index time precision level. */
  neighbours?: <<GeoHashPrecision>>[]
  pass:[/**] @property precision The precision of the geohash to encode the query geo point. Can be specified as a distance value (`5m`, `10km`, etc.), or as a raw geohash precision (`1`..`12`). Defaults to index time precision level. */
  precision?: <<GeoHashPrecision>>
  pass:[/**] @property prefix Whether the category value should be treated as a prefix or not. */
  prefix?: boolean
}
----


[discrete]
[[SearchCompletionSuggest]]
=== SearchCompletionSuggest

[source,ts,subs=+macros]
----
interface SearchCompletionSuggest<TDocument = unknown> extends <<SearchSuggestBase>> {
  options: <<SearchCompletionSuggestOption>><TDocument> | <<SearchCompletionSuggestOption>><TDocument>[]
}
----


[discrete]
[[SearchCompletionSuggestOption]]
=== SearchCompletionSuggestOption

[source,ts,subs=+macros]
----
interface SearchCompletionSuggestOption<TDocument = unknown> {
  collate_match?: boolean
  contexts?: Record<string, <<SearchContext>>[]>
  fields?: Record<string, any>
  _id?: string
  _index?: <<IndexName>>
  _routing?: <<Routing>>
  _score?: <<double>>
  _source?: TDocument
  text: string
  score?: <<double>>
}
----


[discrete]
[[SearchCompletionSuggester]]
=== SearchCompletionSuggester

[source,ts,subs=+macros]
----
interface SearchCompletionSuggester extends <<SearchSuggesterBase>> {
  pass:[/**] @property contexts A value, geo point object, or a geo hash string to filter or boost the suggestion on. */
  contexts?: Record<<<Field>>, <<SearchCompletionContext>> | <<SearchContext>> | (<<SearchCompletionContext>> | <<SearchContext>>)[]>
  pass:[/**] @property fuzzy Enables fuzziness, meaning you can have a typo in your search and still get results back. */
  fuzzy?: <<SearchSuggestFuzziness>>
  pass:[/**] @property regex A regex query that expresses a prefix as a regular expression. */
  regex?: <<SearchRegexOptions>>
  pass:[/**] @property skip_duplicates Whether duplicate suggestions should be filtered out. */
  skip_duplicates?: boolean
}
----


[discrete]
[[SearchContext]]
=== SearchContext

[source,ts,subs=+macros]
----
type SearchContext = string | <<GeoLocation>>
----


[discrete]
[[SearchDfsKnnProfile]]
=== SearchDfsKnnProfile

[source,ts,subs=+macros]
----
interface SearchDfsKnnProfile {
  vector_operations_count?: <<long>>
  query: <<SearchKnnQueryProfileResult>>[]
  rewrite_time: <<long>>
  collector: <<SearchKnnCollectorResult>>[]
}
----


[discrete]
[[SearchDfsProfile]]
=== SearchDfsProfile

[source,ts,subs=+macros]
----
interface SearchDfsProfile {
  statistics?: <<SearchDfsStatisticsProfile>>
  knn?: <<SearchDfsKnnProfile>>[]
}
----


[discrete]
[[SearchDfsStatisticsBreakdown]]
=== SearchDfsStatisticsBreakdown

[source,ts,subs=+macros]
----
interface SearchDfsStatisticsBreakdown {
  collection_statistics: <<long>>
  collection_statistics_count: <<long>>
  create_weight: <<long>>
  create_weight_count: <<long>>
  rewrite: <<long>>
  rewrite_count: <<long>>
  term_statistics: <<long>>
  term_statistics_count: <<long>>
}
----


[discrete]
[[SearchDfsStatisticsProfile]]
=== SearchDfsStatisticsProfile

[source,ts,subs=+macros]
----
interface SearchDfsStatisticsProfile {
  type: string
  description: string
  time?: <<Duration>>
  time_in_nanos: <<DurationValue>><<<UnitNanos>>>
  breakdown: <<SearchDfsStatisticsBreakdown>>
  debug?: Record<string, any>
  children?: <<SearchDfsStatisticsProfile>>[]
}
----


[discrete]
[[SearchDirectGenerator]]
=== SearchDirectGenerator

[source,ts,subs=+macros]
----
interface SearchDirectGenerator {
  pass:[/**] @property field The field to fetch the candidate suggestions from. Needs to be set globally or per suggestion. */
  field: <<Field>>
  pass:[/**] @property max_edits The maximum edit distance candidate suggestions can have in order to be considered as a suggestion. Can only be `1` or `2`. */
  max_edits?: <<integer>>
  pass:[/**] @property max_inspections A factor that is used to multiply with the shard_size in order to inspect more candidate spelling corrections on the shard level. Can improve accuracy at the cost of performance. */
  max_inspections?: <<float>>
  pass:[/**] @property max_term_freq The maximum threshold in number of documents in which a suggest text token can exist in order to be included. This can be used to exclude high frequency terms — which are usually spelled correctly — from being spellchecked. Can be a relative percentage number (for example `0.4`) or an absolute number to represent document frequencies. If a value higher than 1 is specified, then fractional can not be specified. */
  max_term_freq?: <<float>>
  pass:[/**] @property min_doc_freq The minimal threshold in number of documents a suggestion should appear in. This can improve quality by only suggesting high frequency terms. Can be specified as an absolute number or as a relative percentage of number of documents. If a value higher than 1 is specified, the number cannot be fractional. */
  min_doc_freq?: <<float>>
  pass:[/**] @property min_word_length The minimum length a suggest text term must have in order to be included. */
  min_word_length?: <<integer>>
  pass:[/**] @property post_filter A filter (analyzer) that is applied to each of the generated tokens before they are passed to the actual phrase scorer. */
  post_filter?: string
  pass:[/**] @property pre_filter A filter (analyzer) that is applied to each of the tokens passed to this candidate generator. This filter is applied to the original token before candidates are generated. */
  pre_filter?: string
  pass:[/**] @property prefix_length The number of minimal prefix characters that must match in order be a candidate suggestions. Increasing this number improves spellcheck performance. */
  prefix_length?: <<integer>>
  pass:[/**] @property size The maximum corrections to be returned per suggest text token. */
  size?: <<integer>>
  pass:[/**] @property suggest_mode Controls what suggestions are included on the suggestions generated on each shard. */
  suggest_mode?: <<SuggestMode>>
}
----


[discrete]
[[SearchFetchProfile]]
=== SearchFetchProfile

[source,ts,subs=+macros]
----
interface SearchFetchProfile {
  type: string
  description: string
  time_in_nanos: <<DurationValue>><<<UnitNanos>>>
  breakdown: <<SearchFetchProfileBreakdown>>
  debug?: <<SearchFetchProfileDebug>>
  children?: <<SearchFetchProfile>>[]
}
----


[discrete]
[[SearchFetchProfileBreakdown]]
=== SearchFetchProfileBreakdown

[source,ts,subs=+macros]
----
interface SearchFetchProfileBreakdown {
  load_source?: <<integer>>
  load_source_count?: <<integer>>
  load_stored_fields?: <<integer>>
  load_stored_fields_count?: <<integer>>
  next_reader?: <<integer>>
  next_reader_count?: <<integer>>
  process_count?: <<integer>>
  process?: <<integer>>
}
----


[discrete]
[[SearchFetchProfileDebug]]
=== SearchFetchProfileDebug

[source,ts,subs=+macros]
----
interface SearchFetchProfileDebug {
  stored_fields?: string[]
  fast_path?: <<integer>>
}
----


[discrete]
[[SearchFieldCollapse]]
=== SearchFieldCollapse

[source,ts,subs=+macros]
----
interface SearchFieldCollapse {
  pass:[/**] @property field The field to collapse the result set on */
  field: <<Field>>
  pass:[/**] @property inner_hits The number of inner hits and their sort order */
  inner_hits?: <<SearchInnerHits>> | <<SearchInnerHits>>[]
  pass:[/**] @property max_concurrent_group_searches The number of concurrent requests allowed to retrieve the inner_hits per group */
  max_concurrent_group_searches?: <<integer>>
  collapse?: <<SearchFieldCollapse>>
}
----


[discrete]
[[SearchFieldSuggester]]
=== SearchFieldSuggester

[source,ts,subs=+macros]
----
interface SearchFieldSuggester {
  pass:[/**] @property completion Provides auto-complete/search-as-you-type functionality. */
  completion?: <<SearchCompletionSuggester>>
  pass:[/**] @property phrase Provides access to word alternatives on a per token basis within a certain string distance. */
  phrase?: <<SearchPhraseSuggester>>
  pass:[/**] @property term Suggests terms based on edit distance. */
  term?: <<SearchTermSuggester>>
  pass:[/**] @property prefix Prefix used to search for suggestions. */
  prefix?: string
  pass:[/**] @property regex A prefix expressed as a regular expression. */
  regex?: string
  pass:[/**] @property text The text to use as input for the suggester. Needs to be set globally or per suggestion. */
  text?: string
}
----


[discrete]
[[SearchHighlight]]
=== SearchHighlight

[source,ts,subs=+macros]
----
interface SearchHighlight extends <<SearchHighlightBase>> {
  encoder?: <<SearchHighlighterEncoder>>
  fields: Record<<<Field>>, <<SearchHighlightField>>>
}
----


[discrete]
[[SearchHighlightBase]]
=== SearchHighlightBase

[source,ts,subs=+macros]
----
interface SearchHighlightBase {
  type?: <<SearchHighlighterType>>
  pass:[/**] @property boundary_chars A string that contains each boundary character. */
  boundary_chars?: string
  pass:[/**] @property boundary_max_scan How far to scan for boundary characters. */
  boundary_max_scan?: <<integer>>
  pass:[/**] @property boundary_scanner Specifies how to break the highlighted fragments: chars, sentence, or word. Only valid for the unified and fvh highlighters. Defaults to `sentence` for the `unified` highlighter. Defaults to `chars` for the `fvh` highlighter. */
  boundary_scanner?: <<SearchBoundaryScanner>>
  pass:[/**] @property boundary_scanner_locale Controls which locale is used to search for sentence and word boundaries. This parameter takes a form of a language tag, for example: `"en-US"`, `"fr-FR"`, `"ja-JP"`. */
  boundary_scanner_locale?: string
  force_source?: boolean
  pass:[/**] @property fragmenter Specifies how text should be broken up in highlight snippets: `simple` or `span`. Only valid for the `plain` highlighter. */
  fragmenter?: <<SearchHighlighterFragmenter>>
  pass:[/**] @property fragment_size The size of the highlighted fragment in characters. */
  fragment_size?: <<integer>>
  highlight_filter?: boolean
  pass:[/**] @property highlight_query Highlight matches for a query other than the search query. This is especially useful if you use a rescore query because those are not taken into account by highlighting by default. */
  highlight_query?: <<QueryDslQueryContainer>>
  max_fragment_length?: <<integer>>
  pass:[/**] @property max_analyzed_offset If set to a non-negative value, highlighting stops at this defined maximum limit. The rest of the text is not processed, thus not highlighted and no error is returned The `max_analyzed_offset` query setting does not override the `index.highlight.max_analyzed_offset` setting, which prevails when it’s set to lower value than the query setting. */
  max_analyzed_offset?: <<integer>>
  pass:[/**] @property no_match_size The amount of text you want to return from the beginning of the field if there are no matching fragments to highlight. */
  no_match_size?: <<integer>>
  pass:[/**] @property number_of_fragments The maximum number of fragments to return. If the number of fragments is set to `0`, no fragments are returned. Instead, the entire field contents are highlighted and returned. This can be handy when you need to highlight <<short>> texts such as a title or address, but fragmentation is not required. If `number_of_fragments` is `0`, `fragment_size` is ignored. */
  number_of_fragments?: <<integer>>
  options?: Record<string, any>
  pass:[/**] @property order Sorts highlighted fragments by score when set to `score`. By default, fragments will be output in the order they appear in the field (order: `none`). Setting this option to `score` will output the most relevant fragments first. Each highlighter applies its own logic to compute relevancy scores. */
  order?: <<SearchHighlighterOrder>>
  pass:[/**] @property phrase_limit Controls the number of matching phrases in a document that are considered. Prevents the `fvh` highlighter from analyzing too many phrases and consuming too much memory. When using `matched_fields`, `phrase_limit` phrases per matched field are considered. Raising the limit increases query time and consumes more memory. Only supported by the `fvh` highlighter. */
  phrase_limit?: <<integer>>
  pass:[/**] @property post_tags Use in conjunction with `pre_tags` to define the HTML tags to use for the highlighted text. By default, highlighted text is wrapped in `<em>` and `</em>` tags. */
  post_tags?: string[]
  pass:[/**] @property pre_tags Use in conjunction with `post_tags` to define the HTML tags to use for the highlighted text. By default, highlighted text is wrapped in `<em>` and `</em>` tags. */
  pre_tags?: string[]
  pass:[/**] @property require_field_match By default, only fields that contains a query match are highlighted. Set to `false` to highlight all fields. */
  require_field_match?: boolean
  pass:[/**] @property tags_schema Set to `styled` to use the built-in tag schema. */
  tags_schema?: <<SearchHighlighterTagsSchema>>
}
----


[discrete]
[[SearchHighlightField]]
=== SearchHighlightField

[source,ts,subs=+macros]
----
interface SearchHighlightField extends <<SearchHighlightBase>> {
  fragment_offset?: <<integer>>
  matched_fields?: <<Fields>>
}
----


[discrete]
[[SearchHighlighterEncoder]]
=== SearchHighlighterEncoder

[source,ts,subs=+macros]
----
type SearchHighlighterEncoder = 'default' | 'html'
----


[discrete]
[[SearchHighlighterFragmenter]]
=== SearchHighlighterFragmenter

[source,ts,subs=+macros]
----
type SearchHighlighterFragmenter = 'simple' | 'span'
----


[discrete]
[[SearchHighlighterOrder]]
=== SearchHighlighterOrder

[source,ts,subs=+macros]
----
type SearchHighlighterOrder = 'score'
----


[discrete]
[[SearchHighlighterTagsSchema]]
=== SearchHighlighterTagsSchema

[source,ts,subs=+macros]
----
type SearchHighlighterTagsSchema = 'styled'
----


[discrete]
[[SearchHighlighterType]]
=== SearchHighlighterType

[source,ts,subs=+macros]
----
type SearchHighlighterType = 'plain' | 'fvh' | 'unified' | string
----


[discrete]
[[SearchHit]]
=== SearchHit

[source,ts,subs=+macros]
----
interface SearchHit<TDocument = unknown> {
  _index: <<IndexName>>
  _id?: <<Id>>
  _score?: <<double>> | null
  _explanation?: <<ExplainExplanation>>
  fields?: Record<string, any>
  highlight?: Record<string, string[]>
  inner_hits?: Record<string, <<SearchInnerHitsResult>>>
  matched_queries?: string[] | Record<string, <<double>>>
  _nested?: <<SearchNestedIdentity>>
  _ignored?: string[]
  ignored_field_values?: Record<string, <<FieldValue>>[]>
  _shard?: string
  _node?: string
  _routing?: string
  _source?: TDocument
  _rank?: <<integer>>
  _seq_no?: <<SequenceNumber>>
  _primary_term?: <<long>>
  _version?: <<VersionNumber>>
  sort?: <<SortResults>>
}
----


[discrete]
[[SearchHitsMetadata]]
=== SearchHitsMetadata

[source,ts,subs=+macros]
----
interface SearchHitsMetadata<T = unknown> {
  pass:[/**] @property total Total hit count information, present only if `track_total_hits` wasn't `false` in the search request. */
  total?: <<SearchTotalHits>> | <<long>>
  hits: <<SearchHit>><T>[]
  max_score?: <<double>> | null
}
----


[discrete]
[[SearchInnerHits]]
=== SearchInnerHits

[source,ts,subs=+macros]
----
interface SearchInnerHits {
  pass:[/**] @property name The name for the particular inner hit definition in the response. Useful when a search request contains multiple inner hits. */
  name?: <<Name>>
  pass:[/**] @property size The maximum number of hits to return per `inner_hits`. */
  size?: <<integer>>
  pass:[/**] @property from Inner hit starting document offset. */
  from?: <<integer>>
  collapse?: <<SearchFieldCollapse>>
  docvalue_fields?: (<<QueryDslFieldAndFormat>> | <<Field>>)[]
  explain?: boolean
  highlight?: <<SearchHighlight>>
  ignore_unmapped?: boolean
  script_fields?: Record<<<Field>>, <<ScriptField>>>
  seq_no_primary_term?: boolean
  fields?: <<Fields>>
  pass:[/**] @property sort How the inner hits should be sorted per `inner_hits`. By default, inner hits are sorted by score. */
  sort?: <<Sort>>
  _source?: <<SearchSourceConfig>>
  stored_fields?: <<Fields>>
  track_scores?: boolean
  version?: boolean
}
----


[discrete]
[[SearchInnerHitsResult]]
=== SearchInnerHitsResult

[source,ts,subs=+macros]
----
interface SearchInnerHitsResult {
  hits: <<SearchHitsMetadata>><any>
}
----


[discrete]
[[SearchKnnCollectorResult]]
=== SearchKnnCollectorResult

[source,ts,subs=+macros]
----
interface SearchKnnCollectorResult {
  name: string
  reason: string
  time?: <<Duration>>
  time_in_nanos: <<DurationValue>><<<UnitNanos>>>
  children?: <<SearchKnnCollectorResult>>[]
}
----


[discrete]
[[SearchKnnQueryProfileBreakdown]]
=== SearchKnnQueryProfileBreakdown

[source,ts,subs=+macros]
----
interface SearchKnnQueryProfileBreakdown {
  advance: <<long>>
  advance_count: <<long>>
  build_scorer: <<long>>
  build_scorer_count: <<long>>
  compute_max_score: <<long>>
  compute_max_score_count: <<long>>
  count_weight: <<long>>
  count_weight_count: <<long>>
  create_weight: <<long>>
  create_weight_count: <<long>>
  match: <<long>>
  match_count: <<long>>
  next_doc: <<long>>
  next_doc_count: <<long>>
  score: <<long>>
  score_count: <<long>>
  set_min_competitive_score: <<long>>
  set_min_competitive_score_count: <<long>>
  shallow_advance: <<long>>
  shallow_advance_count: <<long>>
}
----


[discrete]
[[SearchKnnQueryProfileResult]]
=== SearchKnnQueryProfileResult

[source,ts,subs=+macros]
----
interface SearchKnnQueryProfileResult {
  type: string
  description: string
  time?: <<Duration>>
  time_in_nanos: <<DurationValue>><<<UnitNanos>>>
  breakdown: <<SearchKnnQueryProfileBreakdown>>
  debug?: Record<string, any>
  children?: <<SearchKnnQueryProfileResult>>[]
}
----


[discrete]
[[SearchLaplaceSmoothingModel]]
=== SearchLaplaceSmoothingModel

[source,ts,subs=+macros]
----
interface SearchLaplaceSmoothingModel {
  pass:[/**] @property alpha A constant that is added to all counts to balance weights. */
  alpha: <<double>>
}
----


[discrete]
[[SearchLearningToRank]]
=== SearchLearningToRank

[source,ts,subs=+macros]
----
interface SearchLearningToRank {
  pass:[/**] @property model_id The unique identifier of the trained model uploaded to Elasticsearch */
  model_id: string
  pass:[/**] @property params Named parameters to be passed to the query templates used for feature */
  params?: Record<string, any>
}
----


[discrete]
[[SearchLinearInterpolationSmoothingModel]]
=== SearchLinearInterpolationSmoothingModel

[source,ts,subs=+macros]
----
interface SearchLinearInterpolationSmoothingModel {
  bigram_lambda: <<double>>
  trigram_lambda: <<double>>
  unigram_lambda: <<double>>
}
----


[discrete]
[[SearchNestedIdentity]]
=== SearchNestedIdentity

[source,ts,subs=+macros]
----
interface SearchNestedIdentity {
  field: <<Field>>
  offset: <<integer>>
  _nested?: <<SearchNestedIdentity>>
}
----


[discrete]
[[SearchPhraseSuggest]]
=== SearchPhraseSuggest

[source,ts,subs=+macros]
----
interface SearchPhraseSuggest extends <<SearchSuggestBase>> {
  options: <<SearchPhraseSuggestOption>> | <<SearchPhraseSuggestOption>>[]
}
----


[discrete]
[[SearchPhraseSuggestCollate]]
=== SearchPhraseSuggestCollate

[source,ts,subs=+macros]
----
interface SearchPhraseSuggestCollate {
  pass:[/**] @property params Parameters to use if the query is templated. */
  params?: Record<string, any>
  pass:[/**] @property prune Returns all suggestions with an extra `collate_match` option indicating whether the generated phrase matched any document. */
  prune?: boolean
  pass:[/**] @property query A collate query that is run once for every suggestion. */
  query: <<SearchPhraseSuggestCollateQuery>>
}
----


[discrete]
[[SearchPhraseSuggestCollateQuery]]
=== SearchPhraseSuggestCollateQuery

[source,ts,subs=+macros]
----
interface SearchPhraseSuggestCollateQuery {
  pass:[/**] @property id The search template ID. */
  id?: <<Id>>
  pass:[/**] @property source The query source. */
  source?: string
}
----


[discrete]
[[SearchPhraseSuggestHighlight]]
=== SearchPhraseSuggestHighlight

[source,ts,subs=+macros]
----
interface SearchPhraseSuggestHighlight {
  pass:[/**] @property post_tag Use in conjunction with `pre_tag` to define the HTML tags to use for the highlighted text. */
  post_tag: string
  pass:[/**] @property pre_tag Use in conjunction with `post_tag` to define the HTML tags to use for the highlighted text. */
  pre_tag: string
}
----


[discrete]
[[SearchPhraseSuggestOption]]
=== SearchPhraseSuggestOption

[source,ts,subs=+macros]
----
interface SearchPhraseSuggestOption {
  text: string
  score: <<double>>
  highlighted?: string
  collate_match?: boolean
}
----


[discrete]
[[SearchPhraseSuggester]]
=== SearchPhraseSuggester

[source,ts,subs=+macros]
----
interface SearchPhraseSuggester extends <<SearchSuggesterBase>> {
  pass:[/**] @property collate Checks each suggestion against the specified query to prune suggestions for which no matching docs exist in the index. */
  collate?: <<SearchPhraseSuggestCollate>>
  pass:[/**] @property confidence Defines a factor applied to the input phrases score, which is used as a threshold for other suggest candidates. Only candidates that score higher than the threshold will be included in the result. */
  confidence?: <<double>>
  pass:[/**] @property direct_generator A list of candidate generators that produce a list of possible terms per term in the given text. */
  direct_generator?: <<SearchDirectGenerator>>[]
  force_unigrams?: boolean
  pass:[/**] @property gram_size Sets max size of the n-grams (shingles) in the field. If the field doesn’t contain n-grams (shingles), this should be omitted or set to `1`. If the field uses a shingle filter, the `gram_size` is set to the `max_shingle_size` if not explicitly set. */
  gram_size?: <<integer>>
  pass:[/**] @property highlight Sets up suggestion highlighting. If not provided, no highlighted field is returned. */
  highlight?: <<SearchPhraseSuggestHighlight>>
  pass:[/**] @property max_errors The maximum percentage of the terms considered to be misspellings in order to form a correction. This method accepts a <<float>> value in the range `[0..1)` as a fraction of the actual query terms or a number `>=1` as an absolute number of query terms. */
  max_errors?: <<double>>
  pass:[/**] @property real_word_error_likelihood The likelihood of a term being misspelled even if the term exists in the dictionary. */
  real_word_error_likelihood?: <<double>>
  pass:[/**] @property separator The separator that is used to separate terms in the bigram field. If not set, the whitespace character is used as a separator. */
  separator?: string
  pass:[/**] @property shard_size Sets the maximum number of suggested terms to be retrieved from each individual shard. */
  shard_size?: <<integer>>
  pass:[/**] @property smoothing The smoothing model used to balance weight between infrequent grams (grams (shingles) are not existing in the index) and frequent grams (appear at least once in the index). The default model is Stupid Backoff. */
  smoothing?: <<SearchSmoothingModelContainer>>
  pass:[/**] @property text The text/query to provide suggestions for. */
  text?: string
  token_limit?: <<integer>>
}
----


[discrete]
[[SearchPointInTimeReference]]
=== SearchPointInTimeReference

[source,ts,subs=+macros]
----
interface SearchPointInTimeReference {
  id: <<Id>>
  keep_alive?: <<Duration>>
}
----


[discrete]
[[SearchProfile]]
=== SearchProfile

[source,ts,subs=+macros]
----
interface SearchProfile {
  shards: <<SearchShardProfile>>[]
}
----


[discrete]
[[SearchQueryBreakdown]]
=== SearchQueryBreakdown

[source,ts,subs=+macros]
----
interface SearchQueryBreakdown {
  advance: <<long>>
  advance_count: <<long>>
  build_scorer: <<long>>
  build_scorer_count: <<long>>
  create_weight: <<long>>
  create_weight_count: <<long>>
  match: <<long>>
  match_count: <<long>>
  shallow_advance: <<long>>
  shallow_advance_count: <<long>>
  next_doc: <<long>>
  next_doc_count: <<long>>
  score: <<long>>
  score_count: <<long>>
  compute_max_score: <<long>>
  compute_max_score_count: <<long>>
  count_weight: <<long>>
  count_weight_count: <<long>>
  set_min_competitive_score: <<long>>
  set_min_competitive_score_count: <<long>>
}
----


[discrete]
[[SearchQueryProfile]]
=== SearchQueryProfile

[source,ts,subs=+macros]
----
interface SearchQueryProfile {
  breakdown: <<SearchQueryBreakdown>>
  description: string
  time_in_nanos: <<DurationValue>><<<UnitNanos>>>
  type: string
  children?: <<SearchQueryProfile>>[]
}
----


[discrete]
[[SearchRegexOptions]]
=== SearchRegexOptions

[source,ts,subs=+macros]
----
interface SearchRegexOptions {
  pass:[/**] @property flags Optional operators for the regular expression. */
  flags?: <<integer>> | string
  pass:[/**] @property max_determinized_states Maximum number of automaton states required for the query. */
  max_determinized_states?: <<integer>>
}
----


[discrete]
[[SearchRescore]]
=== SearchRescore

[source,ts,subs=+macros]
----
interface SearchRescore {
  window_size?: <<integer>>
  query?: <<SearchRescoreQuery>>
  learning_to_rank?: <<SearchLearningToRank>>
}
----


[discrete]
[[SearchRescoreQuery]]
=== SearchRescoreQuery

[source,ts,subs=+macros]
----
interface SearchRescoreQuery {
  pass:[/**] @property rescore_query The query to use for rescoring. This query is only run on the Top-K results returned by the `query` and `post_filter` phases. */
  rescore_query: <<QueryDslQueryContainer>>
  pass:[/**] @property query_weight Relative importance of the original query versus the rescore query. */
  query_weight?: <<double>>
  pass:[/**] @property rescore_query_weight Relative importance of the rescore query versus the original query. */
  rescore_query_weight?: <<double>>
  pass:[/**] @property score_mode Determines how scores are combined. */
  score_mode?: <<SearchScoreMode>>
}
----


[discrete]
[[SearchScoreMode]]
=== SearchScoreMode

[source,ts,subs=+macros]
----
type SearchScoreMode = 'avg' | 'max' | 'min' | 'multiply' | 'total'
----


[discrete]
[[SearchSearchProfile]]
=== SearchSearchProfile

[source,ts,subs=+macros]
----
interface SearchSearchProfile {
  collector: <<SearchCollector>>[]
  query: <<SearchQueryProfile>>[]
  rewrite_time: <<long>>
}
----


[discrete]
[[SearchShardProfile]]
=== SearchShardProfile

[source,ts,subs=+macros]
----
interface SearchShardProfile {
  aggregations: <<SearchAggregationProfile>>[]
  cluster: string
  dfs?: <<SearchDfsProfile>>
  fetch?: <<SearchFetchProfile>>
  id: string
  index: <<IndexName>>
  node_id: <<NodeId>>
  searches: <<SearchSearchProfile>>[]
  shard_id: <<long>>
}
----


[discrete]
[[SearchSmoothingModelContainer]]
=== SearchSmoothingModelContainer

[source,ts,subs=+macros]
----
interface SearchSmoothingModelContainer {
  pass:[/**] @property laplace A smoothing model that uses an additive smoothing where a constant (typically `1.0` or smaller) is added to all counts to balance weights. */
  laplace?: <<SearchLaplaceSmoothingModel>>
  pass:[/**] @property linear_interpolation A smoothing model that takes the weighted mean of the unigrams, bigrams, and trigrams based on user supplied weights (lambdas). */
  linear_interpolation?: <<SearchLinearInterpolationSmoothingModel>>
  pass:[/**] @property stupid_backoff A simple backoff model that backs off to lower order n-gram models if the higher order count is `0` and discounts the lower order n-gram model by a constant factor. */
  stupid_backoff?: <<SearchStupidBackoffSmoothingModel>>
}
----


[discrete]
[[SearchSourceConfig]]
=== SearchSourceConfig

[source,ts,subs=+macros]
----
type SearchSourceConfig = boolean | <<SearchSourceFilter>> | <<Fields>>
----


[discrete]
[[SearchSourceConfigParam]]
=== SearchSourceConfigParam

[source,ts,subs=+macros]
----
type SearchSourceConfigParam = boolean | <<Fields>>
----


[discrete]
[[SearchSourceFilter]]
=== SearchSourceFilter

[source,ts,subs=+macros]
----
interface SearchSourceFilter {
  excludes?: <<Fields>>
  exclude?: <<Fields>>
  includes?: <<Fields>>
  include?: <<Fields>>
}
----


[discrete]
[[SearchStringDistance]]
=== SearchStringDistance

[source,ts,subs=+macros]
----
type SearchStringDistance = 'internal' | 'damerau_levenshtein' | 'levenshtein' | 'jaro_winkler' | 'ngram'
----


[discrete]
[[SearchStupidBackoffSmoothingModel]]
=== SearchStupidBackoffSmoothingModel

[source,ts,subs=+macros]
----
interface SearchStupidBackoffSmoothingModel {
  pass:[/**] @property discount A constant factor that the lower order n-gram model is discounted by. */
  discount: <<double>>
}
----


[discrete]
[[SearchSuggest]]
=== SearchSuggest

[source,ts,subs=+macros]
----
type SearchSuggest<TDocument = unknown> = <<SearchCompletionSuggest>><TDocument> | <<SearchPhraseSuggest>> | <<SearchTermSuggest>>
----


[discrete]
[[SearchSuggestBase]]
=== SearchSuggestBase

[source,ts,subs=+macros]
----
interface SearchSuggestBase {
  length: <<integer>>
  offset: <<integer>>
  text: string
}
----


[discrete]
[[SearchSuggestFuzziness]]
=== SearchSuggestFuzziness

[source,ts,subs=+macros]
----
interface SearchSuggestFuzziness {
  pass:[/**] @property fuzziness The fuzziness factor. */
  fuzziness?: <<Fuzziness>>
  pass:[/**] @property min_length Minimum length of the input before fuzzy suggestions are returned. */
  min_length?: <<integer>>
  pass:[/**] @property prefix_length Minimum length of the input, which is not checked for fuzzy alternatives. */
  prefix_length?: <<integer>>
  pass:[/**] @property transpositions If set to `true`, transpositions are counted as one change instead of two. */
  transpositions?: boolean
  pass:[/**] @property unicode_aware If `true`, all measurements (like fuzzy edit distance, transpositions, and lengths) are measured in Unicode code points instead of in bytes. This is slightly slower than raw bytes. */
  unicode_aware?: boolean
}
----


[discrete]
[[SearchSuggestSort]]
=== SearchSuggestSort

[source,ts,subs=+macros]
----
type SearchSuggestSort = 'score' | 'frequency'
----


[discrete]
[[SearchSuggester]]
=== SearchSuggester

[source,ts,subs=+macros]
----
interface SearchSuggesterKeys {
  text?: string
}
type SearchSuggester = SearchSuggesterKeys
  & { [property: string]: <<SearchFieldSuggester>> | string }
----


[discrete]
[[SearchSuggesterBase]]
=== SearchSuggesterBase

[source,ts,subs=+macros]
----
interface SearchSuggesterBase {
  pass:[/**] @property field The field to fetch the candidate suggestions from. Needs to be set globally or per suggestion. */
  field: <<Field>>
  pass:[/**] @property analyzer The analyzer to analyze the suggest text with. Defaults to the search analyzer of the suggest field. */
  analyzer?: string
  pass:[/**] @property size The maximum corrections to be returned per suggest text token. */
  size?: <<integer>>
}
----


[discrete]
[[SearchTermSuggest]]
=== SearchTermSuggest

[source,ts,subs=+macros]
----
interface SearchTermSuggest extends <<SearchSuggestBase>> {
  options: <<SearchTermSuggestOption>> | <<SearchTermSuggestOption>>[]
}
----


[discrete]
[[SearchTermSuggestOption]]
=== SearchTermSuggestOption

[source,ts,subs=+macros]
----
interface SearchTermSuggestOption {
  text: string
  score: <<double>>
  freq: <<long>>
  highlighted?: string
  collate_match?: boolean
}
----


[discrete]
[[SearchTermSuggester]]
=== SearchTermSuggester

[source,ts,subs=+macros]
----
interface SearchTermSuggester extends <<SearchSuggesterBase>> {
  lowercase_terms?: boolean
  pass:[/**] @property max_edits The maximum edit distance candidate suggestions can have in order to be considered as a suggestion. Can only be `1` or `2`. */
  max_edits?: <<integer>>
  pass:[/**] @property max_inspections A factor that is used to multiply with the shard_size in order to inspect more candidate spelling corrections on the shard level. Can improve accuracy at the cost of performance. */
  max_inspections?: <<integer>>
  pass:[/**] @property max_term_freq The maximum threshold in number of documents in which a suggest text token can exist in order to be included. Can be a relative percentage number (for example `0.4`) or an absolute number to represent document frequencies. If a value higher than 1 is specified, then fractional can not be specified. */
  max_term_freq?: <<float>>
  pass:[/**] @property min_doc_freq The minimal threshold in number of documents a suggestion should appear in. This can improve quality by only suggesting high frequency terms. Can be specified as an absolute number or as a relative percentage of number of documents. If a value higher than 1 is specified, then the number cannot be fractional. */
  min_doc_freq?: <<float>>
  pass:[/**] @property min_word_length The minimum length a suggest text term must have in order to be included. */
  min_word_length?: <<integer>>
  pass:[/**] @property prefix_length The number of minimal prefix characters that must match in order be a candidate for suggestions. Increasing this number improves spellcheck performance. */
  prefix_length?: <<integer>>
  pass:[/**] @property shard_size Sets the maximum number of suggestions to be retrieved from each individual shard. */
  shard_size?: <<integer>>
  pass:[/**] @property sort Defines how suggestions should be sorted per suggest text term. */
  sort?: <<SearchSuggestSort>>
  pass:[/**] @property string_distance The string distance implementation to use for comparing how similar suggested terms are. */
  string_distance?: <<SearchStringDistance>>
  pass:[/**] @property suggest_mode Controls what suggestions are included or controls for what suggest text terms, suggestions should be suggested. */
  suggest_mode?: <<SuggestMode>>
  pass:[/**] @property text The suggest text. Needs to be set globally or per suggestion. */
  text?: string
}
----


[discrete]
[[SearchTotalHits]]
=== SearchTotalHits

[source,ts,subs=+macros]
----
interface SearchTotalHits {
  relation: <<SearchTotalHitsRelation>>
  value: <<long>>
}
----


[discrete]
[[SearchTotalHitsRelation]]
=== SearchTotalHitsRelation

[source,ts,subs=+macros]
----
type SearchTotalHitsRelation = 'eq' | 'gte'
----


[discrete]
[[SearchTrackHits]]
=== SearchTrackHits

[source,ts,subs=+macros]
----
type SearchTrackHits = boolean | <<integer>>
----


