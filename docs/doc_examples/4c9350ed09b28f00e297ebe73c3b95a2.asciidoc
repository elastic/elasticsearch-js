// This file is autogenerated, DO NOT EDIT
// Use `node scripts/generate-docs-examples.mjs` to generate the docs examples

[source, js]
----
const response = await client.inference.put({
  task_type: "text_embedding",
  inference_id: "my-msmarco-minilm-model",
  inference_config: {
    service: "elasticsearch",
    service_settings: {
      num_allocations: 1,
      num_threads: 1,
      model_id: "msmarco-MiniLM-L12-cos-v5",
    },
  },
});
console.log(response);
----
