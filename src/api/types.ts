/*
 * Copyright Elasticsearch B.V. and contributors
 * SPDX-License-Identifier: Apache-2.0
 */

/* eslint-disable @typescript-eslint/array-type */
/* eslint-disable @typescript-eslint/no-empty-interface */
/* eslint-disable @typescript-eslint/no-unused-vars */

/**
 * We are still working on this type, it will arrive soon.
 * If it's critical for you, please open an issue.
 * https://github.com/elastic/elasticsearch-js
 */
export type TODO = Record<string, any>

export interface BulkCreateOperation extends BulkWriteOperation {
}

export interface BulkDeleteOperation extends BulkOperationBase {
}

export type BulkFailureStoreStatus = 'not_applicable_or_unknown' | 'used' | 'not_enabled' | 'failed'

export interface BulkIndexOperation extends BulkWriteOperation {
}

export interface BulkOperationBase {
  _id?: Id
  _index?: IndexName
  routing?: Routing
  if_primary_term?: long
  if_seq_no?: SequenceNumber
  version?: VersionNumber
  version_type?: VersionType
}

export interface BulkOperationContainer {
  index?: BulkIndexOperation
  create?: BulkCreateOperation
  update?: BulkUpdateOperation
  delete?: BulkDeleteOperation
}

export type BulkOperationType = 'index' | 'create' | 'update' | 'delete'

export interface BulkRequest<TDocument = unknown, TPartialDocument = unknown> extends RequestBase {
/** The name of the data stream, index, or index alias to perform bulk actions on. */
  index?: IndexName
  /** True or false if to include the document source in the error message in case of parsing errors. */
  include_source_on_error?: boolean
  /** If `true`, the response will include the ingest pipelines that were run for each index or create. */
  list_executed_pipelines?: boolean
  /** The pipeline identifier to use to preprocess incoming documents. If the index has a default ingest pipeline specified, setting the value to `_none` turns off the default ingest pipeline for this request. If a final pipeline is configured, it will always run regardless of the value of this parameter. */
  pipeline?: string
  /** If `true`, Elasticsearch refreshes the affected shards to make this operation visible to search. If `wait_for`, wait for a refresh to make this operation visible to search. If `false`, do nothing with refreshes. Valid values: `true`, `false`, `wait_for`. */
  refresh?: Refresh
  /** A custom value that is used to route operations to a specific shard. */
  routing?: Routing
  /** Indicates whether to return the `_source` field (`true` or `false`) or contains a list of fields to return. */
  _source?: SearchSourceConfigParam
  /** A comma-separated list of source fields to exclude from the response. You can also use this parameter to exclude fields from the subset specified in `_source_includes` query parameter. If the `_source` parameter is `false`, this parameter is ignored. */
  _source_excludes?: Fields
  /** A comma-separated list of source fields to include in the response. If this parameter is specified, only these source fields are returned. You can exclude fields from this subset using the `_source_excludes` query parameter. If the `_source` parameter is `false`, this parameter is ignored. */
  _source_includes?: Fields
  /** The period each action waits for the following operations: automatic index creation, dynamic mapping updates, and waiting for active shards. The default is `1m` (one minute), which guarantees Elasticsearch waits for at least the timeout before failing. The actual wait time could be longer, particularly when multiple waits occur. */
  timeout?: Duration
  /** The number of shard copies that must be active before proceeding with the operation. Set to `all` or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). The default is `1`, which waits for each primary shard to be active. */
  wait_for_active_shards?: WaitForActiveShards
  /** If `true`, the request's actions must target an index alias. */
  require_alias?: boolean
  /** If `true`, the request's actions must target a data stream (existing or to be created). */
  require_data_stream?: boolean
  operations?: (BulkOperationContainer | BulkUpdateAction<TDocument, TPartialDocument> | TDocument)[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, include_source_on_error?: never, list_executed_pipelines?: never, pipeline?: never, refresh?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, timeout?: never, wait_for_active_shards?: never, require_alias?: never, require_data_stream?: never, operations?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, include_source_on_error?: never, list_executed_pipelines?: never, pipeline?: never, refresh?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, timeout?: never, wait_for_active_shards?: never, require_alias?: never, require_data_stream?: never, operations?: never }
}

export interface BulkResponse {
  errors: boolean
  items: Partial<Record<BulkOperationType, BulkResponseItem>>[]
  took: long
  ingest_took?: long
}

export interface BulkResponseItem {
  _id?: string | null
  _index: string
  status: integer
  failure_store?: BulkFailureStoreStatus
  error?: ErrorCause
  _primary_term?: long
  result?: string
  _seq_no?: SequenceNumber
  _shards?: ShardStatistics
  _version?: VersionNumber
  forced_refresh?: boolean
  get?: InlineGet<Record<string, any>>
}

export interface BulkUpdateAction<TDocument = unknown, TPartialDocument = unknown> {
  detect_noop?: boolean
  doc?: TPartialDocument
  doc_as_upsert?: boolean
  script?: Script | string
  scripted_upsert?: boolean
  _source?: SearchSourceConfig
  upsert?: TDocument
}

export interface BulkUpdateOperation extends BulkOperationBase {
  require_alias?: boolean
  retry_on_conflict?: integer
}

export interface BulkWriteOperation extends BulkOperationBase {
  dynamic_templates?: Record<string, string>
  pipeline?: string
  require_alias?: boolean
}

export interface ClearScrollRequest extends RequestBase {
/** A comma-separated list of scroll IDs to clear. To clear all scroll IDs, use `_all`. IMPORTANT: Scroll IDs can be long. It is recommended to specify scroll IDs in the request body parameter. */
  scroll_id?: ScrollIds
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { scroll_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { scroll_id?: never }
}

export interface ClearScrollResponse {
  succeeded: boolean
  num_freed: integer
}

export interface ClosePointInTimeRequest extends RequestBase {
/** The ID of the point-in-time. */
  id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export interface ClosePointInTimeResponse {
  succeeded: boolean
  num_freed: integer
}

export interface CountRequest extends RequestBase {
/** A comma-separated list of data streams, indices, and aliases to search. It supports wildcards (`*`). To search all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. */
  allow_no_indices?: boolean
  /** The analyzer to use for the query string. This parameter can be used only when the `q` query string parameter is specified. */
  analyzer?: string
  /** If `true`, wildcard and prefix queries are analyzed. This parameter can be used only when the `q` query string parameter is specified. */
  analyze_wildcard?: boolean
  /** The default operator for query string query: `AND` or `OR`. This parameter can be used only when the `q` query string parameter is specified. */
  default_operator?: QueryDslOperator
  /** The field to use as a default when no field prefix is given in the query string. This parameter can be used only when the `q` query string parameter is specified. */
  df?: string
  /** The type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. It supports comma-separated values, such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, concrete, expanded, or aliased indices are ignored when frozen. */
  ignore_throttled?: boolean
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** If `true`, format-based query failures (such as providing text to a numeric field) in the query string will be ignored. This parameter can be used only when the `q` query string parameter is specified. */
  lenient?: boolean
  /** The minimum `_score` value that documents must have to be included in the result. */
  min_score?: double
  /** The node or shard the operation should be performed on. By default, it is random. */
  preference?: string
  /** A custom value used to route operations to a specific shard. */
  routing?: Routing
  /** The maximum number of documents to collect for each shard. If a query reaches this limit, Elasticsearch terminates the query early. Elasticsearch collects documents before sorting. IMPORTANT: Use with caution. Elasticsearch applies this parameter to each shard handling the request. When possible, let Elasticsearch perform early termination automatically. Avoid specifying this parameter for requests that target data streams with backing indices across multiple data tiers. */
  terminate_after?: long
  /** The query in Lucene query string syntax. This parameter cannot be used with a request body. */
  q?: string
  /** Defines the search query using Query DSL. A request body query cannot be used with the `q` query string parameter. */
  query?: QueryDslQueryContainer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, analyzer?: never, analyze_wildcard?: never, default_operator?: never, df?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, lenient?: never, min_score?: never, preference?: never, routing?: never, terminate_after?: never, q?: never, query?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, analyzer?: never, analyze_wildcard?: never, default_operator?: never, df?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, lenient?: never, min_score?: never, preference?: never, routing?: never, terminate_after?: never, q?: never, query?: never }
}

export interface CountResponse {
  count: long
  _shards: ShardStatistics
}

export interface CreateRequest<TDocument = unknown> extends RequestBase {
/** A unique identifier for the document. To automatically generate a document ID, use the `POST /<target>/_doc/` request format. */
  id: Id
  /** The name of the data stream or index to target. If the target doesn't exist and matches the name or wildcard (`*`) pattern of an index template with a `data_stream` definition, this request creates the data stream. If the target doesn't exist and doesn’t match a data stream template, this request creates the index. */
  index: IndexName
  /** Only perform the operation if the document has this primary term. */
  if_primary_term?: long
  /** Only perform the operation if the document has this sequence number. */
  if_seq_no?: SequenceNumber
  /** True or false if to include the document source in the error message in case of parsing errors. */
  include_source_on_error?: boolean
  /** Set to `create` to only index the document if it does not already exist (put if absent). If a document with the specified `_id` already exists, the indexing operation will fail. The behavior is the same as using the `<index>/_create` endpoint. If a document ID is specified, this paramater defaults to `index`. Otherwise, it defaults to `create`. If the request targets a data stream, an `op_type` of `create` is required. */
  op_type?: OpType
  /** The ID of the pipeline to use to preprocess incoming documents. If the index has a default ingest pipeline specified, setting the value to `_none` turns off the default ingest pipeline for this request. If a final pipeline is configured, it will always run regardless of the value of this parameter. */
  pipeline?: string
  /** If `true`, Elasticsearch refreshes the affected shards to make this operation visible to search. If `wait_for`, it waits for a refresh to make this operation visible to search. If `false`, it does nothing with refreshes. */
  refresh?: Refresh
  /** If `true`, the destination must be an index alias. */
  require_alias?: boolean
  /** If `true`, the request's actions must target a data stream (existing or to be created). */
  require_data_stream?: boolean
  /** A custom value that is used to route operations to a specific shard. */
  routing?: Routing
  /** The period the request waits for the following operations: automatic index creation, dynamic mapping updates, waiting for active shards. Elasticsearch waits for at least the specified timeout period before failing. The actual wait time could be longer, particularly when multiple waits occur. This parameter is useful for situations where the primary shard assigned to perform the operation might not be available when the operation runs. Some reasons for this might be that the primary shard is currently recovering from a gateway or undergoing relocation. By default, the operation will wait on the primary shard to become available for at least 1 minute before failing and responding with an error. The actual wait time could be longer, particularly when multiple waits occur. */
  timeout?: Duration
  /** The explicit version number for concurrency control. It must be a non-negative long number. */
  version?: VersionNumber
  /** The version type. */
  version_type?: VersionType
  /** The number of shard copies that must be active before proceeding with the operation. You can set it to `all` or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). The default value of `1` means it waits for each primary shard to be active. */
  wait_for_active_shards?: WaitForActiveShards
  document?: TDocument
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, index?: never, if_primary_term?: never, if_seq_no?: never, include_source_on_error?: never, op_type?: never, pipeline?: never, refresh?: never, require_alias?: never, require_data_stream?: never, routing?: never, timeout?: never, version?: never, version_type?: never, wait_for_active_shards?: never, document?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, index?: never, if_primary_term?: never, if_seq_no?: never, include_source_on_error?: never, op_type?: never, pipeline?: never, refresh?: never, require_alias?: never, require_data_stream?: never, routing?: never, timeout?: never, version?: never, version_type?: never, wait_for_active_shards?: never, document?: never }
}

export type CreateResponse = WriteResponseBase

export interface DeleteRequest extends RequestBase {
/** A unique identifier for the document. */
  id: Id
  /** The name of the target index. */
  index: IndexName
  /** Only perform the operation if the document has this primary term. */
  if_primary_term?: long
  /** Only perform the operation if the document has this sequence number. */
  if_seq_no?: SequenceNumber
  /** If `true`, Elasticsearch refreshes the affected shards to make this operation visible to search. If `wait_for`, it waits for a refresh to make this operation visible to search. If `false`, it does nothing with refreshes. */
  refresh?: Refresh
  /** A custom value used to route operations to a specific shard. */
  routing?: Routing
  /** The period to wait for active shards. This parameter is useful for situations where the primary shard assigned to perform the delete operation might not be available when the delete operation runs. Some reasons for this might be that the primary shard is currently recovering from a store or undergoing relocation. By default, the delete operation will wait on the primary shard to become available for up to 1 minute before failing and responding with an error. */
  timeout?: Duration
  /** An explicit version number for concurrency control. It must match the current version of the document for the request to succeed. */
  version?: VersionNumber
  /** The version type. */
  version_type?: VersionType
  /** The minimum number of shard copies that must be active before proceeding with the operation. You can set it to `all` or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). The default value of `1` means it waits for each primary shard to be active. */
  wait_for_active_shards?: WaitForActiveShards
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, index?: never, if_primary_term?: never, if_seq_no?: never, refresh?: never, routing?: never, timeout?: never, version?: never, version_type?: never, wait_for_active_shards?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, index?: never, if_primary_term?: never, if_seq_no?: never, refresh?: never, routing?: never, timeout?: never, version?: never, version_type?: never, wait_for_active_shards?: never }
}

export type DeleteResponse = WriteResponseBase

export interface DeleteByQueryRequest extends RequestBase {
/** A comma-separated list of data streams, indices, and aliases to search. It supports wildcards (`*`). To search all data streams or indices, omit this parameter or use `*` or `_all`. */
  index: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. */
  allow_no_indices?: boolean
  /** Analyzer to use for the query string. This parameter can be used only when the `q` query string parameter is specified. */
  analyzer?: string
  /** If `true`, wildcard and prefix queries are analyzed. This parameter can be used only when the `q` query string parameter is specified. */
  analyze_wildcard?: boolean
  /** What to do if delete by query hits version conflicts: `abort` or `proceed`. */
  conflicts?: Conflicts
  /** The default operator for query string query: `AND` or `OR`. This parameter can be used only when the `q` query string parameter is specified. */
  default_operator?: QueryDslOperator
  /** The field to use as default where no field prefix is given in the query string. This parameter can be used only when the `q` query string parameter is specified. */
  df?: string
  /** The type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. It supports comma-separated values, such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** Starting offset (default: 0) */
  from?: long
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** If `true`, format-based query failures (such as providing text to a numeric field) in the query string will be ignored. This parameter can be used only when the `q` query string parameter is specified. */
  lenient?: boolean
  /** The node or shard the operation should be performed on. It is random by default. */
  preference?: string
  /** If `true`, Elasticsearch refreshes all shards involved in the delete by query after the request completes. This is different than the delete API's `refresh` parameter, which causes just the shard that received the delete request to be refreshed. Unlike the delete API, it does not support `wait_for`. */
  refresh?: boolean
  /** If `true`, the request cache is used for this request. Defaults to the index-level setting. */
  request_cache?: boolean
  /** The throttle for this request in sub-requests per second. */
  requests_per_second?: float
  /** A custom value used to route operations to a specific shard. */
  routing?: Routing
  /** A query in the Lucene query string syntax. */
  q?: string
  /** The period to retain the search context for scrolling. */
  scroll?: Duration
  /** The size of the scroll request that powers the operation. */
  scroll_size?: long
  /** The explicit timeout for each search request. It defaults to no timeout. */
  search_timeout?: Duration
  /** The type of the search operation. Available options include `query_then_fetch` and `dfs_query_then_fetch`. */
  search_type?: SearchType
  /** The number of slices this task should be divided into. */
  slices?: Slices
  /** A comma-separated list of `<field>:<direction>` pairs. */
  sort?: string[]
  /** The specific `tag` of the request for logging and statistical purposes. */
  stats?: string[]
  /** The maximum number of documents to collect for each shard. If a query reaches this limit, Elasticsearch terminates the query early. Elasticsearch collects documents before sorting. Use with caution. Elasticsearch applies this parameter to each shard handling the request. When possible, let Elasticsearch perform early termination automatically. Avoid specifying this parameter for requests that target data streams with backing indices across multiple data tiers. */
  terminate_after?: long
  /** The period each deletion request waits for active shards. */
  timeout?: Duration
  /** If `true`, returns the document version as part of a hit. */
  version?: boolean
  /** The number of shard copies that must be active before proceeding with the operation. Set to `all` or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). The `timeout` value controls how long each write request waits for unavailable shards to become available. */
  wait_for_active_shards?: WaitForActiveShards
  /** If `true`, the request blocks until the operation is complete. If `false`, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task. Elasticsearch creates a record of this task as a document at `.tasks/task/${taskId}`. When you are done with a task, you should delete the task document so Elasticsearch can reclaim the space. */
  wait_for_completion?: boolean
  /** The maximum number of documents to delete. */
  max_docs?: long
  /** The documents to delete specified with Query DSL. */
  query?: QueryDslQueryContainer
  /** Slice the request manually using the provided slice ID and total number of slices. */
  slice?: SlicedScroll
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, analyzer?: never, analyze_wildcard?: never, conflicts?: never, default_operator?: never, df?: never, expand_wildcards?: never, from?: never, ignore_unavailable?: never, lenient?: never, preference?: never, refresh?: never, request_cache?: never, requests_per_second?: never, routing?: never, q?: never, scroll?: never, scroll_size?: never, search_timeout?: never, search_type?: never, slices?: never, sort?: never, stats?: never, terminate_after?: never, timeout?: never, version?: never, wait_for_active_shards?: never, wait_for_completion?: never, max_docs?: never, query?: never, slice?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, analyzer?: never, analyze_wildcard?: never, conflicts?: never, default_operator?: never, df?: never, expand_wildcards?: never, from?: never, ignore_unavailable?: never, lenient?: never, preference?: never, refresh?: never, request_cache?: never, requests_per_second?: never, routing?: never, q?: never, scroll?: never, scroll_size?: never, search_timeout?: never, search_type?: never, slices?: never, sort?: never, stats?: never, terminate_after?: never, timeout?: never, version?: never, wait_for_active_shards?: never, wait_for_completion?: never, max_docs?: never, query?: never, slice?: never }
}

export interface DeleteByQueryResponse {
  batches?: long
  deleted?: long
  failures?: BulkIndexByScrollFailure[]
  noops?: long
  requests_per_second?: float
  retries?: Retries
  slice_id?: integer
  task?: TaskId
  throttled?: Duration
  throttled_millis?: DurationValue<UnitMillis>
  throttled_until?: Duration
  throttled_until_millis?: DurationValue<UnitMillis>
  timed_out?: boolean
  took?: DurationValue<UnitMillis>
  total?: long
  version_conflicts?: long
}

export interface DeleteByQueryRethrottleRequest extends RequestBase {
/** The ID for the task. */
  task_id: TaskId
  /** The throttle for this request in sub-requests per second. To disable throttling, set it to `-1`. */
  requests_per_second?: float
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { task_id?: never, requests_per_second?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { task_id?: never, requests_per_second?: never }
}

export type DeleteByQueryRethrottleResponse = TasksTaskListResponseBase

export interface DeleteScriptRequest extends RequestBase {
/** The identifier for the stored script or search template. */
  id: Id
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never }
}

export type DeleteScriptResponse = AcknowledgedResponseBase

export interface ExistsRequest extends RequestBase {
/** A unique document identifier. */
  id: Id
  /** A comma-separated list of data streams, indices, and aliases. It supports wildcards (`*`). */
  index: IndexName
  /** The node or shard the operation should be performed on. By default, the operation is randomized between the shard replicas. If it is set to `_local`, the operation will prefer to be run on a local allocated shard when possible. If it is set to a custom value, the value is used to guarantee that the same shards will be used for the same custom value. This can help with "jumping values" when hitting different shards in different refresh states. A sample value can be something like the web session ID or the user name. */
  preference?: string
  /** If `true`, the request is real-time as opposed to near-real-time. */
  realtime?: boolean
  /** If `true`, the request refreshes the relevant shards before retrieving the document. Setting it to `true` should be done after careful thought and verification that this does not cause a heavy load on the system (and slow down indexing). */
  refresh?: boolean
  /** A custom value used to route operations to a specific shard. */
  routing?: Routing
  /** Indicates whether to return the `_source` field (`true` or `false`) or lists the fields to return. */
  _source?: SearchSourceConfigParam
  /** A comma-separated list of source fields to exclude from the response. You can also use this parameter to exclude fields from the subset specified in `_source_includes` query parameter. If the `_source` parameter is `false`, this parameter is ignored. */
  _source_excludes?: Fields
  /** A comma-separated list of source fields to include in the response. If this parameter is specified, only these source fields are returned. You can exclude fields from this subset using the `_source_excludes` query parameter. If the `_source` parameter is `false`, this parameter is ignored. */
  _source_includes?: Fields
  /** A comma-separated list of stored fields to return as part of a hit. If no fields are specified, no stored fields are included in the response. If this field is specified, the `_source` parameter defaults to `false`. */
  stored_fields?: Fields
  /** Explicit version number for concurrency control. The specified version must match the current version of the document for the request to succeed. */
  version?: VersionNumber
  /** The version type. */
  version_type?: VersionType
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, index?: never, preference?: never, realtime?: never, refresh?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, stored_fields?: never, version?: never, version_type?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, index?: never, preference?: never, realtime?: never, refresh?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, stored_fields?: never, version?: never, version_type?: never }
}

export type ExistsResponse = boolean

export interface ExistsSourceRequest extends RequestBase {
/** A unique identifier for the document. */
  id: Id
  /** A comma-separated list of data streams, indices, and aliases. It supports wildcards (`*`). */
  index: IndexName
  /** The node or shard the operation should be performed on. By default, the operation is randomized between the shard replicas. */
  preference?: string
  /** If `true`, the request is real-time as opposed to near-real-time. */
  realtime?: boolean
  /** If `true`, the request refreshes the relevant shards before retrieving the document. Setting it to `true` should be done after careful thought and verification that this does not cause a heavy load on the system (and slow down indexing). */
  refresh?: boolean
  /** A custom value used to route operations to a specific shard. */
  routing?: Routing
  /** Indicates whether to return the `_source` field (`true` or `false`) or lists the fields to return. */
  _source?: SearchSourceConfigParam
  /** A comma-separated list of source fields to exclude in the response. */
  _source_excludes?: Fields
  /** A comma-separated list of source fields to include in the response. */
  _source_includes?: Fields
  /** The version number for concurrency control. It must match the current version of the document for the request to succeed. */
  version?: VersionNumber
  /** The version type. */
  version_type?: VersionType
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, index?: never, preference?: never, realtime?: never, refresh?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, version?: never, version_type?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, index?: never, preference?: never, realtime?: never, refresh?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, version?: never, version_type?: never }
}

export type ExistsSourceResponse = boolean

export interface ExplainExplanation {
  description: string
  details: ExplainExplanationDetail[]
  value: float
}

export interface ExplainExplanationDetail {
  description: string
  details?: ExplainExplanationDetail[]
  value: float
}

export interface ExplainRequest extends RequestBase {
/** The document identifier. */
  id: Id
  /** Index names that are used to limit the request. Only a single index name can be provided to this parameter. */
  index: IndexName
  /** The analyzer to use for the query string. This parameter can be used only when the `q` query string parameter is specified. */
  analyzer?: string
  /** If `true`, wildcard and prefix queries are analyzed. This parameter can be used only when the `q` query string parameter is specified. */
  analyze_wildcard?: boolean
  /** The default operator for query string query: `AND` or `OR`. This parameter can be used only when the `q` query string parameter is specified. */
  default_operator?: QueryDslOperator
  /** The field to use as default where no field prefix is given in the query string. This parameter can be used only when the `q` query string parameter is specified. */
  df?: string
  /** If `true`, format-based query failures (such as providing text to a numeric field) in the query string will be ignored. This parameter can be used only when the `q` query string parameter is specified. */
  lenient?: boolean
  /** The node or shard the operation should be performed on. It is random by default. */
  preference?: string
  /** A custom value used to route operations to a specific shard. */
  routing?: Routing
  /** `True` or `false` to return the `_source` field or not or a list of fields to return. */
  _source?: SearchSourceConfigParam
  /** A comma-separated list of source fields to exclude from the response. You can also use this parameter to exclude fields from the subset specified in `_source_includes` query parameter. If the `_source` parameter is `false`, this parameter is ignored. */
  _source_excludes?: Fields
  /** A comma-separated list of source fields to include in the response. If this parameter is specified, only these source fields are returned. You can exclude fields from this subset using the `_source_excludes` query parameter. If the `_source` parameter is `false`, this parameter is ignored. */
  _source_includes?: Fields
  /** A comma-separated list of stored fields to return in the response. */
  stored_fields?: Fields
  /** The query in the Lucene query string syntax. */
  q?: string
  /** Defines the search definition using the Query DSL. */
  query?: QueryDslQueryContainer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, index?: never, analyzer?: never, analyze_wildcard?: never, default_operator?: never, df?: never, lenient?: never, preference?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, stored_fields?: never, q?: never, query?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, index?: never, analyzer?: never, analyze_wildcard?: never, default_operator?: never, df?: never, lenient?: never, preference?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, stored_fields?: never, q?: never, query?: never }
}

export interface ExplainResponse<TDocument = unknown> {
  _index: IndexName
  _id: Id
  matched: boolean
  explanation?: ExplainExplanationDetail
  get?: InlineGet<TDocument>
}

export interface FieldCapsFieldCapability {
  aggregatable: boolean
  indices?: Indices
  meta?: Metadata
  non_aggregatable_indices?: Indices
  non_searchable_indices?: Indices
  searchable: boolean
  type: string
  metadata_field?: boolean
  time_series_dimension?: boolean
  time_series_metric?: MappingTimeSeriesMetricType
  non_dimension_indices?: IndexName[]
  metric_conflicts_indices?: IndexName[]
}

export interface FieldCapsRequest extends RequestBase {
/** A comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (*). To target all data streams and indices, omit this parameter or use * or _all. */
  index?: Indices
  /** If false, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with foo but no index starts with bar. */
  allow_no_indices?: boolean
  /** The type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, missing or closed indices are not included in the response. */
  ignore_unavailable?: boolean
  /** If true, unmapped fields are included in the response. */
  include_unmapped?: boolean
  /** A comma-separated list of filters to apply to the response. */
  filters?: string
  /** A comma-separated list of field types to include. Any fields that do not match one of these types will be excluded from the results. It defaults to empty, meaning that all field types are returned. */
  types?: string[]
  /** If false, empty fields are not included in the response. */
  include_empty_fields?: boolean
  /** A list of fields to retrieve capabilities for. Wildcard (`*`) expressions are supported. */
  fields?: Fields
  /** Filter indices if the provided query rewrites to `match_none` on every shard. IMPORTANT: The filtering is done on a best-effort basis, it uses index statistics and mappings to rewrite queries to `match_none` instead of fully running the request. For instance a range query over a date field can rewrite to `match_none` if all documents within a shard (including deleted documents) are outside of the provided range. However, not all queries can rewrite to `match_none` so this API may return an index even if the provided filter matches no document. */
  index_filter?: QueryDslQueryContainer
  /** Define ad-hoc runtime fields in the request similar to the way it is done in search requests. These fields exist only as part of the query and take precedence over fields defined with the same name in the index mappings. */
  runtime_mappings?: MappingRuntimeFields
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, include_unmapped?: never, filters?: never, types?: never, include_empty_fields?: never, fields?: never, index_filter?: never, runtime_mappings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, include_unmapped?: never, filters?: never, types?: never, include_empty_fields?: never, fields?: never, index_filter?: never, runtime_mappings?: never }
}

export interface FieldCapsResponse {
  indices: Indices
  fields: Record<Field, Record<string, FieldCapsFieldCapability>>
}

export interface GetGetResult<TDocument = unknown> {
  _index: IndexName
  fields?: Record<string, any>
  _ignored?: string[]
  found: boolean
  _id: Id
  _primary_term?: long
  _routing?: string
  _seq_no?: SequenceNumber
  _source?: TDocument
  _version?: VersionNumber
}

export interface GetRequest extends RequestBase {
/** A unique document identifier. */
  id: Id
  /** The name of the index that contains the document. */
  index: IndexName
  /** Indicates whether the request forces synthetic `_source`. Use this paramater to test if the mapping supports synthetic `_source` and to get a sense of the worst case performance. Fetches with this parameter enabled will be slower than enabling synthetic source natively in the index. */
  force_synthetic_source?: boolean
  /** The node or shard the operation should be performed on. By default, the operation is randomized between the shard replicas. If it is set to `_local`, the operation will prefer to be run on a local allocated shard when possible. If it is set to a custom value, the value is used to guarantee that the same shards will be used for the same custom value. This can help with "jumping values" when hitting different shards in different refresh states. A sample value can be something like the web session ID or the user name. */
  preference?: string
  /** If `true`, the request is real-time as opposed to near-real-time. */
  realtime?: boolean
  /** If `true`, the request refreshes the relevant shards before retrieving the document. Setting it to `true` should be done after careful thought and verification that this does not cause a heavy load on the system (and slow down indexing). */
  refresh?: boolean
  /** A custom value used to route operations to a specific shard. */
  routing?: Routing
  /** Indicates whether to return the `_source` field (`true` or `false`) or lists the fields to return. */
  _source?: SearchSourceConfigParam
  /** A comma-separated list of source fields to exclude from the response. You can also use this parameter to exclude fields from the subset specified in `_source_includes` query parameter. If the `_source` parameter is `false`, this parameter is ignored. */
  _source_excludes?: Fields
  /** A comma-separated list of source fields to include in the response. If this parameter is specified, only these source fields are returned. You can exclude fields from this subset using the `_source_excludes` query parameter. If the `_source` parameter is `false`, this parameter is ignored. */
  _source_includes?: Fields
  /** A comma-separated list of stored fields to return as part of a hit. If no fields are specified, no stored fields are included in the response. If this field is specified, the `_source` parameter defaults to `false`. Only leaf fields can be retrieved with the `stored_field` option. Object fields can't be returned;if specified, the request fails. */
  stored_fields?: Fields
  /** The version number for concurrency control. It must match the current version of the document for the request to succeed. */
  version?: VersionNumber
  /** The version type. */
  version_type?: VersionType
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, index?: never, force_synthetic_source?: never, preference?: never, realtime?: never, refresh?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, stored_fields?: never, version?: never, version_type?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, index?: never, force_synthetic_source?: never, preference?: never, realtime?: never, refresh?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, stored_fields?: never, version?: never, version_type?: never }
}

export type GetResponse<TDocument = unknown> = GetGetResult<TDocument>

export interface GetScriptRequest extends RequestBase {
/** The identifier for the stored script or search template. */
  id: Id
  /** The period to wait for the master node. If the master node is not available before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, master_timeout?: never }
}

export interface GetScriptResponse {
  _id: Id
  found: boolean
  script?: StoredScript
}

export interface GetScriptContextContext {
  methods: GetScriptContextContextMethod[]
  name: Name
}

export interface GetScriptContextContextMethod {
  name: Name
  return_type: string
  params: GetScriptContextContextMethodParam[]
}

export interface GetScriptContextContextMethodParam {
  name: Name
  type: string
}

export interface GetScriptContextRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface GetScriptContextResponse {
  contexts: GetScriptContextContext[]
}

export interface GetScriptLanguagesLanguageContext {
  contexts: string[]
  language: ScriptLanguage
}

export interface GetScriptLanguagesRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface GetScriptLanguagesResponse {
  language_contexts: GetScriptLanguagesLanguageContext[]
  types_allowed: string[]
}

export interface GetSourceRequest extends RequestBase {
/** A unique document identifier. */
  id: Id
  /** The name of the index that contains the document. */
  index: IndexName
  /** The node or shard the operation should be performed on. By default, the operation is randomized between the shard replicas. */
  preference?: string
  /** If `true`, the request is real-time as opposed to near-real-time. */
  realtime?: boolean
  /** If `true`, the request refreshes the relevant shards before retrieving the document. Setting it to `true` should be done after careful thought and verification that this does not cause a heavy load on the system (and slow down indexing). */
  refresh?: boolean
  /** A custom value used to route operations to a specific shard. */
  routing?: Routing
  /** Indicates whether to return the `_source` field (`true` or `false`) or lists the fields to return. */
  _source?: SearchSourceConfigParam
  /** A comma-separated list of source fields to exclude in the response. */
  _source_excludes?: Fields
  /** A comma-separated list of source fields to include in the response. */
  _source_includes?: Fields
  /** A comma-separated list of stored fields to return as part of a hit. */
  stored_fields?: Fields
  /** The version number for concurrency control. It must match the current version of the document for the request to succeed. */
  version?: VersionNumber
  /** The version type. */
  version_type?: VersionType
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, index?: never, preference?: never, realtime?: never, refresh?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, stored_fields?: never, version?: never, version_type?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, index?: never, preference?: never, realtime?: never, refresh?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, stored_fields?: never, version?: never, version_type?: never }
}

export type GetSourceResponse<TDocument = unknown> = TDocument

export interface HealthReportBaseIndicator {
  status: HealthReportIndicatorHealthStatus
  symptom: string
  impacts?: HealthReportImpact[]
  diagnosis?: HealthReportDiagnosis[]
}

export interface HealthReportDataStreamLifecycleDetails {
  stagnating_backing_indices_count: integer
  total_backing_indices_in_error: integer
  stagnating_backing_indices?: HealthReportStagnatingBackingIndices[]
}

export interface HealthReportDataStreamLifecycleIndicator extends HealthReportBaseIndicator {
  details?: HealthReportDataStreamLifecycleDetails
}

export interface HealthReportDiagnosis {
  id: string
  action: string
  affected_resources: HealthReportDiagnosisAffectedResources
  cause: string
  help_url: string
}

export interface HealthReportDiagnosisAffectedResources {
  indices?: Indices
  nodes?: HealthReportIndicatorNode[]
  slm_policies?: string[]
  feature_states?: string[]
  snapshot_repositories?: string[]
}

export interface HealthReportDiskIndicator extends HealthReportBaseIndicator {
  details?: HealthReportDiskIndicatorDetails
}

export interface HealthReportDiskIndicatorDetails {
  indices_with_readonly_block: long
  nodes_with_enough_disk_space: long
  nodes_over_high_watermark: long
  nodes_over_flood_stage_watermark: long
  nodes_with_unknown_disk_status: long
}

export interface HealthReportFileSettingsIndicator extends HealthReportBaseIndicator {
  details?: HealthReportFileSettingsIndicatorDetails
}

export interface HealthReportFileSettingsIndicatorDetails {
  failure_streak: long
  most_recent_failure: string
}

export interface HealthReportIlmIndicator extends HealthReportBaseIndicator {
  details?: HealthReportIlmIndicatorDetails
}

export interface HealthReportIlmIndicatorDetails {
  ilm_status: LifecycleOperationMode
  policies: long
  stagnating_indices: integer
}

export interface HealthReportImpact {
  description: string
  id: string
  impact_areas: HealthReportImpactArea[]
  severity: integer
}

export type HealthReportImpactArea = 'search' | 'ingest' | 'backup' | 'deployment_management'

export type HealthReportIndicatorHealthStatus = 'green' | 'yellow' | 'red' | 'unknown'

export interface HealthReportIndicatorNode {
  name: string | null
  node_id: string | null
}

export interface HealthReportIndicators {
  master_is_stable?: HealthReportMasterIsStableIndicator
  shards_availability?: HealthReportShardsAvailabilityIndicator
  disk?: HealthReportDiskIndicator
  repository_integrity?: HealthReportRepositoryIntegrityIndicator
  data_stream_lifecycle?: HealthReportDataStreamLifecycleIndicator
  ilm?: HealthReportIlmIndicator
  slm?: HealthReportSlmIndicator
  shards_capacity?: HealthReportShardsCapacityIndicator
  file_settings?: HealthReportFileSettingsIndicator
}

export interface HealthReportMasterIsStableIndicator extends HealthReportBaseIndicator {
  details?: HealthReportMasterIsStableIndicatorDetails
}

export interface HealthReportMasterIsStableIndicatorClusterFormationNode {
  name?: string
  node_id: string
  cluster_formation_message: string
}

export interface HealthReportMasterIsStableIndicatorDetails {
  current_master: HealthReportIndicatorNode
  recent_masters: HealthReportIndicatorNode[]
  exception_fetching_history?: HealthReportMasterIsStableIndicatorExceptionFetchingHistory
  cluster_formation?: HealthReportMasterIsStableIndicatorClusterFormationNode[]
}

export interface HealthReportMasterIsStableIndicatorExceptionFetchingHistory {
  message: string
  stack_trace: string
}

export interface HealthReportRepositoryIntegrityIndicator extends HealthReportBaseIndicator {
  details?: HealthReportRepositoryIntegrityIndicatorDetails
}

export interface HealthReportRepositoryIntegrityIndicatorDetails {
  total_repositories?: long
  corrupted_repositories?: long
  corrupted?: string[]
}

export interface HealthReportRequest extends RequestBase {
/** A feature of the cluster, as returned by the top-level health report API. */
  feature?: string | string[]
  /** Explicit operation timeout. */
  timeout?: Duration
  /** Opt-in for more information about the health of the system. */
  verbose?: boolean
  /** Limit the number of affected resources the health report API returns. */
  size?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { feature?: never, timeout?: never, verbose?: never, size?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { feature?: never, timeout?: never, verbose?: never, size?: never }
}

export interface HealthReportResponse {
  cluster_name: string
  indicators: HealthReportIndicators
  status?: HealthReportIndicatorHealthStatus
}

export interface HealthReportShardsAvailabilityIndicator extends HealthReportBaseIndicator {
  details?: HealthReportShardsAvailabilityIndicatorDetails
}

export interface HealthReportShardsAvailabilityIndicatorDetails {
  creating_primaries: long
  creating_replicas: long
  initializing_primaries: long
  initializing_replicas: long
  restarting_primaries: long
  restarting_replicas: long
  started_primaries: long
  started_replicas: long
  unassigned_primaries: long
  unassigned_replicas: long
}

export interface HealthReportShardsCapacityIndicator extends HealthReportBaseIndicator {
  details?: HealthReportShardsCapacityIndicatorDetails
}

export interface HealthReportShardsCapacityIndicatorDetails {
  data: HealthReportShardsCapacityIndicatorTierDetail
  frozen: HealthReportShardsCapacityIndicatorTierDetail
}

export interface HealthReportShardsCapacityIndicatorTierDetail {
  max_shards_in_cluster: integer
  current_used_shards?: integer
}

export interface HealthReportSlmIndicator extends HealthReportBaseIndicator {
  details?: HealthReportSlmIndicatorDetails
}

export interface HealthReportSlmIndicatorDetails {
  slm_status: LifecycleOperationMode
  policies: long
  unhealthy_policies?: HealthReportSlmIndicatorUnhealthyPolicies
}

export interface HealthReportSlmIndicatorUnhealthyPolicies {
  count: long
  invocations_since_last_success?: Record<string, long>
}

export interface HealthReportStagnatingBackingIndices {
  index_name: IndexName
  first_occurrence_timestamp: long
  retry_count: integer
}

export interface IndexRequest<TDocument = unknown> extends RequestBase {
/** A unique identifier for the document. To automatically generate a document ID, use the `POST /<target>/_doc/` request format and omit this parameter. */
  id?: Id
  /** The name of the data stream or index to target. If the target doesn't exist and matches the name or wildcard (`*`) pattern of an index template with a `data_stream` definition, this request creates the data stream. If the target doesn't exist and doesn't match a data stream template, this request creates the index. You can check for existing targets with the resolve index API. */
  index: IndexName
  /** Only perform the operation if the document has this primary term. */
  if_primary_term?: long
  /** Only perform the operation if the document has this sequence number. */
  if_seq_no?: SequenceNumber
  /** True or false if to include the document source in the error message in case of parsing errors. */
  include_source_on_error?: boolean
  /** Set to `create` to only index the document if it does not already exist (put if absent). If a document with the specified `_id` already exists, the indexing operation will fail. The behavior is the same as using the `<index>/_create` endpoint. If a document ID is specified, this paramater defaults to `index`. Otherwise, it defaults to `create`. If the request targets a data stream, an `op_type` of `create` is required. */
  op_type?: OpType
  /** The ID of the pipeline to use to preprocess incoming documents. If the index has a default ingest pipeline specified, then setting the value to `_none` disables the default ingest pipeline for this request. If a final pipeline is configured it will always run, regardless of the value of this parameter. */
  pipeline?: string
  /** If `true`, Elasticsearch refreshes the affected shards to make this operation visible to search. If `wait_for`, it waits for a refresh to make this operation visible to search. If `false`, it does nothing with refreshes. */
  refresh?: Refresh
  /** A custom value that is used to route operations to a specific shard. */
  routing?: Routing
  /** The period the request waits for the following operations: automatic index creation, dynamic mapping updates, waiting for active shards. This parameter is useful for situations where the primary shard assigned to perform the operation might not be available when the operation runs. Some reasons for this might be that the primary shard is currently recovering from a gateway or undergoing relocation. By default, the operation will wait on the primary shard to become available for at least 1 minute before failing and responding with an error. The actual wait time could be longer, particularly when multiple waits occur. */
  timeout?: Duration
  /** An explicit version number for concurrency control. It must be a non-negative long number. */
  version?: VersionNumber
  /** The version type. */
  version_type?: VersionType
  /** The number of shard copies that must be active before proceeding with the operation. You can set it to `all` or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). The default value of `1` means it waits for each primary shard to be active. */
  wait_for_active_shards?: WaitForActiveShards
  /** If `true`, the destination must be an index alias. */
  require_alias?: boolean
  document?: TDocument
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, index?: never, if_primary_term?: never, if_seq_no?: never, include_source_on_error?: never, op_type?: never, pipeline?: never, refresh?: never, routing?: never, timeout?: never, version?: never, version_type?: never, wait_for_active_shards?: never, require_alias?: never, document?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, index?: never, if_primary_term?: never, if_seq_no?: never, include_source_on_error?: never, op_type?: never, pipeline?: never, refresh?: never, routing?: never, timeout?: never, version?: never, version_type?: never, wait_for_active_shards?: never, require_alias?: never, document?: never }
}

export type IndexResponse = WriteResponseBase

export interface InfoRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface InfoResponse {
  cluster_name: Name
  cluster_uuid: Uuid
  name: Name
  tagline: string
  version: ElasticsearchVersionInfo
}

export interface KnnSearchRequest extends RequestBase {
/** A comma-separated list of index names to search; use `_all` or to perform the operation on all indices. */
  index: Indices
  /** A comma-separated list of specific routing values. */
  routing?: Routing
  /** Indicates which source fields are returned for matching documents. These fields are returned in the `hits._source` property of the search response. */
  _source?: SearchSourceConfig
  /** The request returns doc values for field names matching these patterns in the `hits.fields` property of the response. It accepts wildcard (`*`) patterns. */
  docvalue_fields?: (QueryDslFieldAndFormat | Field)[]
  /** A list of stored fields to return as part of a hit. If no fields are specified, no stored fields are included in the response. If this field is specified, the `_source` parameter defaults to `false`. You can pass `_source: true` to return both source fields and stored fields in the search response. */
  stored_fields?: Fields
  /** The request returns values for field names matching these patterns in the `hits.fields` property of the response. It accepts wildcard (`*`) patterns. */
  fields?: Fields
  /** A query to filter the documents that can match. The kNN search will return the top `k` documents that also match this filter. The value can be a single query or a list of queries. If `filter` isn't provided, all documents are allowed to match. */
  filter?: QueryDslQueryContainer | QueryDslQueryContainer[]
  /** The kNN query to run. */
  knn: KnnSearchQuery
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, routing?: never, _source?: never, docvalue_fields?: never, stored_fields?: never, fields?: never, filter?: never, knn?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, routing?: never, _source?: never, docvalue_fields?: never, stored_fields?: never, fields?: never, filter?: never, knn?: never }
}

export interface KnnSearchResponse<TDocument = unknown> {
  took: long
  timed_out: boolean
  _shards: ShardStatistics
  hits: SearchHitsMetadata<TDocument>
  fields?: Record<string, any>
  max_score?: double
}

export interface KnnSearchQuery {
  field: Field
  query_vector: QueryVector
  k: integer
  num_candidates: integer
}

export interface MgetMultiGetError {
  error: ErrorCause
  _id: Id
  _index: IndexName
}

export interface MgetOperation {
  _id: Id
  _index?: IndexName
  routing?: Routing
  _source?: SearchSourceConfig
  stored_fields?: Fields
  version?: VersionNumber
  version_type?: VersionType
}

export interface MgetRequest extends RequestBase {
/** Name of the index to retrieve documents from when `ids` are specified, or when a document in the `docs` array does not specify an index. */
  index?: IndexName
  /** Should this request force synthetic _source? Use this to test if the mapping supports synthetic _source and to get a sense of the worst case performance. Fetches with this enabled will be slower the enabling synthetic source natively in the index. */
  force_synthetic_source?: boolean
  /** Specifies the node or shard the operation should be performed on. Random by default. */
  preference?: string
  /** If `true`, the request is real-time as opposed to near-real-time. */
  realtime?: boolean
  /** If `true`, the request refreshes relevant shards before retrieving documents. */
  refresh?: boolean
  /** Custom value used to route operations to a specific shard. */
  routing?: Routing
  /** True or false to return the `_source` field or not, or a list of fields to return. */
  _source?: SearchSourceConfigParam
  /** A comma-separated list of source fields to exclude from the response. You can also use this parameter to exclude fields from the subset specified in `_source_includes` query parameter. */
  _source_excludes?: Fields
  /** A comma-separated list of source fields to include in the response. If this parameter is specified, only these source fields are returned. You can exclude fields from this subset using the `_source_excludes` query parameter. If the `_source` parameter is `false`, this parameter is ignored. */
  _source_includes?: Fields
  /** If `true`, retrieves the document fields stored in the index rather than the document `_source`. */
  stored_fields?: Fields
  /** The documents you want to retrieve. Required if no index is specified in the request URI. */
  docs?: MgetOperation[]
  /** The IDs of the documents you want to retrieve. Allowed when the index is specified in the request URI. */
  ids?: Ids
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, force_synthetic_source?: never, preference?: never, realtime?: never, refresh?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, stored_fields?: never, docs?: never, ids?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, force_synthetic_source?: never, preference?: never, realtime?: never, refresh?: never, routing?: never, _source?: never, _source_excludes?: never, _source_includes?: never, stored_fields?: never, docs?: never, ids?: never }
}

export interface MgetResponse<TDocument = unknown> {
  docs: MgetResponseItem<TDocument>[]
}

export type MgetResponseItem<TDocument = unknown> = GetGetResult<TDocument> | MgetMultiGetError

export interface MsearchMultiSearchItem<TDocument = unknown> extends SearchResponseBody<TDocument> {
  status?: integer
}

export interface MsearchMultiSearchResult<TDocument = unknown, TAggregations = Record<AggregateName, AggregationsAggregate>> {
  took: long
  responses: MsearchResponseItem<TDocument>[]
}

export interface MsearchMultisearchBody {
  aggregations?: Record<string, AggregationsAggregationContainer>
  aggs?: Record<string, AggregationsAggregationContainer>
  collapse?: SearchFieldCollapse
  query?: QueryDslQueryContainer
  explain?: boolean
  ext?: Record<string, any>
  stored_fields?: Fields
  docvalue_fields?: (QueryDslFieldAndFormat | Field)[]
  knn?: KnnSearch | KnnSearch[]
  from?: integer
  highlight?: SearchHighlight
  indices_boost?: Record<IndexName, double>[]
  min_score?: double
  post_filter?: QueryDslQueryContainer
  profile?: boolean
  rescore?: SearchRescore | SearchRescore[]
  script_fields?: Record<string, ScriptField>
  search_after?: SortResults
  size?: integer
  sort?: Sort
  _source?: SearchSourceConfig
  fields?: (QueryDslFieldAndFormat | Field)[]
  terminate_after?: long
  stats?: string[]
  timeout?: string
  track_scores?: boolean
  track_total_hits?: SearchTrackHits
  version?: boolean
  runtime_mappings?: MappingRuntimeFields
  seq_no_primary_term?: boolean
  pit?: SearchPointInTimeReference
  suggest?: SearchSuggester
}

export interface MsearchMultisearchHeader {
  allow_no_indices?: boolean
  expand_wildcards?: ExpandWildcards
  ignore_unavailable?: boolean
  index?: Indices
  preference?: string
  request_cache?: boolean
  routing?: Routing
  search_type?: SearchType
  ccs_minimize_roundtrips?: boolean
  allow_partial_search_results?: boolean
  ignore_throttled?: boolean
}

export interface MsearchRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and index aliases to search. */
  index?: Indices
  /** If false, the request returns an error if any wildcard expression, index alias, or _all value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting foo*,bar* returns an error if an index starts with foo but no index starts with bar. */
  allow_no_indices?: boolean
  /** If true, network roundtrips between the coordinating node and remote clusters are minimized for cross-cluster search requests. */
  ccs_minimize_roundtrips?: boolean
  /** Type of index that wildcard expressions can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. */
  expand_wildcards?: ExpandWildcards
  /** If true, concrete, expanded or aliased indices are ignored when frozen. */
  ignore_throttled?: boolean
  /** If true, missing or closed indices are not included in the response. */
  ignore_unavailable?: boolean
  /** Indicates whether hit.matched_queries should be rendered as a map that includes the name of the matched query associated with its score (true) or as an array containing the name of the matched queries (false) This functionality reruns each named query on every hit in a search response. Typically, this adds a small overhead to a request. However, using computationally expensive named queries on a large number of hits may add significant overhead. */
  include_named_queries_score?: boolean
  /** Maximum number of concurrent searches the multi search API can execute. */
  max_concurrent_searches?: long
  /** Maximum number of concurrent shard requests that each sub-search request executes per node. */
  max_concurrent_shard_requests?: long
  /** Defines a threshold that enforces a pre-filter roundtrip to prefilter search shards based on query rewriting if the number of shards the search request expands to exceeds the threshold. This filter roundtrip can limit the number of shards significantly if for instance a shard can not match any documents based on its rewrite method i.e., if date filters are mandatory to match but the shard bounds and the query are disjoint. */
  pre_filter_shard_size?: long
  /** If true, hits.total are returned as an integer in the response. Defaults to false, which returns an object. */
  rest_total_hits_as_int?: boolean
  /** Custom routing value used to route search operations to a specific shard. */
  routing?: Routing
  /** Indicates whether global term and document frequencies should be used when scoring returned documents. */
  search_type?: SearchType
  /** Specifies whether aggregation and suggester names should be prefixed by their respective types in the response. */
  typed_keys?: boolean
  searches?: MsearchRequestItem[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, ccs_minimize_roundtrips?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, include_named_queries_score?: never, max_concurrent_searches?: never, max_concurrent_shard_requests?: never, pre_filter_shard_size?: never, rest_total_hits_as_int?: never, routing?: never, search_type?: never, typed_keys?: never, searches?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, ccs_minimize_roundtrips?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, include_named_queries_score?: never, max_concurrent_searches?: never, max_concurrent_shard_requests?: never, pre_filter_shard_size?: never, rest_total_hits_as_int?: never, routing?: never, search_type?: never, typed_keys?: never, searches?: never }
}

export type MsearchRequestItem = MsearchMultisearchHeader | MsearchMultisearchBody

export type MsearchResponse<TDocument = unknown, TAggregations = Record<AggregateName, AggregationsAggregate>> = MsearchMultiSearchResult<TDocument, TAggregations>

export type MsearchResponseItem<TDocument = unknown> = MsearchMultiSearchItem<TDocument> | ErrorResponseBase

export interface MsearchTemplateRequest extends RequestBase {
/** A comma-separated list of data streams, indices, and aliases to search. It supports wildcards (`*`). To search all data streams and indices, omit this parameter or use `*`. */
  index?: Indices
  /** If `true`, network round-trips are minimized for cross-cluster search requests. */
  ccs_minimize_roundtrips?: boolean
  /** The maximum number of concurrent searches the API can run. */
  max_concurrent_searches?: long
  /** The type of the search operation. */
  search_type?: SearchType
  /** If `true`, the response returns `hits.total` as an integer. If `false`, it returns `hits.total` as an object. */
  rest_total_hits_as_int?: boolean
  /** If `true`, the response prefixes aggregation and suggester names with their respective types. */
  typed_keys?: boolean
  search_templates?: MsearchTemplateRequestItem[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, ccs_minimize_roundtrips?: never, max_concurrent_searches?: never, search_type?: never, rest_total_hits_as_int?: never, typed_keys?: never, search_templates?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, ccs_minimize_roundtrips?: never, max_concurrent_searches?: never, search_type?: never, rest_total_hits_as_int?: never, typed_keys?: never, search_templates?: never }
}

export type MsearchTemplateRequestItem = MsearchMultisearchHeader | MsearchTemplateTemplateConfig

export type MsearchTemplateResponse<TDocument = unknown, TAggregations = Record<AggregateName, AggregationsAggregate>> = MsearchMultiSearchResult<TDocument, TAggregations>

export interface MsearchTemplateTemplateConfig {
  explain?: boolean
  id?: Id
  params?: Record<string, any>
  profile?: boolean
  source?: string
}

export interface MtermvectorsOperation {
  _id?: Id
  _index?: IndexName
  doc?: any
  fields?: Fields
  field_statistics?: boolean
  filter?: TermvectorsFilter
  offsets?: boolean
  payloads?: boolean
  positions?: boolean
  routing?: Routing
  term_statistics?: boolean
  version?: VersionNumber
  version_type?: VersionType
}

export interface MtermvectorsRequest extends RequestBase {
/** The name of the index that contains the documents. */
  index?: IndexName
  /** A comma-separated list or wildcard expressions of fields to include in the statistics. It is used as the default list unless a specific field list is provided in the `completion_fields` or `fielddata_fields` parameters. */
  fields?: Fields
  /** If `true`, the response includes the document count, sum of document frequencies, and sum of total term frequencies. */
  field_statistics?: boolean
  /** If `true`, the response includes term offsets. */
  offsets?: boolean
  /** If `true`, the response includes term payloads. */
  payloads?: boolean
  /** If `true`, the response includes term positions. */
  positions?: boolean
  /** The node or shard the operation should be performed on. It is random by default. */
  preference?: string
  /** If true, the request is real-time as opposed to near-real-time. */
  realtime?: boolean
  /** A custom value used to route operations to a specific shard. */
  routing?: Routing
  /** If true, the response includes term frequency and document frequency. */
  term_statistics?: boolean
  /** If `true`, returns the document version as part of a hit. */
  version?: VersionNumber
  /** The version type. */
  version_type?: VersionType
  /** An array of existing or artificial documents. */
  docs?: MtermvectorsOperation[]
  /** A simplified syntax to specify documents by their ID if they're in the same index. */
  ids?: Id[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, fields?: never, field_statistics?: never, offsets?: never, payloads?: never, positions?: never, preference?: never, realtime?: never, routing?: never, term_statistics?: never, version?: never, version_type?: never, docs?: never, ids?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, fields?: never, field_statistics?: never, offsets?: never, payloads?: never, positions?: never, preference?: never, realtime?: never, routing?: never, term_statistics?: never, version?: never, version_type?: never, docs?: never, ids?: never }
}

export interface MtermvectorsResponse {
  docs: MtermvectorsTermVectorsResult[]
}

export interface MtermvectorsTermVectorsResult {
  _id?: Id
  _index: IndexName
  _version?: VersionNumber
  took?: long
  found?: boolean
  term_vectors?: Record<Field, TermvectorsTermVector>
  error?: ErrorCause
}

export interface OpenPointInTimeRequest extends RequestBase {
/** A comma-separated list of index names to open point in time; use `_all` or empty string to perform the operation on all indices */
  index: Indices
  /** Extend the length of time that the point in time persists. */
  keep_alive: Duration
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** The node or shard the operation should be performed on. By default, it is random. */
  preference?: string
  /** A custom value that is used to route operations to a specific shard. */
  routing?: Routing
  /** The type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. It supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** Indicates whether the point in time tolerates unavailable shards or shard failures when initially creating the PIT. If `false`, creating a point in time request when a shard is missing or unavailable will throw an exception. If `true`, the point in time will contain all the shards that are available at the time of the request. */
  allow_partial_search_results?: boolean
  /** Filter indices if the provided query rewrites to `match_none` on every shard. */
  index_filter?: QueryDslQueryContainer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, keep_alive?: never, ignore_unavailable?: never, preference?: never, routing?: never, expand_wildcards?: never, allow_partial_search_results?: never, index_filter?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, keep_alive?: never, ignore_unavailable?: never, preference?: never, routing?: never, expand_wildcards?: never, allow_partial_search_results?: never, index_filter?: never }
}

export interface OpenPointInTimeResponse {
  _shards: ShardStatistics
  id: Id
}

export interface PingRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export type PingResponse = boolean

export interface PutScriptRequest extends RequestBase {
/** The identifier for the stored script or search template. It must be unique within the cluster. */
  id: Id
  /** The context in which the script or search template should run. To prevent errors, the API immediately compiles the script or template in this context. */
  context?: Name
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  timeout?: Duration
  /** The script or search template, its parameters, and its language. */
  script: StoredScript
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, context?: never, master_timeout?: never, timeout?: never, script?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, context?: never, master_timeout?: never, timeout?: never, script?: never }
}

export type PutScriptResponse = AcknowledgedResponseBase

export interface RankEvalDocumentRating {
  _id: Id
  _index: IndexName
  rating: integer
}

export interface RankEvalRankEvalHit {
  _id: Id
  _index: IndexName
  _score: double
}

export interface RankEvalRankEvalHitItem {
  hit: RankEvalRankEvalHit
  rating?: double | null
}

export interface RankEvalRankEvalMetric {
  precision?: RankEvalRankEvalMetricPrecision
  recall?: RankEvalRankEvalMetricRecall
  mean_reciprocal_rank?: RankEvalRankEvalMetricMeanReciprocalRank
  dcg?: RankEvalRankEvalMetricDiscountedCumulativeGain
  expected_reciprocal_rank?: RankEvalRankEvalMetricExpectedReciprocalRank
}

export interface RankEvalRankEvalMetricBase {
  k?: integer
}

export interface RankEvalRankEvalMetricDetail {
  metric_score: double
  unrated_docs: RankEvalUnratedDocument[]
  hits: RankEvalRankEvalHitItem[]
  metric_details: Record<string, Record<string, any>>
}

export interface RankEvalRankEvalMetricDiscountedCumulativeGain extends RankEvalRankEvalMetricBase {
  normalize?: boolean
}

export interface RankEvalRankEvalMetricExpectedReciprocalRank extends RankEvalRankEvalMetricBase {
  maximum_relevance: integer
}

export interface RankEvalRankEvalMetricMeanReciprocalRank extends RankEvalRankEvalMetricRatingTreshold {
}

export interface RankEvalRankEvalMetricPrecision extends RankEvalRankEvalMetricRatingTreshold {
  ignore_unlabeled?: boolean
}

export interface RankEvalRankEvalMetricRatingTreshold extends RankEvalRankEvalMetricBase {
  relevant_rating_threshold?: integer
}

export interface RankEvalRankEvalMetricRecall extends RankEvalRankEvalMetricRatingTreshold {
}

export interface RankEvalRankEvalQuery {
  query: QueryDslQueryContainer
  size?: integer
}

export interface RankEvalRankEvalRequestItem {
  id: Id
  request?: RankEvalRankEvalQuery | QueryDslQueryContainer
  ratings: RankEvalDocumentRating[]
  template_id?: Id
  params?: Record<string, any>
}

export interface RankEvalRequest extends RequestBase {
/** A comma-separated list of data streams, indices, and index aliases used to limit the request. Wildcard (`*`) expressions are supported. To target all data streams and indices in a cluster, omit this parameter or use `_all` or `*`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. */
  allow_no_indices?: boolean
  /** Whether to expand wildcard expression to concrete indices that are open, closed or both. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, missing or closed indices are not included in the response. */
  ignore_unavailable?: boolean
  /** Search operation type */
  search_type?: string
  /** A set of typical search requests, together with their provided ratings. */
  requests: RankEvalRankEvalRequestItem[]
  /** Definition of the evaluation metric to calculate. */
  metric?: RankEvalRankEvalMetric
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, search_type?: never, requests?: never, metric?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, search_type?: never, requests?: never, metric?: never }
}

export interface RankEvalResponse {
  metric_score: double
  details: Record<Id, RankEvalRankEvalMetricDetail>
  failures: Record<string, any>
}

export interface RankEvalUnratedDocument {
  _id: Id
  _index: IndexName
}

export interface ReindexDestination {
  index: IndexName
  op_type?: OpType
  pipeline?: string
  routing?: Routing
  version_type?: VersionType
}

export interface ReindexRemoteSource {
  connect_timeout?: Duration
  headers?: Record<string, string>
  host: Host
  username?: Username
  password?: Password
  socket_timeout?: Duration
}

export interface ReindexRequest extends RequestBase {
/** If `true`, the request refreshes affected shards to make this operation visible to search. */
  refresh?: boolean
  /** The throttle for this request in sub-requests per second. By default, there is no throttle. */
  requests_per_second?: float
  /** The period of time that a consistent view of the index should be maintained for scrolled search. */
  scroll?: Duration
  /** The number of slices this task should be divided into. It defaults to one slice, which means the task isn't sliced into subtasks. Reindex supports sliced scroll to parallelize the reindexing process. This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts. NOTE: Reindexing from remote clusters does not support manual or automatic slicing. If set to `auto`, Elasticsearch chooses the number of slices to use. This setting will use one slice per shard, up to a certain limit. If there are multiple sources, it will choose the number of slices based on the index or backing index with the smallest number of shards. */
  slices?: Slices
  /** The period each indexing waits for automatic index creation, dynamic mapping updates, and waiting for active shards. By default, Elasticsearch waits for at least one minute before failing. The actual wait time could be longer, particularly when multiple waits occur. */
  timeout?: Duration
  /** The number of shard copies that must be active before proceeding with the operation. Set it to `all` or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). The default value is one, which means it waits for each primary shard to be active. */
  wait_for_active_shards?: WaitForActiveShards
  /** If `true`, the request blocks until the operation is complete. */
  wait_for_completion?: boolean
  /** If `true`, the destination must be an index alias. */
  require_alias?: boolean
  /** Indicates whether to continue reindexing even when there are conflicts. */
  conflicts?: Conflicts
  /** The destination you are copying to. */
  dest: ReindexDestination
  /** The maximum number of documents to reindex. By default, all documents are reindexed. If it is a value less then or equal to `scroll_size`, a scroll will not be used to retrieve the results for the operation. If `conflicts` is set to `proceed`, the reindex operation could attempt to reindex more documents from the source than `max_docs` until it has successfully indexed `max_docs` documents into the target or it has gone through every document in the source query. */
  max_docs?: long
  /** The script to run to update the document source or metadata when reindexing. */
  script?: Script | string
  size?: long
  /** The source you are copying from. */
  source: ReindexSource
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { refresh?: never, requests_per_second?: never, scroll?: never, slices?: never, timeout?: never, wait_for_active_shards?: never, wait_for_completion?: never, require_alias?: never, conflicts?: never, dest?: never, max_docs?: never, script?: never, size?: never, source?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { refresh?: never, requests_per_second?: never, scroll?: never, slices?: never, timeout?: never, wait_for_active_shards?: never, wait_for_completion?: never, require_alias?: never, conflicts?: never, dest?: never, max_docs?: never, script?: never, size?: never, source?: never }
}

export interface ReindexResponse {
  batches?: long
  created?: long
  deleted?: long
  failures?: BulkIndexByScrollFailure[]
  noops?: long
  retries?: Retries
  requests_per_second?: float
  slice_id?: integer
  task?: TaskId
  throttled_millis?: EpochTime<UnitMillis>
  throttled_until_millis?: EpochTime<UnitMillis>
  timed_out?: boolean
  took?: DurationValue<UnitMillis>
  total?: long
  updated?: long
  version_conflicts?: long
}

export interface ReindexSource {
  index: Indices
  query?: QueryDslQueryContainer
  remote?: ReindexRemoteSource
  size?: integer
  slice?: SlicedScroll
  sort?: Sort
  _source?: Fields
  runtime_mappings?: MappingRuntimeFields
}

export interface ReindexRethrottleReindexNode extends SpecUtilsBaseNode {
  tasks: Record<TaskId, ReindexRethrottleReindexTask>
}

export interface ReindexRethrottleReindexStatus {
  batches: long
  created: long
  deleted: long
  noops: long
  requests_per_second: float
  retries: Retries
  throttled?: Duration
  throttled_millis: DurationValue<UnitMillis>
  throttled_until?: Duration
  throttled_until_millis: DurationValue<UnitMillis>
  total: long
  updated: long
  version_conflicts: long
}

export interface ReindexRethrottleReindexTask {
  action: string
  cancellable: boolean
  description: string
  id: long
  node: Name
  running_time_in_nanos: DurationValue<UnitNanos>
  start_time_in_millis: EpochTime<UnitMillis>
  status: ReindexRethrottleReindexStatus
  type: string
  headers: HttpHeaders
}

export interface ReindexRethrottleRequest extends RequestBase {
/** The task identifier, which can be found by using the tasks API. */
  task_id: Id
  /** The throttle for this request in sub-requests per second. It can be either `-1` to turn off throttling or any decimal number like `1.7` or `12` to throttle to that level. */
  requests_per_second?: float
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { task_id?: never, requests_per_second?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { task_id?: never, requests_per_second?: never }
}

export interface ReindexRethrottleResponse {
  nodes: Record<string, ReindexRethrottleReindexNode>
}

export interface RenderSearchTemplateRequest extends RequestBase {
/** The ID of the search template to render. If no `source` is specified, this or the `id` request body parameter is required. */
  id?: Id
  file?: string
  /** Key-value pairs used to replace Mustache variables in the template. The key is the variable name. The value is the variable value. */
  params?: Record<string, any>
  /** An inline search template. It supports the same parameters as the search API's request body. These parameters also support Mustache variables. If no `id` or `<templated-id>` is specified, this parameter is required. */
  source?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, file?: never, params?: never, source?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, file?: never, params?: never, source?: never }
}

export interface RenderSearchTemplateResponse {
  template_output: Record<string, any>
}

export type ScriptsPainlessExecutePainlessContext = 'painless_test' | 'filter' | 'score' | 'boolean_field' | 'date_field' | 'double_field' | 'geo_point_field' | 'ip_field' | 'keyword_field' | 'long_field' | 'composite_field'

export interface ScriptsPainlessExecutePainlessContextSetup {
  document: any
  index: IndexName
  query?: QueryDslQueryContainer
}

export interface ScriptsPainlessExecuteRequest extends RequestBase {
/** The context that the script should run in. NOTE: Result ordering in the field contexts is not guaranteed. */
  context?: ScriptsPainlessExecutePainlessContext
  /** Additional parameters for the `context`. NOTE: This parameter is required for all contexts except `painless_test`, which is the default if no value is provided for `context`. */
  context_setup?: ScriptsPainlessExecutePainlessContextSetup
  /** The Painless script to run. */
  script?: Script | string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { context?: never, context_setup?: never, script?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { context?: never, context_setup?: never, script?: never }
}

export interface ScriptsPainlessExecuteResponse<TResult = unknown> {
  result: TResult
}

export interface ScrollRequest extends RequestBase {
/** The scroll ID */
  scroll_id?: ScrollId
  /** If true, the API response’s hit.total property is returned as an integer. If false, the API response’s hit.total property is returned as an object. */
  rest_total_hits_as_int?: boolean
  /** The period to retain the search context for scrolling. */
  scroll?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { scroll_id?: never, rest_total_hits_as_int?: never, scroll?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { scroll_id?: never, rest_total_hits_as_int?: never, scroll?: never }
}

export type ScrollResponse<TDocument = unknown, TAggregations = Record<AggregateName, AggregationsAggregate>> = SearchResponseBody<TDocument, TAggregations>

export interface SearchRequest extends RequestBase {
/** A comma-separated list of data streams, indices, and aliases to search. It supports wildcards (`*`). To search all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. */
  allow_no_indices?: boolean
  /** If `true` and there are shard request timeouts or shard failures, the request returns partial results. If `false`, it returns an error with no partial results. To override the default behavior, you can set the `search.default_allow_partial_results` cluster setting to `false`. */
  allow_partial_search_results?: boolean
  /** The analyzer to use for the query string. This parameter can be used only when the `q` query string parameter is specified. */
  analyzer?: string
  /** If `true`, wildcard and prefix queries are analyzed. This parameter can be used only when the `q` query string parameter is specified. */
  analyze_wildcard?: boolean
  /** The number of shard results that should be reduced at once on the coordinating node. If the potential number of shards in the request can be large, this value should be used as a protection mechanism to reduce the memory overhead per search request. */
  batched_reduce_size?: long
  /** If `true`, network round-trips between the coordinating node and the remote clusters are minimized when running cross-cluster search (CCS) requests. */
  ccs_minimize_roundtrips?: boolean
  /** The default operator for the query string query: `AND` or `OR`. This parameter can be used only when the `q` query string parameter is specified. */
  default_operator?: QueryDslOperator
  /** The field to use as a default when no field prefix is given in the query string. This parameter can be used only when the `q` query string parameter is specified. */
  df?: string
  /** The type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. It supports comma-separated values such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, concrete, expanded or aliased indices will be ignored when frozen. */
  ignore_throttled?: boolean
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** If `true`, the response includes the score contribution from any named queries. This functionality reruns each named query on every hit in a search response. Typically, this adds a small overhead to a request. However, using computationally expensive named queries on a large number of hits may add significant overhead. */
  include_named_queries_score?: boolean
  /** If `true`, format-based query failures (such as providing text to a numeric field) in the query string will be ignored. This parameter can be used only when the `q` query string parameter is specified. */
  lenient?: boolean
  /** The number of concurrent shard requests per node that the search runs concurrently. This value should be used to limit the impact of the search on the cluster in order to limit the number of concurrent shard requests. */
  max_concurrent_shard_requests?: long
  /** The nodes and shards used for the search. By default, Elasticsearch selects from eligible nodes and shards using adaptive replica selection, accounting for allocation awareness. Valid values are: * `_only_local` to run the search only on shards on the local node. * `_local` to, if possible, run the search on shards on the local node, or if not, select shards using the default method. * `_only_nodes:<node-id>,<node-id>` to run the search on only the specified nodes IDs. If suitable shards exist on more than one selected node, use shards on those nodes using the default method. If none of the specified nodes are available, select shards from any available node using the default method. * `_prefer_nodes:<node-id>,<node-id>` to if possible, run the search on the specified nodes IDs. If not, select shards using the default method. `_shards:<shard>,<shard>` to run the search only on the specified shards. You can combine this value with other `preference` values. However, the `_shards` value must come first. For example: `_shards:2,3|_local`. `<custom-string>` (any string that does not start with `_`) to route searches with the same `<custom-string>` to the same shards in the same order. */
  preference?: string
  /** A threshold that enforces a pre-filter roundtrip to prefilter search shards based on query rewriting if the number of shards the search request expands to exceeds the threshold. This filter roundtrip can limit the number of shards significantly if for instance a shard can not match any documents based on its rewrite method (if date filters are mandatory to match but the shard bounds and the query are disjoint). When unspecified, the pre-filter phase is executed if any of these conditions is met: * The request targets more than 128 shards. * The request targets one or more read-only index. * The primary sort of the query targets an indexed field. */
  pre_filter_shard_size?: long
  /** If `true`, the caching of search results is enabled for requests where `size` is `0`. It defaults to index level settings. */
  request_cache?: boolean
  /** A custom value that is used to route operations to a specific shard. */
  routing?: Routing
  /** The period to retain the search context for scrolling. By default, this value cannot exceed `1d` (24 hours). You can change this limit by using the `search.max_keep_alive` cluster-level setting. */
  scroll?: Duration
  /** Indicates how distributed term frequencies are calculated for relevance scoring. */
  search_type?: SearchType
  /** The field to use for suggestions. */
  suggest_field?: Field
  /** The suggest mode. This parameter can be used only when the `suggest_field` and `suggest_text` query string parameters are specified. */
  suggest_mode?: SuggestMode
  /** The number of suggestions to return. This parameter can be used only when the `suggest_field` and `suggest_text` query string parameters are specified. */
  suggest_size?: long
  /** The source text for which the suggestions should be returned. This parameter can be used only when the `suggest_field` and `suggest_text` query string parameters are specified. */
  suggest_text?: string
  /** If `true`, aggregation and suggester names are be prefixed by their respective types in the response. */
  typed_keys?: boolean
  /** Indicates whether `hits.total` should be rendered as an integer or an object in the rest search response. */
  rest_total_hits_as_int?: boolean
  /** A comma-separated list of source fields to exclude from the response. You can also use this parameter to exclude fields from the subset specified in `_source_includes` query parameter. If the `_source` parameter is `false`, this parameter is ignored. */
  _source_excludes?: Fields
  /** A comma-separated list of source fields to include in the response. If this parameter is specified, only these source fields are returned. You can exclude fields from this subset using the `_source_excludes` query parameter. If the `_source` parameter is `false`, this parameter is ignored. */
  _source_includes?: Fields
  /** A query in the Lucene query string syntax. Query parameter searches do not support the full Elasticsearch Query DSL but are handy for testing. IMPORTANT: This parameter overrides the query parameter in the request body. If both parameters are specified, documents matching the query request body parameter are not returned. */
  q?: string
  /** Should this request force synthetic _source? Use this to test if the mapping supports synthetic _source and to get a sense of the worst case performance. Fetches with this enabled will be slower the enabling synthetic source natively in the index. */
  force_synthetic_source?: boolean
  /** Defines the aggregations that are run as part of the search request. */
  aggregations?: Record<string, AggregationsAggregationContainer>
  /** @alias aggregations */
  /** Defines the aggregations that are run as part of the search request. */
  aggs?: Record<string, AggregationsAggregationContainer>
  /** Collapses search results the values of the specified field. */
  collapse?: SearchFieldCollapse
  /** If `true`, the request returns detailed information about score computation as part of a hit. */
  explain?: boolean
  /** Configuration of search extensions defined by Elasticsearch plugins. */
  ext?: Record<string, any>
  /** The starting document offset, which must be non-negative. By default, you cannot page through more than 10,000 hits using the `from` and `size` parameters. To page through more hits, use the `search_after` parameter. */
  from?: integer
  /** Specifies the highlighter to use for retrieving highlighted snippets from one or more fields in your search results. */
  highlight?: SearchHighlight
  /** Number of hits matching the query to count accurately. If `true`, the exact number of hits is returned at the cost of some performance. If `false`, the response does not include the total number of hits matching the query. */
  track_total_hits?: SearchTrackHits
  /** Boost the `_score` of documents from specified indices. The boost value is the factor by which scores are multiplied. A boost value greater than `1.0` increases the score. A boost value between `0` and `1.0` decreases the score. */
  indices_boost?: Record<IndexName, double>[]
  /** An array of wildcard (`*`) field patterns. The request returns doc values for field names matching these patterns in the `hits.fields` property of the response. */
  docvalue_fields?: (QueryDslFieldAndFormat | Field)[]
  /** The approximate kNN search to run. */
  knn?: KnnSearch | KnnSearch[]
  /** The Reciprocal Rank Fusion (RRF) to use. */
  rank?: RankContainer
  /** The minimum `_score` for matching documents. Documents with a lower `_score` are not included in the search results. */
  min_score?: double
  /** Use the `post_filter` parameter to filter search results. The search hits are filtered after the aggregations are calculated. A post filter has no impact on the aggregation results. */
  post_filter?: QueryDslQueryContainer
  /** Set to `true` to return detailed timing information about the execution of individual components in a search request. NOTE: This is a debugging tool and adds significant overhead to search execution. */
  profile?: boolean
  /** The search definition using the Query DSL. */
  query?: QueryDslQueryContainer
  /** Can be used to improve precision by reordering just the top (for example 100 - 500) documents returned by the `query` and `post_filter` phases. */
  rescore?: SearchRescore | SearchRescore[]
  /** A retriever is a specification to describe top documents returned from a search. A retriever replaces other elements of the search API that also return top documents such as `query` and `knn`. */
  retriever?: RetrieverContainer
  /** Retrieve a script evaluation (based on different fields) for each hit. */
  script_fields?: Record<string, ScriptField>
  /** Used to retrieve the next page of hits using a set of sort values from the previous page. */
  search_after?: SortResults
  /** The number of hits to return, which must not be negative. By default, you cannot page through more than 10,000 hits using the `from` and `size` parameters. To page through more hits, use the `search_after` property. */
  size?: integer
  /** Split a scrolled search into multiple slices that can be consumed independently. */
  slice?: SlicedScroll
  /** A comma-separated list of <field>:<direction> pairs. */
  sort?: Sort
  /** The source fields that are returned for matching documents. These fields are returned in the `hits._source` property of the search response. If the `stored_fields` property is specified, the `_source` property defaults to `false`. Otherwise, it defaults to `true`. */
  _source?: SearchSourceConfig
  /** An array of wildcard (`*`) field patterns. The request returns values for field names matching these patterns in the `hits.fields` property of the response. */
  fields?: (QueryDslFieldAndFormat | Field)[]
  /** Defines a suggester that provides similar looking terms based on a provided text. */
  suggest?: SearchSuggester
  /** The maximum number of documents to collect for each shard. If a query reaches this limit, Elasticsearch terminates the query early. Elasticsearch collects documents before sorting. IMPORTANT: Use with caution. Elasticsearch applies this property to each shard handling the request. When possible, let Elasticsearch perform early termination automatically. Avoid specifying this property for requests that target data streams with backing indices across multiple data tiers. If set to `0` (default), the query does not terminate early. */
  terminate_after?: long
  /** The period of time to wait for a response from each shard. If no response is received before the timeout expires, the request fails and returns an error. Defaults to no timeout. */
  timeout?: string
  /** If `true`, calculate and return document scores, even if the scores are not used for sorting. */
  track_scores?: boolean
  /** If `true`, the request returns the document version as part of a hit. */
  version?: boolean
  /** If `true`, the request returns sequence number and primary term of the last modification of each hit. */
  seq_no_primary_term?: boolean
  /** A comma-separated list of stored fields to return as part of a hit. If no fields are specified, no stored fields are included in the response. If this field is specified, the `_source` property defaults to `false`. You can pass `_source: true` to return both source fields and stored fields in the search response. */
  stored_fields?: Fields
  /** Limit the search to a point in time (PIT). If you provide a PIT, you cannot specify an `<index>` in the request path. */
  pit?: SearchPointInTimeReference
  /** One or more runtime fields in the search request. These fields take precedence over mapped fields with the same name. */
  runtime_mappings?: MappingRuntimeFields
  /** The stats groups to associate with the search. Each group maintains a statistics aggregation for its associated searches. You can retrieve these stats using the indices stats API. */
  stats?: string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, allow_partial_search_results?: never, analyzer?: never, analyze_wildcard?: never, batched_reduce_size?: never, ccs_minimize_roundtrips?: never, default_operator?: never, df?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, include_named_queries_score?: never, lenient?: never, max_concurrent_shard_requests?: never, preference?: never, pre_filter_shard_size?: never, request_cache?: never, routing?: never, scroll?: never, search_type?: never, suggest_field?: never, suggest_mode?: never, suggest_size?: never, suggest_text?: never, typed_keys?: never, rest_total_hits_as_int?: never, _source_excludes?: never, _source_includes?: never, q?: never, force_synthetic_source?: never, aggregations?: never, aggs?: never, collapse?: never, explain?: never, ext?: never, from?: never, highlight?: never, track_total_hits?: never, indices_boost?: never, docvalue_fields?: never, knn?: never, rank?: never, min_score?: never, post_filter?: never, profile?: never, query?: never, rescore?: never, retriever?: never, script_fields?: never, search_after?: never, size?: never, slice?: never, sort?: never, _source?: never, fields?: never, suggest?: never, terminate_after?: never, timeout?: never, track_scores?: never, version?: never, seq_no_primary_term?: never, stored_fields?: never, pit?: never, runtime_mappings?: never, stats?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, allow_partial_search_results?: never, analyzer?: never, analyze_wildcard?: never, batched_reduce_size?: never, ccs_minimize_roundtrips?: never, default_operator?: never, df?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, include_named_queries_score?: never, lenient?: never, max_concurrent_shard_requests?: never, preference?: never, pre_filter_shard_size?: never, request_cache?: never, routing?: never, scroll?: never, search_type?: never, suggest_field?: never, suggest_mode?: never, suggest_size?: never, suggest_text?: never, typed_keys?: never, rest_total_hits_as_int?: never, _source_excludes?: never, _source_includes?: never, q?: never, force_synthetic_source?: never, aggregations?: never, aggs?: never, collapse?: never, explain?: never, ext?: never, from?: never, highlight?: never, track_total_hits?: never, indices_boost?: never, docvalue_fields?: never, knn?: never, rank?: never, min_score?: never, post_filter?: never, profile?: never, query?: never, rescore?: never, retriever?: never, script_fields?: never, search_after?: never, size?: never, slice?: never, sort?: never, _source?: never, fields?: never, suggest?: never, terminate_after?: never, timeout?: never, track_scores?: never, version?: never, seq_no_primary_term?: never, stored_fields?: never, pit?: never, runtime_mappings?: never, stats?: never }
}

export type SearchResponse<TDocument = unknown, TAggregations = Record<AggregateName, AggregationsAggregate>> = SearchResponseBody<TDocument, TAggregations>

export interface SearchResponseBody<TDocument = unknown, TAggregations = Record<AggregateName, AggregationsAggregate>> {
  took: long
  timed_out: boolean
  _shards: ShardStatistics
  hits: SearchHitsMetadata<TDocument>
  aggregations?: TAggregations
  _clusters?: ClusterStatistics
  fields?: Record<string, any>
  max_score?: double
  num_reduce_phases?: long
  profile?: SearchProfile
  pit_id?: Id
  _scroll_id?: ScrollId
  suggest?: Record<SuggestionName, SearchSuggest<TDocument>[]>
  terminated_early?: boolean
}

export interface SearchAggregationBreakdown {
  build_aggregation: long
  build_aggregation_count: long
  build_leaf_collector: long
  build_leaf_collector_count: long
  collect: long
  collect_count: long
  initialize: long
  initialize_count: long
  post_collection?: long
  post_collection_count?: long
  reduce: long
  reduce_count: long
}

export interface SearchAggregationProfile {
  breakdown: SearchAggregationBreakdown
  description: string
  time_in_nanos: DurationValue<UnitNanos>
  type: string
  debug?: SearchAggregationProfileDebug
  children?: SearchAggregationProfile[]
}

export interface SearchAggregationProfileDebug {
  segments_with_multi_valued_ords?: integer
  collection_strategy?: string
  segments_with_single_valued_ords?: integer
  total_buckets?: integer
  built_buckets?: integer
  result_strategy?: string
  has_filter?: boolean
  delegate?: string
  delegate_debug?: SearchAggregationProfileDebug
  chars_fetched?: integer
  extract_count?: integer
  extract_ns?: integer
  values_fetched?: integer
  collect_analyzed_ns?: integer
  collect_analyzed_count?: integer
  surviving_buckets?: integer
  ordinals_collectors_used?: integer
  ordinals_collectors_overhead_too_high?: integer
  string_hashing_collectors_used?: integer
  numeric_collectors_used?: integer
  empty_collectors_used?: integer
  deferred_aggregators?: string[]
  segments_with_doc_count_field?: integer
  segments_with_deleted_docs?: integer
  filters?: SearchAggregationProfileDelegateDebugFilter[]
  segments_counted?: integer
  segments_collected?: integer
  map_reducer?: string
  brute_force_used?: integer
  dynamic_pruning_attempted?: integer
  dynamic_pruning_used?: integer
  skipped_due_to_no_data?: integer
}

export interface SearchAggregationProfileDelegateDebugFilter {
  results_from_metadata?: integer
  query?: string
  specialized_for?: string
  segments_counted_in_constant_time?: integer
}

export type SearchBoundaryScanner = 'chars' | 'sentence' | 'word'

export interface SearchCollector {
  name: string
  reason: string
  time_in_nanos: DurationValue<UnitNanos>
  children?: SearchCollector[]
}

export interface SearchCompletionContext {
  boost?: double
  context: SearchContext
  neighbours?: GeoHashPrecision[]
  precision?: GeoHashPrecision
  prefix?: boolean
}

export interface SearchCompletionSuggest<TDocument = unknown> extends SearchSuggestBase {
  options: SearchCompletionSuggestOption<TDocument> | SearchCompletionSuggestOption<TDocument>[]
}

export interface SearchCompletionSuggestOption<TDocument = unknown> {
  collate_match?: boolean
  contexts?: Record<string, SearchContext[]>
  fields?: Record<string, any>
  _id?: string
  _index?: IndexName
  _routing?: Routing
  _score?: double
  _source?: TDocument
  text: string
  score?: double
}

export interface SearchCompletionSuggester extends SearchSuggesterBase {
  contexts?: Record<Field, SearchCompletionContext | SearchContext | (SearchCompletionContext | SearchContext)[]>
  fuzzy?: SearchSuggestFuzziness
  regex?: SearchRegexOptions
  skip_duplicates?: boolean
}

export type SearchContext = string | GeoLocation

export interface SearchDfsKnnProfile {
  vector_operations_count?: long
  query: SearchKnnQueryProfileResult[]
  rewrite_time: long
  collector: SearchKnnCollectorResult[]
}

export interface SearchDfsProfile {
  statistics?: SearchDfsStatisticsProfile
  knn?: SearchDfsKnnProfile[]
}

export interface SearchDfsStatisticsBreakdown {
  collection_statistics: long
  collection_statistics_count: long
  create_weight: long
  create_weight_count: long
  rewrite: long
  rewrite_count: long
  term_statistics: long
  term_statistics_count: long
}

export interface SearchDfsStatisticsProfile {
  type: string
  description: string
  time?: Duration
  time_in_nanos: DurationValue<UnitNanos>
  breakdown: SearchDfsStatisticsBreakdown
  debug?: Record<string, any>
  children?: SearchDfsStatisticsProfile[]
}

export interface SearchDirectGenerator {
  field: Field
  max_edits?: integer
  max_inspections?: float
  max_term_freq?: float
  min_doc_freq?: float
  min_word_length?: integer
  post_filter?: string
  pre_filter?: string
  prefix_length?: integer
  size?: integer
  suggest_mode?: SuggestMode
}

export interface SearchFetchProfile {
  type: string
  description: string
  time_in_nanos: DurationValue<UnitNanos>
  breakdown: SearchFetchProfileBreakdown
  debug?: SearchFetchProfileDebug
  children?: SearchFetchProfile[]
}

export interface SearchFetchProfileBreakdown {
  load_source?: integer
  load_source_count?: integer
  load_stored_fields?: integer
  load_stored_fields_count?: integer
  next_reader?: integer
  next_reader_count?: integer
  process_count?: integer
  process?: integer
}

export interface SearchFetchProfileDebug {
  stored_fields?: string[]
  fast_path?: integer
}

export interface SearchFieldCollapse {
  field: Field
  inner_hits?: SearchInnerHits | SearchInnerHits[]
  max_concurrent_group_searches?: integer
  collapse?: SearchFieldCollapse
}

export interface SearchFieldSuggester {
  completion?: SearchCompletionSuggester
  phrase?: SearchPhraseSuggester
  term?: SearchTermSuggester
  prefix?: string
  regex?: string
  text?: string
}

export interface SearchHighlight extends SearchHighlightBase {
  encoder?: SearchHighlighterEncoder
  fields: Record<Field, SearchHighlightField>
}

export interface SearchHighlightBase {
  type?: SearchHighlighterType
  boundary_chars?: string
  boundary_max_scan?: integer
  boundary_scanner?: SearchBoundaryScanner
  boundary_scanner_locale?: string
  force_source?: boolean
  fragmenter?: SearchHighlighterFragmenter
  fragment_size?: integer
  highlight_filter?: boolean
  highlight_query?: QueryDslQueryContainer
  max_fragment_length?: integer
  max_analyzed_offset?: integer
  no_match_size?: integer
  number_of_fragments?: integer
  options?: Record<string, any>
  order?: SearchHighlighterOrder
  phrase_limit?: integer
  post_tags?: string[]
  pre_tags?: string[]
  require_field_match?: boolean
  tags_schema?: SearchHighlighterTagsSchema
}

export interface SearchHighlightField extends SearchHighlightBase {
  fragment_offset?: integer
  matched_fields?: Fields
}

export type SearchHighlighterEncoder = 'default' | 'html'

export type SearchHighlighterFragmenter = 'simple' | 'span'

export type SearchHighlighterOrder = 'score'

export type SearchHighlighterTagsSchema = 'styled'

export type SearchHighlighterType = 'plain' | 'fvh' | 'unified' | string

export interface SearchHit<TDocument = unknown> {
  _index: IndexName
  _id?: Id
  _score?: double | null
  _explanation?: ExplainExplanation
  fields?: Record<string, any>
  highlight?: Record<string, string[]>
  inner_hits?: Record<string, SearchInnerHitsResult>
  matched_queries?: string[] | Record<string, double>
  _nested?: SearchNestedIdentity
  _ignored?: string[]
  ignored_field_values?: Record<string, any[]>
  _shard?: string
  _node?: string
  _routing?: string
  _source?: TDocument
  _rank?: integer
  _seq_no?: SequenceNumber
  _primary_term?: long
  _version?: VersionNumber
  sort?: SortResults
}

export interface SearchHitsMetadata<T = unknown> {
  total?: SearchTotalHits | long
  hits: SearchHit<T>[]
  max_score?: double | null
}

export interface SearchInnerHits {
  name?: Name
  size?: integer
  from?: integer
  collapse?: SearchFieldCollapse
  docvalue_fields?: (QueryDslFieldAndFormat | Field)[]
  explain?: boolean
  highlight?: SearchHighlight
  ignore_unmapped?: boolean
  script_fields?: Record<Field, ScriptField>
  seq_no_primary_term?: boolean
  fields?: Fields
  sort?: Sort
  _source?: SearchSourceConfig
  stored_fields?: Fields
  track_scores?: boolean
  version?: boolean
}

export interface SearchInnerHitsResult {
  hits: SearchHitsMetadata<any>
}

export interface SearchKnnCollectorResult {
  name: string
  reason: string
  time?: Duration
  time_in_nanos: DurationValue<UnitNanos>
  children?: SearchKnnCollectorResult[]
}

export interface SearchKnnQueryProfileBreakdown {
  advance: long
  advance_count: long
  build_scorer: long
  build_scorer_count: long
  compute_max_score: long
  compute_max_score_count: long
  count_weight: long
  count_weight_count: long
  create_weight: long
  create_weight_count: long
  match: long
  match_count: long
  next_doc: long
  next_doc_count: long
  score: long
  score_count: long
  set_min_competitive_score: long
  set_min_competitive_score_count: long
  shallow_advance: long
  shallow_advance_count: long
}

export interface SearchKnnQueryProfileResult {
  type: string
  description: string
  time?: Duration
  time_in_nanos: DurationValue<UnitNanos>
  breakdown: SearchKnnQueryProfileBreakdown
  debug?: Record<string, any>
  children?: SearchKnnQueryProfileResult[]
}

export interface SearchLaplaceSmoothingModel {
  alpha: double
}

export interface SearchLearningToRank {
  model_id: string
  params?: Record<string, any>
}

export interface SearchLinearInterpolationSmoothingModel {
  bigram_lambda: double
  trigram_lambda: double
  unigram_lambda: double
}

export interface SearchNestedIdentity {
  field: Field
  offset: integer
  _nested?: SearchNestedIdentity
}

export interface SearchPhraseSuggest extends SearchSuggestBase {
  options: SearchPhraseSuggestOption | SearchPhraseSuggestOption[]
}

export interface SearchPhraseSuggestCollate {
  params?: Record<string, any>
  prune?: boolean
  query: SearchPhraseSuggestCollateQuery
}

export interface SearchPhraseSuggestCollateQuery {
  id?: Id
  source?: string
}

export interface SearchPhraseSuggestHighlight {
  post_tag: string
  pre_tag: string
}

export interface SearchPhraseSuggestOption {
  text: string
  score: double
  highlighted?: string
  collate_match?: boolean
}

export interface SearchPhraseSuggester extends SearchSuggesterBase {
  collate?: SearchPhraseSuggestCollate
  confidence?: double
  direct_generator?: SearchDirectGenerator[]
  force_unigrams?: boolean
  gram_size?: integer
  highlight?: SearchPhraseSuggestHighlight
  max_errors?: double
  real_word_error_likelihood?: double
  separator?: string
  shard_size?: integer
  smoothing?: SearchSmoothingModelContainer
  text?: string
  token_limit?: integer
}

export interface SearchPointInTimeReference {
  id: Id
  keep_alive?: Duration
}

export interface SearchProfile {
  shards: SearchShardProfile[]
}

export interface SearchQueryBreakdown {
  advance: long
  advance_count: long
  build_scorer: long
  build_scorer_count: long
  create_weight: long
  create_weight_count: long
  match: long
  match_count: long
  shallow_advance: long
  shallow_advance_count: long
  next_doc: long
  next_doc_count: long
  score: long
  score_count: long
  compute_max_score: long
  compute_max_score_count: long
  count_weight: long
  count_weight_count: long
  set_min_competitive_score: long
  set_min_competitive_score_count: long
}

export interface SearchQueryProfile {
  breakdown: SearchQueryBreakdown
  description: string
  time_in_nanos: DurationValue<UnitNanos>
  type: string
  children?: SearchQueryProfile[]
}

export interface SearchRegexOptions {
  flags?: integer | string
  max_determinized_states?: integer
}

export interface SearchRescore {
  window_size?: integer
  query?: SearchRescoreQuery
  learning_to_rank?: SearchLearningToRank
}

export interface SearchRescoreQuery {
  rescore_query: QueryDslQueryContainer
  query_weight?: double
  rescore_query_weight?: double
  score_mode?: SearchScoreMode
}

export type SearchScoreMode = 'avg' | 'max' | 'min' | 'multiply' | 'total'

export interface SearchSearchProfile {
  collector: SearchCollector[]
  query: SearchQueryProfile[]
  rewrite_time: long
}

export interface SearchShardProfile {
  aggregations: SearchAggregationProfile[]
  cluster: string
  dfs?: SearchDfsProfile
  fetch?: SearchFetchProfile
  id: string
  index: IndexName
  node_id: NodeId
  searches: SearchSearchProfile[]
  shard_id: long
}

export interface SearchSmoothingModelContainer {
  laplace?: SearchLaplaceSmoothingModel
  linear_interpolation?: SearchLinearInterpolationSmoothingModel
  stupid_backoff?: SearchStupidBackoffSmoothingModel
}

export type SearchSourceConfig = boolean | SearchSourceFilter | Fields

export type SearchSourceConfigParam = boolean | Fields

export interface SearchSourceFilter {
  excludes?: Fields
  exclude?: Fields
  includes?: Fields
  include?: Fields
}

export type SearchStringDistance = 'internal' | 'damerau_levenshtein' | 'levenshtein' | 'jaro_winkler' | 'ngram'

export interface SearchStupidBackoffSmoothingModel {
  discount: double
}

export type SearchSuggest<TDocument = unknown> = SearchCompletionSuggest<TDocument> | SearchPhraseSuggest | SearchTermSuggest

export interface SearchSuggestBase {
  length: integer
  offset: integer
  text: string
}

export interface SearchSuggestFuzziness {
  fuzziness?: Fuzziness
  min_length?: integer
  prefix_length?: integer
  transpositions?: boolean
  unicode_aware?: boolean
}

export type SearchSuggestSort = 'score' | 'frequency'

export interface SearchSuggesterKeys {
  text?: string
}
export type SearchSuggester = SearchSuggesterKeys
& { [property: string]: SearchFieldSuggester | string }

export interface SearchSuggesterBase {
  field: Field
  analyzer?: string
  size?: integer
}

export interface SearchTermSuggest extends SearchSuggestBase {
  options: SearchTermSuggestOption | SearchTermSuggestOption[]
}

export interface SearchTermSuggestOption {
  text: string
  score: double
  freq: long
  highlighted?: string
  collate_match?: boolean
}

export interface SearchTermSuggester extends SearchSuggesterBase {
  lowercase_terms?: boolean
  max_edits?: integer
  max_inspections?: integer
  max_term_freq?: float
  min_doc_freq?: float
  min_word_length?: integer
  prefix_length?: integer
  shard_size?: integer
  sort?: SearchSuggestSort
  string_distance?: SearchStringDistance
  suggest_mode?: SuggestMode
  text?: string
}

export interface SearchTotalHits {
  relation: SearchTotalHitsRelation
  value: long
}

export type SearchTotalHitsRelation = 'eq' | 'gte'

export type SearchTrackHits = boolean | integer

export interface SearchMvtRequest extends RequestBase {
/** Comma-separated list of data streams, indices, or aliases to search */
  index: Indices
  /** Field containing geospatial data to return */
  field: Field
  /** Zoom level for the vector tile to search */
  zoom: SearchMvtZoomLevel
  /** X coordinate for the vector tile to search */
  x: SearchMvtCoordinate
  /** Y coordinate for the vector tile to search */
  y: SearchMvtCoordinate
  /** Sub-aggregations for the geotile_grid. It supports the following aggregation types: - `avg` - `boxplot` - `cardinality` - `extended stats` - `max` - `median absolute deviation` - `min` - `percentile` - `percentile-rank` - `stats` - `sum` - `value count` The aggregation names can't start with `_mvt_`. The `_mvt_` prefix is reserved for internal aggregations. */
  aggs?: Record<string, AggregationsAggregationContainer>
  /** The size, in pixels, of a clipping buffer outside the tile. This allows renderers to avoid outline artifacts from geometries that extend past the extent of the tile. */
  buffer?: integer
  /** If `false`, the meta layer's feature is the bounding box of the tile. If `true`, the meta layer's feature is a bounding box resulting from a `geo_bounds` aggregation. The aggregation runs on <field> values that intersect the `<zoom>/<x>/<y>` tile with `wrap_longitude` set to `false`. The resulting bounding box may be larger than the vector tile. */
  exact_bounds?: boolean
  /** The size, in pixels, of a side of the tile. Vector tiles are square with equal sides. */
  extent?: integer
  /** The fields to return in the `hits` layer. It supports wildcards (`*`). This parameter does not support fields with array values. Fields with array values may return inconsistent results. */
  fields?: Fields
  /** The aggregation used to create a grid for the `field`. */
  grid_agg?: SearchMvtGridAggregationType
  /** Additional zoom levels available through the aggs layer. For example, if `<zoom>` is `7` and `grid_precision` is `8`, you can zoom in up to level 15. Accepts 0-8. If 0, results don't include the aggs layer. */
  grid_precision?: integer
  /** Determines the geometry type for features in the aggs layer. In the aggs layer, each feature represents a `geotile_grid` cell. If `grid, each feature is a polygon of the cells bounding box. If `point`, each feature is a Point that is the centroid of the cell. */
  grid_type?: SearchMvtGridType
  /** The query DSL used to filter documents for the search. */
  query?: QueryDslQueryContainer
  /** Defines one or more runtime fields in the search request. These fields take precedence over mapped fields with the same name. */
  runtime_mappings?: MappingRuntimeFields
  /** The maximum number of features to return in the hits layer. Accepts 0-10000. If 0, results don't include the hits layer. */
  size?: integer
  /** Sort the features in the hits layer. By default, the API calculates a bounding box for each feature. It sorts features based on this box's diagonal length, from longest to shortest. */
  sort?: Sort
  /** The number of hits matching the query to count accurately. If `true`, the exact number of hits is returned at the cost of some performance. If `false`, the response does not include the total number of hits matching the query. */
  track_total_hits?: SearchTrackHits
  /** If `true`, the hits and aggs layers will contain additional point features representing suggested label positions for the original features. * `Point` and `MultiPoint` features will have one of the points selected. * `Polygon` and `MultiPolygon` features will have a single point generated, either the centroid, if it is within the polygon, or another point within the polygon selected from the sorted triangle-tree. * `LineString` features will likewise provide a roughly central point selected from the triangle-tree. * The aggregation results will provide one central point for each aggregation bucket. All attributes from the original features will also be copied to the new label features. In addition, the new features will be distinguishable using the tag `_mvt_label_position`. */
  with_labels?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, field?: never, zoom?: never, x?: never, y?: never, aggs?: never, buffer?: never, exact_bounds?: never, extent?: never, fields?: never, grid_agg?: never, grid_precision?: never, grid_type?: never, query?: never, runtime_mappings?: never, size?: never, sort?: never, track_total_hits?: never, with_labels?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, field?: never, zoom?: never, x?: never, y?: never, aggs?: never, buffer?: never, exact_bounds?: never, extent?: never, fields?: never, grid_agg?: never, grid_precision?: never, grid_type?: never, query?: never, runtime_mappings?: never, size?: never, sort?: never, track_total_hits?: never, with_labels?: never }
}

export type SearchMvtResponse = MapboxVectorTiles

export type SearchMvtCoordinate = integer

export type SearchMvtGridAggregationType = 'geotile' | 'geohex'

export type SearchMvtGridType = 'grid' | 'point' | 'centroid'

export type SearchMvtZoomLevel = integer

export interface SearchShardsRequest extends RequestBase {
/** A comma-separated list of data streams, indices, and aliases to search. It supports wildcards (`*`). To search all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** If `true`, the request retrieves information from the local node only. */
  local?: boolean
  /** The period to wait for a connection to the master node. If the master node is not available before the timeout expires, the request fails and returns an error. IT can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  /** The node or shard the operation should be performed on. It is random by default. */
  preference?: string
  /** A custom value used to route operations to a specific shard. */
  routing?: Routing
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, local?: never, master_timeout?: never, preference?: never, routing?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, local?: never, master_timeout?: never, preference?: never, routing?: never }
}

export interface SearchShardsResponse {
  nodes: Record<NodeId, SearchShardsSearchShardsNodeAttributes>
  shards: NodeShard[][]
  indices: Record<IndexName, SearchShardsShardStoreIndex>
}

export interface SearchShardsSearchShardsNodeAttributes {
  name: NodeName
  ephemeral_id: Id
  transport_address: TransportAddress
  external_id: string
  attributes: Record<string, string>
  roles: NodeRoles
  version: VersionString
  min_index_version: integer
  max_index_version: integer
}

export interface SearchShardsShardStoreIndex {
  aliases?: Name[]
  filter?: QueryDslQueryContainer
}

export interface SearchTemplateRequest extends RequestBase {
/** A comma-separated list of data streams, indices, and aliases to search. It supports wildcards (`*`). */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. */
  allow_no_indices?: boolean
  /** If `true`, network round-trips are minimized for cross-cluster search requests. */
  ccs_minimize_roundtrips?: boolean
  /** The type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, specified concrete, expanded, or aliased indices are not included in the response when throttled. */
  ignore_throttled?: boolean
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** The node or shard the operation should be performed on. It is random by default. */
  preference?: string
  /** A custom value used to route operations to a specific shard. */
  routing?: Routing
  /** Specifies how long a consistent view of the index should be maintained for scrolled search. */
  scroll?: Duration
  /** The type of the search operation. */
  search_type?: SearchType
  /** If `true`, `hits.total` is rendered as an integer in the response. If `false`, it is rendered as an object. */
  rest_total_hits_as_int?: boolean
  /** If `true`, the response prefixes aggregation and suggester names with their respective types. */
  typed_keys?: boolean
  /** If `true`, returns detailed information about score calculation as part of each hit. If you specify both this and the `explain` query parameter, the API uses only the query parameter. */
  explain?: boolean
  /** The ID of the search template to use. If no `source` is specified, this parameter is required. */
  id?: Id
  /** Key-value pairs used to replace Mustache variables in the template. The key is the variable name. The value is the variable value. */
  params?: Record<string, any>
  /** If `true`, the query execution is profiled. */
  profile?: boolean
  /** An inline search template. Supports the same parameters as the search API's request body. It also supports Mustache variables. If no `id` is specified, this parameter is required. */
  source?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, ccs_minimize_roundtrips?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, preference?: never, routing?: never, scroll?: never, search_type?: never, rest_total_hits_as_int?: never, typed_keys?: never, explain?: never, id?: never, params?: never, profile?: never, source?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, ccs_minimize_roundtrips?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, preference?: never, routing?: never, scroll?: never, search_type?: never, rest_total_hits_as_int?: never, typed_keys?: never, explain?: never, id?: never, params?: never, profile?: never, source?: never }
}

export interface SearchTemplateResponse<TDocument = unknown> {
  took: long
  timed_out: boolean
  _shards: ShardStatistics
  hits: SearchHitsMetadata<TDocument>
  aggregations?: Record<AggregateName, AggregationsAggregate>
  _clusters?: ClusterStatistics
  fields?: Record<string, any>
  max_score?: double
  num_reduce_phases?: long
  profile?: SearchProfile
  pit_id?: Id
  _scroll_id?: ScrollId
  suggest?: Record<SuggestionName, SearchSuggest<TDocument>[]>
  terminated_early?: boolean
}

export interface TermsEnumRequest extends RequestBase {
/** A comma-separated list of data streams, indices, and index aliases to search. Wildcard (`*`) expressions are supported. To search all data streams or indices, omit this parameter or use `*` or `_all`. */
  index: IndexName
  /** The string to match at the start of indexed terms. If not provided, all terms in the field are considered. */
  field: Field
  /** The number of matching terms to return. */
  size?: integer
  /** The maximum length of time to spend collecting results. If the timeout is exceeded the `complete` flag set to `false` in the response and the results may be partial or empty. */
  timeout?: Duration
  /** When `true`, the provided search string is matched against index terms without case sensitivity. */
  case_insensitive?: boolean
  /** Filter an index shard if the provided query rewrites to `match_none`. */
  index_filter?: QueryDslQueryContainer
  /** The string to match at the start of indexed terms. If it is not provided, all terms in the field are considered. > info > The prefix string cannot be larger than the largest possible keyword value, which is Lucene's term byte-length limit of 32766. */
  string?: string
  /** The string after which terms in the index should be returned. It allows for a form of pagination if the last result from one request is passed as the `search_after` parameter for a subsequent request. */
  search_after?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, field?: never, size?: never, timeout?: never, case_insensitive?: never, index_filter?: never, string?: never, search_after?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, field?: never, size?: never, timeout?: never, case_insensitive?: never, index_filter?: never, string?: never, search_after?: never }
}

export interface TermsEnumResponse {
  _shards: ShardStatistics
  terms: string[]
  complete: boolean
}

export interface TermvectorsFieldStatistics {
  doc_count: integer
  sum_doc_freq: long
  sum_ttf: long
}

export interface TermvectorsFilter {
  max_doc_freq?: integer
  max_num_terms?: integer
  max_term_freq?: integer
  max_word_length?: integer
  min_doc_freq?: integer
  min_term_freq?: integer
  min_word_length?: integer
}

export interface TermvectorsRequest<TDocument = unknown> extends RequestBase {
/** The name of the index that contains the document. */
  index: IndexName
  /** A unique identifier for the document. */
  id?: Id
  /** The node or shard the operation should be performed on. It is random by default. */
  preference?: string
  /** If true, the request is real-time as opposed to near-real-time. */
  realtime?: boolean
  /** An artificial document (a document not present in the index) for which you want to retrieve term vectors. */
  doc?: TDocument
  /** Filter terms based on their tf-idf scores. This could be useful in order find out a good characteristic vector of a document. This feature works in a similar manner to the second phase of the More Like This Query. */
  filter?: TermvectorsFilter
  /** Override the default per-field analyzer. This is useful in order to generate term vectors in any fashion, especially when using artificial documents. When providing an analyzer for a field that already stores term vectors, the term vectors will be regenerated. */
  per_field_analyzer?: Record<Field, string>
  /** A list of fields to include in the statistics. It is used as the default list unless a specific field list is provided in the `completion_fields` or `fielddata_fields` parameters. */
  fields?: Fields
  /** If `true`, the response includes: * The document count (how many documents contain this field). * The sum of document frequencies (the sum of document frequencies for all terms in this field). * The sum of total term frequencies (the sum of total term frequencies of each term in this field). */
  field_statistics?: boolean
  /** If `true`, the response includes term offsets. */
  offsets?: boolean
  /** If `true`, the response includes term payloads. */
  payloads?: boolean
  /** If `true`, the response includes term positions. */
  positions?: boolean
  /** If `true`, the response includes: * The total term frequency (how often a term occurs in all documents). * The document frequency (the number of documents containing the current term). By default these values are not returned since term statistics can have a serious performance impact. */
  term_statistics?: boolean
  /** A custom value that is used to route operations to a specific shard. */
  routing?: Routing
  /** If `true`, returns the document version as part of a hit. */
  version?: VersionNumber
  /** The version type. */
  version_type?: VersionType
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, id?: never, preference?: never, realtime?: never, doc?: never, filter?: never, per_field_analyzer?: never, fields?: never, field_statistics?: never, offsets?: never, payloads?: never, positions?: never, term_statistics?: never, routing?: never, version?: never, version_type?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, id?: never, preference?: never, realtime?: never, doc?: never, filter?: never, per_field_analyzer?: never, fields?: never, field_statistics?: never, offsets?: never, payloads?: never, positions?: never, term_statistics?: never, routing?: never, version?: never, version_type?: never }
}

export interface TermvectorsResponse {
  found: boolean
  _id?: Id
  _index: IndexName
  term_vectors?: Record<Field, TermvectorsTermVector>
  took: long
  _version: VersionNumber
}

export interface TermvectorsTerm {
  doc_freq?: integer
  score?: double
  term_freq: integer
  tokens?: TermvectorsToken[]
  ttf?: integer
}

export interface TermvectorsTermVector {
  field_statistics?: TermvectorsFieldStatistics
  terms: Record<string, TermvectorsTerm>
}

export interface TermvectorsToken {
  end_offset?: integer
  payload?: string
  position: integer
  start_offset?: integer
}

export interface UpdateRequest<TDocument = unknown, TPartialDocument = unknown> extends RequestBase {
/** A unique identifier for the document to be updated. */
  id: Id
  /** The name of the target index. By default, the index is created automatically if it doesn't exist. */
  index: IndexName
  /** Only perform the operation if the document has this primary term. */
  if_primary_term?: long
  /** Only perform the operation if the document has this sequence number. */
  if_seq_no?: SequenceNumber
  /** True or false if to include the document source in the error message in case of parsing errors. */
  include_source_on_error?: boolean
  /** The script language. */
  lang?: string
  /** If 'true', Elasticsearch refreshes the affected shards to make this operation visible to search. If 'wait_for', it waits for a refresh to make this operation visible to search. If 'false', it does nothing with refreshes. */
  refresh?: Refresh
  /** If `true`, the destination must be an index alias. */
  require_alias?: boolean
  /** The number of times the operation should be retried when a conflict occurs. */
  retry_on_conflict?: integer
  /** A custom value used to route operations to a specific shard. */
  routing?: Routing
  /** The period to wait for the following operations: dynamic mapping updates and waiting for active shards. Elasticsearch waits for at least the timeout period before failing. The actual wait time could be longer, particularly when multiple waits occur. */
  timeout?: Duration
  /** The number of copies of each shard that must be active before proceeding with the operation. Set to 'all' or any positive integer up to the total number of shards in the index (`number_of_replicas`+1). The default value of `1` means it waits for each primary shard to be active. */
  wait_for_active_shards?: WaitForActiveShards
  /** The source fields you want to exclude. */
  _source_excludes?: Fields
  /** The source fields you want to retrieve. */
  _source_includes?: Fields
  /** If `true`, the `result` in the response is set to `noop` (no operation) when there are no changes to the document. */
  detect_noop?: boolean
  /** A partial update to an existing document. If both `doc` and `script` are specified, `doc` is ignored. */
  doc?: TPartialDocument
  /** If `true`, use the contents of 'doc' as the value of 'upsert'. NOTE: Using ingest pipelines with `doc_as_upsert` is not supported. */
  doc_as_upsert?: boolean
  /** The script to run to update the document. */
  script?: Script | string
  /** If `true`, run the script whether or not the document exists. */
  scripted_upsert?: boolean
  /** If `false`, turn off source retrieval. You can also specify a comma-separated list of the fields you want to retrieve. */
  _source?: SearchSourceConfig
  /** If the document does not already exist, the contents of 'upsert' are inserted as a new document. If the document exists, the 'script' is run. */
  upsert?: TDocument
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, index?: never, if_primary_term?: never, if_seq_no?: never, include_source_on_error?: never, lang?: never, refresh?: never, require_alias?: never, retry_on_conflict?: never, routing?: never, timeout?: never, wait_for_active_shards?: never, _source_excludes?: never, _source_includes?: never, detect_noop?: never, doc?: never, doc_as_upsert?: never, script?: never, scripted_upsert?: never, _source?: never, upsert?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, index?: never, if_primary_term?: never, if_seq_no?: never, include_source_on_error?: never, lang?: never, refresh?: never, require_alias?: never, retry_on_conflict?: never, routing?: never, timeout?: never, wait_for_active_shards?: never, _source_excludes?: never, _source_includes?: never, detect_noop?: never, doc?: never, doc_as_upsert?: never, script?: never, scripted_upsert?: never, _source?: never, upsert?: never }
}

export type UpdateResponse<TDocument = unknown> = UpdateUpdateWriteResponseBase<TDocument>

export interface UpdateUpdateWriteResponseBase<TDocument = unknown> extends WriteResponseBase {
  get?: InlineGet<TDocument>
}

export interface UpdateByQueryRequest extends RequestBase {
/** A comma-separated list of data streams, indices, and aliases to search. It supports wildcards (`*`). To search all data streams or indices, omit this parameter or use `*` or `_all`. */
  index: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. */
  allow_no_indices?: boolean
  /** The analyzer to use for the query string. This parameter can be used only when the `q` query string parameter is specified. */
  analyzer?: string
  /** If `true`, wildcard and prefix queries are analyzed. This parameter can be used only when the `q` query string parameter is specified. */
  analyze_wildcard?: boolean
  /** The default operator for query string query: `AND` or `OR`. This parameter can be used only when the `q` query string parameter is specified. */
  default_operator?: QueryDslOperator
  /** The field to use as default where no field prefix is given in the query string. This parameter can be used only when the `q` query string parameter is specified. */
  df?: string
  /** The type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. It supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** Starting offset (default: 0) */
  from?: long
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** If `true`, format-based query failures (such as providing text to a numeric field) in the query string will be ignored. This parameter can be used only when the `q` query string parameter is specified. */
  lenient?: boolean
  /** The ID of the pipeline to use to preprocess incoming documents. If the index has a default ingest pipeline specified, then setting the value to `_none` disables the default ingest pipeline for this request. If a final pipeline is configured it will always run, regardless of the value of this parameter. */
  pipeline?: string
  /** The node or shard the operation should be performed on. It is random by default. */
  preference?: string
  /** A query in the Lucene query string syntax. */
  q?: string
  /** If `true`, Elasticsearch refreshes affected shards to make the operation visible to search after the request completes. This is different than the update API's `refresh` parameter, which causes just the shard that received the request to be refreshed. */
  refresh?: boolean
  /** If `true`, the request cache is used for this request. It defaults to the index-level setting. */
  request_cache?: boolean
  /** The throttle for this request in sub-requests per second. */
  requests_per_second?: float
  /** A custom value used to route operations to a specific shard. */
  routing?: Routing
  /** The period to retain the search context for scrolling. */
  scroll?: Duration
  /** The size of the scroll request that powers the operation. */
  scroll_size?: long
  /** An explicit timeout for each search request. By default, there is no timeout. */
  search_timeout?: Duration
  /** The type of the search operation. Available options include `query_then_fetch` and `dfs_query_then_fetch`. */
  search_type?: SearchType
  /** The number of slices this task should be divided into. */
  slices?: Slices
  /** A comma-separated list of <field>:<direction> pairs. */
  sort?: string[]
  /** The specific `tag` of the request for logging and statistical purposes. */
  stats?: string[]
  /** The maximum number of documents to collect for each shard. If a query reaches this limit, Elasticsearch terminates the query early. Elasticsearch collects documents before sorting. IMPORTANT: Use with caution. Elasticsearch applies this parameter to each shard handling the request. When possible, let Elasticsearch perform early termination automatically. Avoid specifying this parameter for requests that target data streams with backing indices across multiple data tiers. */
  terminate_after?: long
  /** The period each update request waits for the following operations: dynamic mapping updates, waiting for active shards. By default, it is one minute. This guarantees Elasticsearch waits for at least the timeout before failing. The actual wait time could be longer, particularly when multiple waits occur. */
  timeout?: Duration
  /** If `true`, returns the document version as part of a hit. */
  version?: boolean
  /** Should the document increment the version number (internal) on hit or not (reindex) */
  version_type?: boolean
  /** The number of shard copies that must be active before proceeding with the operation. Set to `all` or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). The `timeout` parameter controls how long each write request waits for unavailable shards to become available. Both work exactly the way they work in the bulk API. */
  wait_for_active_shards?: WaitForActiveShards
  /** If `true`, the request blocks until the operation is complete. If `false`, Elasticsearch performs some preflight checks, launches the request, and returns a task ID that you can use to cancel or get the status of the task. Elasticsearch creates a record of this task as a document at `.tasks/task/${taskId}`. */
  wait_for_completion?: boolean
  /** The maximum number of documents to update. */
  max_docs?: long
  /** The documents to update using the Query DSL. */
  query?: QueryDslQueryContainer
  /** The script to run to update the document source or metadata when updating. */
  script?: Script | string
  /** Slice the request manually using the provided slice ID and total number of slices. */
  slice?: SlicedScroll
  /** The preferred behavior when update by query hits version conflicts: `abort` or `proceed`. */
  conflicts?: Conflicts
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, analyzer?: never, analyze_wildcard?: never, default_operator?: never, df?: never, expand_wildcards?: never, from?: never, ignore_unavailable?: never, lenient?: never, pipeline?: never, preference?: never, q?: never, refresh?: never, request_cache?: never, requests_per_second?: never, routing?: never, scroll?: never, scroll_size?: never, search_timeout?: never, search_type?: never, slices?: never, sort?: never, stats?: never, terminate_after?: never, timeout?: never, version?: never, version_type?: never, wait_for_active_shards?: never, wait_for_completion?: never, max_docs?: never, query?: never, script?: never, slice?: never, conflicts?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, analyzer?: never, analyze_wildcard?: never, default_operator?: never, df?: never, expand_wildcards?: never, from?: never, ignore_unavailable?: never, lenient?: never, pipeline?: never, preference?: never, q?: never, refresh?: never, request_cache?: never, requests_per_second?: never, routing?: never, scroll?: never, scroll_size?: never, search_timeout?: never, search_type?: never, slices?: never, sort?: never, stats?: never, terminate_after?: never, timeout?: never, version?: never, version_type?: never, wait_for_active_shards?: never, wait_for_completion?: never, max_docs?: never, query?: never, script?: never, slice?: never, conflicts?: never }
}

export interface UpdateByQueryResponse {
  batches?: long
  failures?: BulkIndexByScrollFailure[]
  noops?: long
  deleted?: long
  requests_per_second?: float
  retries?: Retries
  task?: TaskId
  timed_out?: boolean
  took?: DurationValue<UnitMillis>
  total?: long
  updated?: long
  version_conflicts?: long
  throttled?: Duration
  throttled_millis?: DurationValue<UnitMillis>
  throttled_until?: Duration
  throttled_until_millis?: DurationValue<UnitMillis>
}

export interface UpdateByQueryRethrottleRequest extends RequestBase {
/** The ID for the task. */
  task_id: Id
  /** The throttle for this request in sub-requests per second. To turn off throttling, set it to `-1`. */
  requests_per_second?: float
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { task_id?: never, requests_per_second?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { task_id?: never, requests_per_second?: never }
}

export interface UpdateByQueryRethrottleResponse {
  nodes: Record<string, UpdateByQueryRethrottleUpdateByQueryRethrottleNode>
}

export interface UpdateByQueryRethrottleUpdateByQueryRethrottleNode extends SpecUtilsBaseNode {
  tasks: Record<TaskId, TasksTaskInfo>
}

export interface SpecUtilsBaseNode {
  attributes: Record<string, string>
  host: Host
  ip: Ip
  name: Name
  roles?: NodeRoles
  transport_address: TransportAddress
}

export type SpecUtilsNullValue = null

export type SpecUtilsPipeSeparatedFlags<T = unknown> = T | string

export type SpecUtilsStringified<T = unknown> = T | string

export type SpecUtilsWithNullValue<T = unknown> = T | SpecUtilsNullValue

export interface AcknowledgedResponseBase {
  acknowledged: boolean
}

export type AggregateName = string

export interface BulkIndexByScrollFailure {
  cause: ErrorCause
  id: Id
  index: IndexName
  status: integer
}

export interface BulkStats {
  total_operations: long
  total_time?: Duration
  total_time_in_millis: DurationValue<UnitMillis>
  total_size?: ByteSize
  total_size_in_bytes: long
  avg_time?: Duration
  avg_time_in_millis: DurationValue<UnitMillis>
  avg_size?: ByteSize
  avg_size_in_bytes: long
}

export type ByteSize = long | string

export type Bytes = 'b' | 'kb' | 'mb' | 'gb' | 'tb' | 'pb'

export type CategoryId = string

export type ClusterAlias = string

export interface ClusterDetails {
  status: ClusterSearchStatus
  indices: string
  took?: DurationValue<UnitMillis>
  timed_out: boolean
  _shards?: ShardStatistics
  failures?: ShardFailure[]
}

export type ClusterInfoTarget = '_all' | 'http' | 'ingest' | 'thread_pool' | 'script'

export type ClusterInfoTargets = ClusterInfoTarget | ClusterInfoTarget[]

export type ClusterSearchStatus = 'running' | 'successful' | 'partial' | 'skipped' | 'failed'

export interface ClusterStatistics {
  skipped: integer
  successful: integer
  total: integer
  running: integer
  partial: integer
  failed: integer
  details?: Record<ClusterAlias, ClusterDetails>
}

export interface CompletionStats {
  size_in_bytes: long
  size?: ByteSize
  fields?: Record<Field, FieldSizeUsage>
}

export type Conflicts = 'abort' | 'proceed'

export interface CoordsGeoBounds {
  top: double
  bottom: double
  left: double
  right: double
}

export type DFIIndependenceMeasure = 'standardized' | 'saturated' | 'chisquared'

export type DFRAfterEffect = 'no' | 'b' | 'l'

export type DFRBasicModel = 'be' | 'd' | 'g' | 'if' | 'in' | 'ine' | 'p'

export type DataStreamName = string

export type DataStreamNames = DataStreamName | DataStreamName[]

export type DateFormat = string

export type DateMath = string | Date

export type DateTime = string | EpochTime<UnitMillis> | Date

export type Distance = string

export type DistanceUnit = 'in' | 'ft' | 'yd' | 'mi' | 'nmi' | 'km' | 'm' | 'cm' | 'mm'

export interface DocStats {
  count: long
  deleted?: long
}

export type Duration = string | -1 | 0

export type DurationLarge = string

export type DurationValue<Unit = unknown> = Unit

export interface ElasticsearchVersionInfo {
  build_date: DateTime
  build_flavor: string
  build_hash: string
  build_snapshot: boolean
  build_type: string
  lucene_version: VersionString
  minimum_index_compatibility_version: VersionString
  minimum_wire_compatibility_version: VersionString
  number: string
}

export interface ElasticsearchVersionMinInfo {
  build_flavor: string
  minimum_index_compatibility_version: VersionString
  minimum_wire_compatibility_version: VersionString
  number: string
}

export interface EmptyObject {
}

export type EpochTime<Unit = unknown> = Unit

export interface ErrorCauseKeys {
  type: string
  reason?: string
  stack_trace?: string
  caused_by?: ErrorCause
  root_cause?: ErrorCause[]
  suppressed?: ErrorCause[]
}
export type ErrorCause = ErrorCauseKeys
& { [property: string]: any }

export interface ErrorResponseBase {
  error: ErrorCause
  status: integer
}

export type EsqlResult = ArrayBuffer

export type ExpandWildcard = 'all' | 'open' | 'closed' | 'hidden' | 'none'

export type ExpandWildcards = ExpandWildcard | ExpandWildcard[]

export type Field = string

export interface FieldMemoryUsage {
  memory_size?: ByteSize
  memory_size_in_bytes: long
}

export interface FieldSizeUsage {
  size?: ByteSize
  size_in_bytes: long
}

export interface FieldSort {
  missing?: AggregationsMissing
  mode?: SortMode
  nested?: NestedSortValue
  order?: SortOrder
  unmapped_type?: MappingFieldType
  numeric_type?: FieldSortNumericType
  format?: string
}

export type FieldSortNumericType = 'long' | 'double' | 'date' | 'date_nanos'

export type FieldValue = long | double | string | boolean | null

export interface FielddataStats {
  evictions?: long
  memory_size?: ByteSize
  memory_size_in_bytes: long
  fields?: Record<Field, FieldMemoryUsage>
}

export type Fields = Field | Field[]

export interface FlushStats {
  periodic: long
  total: long
  total_time?: Duration
  total_time_in_millis: DurationValue<UnitMillis>
}

export type Fuzziness = string | integer

export type GeoBounds = CoordsGeoBounds | TopLeftBottomRightGeoBounds | TopRightBottomLeftGeoBounds | WktGeoBounds

export interface GeoDistanceSortKeys {
  mode?: SortMode
  distance_type?: GeoDistanceType
  ignore_unmapped?: boolean
  order?: SortOrder
  unit?: DistanceUnit
  nested?: NestedSortValue
}
export type GeoDistanceSort = GeoDistanceSortKeys
& { [property: string]: GeoLocation | GeoLocation[] | SortMode | GeoDistanceType | boolean | SortOrder | DistanceUnit | NestedSortValue }

export type GeoDistanceType = 'arc' | 'plane'

export type GeoHash = string

export interface GeoHashLocation {
  geohash: GeoHash
}

export type GeoHashPrecision = number | string

export type GeoHexCell = string

export interface GeoLine {
  type: string
  coordinates: double[][]
}

export type GeoLocation = LatLonGeoLocation | GeoHashLocation | double[] | string

export type GeoShape = any

export type GeoShapeRelation = 'intersects' | 'disjoint' | 'within' | 'contains'

export type GeoTile = string

export type GeoTilePrecision = number

export interface GetStats {
  current: long
  exists_time?: Duration
  exists_time_in_millis: DurationValue<UnitMillis>
  exists_total: long
  missing_time?: Duration
  missing_time_in_millis: DurationValue<UnitMillis>
  missing_total: long
  time?: Duration
  time_in_millis: DurationValue<UnitMillis>
  total: long
}

export type GrokPattern = string

export type HealthStatus = 'green' | 'GREEN' | 'yellow' | 'YELLOW' | 'red' | 'RED'

export type Host = string

export type HttpHeaders = Record<string, string | string[]>

export type IBDistribution = 'll' | 'spl'

export type IBLambda = 'df' | 'ttf'

export type Id = string

export type Ids = Id | Id[]

export type IndexAlias = string

export type IndexName = string

export type IndexPattern = string

export type IndexPatterns = IndexPattern[]

export interface IndexingStats {
  index_current: long
  delete_current: long
  delete_time?: Duration
  delete_time_in_millis: DurationValue<UnitMillis>
  delete_total: long
  is_throttled: boolean
  noop_update_total: long
  throttle_time?: Duration
  throttle_time_in_millis: DurationValue<UnitMillis>
  index_time?: Duration
  index_time_in_millis: DurationValue<UnitMillis>
  index_total: long
  index_failed: long
  types?: Record<string, IndexingStats>
  write_load?: double
}

export type Indices = IndexName | IndexName[]

export interface IndicesOptions {
  allow_no_indices?: boolean
  expand_wildcards?: ExpandWildcards
  ignore_unavailable?: boolean
  ignore_throttled?: boolean
}

export interface IndicesResponseBase extends AcknowledgedResponseBase {
  _shards?: ShardStatistics
}

export interface InlineGetKeys<TDocument = unknown> {
  fields?: Record<string, any>
  found: boolean
  _seq_no?: SequenceNumber
  _primary_term?: long
  _routing?: Routing
  _source?: TDocument
}
export type InlineGet<TDocument = unknown> = InlineGetKeys<TDocument>
& { [property: string]: any }

export type Ip = string

export interface KnnQuery extends QueryDslQueryBase {
  field: Field
  query_vector?: QueryVector
  query_vector_builder?: QueryVectorBuilder
  num_candidates?: integer
  k?: integer
  filter?: QueryDslQueryContainer | QueryDslQueryContainer[]
  similarity?: float
  rescore_vector?: RescoreVector
}

export interface KnnRetriever extends RetrieverBase {
  field: string
  query_vector?: QueryVector
  query_vector_builder?: QueryVectorBuilder
  k: integer
  num_candidates: integer
  similarity?: float
  rescore_vector?: RescoreVector
}

export interface KnnSearch {
  field: Field
  query_vector?: QueryVector
  query_vector_builder?: QueryVectorBuilder
  k?: integer
  num_candidates?: integer
  boost?: float
  filter?: QueryDslQueryContainer | QueryDslQueryContainer[]
  similarity?: float
  inner_hits?: SearchInnerHits
  rescore_vector?: RescoreVector
}

export interface LatLonGeoLocation {
  lat: double
  lon: double
}

export type Level = 'cluster' | 'indices' | 'shards'

export type LifecycleOperationMode = 'RUNNING' | 'STOPPING' | 'STOPPED'

export type MapboxVectorTiles = ArrayBuffer

export interface MergesStats {
  current: long
  current_docs: long
  current_size?: string
  current_size_in_bytes: long
  total: long
  total_auto_throttle?: string
  total_auto_throttle_in_bytes: long
  total_docs: long
  total_size?: string
  total_size_in_bytes: long
  total_stopped_time?: Duration
  total_stopped_time_in_millis: DurationValue<UnitMillis>
  total_throttled_time?: Duration
  total_throttled_time_in_millis: DurationValue<UnitMillis>
  total_time?: Duration
  total_time_in_millis: DurationValue<UnitMillis>
}

export type Metadata = Record<string, any>

export type Metrics = string | string[]

export type MinimumShouldMatch = integer | string

export type MultiTermQueryRewrite = string

export type Name = string

export type Names = Name | Name[]

export type Namespace = string

export interface NestedSortValue {
  filter?: QueryDslQueryContainer
  max_children?: integer
  nested?: NestedSortValue
  path: Field
}

export interface NodeAttributes {
  attributes: Record<string, string>
  ephemeral_id: Id
  id?: NodeId
  name: NodeName
  transport_address: TransportAddress
}

export type NodeId = string

export type NodeIds = NodeId | NodeId[]

export type NodeName = string

export type NodeRole = 'master' | 'data' | 'data_cold' | 'data_content' | 'data_frozen' | 'data_hot' | 'data_warm' | 'client' | 'ingest' | 'ml' | 'voting_only' | 'transform' | 'remote_cluster_client' | 'coordinating_only'

export type NodeRoles = NodeRole[]

export interface NodeShard {
  state: IndicesStatsShardRoutingState
  primary: boolean
  node?: NodeName
  shard: integer
  index: IndexName
  allocation_id?: Record<string, Id>
  recovery_source?: Record<string, Id>
  unassigned_info?: ClusterAllocationExplainUnassignedInformation
  relocating_node?: NodeId | null
  relocation_failure_info?: RelocationFailureInfo
}

export interface NodeStatistics {
  failures?: ErrorCause[]
  total: integer
  successful: integer
  failed: integer
}

export type Normalization = 'no' | 'h1' | 'h2' | 'h3' | 'z'

export type OpType = 'index' | 'create'

export type Password = string

export type Percentage = string | float

export type PipelineName = string

export interface PluginStats {
  classname: string
  description: string
  elasticsearch_version: VersionString
  extended_plugins: string[]
  has_native_controller: boolean
  java_version: VersionString
  name: Name
  version: VersionString
  licensed: boolean
}

export type PropertyName = string

export interface QueryCacheStats {
  cache_count: long
  cache_size: long
  evictions: long
  hit_count: long
  memory_size?: ByteSize
  memory_size_in_bytes: long
  miss_count: long
  total_count: long
}

export type QueryVector = float[]

export interface QueryVectorBuilder {
  text_embedding?: TextEmbedding
}

export interface RRFRetriever extends RetrieverBase {
  retrievers: RetrieverContainer[]
  rank_constant?: integer
  rank_window_size?: integer
}

export interface RankBase {
}

export interface RankContainer {
  rrf?: RrfRank
}

export interface RecoveryStats {
  current_as_source: long
  current_as_target: long
  throttle_time?: Duration
  throttle_time_in_millis: DurationValue<UnitMillis>
}

export type Refresh = boolean | 'true' | 'false' | 'wait_for'

export interface RefreshStats {
  external_total: long
  external_total_time_in_millis: DurationValue<UnitMillis>
  listeners: long
  total: long
  total_time?: Duration
  total_time_in_millis: DurationValue<UnitMillis>
}

export type RelationName = string

export interface RelocationFailureInfo {
  failed_attempts: integer
}

export interface RequestBase extends SpecUtilsCommonQueryParameters {
}

export interface RequestCacheStats {
  evictions: long
  hit_count: long
  memory_size?: string
  memory_size_in_bytes: long
  miss_count: long
}

export interface RescoreVector {
  oversample: float
}

export type Result = 'created' | 'updated' | 'deleted' | 'not_found' | 'noop'

export interface Retries {
  bulk: long
  search: long
}

export interface RetrieverBase {
  filter?: QueryDslQueryContainer | QueryDslQueryContainer[]
  min_score?: float
}

export interface RetrieverContainer {
  standard?: StandardRetriever
  knn?: KnnRetriever
  rrf?: RRFRetriever
  text_similarity_reranker?: TextSimilarityReranker
  rule?: RuleRetriever
}

export type Routing = string

export interface RrfRank {
  rank_constant?: long
  rank_window_size?: long
}

export interface RuleRetriever extends RetrieverBase {
  ruleset_ids: Id[]
  match_criteria: any
  retriever: RetrieverContainer
  rank_window_size?: integer
}

export type ScalarValue = long | double | string | boolean | null

export interface ScoreSort {
  order?: SortOrder
}

export interface Script {
  source?: string
  id?: Id
  params?: Record<string, any>
  lang?: ScriptLanguage
  options?: Record<string, string>
}

export interface ScriptField {
  script: Script | string
  ignore_failure?: boolean
}

export type ScriptLanguage = 'painless' | 'expression' | 'mustache' | 'java' | string

export interface ScriptSort {
  order?: SortOrder
  script: Script | string
  type?: ScriptSortType
  mode?: SortMode
  nested?: NestedSortValue
}

export type ScriptSortType = 'string' | 'number' | 'version'

export interface ScriptTransform {
  lang?: string
  params?: Record<string, any>
  source?: string
  id?: string
}

export type ScrollId = string

export type ScrollIds = ScrollId | ScrollId[]

export interface SearchStats {
  fetch_current: long
  fetch_time?: Duration
  fetch_time_in_millis: DurationValue<UnitMillis>
  fetch_total: long
  open_contexts?: long
  query_current: long
  query_time?: Duration
  query_time_in_millis: DurationValue<UnitMillis>
  query_total: long
  scroll_current: long
  scroll_time?: Duration
  scroll_time_in_millis: DurationValue<UnitMillis>
  scroll_total: long
  suggest_current: long
  suggest_time?: Duration
  suggest_time_in_millis: DurationValue<UnitMillis>
  suggest_total: long
  groups?: Record<string, SearchStats>
}

export interface SearchTransform {
  request: WatcherSearchInputRequestDefinition
  timeout: Duration
}

export type SearchType = 'query_then_fetch' | 'dfs_query_then_fetch'

export interface SegmentsStats {
  count: integer
  doc_values_memory?: ByteSize
  doc_values_memory_in_bytes: long
  file_sizes: Record<string, IndicesStatsShardFileSizeInfo>
  fixed_bit_set?: ByteSize
  fixed_bit_set_memory_in_bytes: long
  index_writer_memory?: ByteSize
  index_writer_max_memory_in_bytes?: long
  index_writer_memory_in_bytes: long
  max_unsafe_auto_id_timestamp: long
  memory?: ByteSize
  memory_in_bytes: long
  norms_memory?: ByteSize
  norms_memory_in_bytes: long
  points_memory?: ByteSize
  points_memory_in_bytes: long
  stored_memory?: ByteSize
  stored_fields_memory_in_bytes: long
  terms_memory_in_bytes: long
  terms_memory?: ByteSize
  term_vectory_memory?: ByteSize
  term_vectors_memory_in_bytes: long
  version_map_memory?: ByteSize
  version_map_memory_in_bytes: long
}

export type SequenceNumber = long

export type Service = string

export interface ShardFailure {
  index?: IndexName
  node?: string
  reason: ErrorCause
  shard: integer
  status?: string
}

export interface ShardStatistics {
  failed: uint
  successful: uint
  total: uint
  failures?: ShardFailure[]
  skipped?: uint
}

export interface ShardsOperationResponseBase {
  _shards?: ShardStatistics
}

export interface SlicedScroll {
  field?: Field
  id: Id
  max: integer
}

export type Slices = integer | SlicesCalculation

export type SlicesCalculation = 'auto'

export type Sort = SortCombinations | SortCombinations[]

export type SortCombinations = Field | SortOptions

export type SortMode = 'min' | 'max' | 'sum' | 'avg' | 'median'

export interface SortOptionsKeys {
  _score?: ScoreSort
  _doc?: ScoreSort
  _geo_distance?: GeoDistanceSort
  _script?: ScriptSort
}
export type SortOptions = SortOptionsKeys
& { [property: string]: FieldSort | SortOrder | ScoreSort | GeoDistanceSort | ScriptSort }

export type SortOrder = 'asc' | 'desc'

export type SortResults = FieldValue[]

export interface StandardRetriever extends RetrieverBase {
  query?: QueryDslQueryContainer
  search_after?: SortResults
  terminate_after?: integer
  sort?: Sort
  collapse?: SearchFieldCollapse
}

export interface StoreStats {
  size?: ByteSize
  size_in_bytes: long
  reserved?: ByteSize
  reserved_in_bytes: long
  total_data_set_size?: ByteSize
  total_data_set_size_in_bytes?: long
}

export interface StoredScript {
  lang: ScriptLanguage
  options?: Record<string, string>
  source: string
}

export type StreamResult = ArrayBuffer

export type SuggestMode = 'missing' | 'popular' | 'always'

export type SuggestionName = string

export interface TaskFailure {
  task_id: long
  node_id: NodeId
  status: string
  reason: ErrorCause
}

export type TaskId = string | integer

export interface TextEmbedding {
  model_id: string
  model_text: string
}

export interface TextSimilarityReranker extends RetrieverBase {
  retriever: RetrieverContainer
  rank_window_size?: integer
  inference_id?: string
  inference_text?: string
  field?: string
}

export type ThreadType = 'cpu' | 'wait' | 'block' | 'gpu' | 'mem'

export type TimeOfDay = string

export type TimeUnit = 'nanos' | 'micros' | 'ms' | 's' | 'm' | 'h' | 'd'

export type TimeZone = string

export interface TopLeftBottomRightGeoBounds {
  top_left: GeoLocation
  bottom_right: GeoLocation
}

export interface TopRightBottomLeftGeoBounds {
  top_right: GeoLocation
  bottom_left: GeoLocation
}

export interface TransformContainer {
  chain?: TransformContainer[]
  script?: ScriptTransform
  search?: SearchTransform
}

export interface TranslogStats {
  earliest_last_modified_age: long
  operations: long
  size?: string
  size_in_bytes: long
  uncommitted_operations: integer
  uncommitted_size?: string
  uncommitted_size_in_bytes: long
}

export type TransportAddress = string

export type UnitFloatMillis = double

export type UnitMillis = long

export type UnitNanos = long

export type UnitSeconds = long

export type Username = string

export type Uuid = string

export type VersionNumber = long

export type VersionString = string

export type VersionType = 'internal' | 'external' | 'external_gte' | 'force'

export type WaitForActiveShardOptions = 'all' | 'index-setting'

export type WaitForActiveShards = integer | WaitForActiveShardOptions

export type WaitForEvents = 'immediate' | 'urgent' | 'high' | 'normal' | 'low' | 'languid'

export interface WarmerStats {
  current: long
  total: long
  total_time?: Duration
  total_time_in_millis: DurationValue<UnitMillis>
}

export interface WktGeoBounds {
  wkt: string
}

export interface WriteResponseBase {
  _id: Id
  _index: IndexName
  _primary_term?: long
  result: Result
  _seq_no?: SequenceNumber
  _shards: ShardStatistics
  _version: VersionNumber
  forced_refresh?: boolean
}

export type byte = number

export type double = number

export type float = number

export type integer = number

export type long = number

export type short = number

export type uint = number

export type ulong = number

export interface AggregationsAdjacencyMatrixAggregate extends AggregationsMultiBucketAggregateBase<AggregationsAdjacencyMatrixBucket> {
}

export interface AggregationsAdjacencyMatrixAggregation extends AggregationsBucketAggregationBase {
  filters?: Record<string, QueryDslQueryContainer>
  separator?: string
}

export interface AggregationsAdjacencyMatrixBucketKeys extends AggregationsMultiBucketBase {
  key: string
}
export type AggregationsAdjacencyMatrixBucket = AggregationsAdjacencyMatrixBucketKeys
& { [property: string]: AggregationsAggregate | string | long }

export type AggregationsAggregate = AggregationsCardinalityAggregate | AggregationsHdrPercentilesAggregate | AggregationsHdrPercentileRanksAggregate | AggregationsTDigestPercentilesAggregate | AggregationsTDigestPercentileRanksAggregate | AggregationsPercentilesBucketAggregate | AggregationsMedianAbsoluteDeviationAggregate | AggregationsMinAggregate | AggregationsMaxAggregate | AggregationsSumAggregate | AggregationsAvgAggregate | AggregationsWeightedAvgAggregate | AggregationsValueCountAggregate | AggregationsSimpleValueAggregate | AggregationsDerivativeAggregate | AggregationsBucketMetricValueAggregate | AggregationsStatsAggregate | AggregationsStatsBucketAggregate | AggregationsExtendedStatsAggregate | AggregationsExtendedStatsBucketAggregate | AggregationsGeoBoundsAggregate | AggregationsGeoCentroidAggregate | AggregationsHistogramAggregate | AggregationsDateHistogramAggregate | AggregationsAutoDateHistogramAggregate | AggregationsVariableWidthHistogramAggregate | AggregationsStringTermsAggregate | AggregationsLongTermsAggregate | AggregationsDoubleTermsAggregate | AggregationsUnmappedTermsAggregate | AggregationsLongRareTermsAggregate | AggregationsStringRareTermsAggregate | AggregationsUnmappedRareTermsAggregate | AggregationsMultiTermsAggregate | AggregationsMissingAggregate | AggregationsNestedAggregate | AggregationsReverseNestedAggregate | AggregationsGlobalAggregate | AggregationsFilterAggregate | AggregationsChildrenAggregate | AggregationsParentAggregate | AggregationsSamplerAggregate | AggregationsUnmappedSamplerAggregate | AggregationsGeoHashGridAggregate | AggregationsGeoTileGridAggregate | AggregationsGeoHexGridAggregate | AggregationsRangeAggregate | AggregationsDateRangeAggregate | AggregationsGeoDistanceAggregate | AggregationsIpRangeAggregate | AggregationsIpPrefixAggregate | AggregationsFiltersAggregate | AggregationsAdjacencyMatrixAggregate | AggregationsSignificantLongTermsAggregate | AggregationsSignificantStringTermsAggregate | AggregationsUnmappedSignificantTermsAggregate | AggregationsCompositeAggregate | AggregationsFrequentItemSetsAggregate | AggregationsTimeSeriesAggregate | AggregationsScriptedMetricAggregate | AggregationsTopHitsAggregate | AggregationsInferenceAggregate | AggregationsStringStatsAggregate | AggregationsBoxPlotAggregate | AggregationsTopMetricsAggregate | AggregationsTTestAggregate | AggregationsRateAggregate | AggregationsCumulativeCardinalityAggregate | AggregationsMatrixStatsAggregate | AggregationsGeoLineAggregate

export interface AggregationsAggregateBase {
  meta?: Metadata
}

export type AggregationsAggregateOrder = Partial<Record<Field, SortOrder>> | Partial<Record<Field, SortOrder>>[]

export interface AggregationsAggregation {
}

export interface AggregationsAggregationContainer {
  aggregations?: Record<string, AggregationsAggregationContainer>
  aggs?: Record<string, AggregationsAggregationContainer>
  meta?: Metadata
  adjacency_matrix?: AggregationsAdjacencyMatrixAggregation
  auto_date_histogram?: AggregationsAutoDateHistogramAggregation
  avg?: AggregationsAverageAggregation
  avg_bucket?: AggregationsAverageBucketAggregation
  boxplot?: AggregationsBoxplotAggregation
  bucket_script?: AggregationsBucketScriptAggregation
  bucket_selector?: AggregationsBucketSelectorAggregation
  bucket_sort?: AggregationsBucketSortAggregation
  bucket_count_ks_test?: AggregationsBucketKsAggregation
  bucket_correlation?: AggregationsBucketCorrelationAggregation
  cardinality?: AggregationsCardinalityAggregation
  categorize_text?: AggregationsCategorizeTextAggregation
  children?: AggregationsChildrenAggregation
  composite?: AggregationsCompositeAggregation
  cumulative_cardinality?: AggregationsCumulativeCardinalityAggregation
  cumulative_sum?: AggregationsCumulativeSumAggregation
  date_histogram?: AggregationsDateHistogramAggregation
  date_range?: AggregationsDateRangeAggregation
  derivative?: AggregationsDerivativeAggregation
  diversified_sampler?: AggregationsDiversifiedSamplerAggregation
  extended_stats?: AggregationsExtendedStatsAggregation
  extended_stats_bucket?: AggregationsExtendedStatsBucketAggregation
  frequent_item_sets?: AggregationsFrequentItemSetsAggregation
  filter?: QueryDslQueryContainer
  filters?: AggregationsFiltersAggregation
  geo_bounds?: AggregationsGeoBoundsAggregation
  geo_centroid?: AggregationsGeoCentroidAggregation
  geo_distance?: AggregationsGeoDistanceAggregation
  geohash_grid?: AggregationsGeoHashGridAggregation
  geo_line?: AggregationsGeoLineAggregation
  geotile_grid?: AggregationsGeoTileGridAggregation
  geohex_grid?: AggregationsGeohexGridAggregation
  global?: AggregationsGlobalAggregation
  histogram?: AggregationsHistogramAggregation
  ip_range?: AggregationsIpRangeAggregation
  ip_prefix?: AggregationsIpPrefixAggregation
  inference?: AggregationsInferenceAggregation
  line?: AggregationsGeoLineAggregation
  matrix_stats?: AggregationsMatrixStatsAggregation
  max?: AggregationsMaxAggregation
  max_bucket?: AggregationsMaxBucketAggregation
  median_absolute_deviation?: AggregationsMedianAbsoluteDeviationAggregation
  min?: AggregationsMinAggregation
  min_bucket?: AggregationsMinBucketAggregation
  missing?: AggregationsMissingAggregation
  moving_avg?: AggregationsMovingAverageAggregation
  moving_percentiles?: AggregationsMovingPercentilesAggregation
  moving_fn?: AggregationsMovingFunctionAggregation
  multi_terms?: AggregationsMultiTermsAggregation
  nested?: AggregationsNestedAggregation
  normalize?: AggregationsNormalizeAggregation
  parent?: AggregationsParentAggregation
  percentile_ranks?: AggregationsPercentileRanksAggregation
  percentiles?: AggregationsPercentilesAggregation
  percentiles_bucket?: AggregationsPercentilesBucketAggregation
  range?: AggregationsRangeAggregation
  rare_terms?: AggregationsRareTermsAggregation
  rate?: AggregationsRateAggregation
  reverse_nested?: AggregationsReverseNestedAggregation
  random_sampler?: AggregationsRandomSamplerAggregation
  sampler?: AggregationsSamplerAggregation
  scripted_metric?: AggregationsScriptedMetricAggregation
  serial_diff?: AggregationsSerialDifferencingAggregation
  significant_terms?: AggregationsSignificantTermsAggregation
  significant_text?: AggregationsSignificantTextAggregation
  stats?: AggregationsStatsAggregation
  stats_bucket?: AggregationsStatsBucketAggregation
  string_stats?: AggregationsStringStatsAggregation
  sum?: AggregationsSumAggregation
  sum_bucket?: AggregationsSumBucketAggregation
  terms?: AggregationsTermsAggregation
  time_series?: AggregationsTimeSeriesAggregation
  top_hits?: AggregationsTopHitsAggregation
  t_test?: AggregationsTTestAggregation
  top_metrics?: AggregationsTopMetricsAggregation
  value_count?: AggregationsValueCountAggregation
  weighted_avg?: AggregationsWeightedAverageAggregation
  variable_width_histogram?: AggregationsVariableWidthHistogramAggregation
}

export interface AggregationsAggregationRange {
  from?: double | null
  key?: string
  to?: double | null
}

export interface AggregationsArrayPercentilesItem {
  key: string
  value: double | null
  value_as_string?: string
}

export interface AggregationsAutoDateHistogramAggregate extends AggregationsMultiBucketAggregateBase<AggregationsDateHistogramBucket> {
  interval: DurationLarge
}

export interface AggregationsAutoDateHistogramAggregation extends AggregationsBucketAggregationBase {
  buckets?: integer
  field?: Field
  format?: string
  minimum_interval?: AggregationsMinimumInterval
  missing?: DateTime
  offset?: string
  params?: Record<string, any>
  script?: Script | string
  time_zone?: TimeZone
}

export interface AggregationsAverageAggregation extends AggregationsFormatMetricAggregationBase {
}

export interface AggregationsAverageBucketAggregation extends AggregationsPipelineAggregationBase {
}

export interface AggregationsAvgAggregate extends AggregationsSingleMetricAggregateBase {
}

export interface AggregationsBoxPlotAggregate extends AggregationsAggregateBase {
  min: double
  max: double
  q1: double
  q2: double
  q3: double
  lower: double
  upper: double
  min_as_string?: string
  max_as_string?: string
  q1_as_string?: string
  q2_as_string?: string
  q3_as_string?: string
  lower_as_string?: string
  upper_as_string?: string
}

export interface AggregationsBoxplotAggregation extends AggregationsMetricAggregationBase {
  compression?: double
}

export interface AggregationsBucketAggregationBase {
}

export interface AggregationsBucketCorrelationAggregation extends AggregationsBucketPathAggregation {
  function: AggregationsBucketCorrelationFunction
}

export interface AggregationsBucketCorrelationFunction {
  count_correlation: AggregationsBucketCorrelationFunctionCountCorrelation
}

export interface AggregationsBucketCorrelationFunctionCountCorrelation {
  indicator: AggregationsBucketCorrelationFunctionCountCorrelationIndicator
}

export interface AggregationsBucketCorrelationFunctionCountCorrelationIndicator {
  doc_count: integer
  expectations: double[]
  fractions?: double[]
}

export interface AggregationsBucketKsAggregation extends AggregationsBucketPathAggregation {
  alternative?: string[]
  fractions?: double[]
  sampling_method?: string
}

export interface AggregationsBucketMetricValueAggregate extends AggregationsSingleMetricAggregateBase {
  keys: string[]
}

export interface AggregationsBucketPathAggregation {
  buckets_path?: AggregationsBucketsPath
}

export interface AggregationsBucketScriptAggregation extends AggregationsPipelineAggregationBase {
  script?: Script | string
}

export interface AggregationsBucketSelectorAggregation extends AggregationsPipelineAggregationBase {
  script?: Script | string
}

export interface AggregationsBucketSortAggregation {
  from?: integer
  gap_policy?: AggregationsGapPolicy
  size?: integer
  sort?: Sort
}

export type AggregationsBuckets<TBucket = unknown> = Record<string, TBucket> | TBucket[]

export type AggregationsBucketsPath = string | string[] | Record<string, string>

export type AggregationsCalendarInterval = 'second' | '1s' | 'minute' | '1m' | 'hour' | '1h' | 'day' | '1d' | 'week' | '1w' | 'month' | '1M' | 'quarter' | '1q' | 'year' | '1y'

export interface AggregationsCardinalityAggregate extends AggregationsAggregateBase {
  value: long
}

export interface AggregationsCardinalityAggregation extends AggregationsMetricAggregationBase {
  precision_threshold?: integer
  rehash?: boolean
  execution_hint?: AggregationsCardinalityExecutionMode
}

export type AggregationsCardinalityExecutionMode = 'global_ordinals' | 'segment_ordinals' | 'direct' | 'save_memory_heuristic' | 'save_time_heuristic'

export interface AggregationsCategorizeTextAggregation {
  field: Field
  max_unique_tokens?: integer
  max_matched_tokens?: integer
  similarity_threshold?: integer
  categorization_filters?: string[]
  categorization_analyzer?: AggregationsCategorizeTextAnalyzer
  shard_size?: integer
  size?: integer
  min_doc_count?: integer
  shard_min_doc_count?: integer
}

export type AggregationsCategorizeTextAnalyzer = string | AggregationsCustomCategorizeTextAnalyzer

export interface AggregationsChiSquareHeuristic {
  background_is_superset: boolean
  include_negatives: boolean
}

export interface AggregationsChildrenAggregateKeys extends AggregationsSingleBucketAggregateBase {
}
export type AggregationsChildrenAggregate = AggregationsChildrenAggregateKeys
& { [property: string]: AggregationsAggregate | long | Metadata }

export interface AggregationsChildrenAggregation extends AggregationsBucketAggregationBase {
  type?: RelationName
}

export interface AggregationsCompositeAggregate extends AggregationsMultiBucketAggregateBase<AggregationsCompositeBucket> {
  after_key?: AggregationsCompositeAggregateKey
}

export type AggregationsCompositeAggregateKey = Record<Field, FieldValue>

export interface AggregationsCompositeAggregation extends AggregationsBucketAggregationBase {
  after?: AggregationsCompositeAggregateKey
  size?: integer
  sources?: Record<string, AggregationsCompositeAggregationSource>[]
}

export interface AggregationsCompositeAggregationBase {
  field?: Field
  missing_bucket?: boolean
  missing_order?: AggregationsMissingOrder
  script?: Script | string
  value_type?: AggregationsValueType
  order?: SortOrder
}

export interface AggregationsCompositeAggregationSource {
  terms?: AggregationsCompositeTermsAggregation
  histogram?: AggregationsCompositeHistogramAggregation
  date_histogram?: AggregationsCompositeDateHistogramAggregation
  geotile_grid?: AggregationsCompositeGeoTileGridAggregation
}

export interface AggregationsCompositeBucketKeys extends AggregationsMultiBucketBase {
  key: AggregationsCompositeAggregateKey
}
export type AggregationsCompositeBucket = AggregationsCompositeBucketKeys
& { [property: string]: AggregationsAggregate | AggregationsCompositeAggregateKey | long }

export interface AggregationsCompositeDateHistogramAggregation extends AggregationsCompositeAggregationBase {
  format?: string
  calendar_interval?: DurationLarge
  fixed_interval?: DurationLarge
  offset?: Duration
  time_zone?: TimeZone
}

export interface AggregationsCompositeGeoTileGridAggregation extends AggregationsCompositeAggregationBase {
  precision?: integer
  bounds?: GeoBounds
}

export interface AggregationsCompositeHistogramAggregation extends AggregationsCompositeAggregationBase {
  interval: double
}

export interface AggregationsCompositeTermsAggregation extends AggregationsCompositeAggregationBase {
}

export interface AggregationsCumulativeCardinalityAggregate extends AggregationsAggregateBase {
  value: long
  value_as_string?: string
}

export interface AggregationsCumulativeCardinalityAggregation extends AggregationsPipelineAggregationBase {
}

export interface AggregationsCumulativeSumAggregation extends AggregationsPipelineAggregationBase {
}

export interface AggregationsCustomCategorizeTextAnalyzer {
  char_filter?: string[]
  tokenizer?: string
  filter?: string[]
}

export interface AggregationsDateHistogramAggregate extends AggregationsMultiBucketAggregateBase<AggregationsDateHistogramBucket> {
}

export interface AggregationsDateHistogramAggregation extends AggregationsBucketAggregationBase {
  calendar_interval?: AggregationsCalendarInterval
  extended_bounds?: AggregationsExtendedBounds<AggregationsFieldDateMath>
  hard_bounds?: AggregationsExtendedBounds<AggregationsFieldDateMath>
  field?: Field
  fixed_interval?: Duration
  format?: string
  interval?: Duration
  min_doc_count?: integer
  missing?: DateTime
  offset?: Duration
  order?: AggregationsAggregateOrder
  params?: Record<string, any>
  script?: Script | string
  time_zone?: TimeZone
  keyed?: boolean
}

export interface AggregationsDateHistogramBucketKeys extends AggregationsMultiBucketBase {
  key_as_string?: string
  key: EpochTime<UnitMillis>
}
export type AggregationsDateHistogramBucket = AggregationsDateHistogramBucketKeys
& { [property: string]: AggregationsAggregate | string | EpochTime<UnitMillis> | long }

export interface AggregationsDateRangeAggregate extends AggregationsRangeAggregate {
}

export interface AggregationsDateRangeAggregation extends AggregationsBucketAggregationBase {
  field?: Field
  format?: string
  missing?: AggregationsMissing
  ranges?: AggregationsDateRangeExpression[]
  time_zone?: TimeZone
  keyed?: boolean
}

export interface AggregationsDateRangeExpression {
  from?: AggregationsFieldDateMath
  key?: string
  to?: AggregationsFieldDateMath
}

export interface AggregationsDerivativeAggregate extends AggregationsSingleMetricAggregateBase {
  normalized_value?: double
  normalized_value_as_string?: string
}

export interface AggregationsDerivativeAggregation extends AggregationsPipelineAggregationBase {
}

export interface AggregationsDiversifiedSamplerAggregation extends AggregationsBucketAggregationBase {
  execution_hint?: AggregationsSamplerAggregationExecutionHint
  max_docs_per_value?: integer
  script?: Script | string
  shard_size?: integer
  field?: Field
}

export interface AggregationsDoubleTermsAggregate extends AggregationsTermsAggregateBase<AggregationsDoubleTermsBucket> {
}

export interface AggregationsDoubleTermsBucketKeys extends AggregationsTermsBucketBase {
  key: double
  key_as_string?: string
}
export type AggregationsDoubleTermsBucket = AggregationsDoubleTermsBucketKeys
& { [property: string]: AggregationsAggregate | double | string | long }

export interface AggregationsEwmaModelSettings {
  alpha?: float
}

export interface AggregationsEwmaMovingAverageAggregation extends AggregationsMovingAverageAggregationBase {
  model: 'ewma'
  settings: AggregationsEwmaModelSettings
}

export interface AggregationsExtendedBounds<T = unknown> {
  max?: T
  min?: T
}

export interface AggregationsExtendedStatsAggregate extends AggregationsStatsAggregate {
  sum_of_squares: double | null
  variance: double | null
  variance_population: double | null
  variance_sampling: double | null
  std_deviation: double | null
  std_deviation_population: double | null
  std_deviation_sampling: double | null
  std_deviation_bounds?: AggregationsStandardDeviationBounds
  sum_of_squares_as_string?: string
  variance_as_string?: string
  variance_population_as_string?: string
  variance_sampling_as_string?: string
  std_deviation_as_string?: string
  std_deviation_bounds_as_string?: AggregationsStandardDeviationBoundsAsString
}

export interface AggregationsExtendedStatsAggregation extends AggregationsFormatMetricAggregationBase {
  sigma?: double
}

export interface AggregationsExtendedStatsBucketAggregate extends AggregationsExtendedStatsAggregate {
}

export interface AggregationsExtendedStatsBucketAggregation extends AggregationsPipelineAggregationBase {
  sigma?: double
}

export type AggregationsFieldDateMath = DateMath | double

export interface AggregationsFilterAggregateKeys extends AggregationsSingleBucketAggregateBase {
}
export type AggregationsFilterAggregate = AggregationsFilterAggregateKeys
& { [property: string]: AggregationsAggregate | long | Metadata }

export interface AggregationsFiltersAggregate extends AggregationsMultiBucketAggregateBase<AggregationsFiltersBucket> {
}

export interface AggregationsFiltersAggregation extends AggregationsBucketAggregationBase {
  filters?: AggregationsBuckets<QueryDslQueryContainer>
  other_bucket?: boolean
  other_bucket_key?: string
  keyed?: boolean
}

export interface AggregationsFiltersBucketKeys extends AggregationsMultiBucketBase {
}
export type AggregationsFiltersBucket = AggregationsFiltersBucketKeys
& { [property: string]: AggregationsAggregate | long }

export interface AggregationsFormatMetricAggregationBase extends AggregationsMetricAggregationBase {
  format?: string
}

export interface AggregationsFormattableMetricAggregation extends AggregationsMetricAggregationBase {
  format?: string
}

export interface AggregationsFrequentItemSetsAggregate extends AggregationsMultiBucketAggregateBase<AggregationsFrequentItemSetsBucket> {
}

export interface AggregationsFrequentItemSetsAggregation {
  fields: AggregationsFrequentItemSetsField[]
  minimum_set_size?: integer
  minimum_support?: double
  size?: integer
  filter?: QueryDslQueryContainer
}

export interface AggregationsFrequentItemSetsBucketKeys extends AggregationsMultiBucketBase {
  key: Record<Field, string[]>
  support: double
}
export type AggregationsFrequentItemSetsBucket = AggregationsFrequentItemSetsBucketKeys
& { [property: string]: AggregationsAggregate | Record<Field, string[]> | double | long }

export interface AggregationsFrequentItemSetsField {
  field: Field
  exclude?: AggregationsTermsExclude
  include?: AggregationsTermsInclude
}

export type AggregationsGapPolicy = 'skip' | 'insert_zeros' | 'keep_values'

export interface AggregationsGeoBoundsAggregate extends AggregationsAggregateBase {
  bounds?: GeoBounds
}

export interface AggregationsGeoBoundsAggregation extends AggregationsMetricAggregationBase {
  wrap_longitude?: boolean
}

export interface AggregationsGeoCentroidAggregate extends AggregationsAggregateBase {
  count: long
  location?: GeoLocation
}

export interface AggregationsGeoCentroidAggregation extends AggregationsMetricAggregationBase {
  count?: long
  location?: GeoLocation
}

export interface AggregationsGeoDistanceAggregate extends AggregationsRangeAggregate {
}

export interface AggregationsGeoDistanceAggregation extends AggregationsBucketAggregationBase {
  distance_type?: GeoDistanceType
  field?: Field
  origin?: GeoLocation
  ranges?: AggregationsAggregationRange[]
  unit?: DistanceUnit
}

export interface AggregationsGeoHashGridAggregate extends AggregationsMultiBucketAggregateBase<AggregationsGeoHashGridBucket> {
}

export interface AggregationsGeoHashGridAggregation extends AggregationsBucketAggregationBase {
  bounds?: GeoBounds
  field?: Field
  precision?: GeoHashPrecision
  shard_size?: integer
  size?: integer
}

export interface AggregationsGeoHashGridBucketKeys extends AggregationsMultiBucketBase {
  key: GeoHash
}
export type AggregationsGeoHashGridBucket = AggregationsGeoHashGridBucketKeys
& { [property: string]: AggregationsAggregate | GeoHash | long }

export interface AggregationsGeoHexGridAggregate extends AggregationsMultiBucketAggregateBase<AggregationsGeoHexGridBucket> {
}

export interface AggregationsGeoHexGridBucketKeys extends AggregationsMultiBucketBase {
  key: GeoHexCell
}
export type AggregationsGeoHexGridBucket = AggregationsGeoHexGridBucketKeys
& { [property: string]: AggregationsAggregate | GeoHexCell | long }

export interface AggregationsGeoLineAggregate extends AggregationsAggregateBase {
  type: string
  geometry: GeoLine
  properties: any
}

export interface AggregationsGeoLineAggregation {
  point: AggregationsGeoLinePoint
  sort: AggregationsGeoLineSort
  include_sort?: boolean
  sort_order?: SortOrder
  size?: integer
}

export interface AggregationsGeoLinePoint {
  field: Field
}

export interface AggregationsGeoLineSort {
  field: Field
}

export interface AggregationsGeoTileGridAggregate extends AggregationsMultiBucketAggregateBase<AggregationsGeoTileGridBucket> {
}

export interface AggregationsGeoTileGridAggregation extends AggregationsBucketAggregationBase {
  field?: Field
  precision?: GeoTilePrecision
  shard_size?: integer
  size?: integer
  bounds?: GeoBounds
}

export interface AggregationsGeoTileGridBucketKeys extends AggregationsMultiBucketBase {
  key: GeoTile
}
export type AggregationsGeoTileGridBucket = AggregationsGeoTileGridBucketKeys
& { [property: string]: AggregationsAggregate | GeoTile | long }

export interface AggregationsGeohexGridAggregation extends AggregationsBucketAggregationBase {
  field: Field
  precision?: integer
  bounds?: GeoBounds
  size?: integer
  shard_size?: integer
}

export interface AggregationsGlobalAggregateKeys extends AggregationsSingleBucketAggregateBase {
}
export type AggregationsGlobalAggregate = AggregationsGlobalAggregateKeys
& { [property: string]: AggregationsAggregate | long | Metadata }

export interface AggregationsGlobalAggregation extends AggregationsBucketAggregationBase {
}

export interface AggregationsGoogleNormalizedDistanceHeuristic {
  background_is_superset?: boolean
}

export interface AggregationsHdrMethod {
  number_of_significant_value_digits?: integer
}

export interface AggregationsHdrPercentileRanksAggregate extends AggregationsPercentilesAggregateBase {
}

export interface AggregationsHdrPercentilesAggregate extends AggregationsPercentilesAggregateBase {
}

export interface AggregationsHistogramAggregate extends AggregationsMultiBucketAggregateBase<AggregationsHistogramBucket> {
}

export interface AggregationsHistogramAggregation extends AggregationsBucketAggregationBase {
  extended_bounds?: AggregationsExtendedBounds<double>
  hard_bounds?: AggregationsExtendedBounds<double>
  field?: Field
  interval?: double
  min_doc_count?: integer
  missing?: double
  offset?: double
  order?: AggregationsAggregateOrder
  script?: Script | string
  format?: string
  keyed?: boolean
}

export interface AggregationsHistogramBucketKeys extends AggregationsMultiBucketBase {
  key_as_string?: string
  key: double
}
export type AggregationsHistogramBucket = AggregationsHistogramBucketKeys
& { [property: string]: AggregationsAggregate | string | double | long }

export interface AggregationsHoltLinearModelSettings {
  alpha?: float
  beta?: float
}

export interface AggregationsHoltMovingAverageAggregation extends AggregationsMovingAverageAggregationBase {
  model: 'holt'
  settings: AggregationsHoltLinearModelSettings
}

export interface AggregationsHoltWintersModelSettings {
  alpha?: float
  beta?: float
  gamma?: float
  pad?: boolean
  period?: integer
  type?: AggregationsHoltWintersType
}

export interface AggregationsHoltWintersMovingAverageAggregation extends AggregationsMovingAverageAggregationBase {
  model: 'holt_winters'
  settings: AggregationsHoltWintersModelSettings
}

export type AggregationsHoltWintersType = 'add' | 'mult'

export interface AggregationsInferenceAggregateKeys extends AggregationsAggregateBase {
  value?: FieldValue
  feature_importance?: AggregationsInferenceFeatureImportance[]
  top_classes?: AggregationsInferenceTopClassEntry[]
  warning?: string
}
export type AggregationsInferenceAggregate = AggregationsInferenceAggregateKeys
& { [property: string]: any }

export interface AggregationsInferenceAggregation extends AggregationsPipelineAggregationBase {
  model_id: Name
  inference_config?: AggregationsInferenceConfigContainer
}

export interface AggregationsInferenceClassImportance {
  class_name: string
  importance: double
}

export interface AggregationsInferenceConfigContainer {
  regression?: MlRegressionInferenceOptions
  classification?: MlClassificationInferenceOptions
}

export interface AggregationsInferenceFeatureImportance {
  feature_name: string
  importance?: double
  classes?: AggregationsInferenceClassImportance[]
}

export interface AggregationsInferenceTopClassEntry {
  class_name: FieldValue
  class_probability: double
  class_score: double
}

export interface AggregationsIpPrefixAggregate extends AggregationsMultiBucketAggregateBase<AggregationsIpPrefixBucket> {
}

export interface AggregationsIpPrefixAggregation extends AggregationsBucketAggregationBase {
  field: Field
  prefix_length: integer
  is_ipv6?: boolean
  append_prefix_length?: boolean
  keyed?: boolean
  min_doc_count?: long
}

export interface AggregationsIpPrefixBucketKeys extends AggregationsMultiBucketBase {
  is_ipv6: boolean
  key: string
  prefix_length: integer
  netmask?: string
}
export type AggregationsIpPrefixBucket = AggregationsIpPrefixBucketKeys
& { [property: string]: AggregationsAggregate | boolean | string | integer | long }

export interface AggregationsIpRangeAggregate extends AggregationsMultiBucketAggregateBase<AggregationsIpRangeBucket> {
}

export interface AggregationsIpRangeAggregation extends AggregationsBucketAggregationBase {
  field?: Field
  ranges?: AggregationsIpRangeAggregationRange[]
}

export interface AggregationsIpRangeAggregationRange {
  from?: string | null
  mask?: string
  to?: string | null
}

export interface AggregationsIpRangeBucketKeys extends AggregationsMultiBucketBase {
  key?: string
  from?: string
  to?: string
}
export type AggregationsIpRangeBucket = AggregationsIpRangeBucketKeys
& { [property: string]: AggregationsAggregate | string | long }

export type AggregationsKeyedPercentiles = Record<string, string | long | null>

export interface AggregationsLinearMovingAverageAggregation extends AggregationsMovingAverageAggregationBase {
  model: 'linear'
  settings: EmptyObject
}

export interface AggregationsLongRareTermsAggregate extends AggregationsMultiBucketAggregateBase<AggregationsLongRareTermsBucket> {
}

export interface AggregationsLongRareTermsBucketKeys extends AggregationsMultiBucketBase {
  key: long
  key_as_string?: string
}
export type AggregationsLongRareTermsBucket = AggregationsLongRareTermsBucketKeys
& { [property: string]: AggregationsAggregate | long | string }

export interface AggregationsLongTermsAggregate extends AggregationsTermsAggregateBase<AggregationsLongTermsBucket> {
}

export interface AggregationsLongTermsBucketKeys extends AggregationsTermsBucketBase {
  key: long
  key_as_string?: string
}
export type AggregationsLongTermsBucket = AggregationsLongTermsBucketKeys
& { [property: string]: AggregationsAggregate | long | string }

export interface AggregationsMatrixAggregation {
  fields?: Fields
  missing?: Record<Field, double>
}

export interface AggregationsMatrixStatsAggregate extends AggregationsAggregateBase {
  doc_count: long
  fields?: AggregationsMatrixStatsFields[]
}

export interface AggregationsMatrixStatsAggregation extends AggregationsMatrixAggregation {
  mode?: SortMode
}

export interface AggregationsMatrixStatsFields {
  name: Field
  count: long
  mean: double
  variance: double
  skewness: double
  kurtosis: double
  covariance: Record<Field, double>
  correlation: Record<Field, double>
}

export interface AggregationsMaxAggregate extends AggregationsSingleMetricAggregateBase {
}

export interface AggregationsMaxAggregation extends AggregationsFormatMetricAggregationBase {
}

export interface AggregationsMaxBucketAggregation extends AggregationsPipelineAggregationBase {
}

export interface AggregationsMedianAbsoluteDeviationAggregate extends AggregationsSingleMetricAggregateBase {
}

export interface AggregationsMedianAbsoluteDeviationAggregation extends AggregationsFormatMetricAggregationBase {
  compression?: double
}

export interface AggregationsMetricAggregationBase {
  field?: Field
  missing?: AggregationsMissing
  script?: Script | string
}

export interface AggregationsMinAggregate extends AggregationsSingleMetricAggregateBase {
}

export interface AggregationsMinAggregation extends AggregationsFormatMetricAggregationBase {
}

export interface AggregationsMinBucketAggregation extends AggregationsPipelineAggregationBase {
}

export type AggregationsMinimumInterval = 'second' | 'minute' | 'hour' | 'day' | 'month' | 'year'

export type AggregationsMissing = string | integer | double | boolean

export interface AggregationsMissingAggregateKeys extends AggregationsSingleBucketAggregateBase {
}
export type AggregationsMissingAggregate = AggregationsMissingAggregateKeys
& { [property: string]: AggregationsAggregate | long | Metadata }

export interface AggregationsMissingAggregation extends AggregationsBucketAggregationBase {
  field?: Field
  missing?: AggregationsMissing
}

export type AggregationsMissingOrder = 'first' | 'last' | 'default'

export type AggregationsMovingAverageAggregation = AggregationsLinearMovingAverageAggregation | AggregationsSimpleMovingAverageAggregation | AggregationsEwmaMovingAverageAggregation | AggregationsHoltMovingAverageAggregation | AggregationsHoltWintersMovingAverageAggregation

export interface AggregationsMovingAverageAggregationBase extends AggregationsPipelineAggregationBase {
  minimize?: boolean
  predict?: integer
  window?: integer
}

export interface AggregationsMovingFunctionAggregation extends AggregationsPipelineAggregationBase {
  script?: string
  shift?: integer
  window?: integer
}

export interface AggregationsMovingPercentilesAggregation extends AggregationsPipelineAggregationBase {
  window?: integer
  shift?: integer
  keyed?: boolean
}

export interface AggregationsMultiBucketAggregateBase<TBucket = unknown> extends AggregationsAggregateBase {
  buckets: AggregationsBuckets<TBucket>
}

export interface AggregationsMultiBucketBase {
  doc_count: long
}

export interface AggregationsMultiTermLookup {
  field: Field
  missing?: AggregationsMissing
}

export interface AggregationsMultiTermsAggregate extends AggregationsTermsAggregateBase<AggregationsMultiTermsBucket> {
}

export interface AggregationsMultiTermsAggregation extends AggregationsBucketAggregationBase {
  collect_mode?: AggregationsTermsAggregationCollectMode
  order?: AggregationsAggregateOrder
  min_doc_count?: long
  shard_min_doc_count?: long
  shard_size?: integer
  show_term_doc_count_error?: boolean
  size?: integer
  terms: AggregationsMultiTermLookup[]
}

export interface AggregationsMultiTermsBucketKeys extends AggregationsMultiBucketBase {
  key: FieldValue[]
  key_as_string?: string
  doc_count_error_upper_bound?: long
}
export type AggregationsMultiTermsBucket = AggregationsMultiTermsBucketKeys
& { [property: string]: AggregationsAggregate | FieldValue[] | string | long }

export interface AggregationsMutualInformationHeuristic {
  background_is_superset?: boolean
  include_negatives?: boolean
}

export interface AggregationsNestedAggregateKeys extends AggregationsSingleBucketAggregateBase {
}
export type AggregationsNestedAggregate = AggregationsNestedAggregateKeys
& { [property: string]: AggregationsAggregate | long | Metadata }

export interface AggregationsNestedAggregation extends AggregationsBucketAggregationBase {
  path?: Field
}

export interface AggregationsNormalizeAggregation extends AggregationsPipelineAggregationBase {
  method?: AggregationsNormalizeMethod
}

export type AggregationsNormalizeMethod = 'rescale_0_1' | 'rescale_0_100' | 'percent_of_sum' | 'mean' | 'z-score' | 'softmax'

export interface AggregationsParentAggregateKeys extends AggregationsSingleBucketAggregateBase {
}
export type AggregationsParentAggregate = AggregationsParentAggregateKeys
& { [property: string]: AggregationsAggregate | long | Metadata }

export interface AggregationsParentAggregation extends AggregationsBucketAggregationBase {
  type?: RelationName
}

export interface AggregationsPercentageScoreHeuristic {
}

export interface AggregationsPercentileRanksAggregation extends AggregationsFormatMetricAggregationBase {
  keyed?: boolean
  values?: double[] | null
  hdr?: AggregationsHdrMethod
  tdigest?: AggregationsTDigest
}

export type AggregationsPercentiles = AggregationsKeyedPercentiles | AggregationsArrayPercentilesItem[]

export interface AggregationsPercentilesAggregateBase extends AggregationsAggregateBase {
  values: AggregationsPercentiles
}

export interface AggregationsPercentilesAggregation extends AggregationsFormatMetricAggregationBase {
  keyed?: boolean
  percents?: double[]
  hdr?: AggregationsHdrMethod
  tdigest?: AggregationsTDigest
}

export interface AggregationsPercentilesBucketAggregate extends AggregationsPercentilesAggregateBase {
}

export interface AggregationsPercentilesBucketAggregation extends AggregationsPipelineAggregationBase {
  percents?: double[]
}

export interface AggregationsPipelineAggregationBase extends AggregationsBucketPathAggregation {
  format?: string
  gap_policy?: AggregationsGapPolicy
}

export interface AggregationsRandomSamplerAggregation extends AggregationsBucketAggregationBase {
  probability: double
  seed?: integer
  shard_seed?: integer
}

export interface AggregationsRangeAggregate extends AggregationsMultiBucketAggregateBase<AggregationsRangeBucket> {
}

export interface AggregationsRangeAggregation extends AggregationsBucketAggregationBase {
  field?: Field
  missing?: integer
  ranges?: AggregationsAggregationRange[]
  script?: Script | string
  keyed?: boolean
  format?: string
}

export interface AggregationsRangeBucketKeys extends AggregationsMultiBucketBase {
  from?: double
  to?: double
  from_as_string?: string
  to_as_string?: string
  key?: string
}
export type AggregationsRangeBucket = AggregationsRangeBucketKeys
& { [property: string]: AggregationsAggregate | double | string | long }

export interface AggregationsRareTermsAggregation extends AggregationsBucketAggregationBase {
  exclude?: AggregationsTermsExclude
  field?: Field
  include?: AggregationsTermsInclude
  max_doc_count?: long
  missing?: AggregationsMissing
  precision?: double
  value_type?: string
}

export interface AggregationsRateAggregate extends AggregationsAggregateBase {
  value: double
  value_as_string?: string
}

export interface AggregationsRateAggregation extends AggregationsFormatMetricAggregationBase {
  unit?: AggregationsCalendarInterval
  mode?: AggregationsRateMode
}

export type AggregationsRateMode = 'sum' | 'value_count'

export interface AggregationsReverseNestedAggregateKeys extends AggregationsSingleBucketAggregateBase {
}
export type AggregationsReverseNestedAggregate = AggregationsReverseNestedAggregateKeys
& { [property: string]: AggregationsAggregate | long | Metadata }

export interface AggregationsReverseNestedAggregation extends AggregationsBucketAggregationBase {
  path?: Field
}

export interface AggregationsSamplerAggregateKeys extends AggregationsSingleBucketAggregateBase {
}
export type AggregationsSamplerAggregate = AggregationsSamplerAggregateKeys
& { [property: string]: AggregationsAggregate | long | Metadata }

export interface AggregationsSamplerAggregation extends AggregationsBucketAggregationBase {
  shard_size?: integer
}

export type AggregationsSamplerAggregationExecutionHint = 'map' | 'global_ordinals' | 'bytes_hash'

export interface AggregationsScriptedHeuristic {
  script: Script | string
}

export interface AggregationsScriptedMetricAggregate extends AggregationsAggregateBase {
  value: any
}

export interface AggregationsScriptedMetricAggregation extends AggregationsMetricAggregationBase {
  combine_script?: Script | string
  init_script?: Script | string
  map_script?: Script | string
  params?: Record<string, any>
  reduce_script?: Script | string
}

export interface AggregationsSerialDifferencingAggregation extends AggregationsPipelineAggregationBase {
  lag?: integer
}

export interface AggregationsSignificantLongTermsAggregate extends AggregationsSignificantTermsAggregateBase<AggregationsSignificantLongTermsBucket> {
}

export interface AggregationsSignificantLongTermsBucketKeys extends AggregationsSignificantTermsBucketBase {
  key: long
  key_as_string?: string
}
export type AggregationsSignificantLongTermsBucket = AggregationsSignificantLongTermsBucketKeys
& { [property: string]: AggregationsAggregate | long | string | double }

export interface AggregationsSignificantStringTermsAggregate extends AggregationsSignificantTermsAggregateBase<AggregationsSignificantStringTermsBucket> {
}

export interface AggregationsSignificantStringTermsBucketKeys extends AggregationsSignificantTermsBucketBase {
  key: string
}
export type AggregationsSignificantStringTermsBucket = AggregationsSignificantStringTermsBucketKeys
& { [property: string]: AggregationsAggregate | string | double | long }

export interface AggregationsSignificantTermsAggregateBase<T = unknown> extends AggregationsMultiBucketAggregateBase<T> {
  bg_count?: long
  doc_count?: long
}

export interface AggregationsSignificantTermsAggregation extends AggregationsBucketAggregationBase {
  background_filter?: QueryDslQueryContainer
  chi_square?: AggregationsChiSquareHeuristic
  exclude?: AggregationsTermsExclude
  execution_hint?: AggregationsTermsAggregationExecutionHint
  field?: Field
  gnd?: AggregationsGoogleNormalizedDistanceHeuristic
  include?: AggregationsTermsInclude
  jlh?: EmptyObject
  min_doc_count?: long
  mutual_information?: AggregationsMutualInformationHeuristic
  percentage?: AggregationsPercentageScoreHeuristic
  script_heuristic?: AggregationsScriptedHeuristic
  shard_min_doc_count?: long
  shard_size?: integer
  size?: integer
}

export interface AggregationsSignificantTermsBucketBase extends AggregationsMultiBucketBase {
  score: double
  bg_count: long
}

export interface AggregationsSignificantTextAggregation extends AggregationsBucketAggregationBase {
  background_filter?: QueryDslQueryContainer
  chi_square?: AggregationsChiSquareHeuristic
  exclude?: AggregationsTermsExclude
  execution_hint?: AggregationsTermsAggregationExecutionHint
  field?: Field
  filter_duplicate_text?: boolean
  gnd?: AggregationsGoogleNormalizedDistanceHeuristic
  include?: AggregationsTermsInclude
  jlh?: EmptyObject
  min_doc_count?: long
  mutual_information?: AggregationsMutualInformationHeuristic
  percentage?: AggregationsPercentageScoreHeuristic
  script_heuristic?: AggregationsScriptedHeuristic
  shard_min_doc_count?: long
  shard_size?: integer
  size?: integer
  source_fields?: Fields
}

export interface AggregationsSimpleMovingAverageAggregation extends AggregationsMovingAverageAggregationBase {
  model: 'simple'
  settings: EmptyObject
}

export interface AggregationsSimpleValueAggregate extends AggregationsSingleMetricAggregateBase {
}

export interface AggregationsSingleBucketAggregateBase extends AggregationsAggregateBase {
  doc_count: long
}

export interface AggregationsSingleMetricAggregateBase extends AggregationsAggregateBase {
  value: double | null
  value_as_string?: string
}

export interface AggregationsStandardDeviationBounds {
  upper: double | null
  lower: double | null
  upper_population: double | null
  lower_population: double | null
  upper_sampling: double | null
  lower_sampling: double | null
}

export interface AggregationsStandardDeviationBoundsAsString {
  upper: string
  lower: string
  upper_population: string
  lower_population: string
  upper_sampling: string
  lower_sampling: string
}

export interface AggregationsStatsAggregate extends AggregationsAggregateBase {
  count: long
  min: double | null
  max: double | null
  avg: double | null
  sum: double
  min_as_string?: string
  max_as_string?: string
  avg_as_string?: string
  sum_as_string?: string
}

export interface AggregationsStatsAggregation extends AggregationsFormatMetricAggregationBase {
}

export interface AggregationsStatsBucketAggregate extends AggregationsStatsAggregate {
}

export interface AggregationsStatsBucketAggregation extends AggregationsPipelineAggregationBase {
}

export interface AggregationsStringRareTermsAggregate extends AggregationsMultiBucketAggregateBase<AggregationsStringRareTermsBucket> {
}

export interface AggregationsStringRareTermsBucketKeys extends AggregationsMultiBucketBase {
  key: string
}
export type AggregationsStringRareTermsBucket = AggregationsStringRareTermsBucketKeys
& { [property: string]: AggregationsAggregate | string | long }

export interface AggregationsStringStatsAggregate extends AggregationsAggregateBase {
  count: long
  min_length: integer | null
  max_length: integer | null
  avg_length: double | null
  entropy: double | null
  distribution?: Record<string, double> | null
  min_length_as_string?: string
  max_length_as_string?: string
  avg_length_as_string?: string
}

export interface AggregationsStringStatsAggregation extends AggregationsMetricAggregationBase {
  show_distribution?: boolean
}

export interface AggregationsStringTermsAggregate extends AggregationsTermsAggregateBase<AggregationsStringTermsBucket> {
}

export interface AggregationsStringTermsBucketKeys extends AggregationsTermsBucketBase {
  key: FieldValue
}
export type AggregationsStringTermsBucket = AggregationsStringTermsBucketKeys
& { [property: string]: AggregationsAggregate | FieldValue | long }

export interface AggregationsSumAggregate extends AggregationsSingleMetricAggregateBase {
}

export interface AggregationsSumAggregation extends AggregationsFormatMetricAggregationBase {
}

export interface AggregationsSumBucketAggregation extends AggregationsPipelineAggregationBase {
}

export interface AggregationsTDigest {
  compression?: integer
}

export interface AggregationsTDigestPercentileRanksAggregate extends AggregationsPercentilesAggregateBase {
}

export interface AggregationsTDigestPercentilesAggregate extends AggregationsPercentilesAggregateBase {
}

export interface AggregationsTTestAggregate extends AggregationsAggregateBase {
  value: double | null
  value_as_string?: string
}

export interface AggregationsTTestAggregation {
  a?: AggregationsTestPopulation
  b?: AggregationsTestPopulation
  type?: AggregationsTTestType
}

export type AggregationsTTestType = 'paired' | 'homoscedastic' | 'heteroscedastic'

export interface AggregationsTermsAggregateBase<TBucket = unknown> extends AggregationsMultiBucketAggregateBase<TBucket> {
  doc_count_error_upper_bound?: long
  sum_other_doc_count?: long
}

export interface AggregationsTermsAggregation extends AggregationsBucketAggregationBase {
  collect_mode?: AggregationsTermsAggregationCollectMode
  exclude?: AggregationsTermsExclude
  execution_hint?: AggregationsTermsAggregationExecutionHint
  field?: Field
  include?: AggregationsTermsInclude
  min_doc_count?: integer
  missing?: AggregationsMissing
  missing_order?: AggregationsMissingOrder
  missing_bucket?: boolean
  value_type?: string
  order?: AggregationsAggregateOrder
  script?: Script | string
  shard_min_doc_count?: long
  shard_size?: integer
  show_term_doc_count_error?: boolean
  size?: integer
  format?: string
}

export type AggregationsTermsAggregationCollectMode = 'depth_first' | 'breadth_first'

export type AggregationsTermsAggregationExecutionHint = 'map' | 'global_ordinals' | 'global_ordinals_hash' | 'global_ordinals_low_cardinality'

export interface AggregationsTermsBucketBase extends AggregationsMultiBucketBase {
  doc_count_error_upper_bound?: long
}

export type AggregationsTermsExclude = string | string[]

export type AggregationsTermsInclude = string | string[] | AggregationsTermsPartition

export interface AggregationsTermsPartition {
  num_partitions: long
  partition: long
}

export interface AggregationsTestPopulation {
  field: Field
  script?: Script | string
  filter?: QueryDslQueryContainer
}

export interface AggregationsTimeSeriesAggregate extends AggregationsMultiBucketAggregateBase<AggregationsTimeSeriesBucket> {
}

export interface AggregationsTimeSeriesAggregation extends AggregationsBucketAggregationBase {
  size?: integer
  keyed?: boolean
}

export interface AggregationsTimeSeriesBucketKeys extends AggregationsMultiBucketBase {
  key: Record<Field, FieldValue>
}
export type AggregationsTimeSeriesBucket = AggregationsTimeSeriesBucketKeys
& { [property: string]: AggregationsAggregate | Record<Field, FieldValue> | long }

export interface AggregationsTopHitsAggregate extends AggregationsAggregateBase {
  hits: SearchHitsMetadata<any>
}

export interface AggregationsTopHitsAggregation extends AggregationsMetricAggregationBase {
  docvalue_fields?: (QueryDslFieldAndFormat | Field)[]
  explain?: boolean
  fields?: (QueryDslFieldAndFormat | Field)[]
  from?: integer
  highlight?: SearchHighlight
  script_fields?: Record<string, ScriptField>
  size?: integer
  sort?: Sort
  _source?: SearchSourceConfig
  stored_fields?: Fields
  track_scores?: boolean
  version?: boolean
  seq_no_primary_term?: boolean
}

export interface AggregationsTopMetrics {
  sort: (FieldValue | null)[]
  metrics: Record<string, FieldValue | null>
}

export interface AggregationsTopMetricsAggregate extends AggregationsAggregateBase {
  top: AggregationsTopMetrics[]
}

export interface AggregationsTopMetricsAggregation extends AggregationsMetricAggregationBase {
  metrics?: AggregationsTopMetricsValue | AggregationsTopMetricsValue[]
  size?: integer
  sort?: Sort
}

export interface AggregationsTopMetricsValue {
  field: Field
}

export interface AggregationsUnmappedRareTermsAggregate extends AggregationsMultiBucketAggregateBase<void> {
}

export interface AggregationsUnmappedSamplerAggregateKeys extends AggregationsSingleBucketAggregateBase {
}
export type AggregationsUnmappedSamplerAggregate = AggregationsUnmappedSamplerAggregateKeys
& { [property: string]: AggregationsAggregate | long | Metadata }

export interface AggregationsUnmappedSignificantTermsAggregate extends AggregationsSignificantTermsAggregateBase<void> {
}

export interface AggregationsUnmappedTermsAggregate extends AggregationsTermsAggregateBase<void> {
}

export interface AggregationsValueCountAggregate extends AggregationsSingleMetricAggregateBase {
}

export interface AggregationsValueCountAggregation extends AggregationsFormattableMetricAggregation {
}

export type AggregationsValueType = 'string' | 'long' | 'double' | 'number' | 'date' | 'date_nanos' | 'ip' | 'numeric' | 'geo_point' | 'boolean'

export interface AggregationsVariableWidthHistogramAggregate extends AggregationsMultiBucketAggregateBase<AggregationsVariableWidthHistogramBucket> {
}

export interface AggregationsVariableWidthHistogramAggregation {
  field?: Field
  buckets?: integer
  shard_size?: integer
  initial_buffer?: integer
  script?: Script | string
}

export interface AggregationsVariableWidthHistogramBucketKeys extends AggregationsMultiBucketBase {
  min: double
  key: double
  max: double
  min_as_string?: string
  key_as_string?: string
  max_as_string?: string
}
export type AggregationsVariableWidthHistogramBucket = AggregationsVariableWidthHistogramBucketKeys
& { [property: string]: AggregationsAggregate | double | string | long }

export interface AggregationsWeightedAverageAggregation {
  format?: string
  value?: AggregationsWeightedAverageValue
  value_type?: AggregationsValueType
  weight?: AggregationsWeightedAverageValue
}

export interface AggregationsWeightedAverageValue {
  field?: Field
  missing?: double
  script?: Script | string
}

export interface AggregationsWeightedAvgAggregate extends AggregationsSingleMetricAggregateBase {
}

export type AnalysisAnalyzer = AnalysisCustomAnalyzer | AnalysisFingerprintAnalyzer | AnalysisKeywordAnalyzer | AnalysisNoriAnalyzer | AnalysisPatternAnalyzer | AnalysisSimpleAnalyzer | AnalysisStandardAnalyzer | AnalysisStopAnalyzer | AnalysisWhitespaceAnalyzer | AnalysisIcuAnalyzer | AnalysisKuromojiAnalyzer | AnalysisSnowballAnalyzer | AnalysisArabicAnalyzer | AnalysisArmenianAnalyzer | AnalysisBasqueAnalyzer | AnalysisBengaliAnalyzer | AnalysisBrazilianAnalyzer | AnalysisBulgarianAnalyzer | AnalysisCatalanAnalyzer | AnalysisChineseAnalyzer | AnalysisCjkAnalyzer | AnalysisCzechAnalyzer | AnalysisDanishAnalyzer | AnalysisDutchAnalyzer | AnalysisEnglishAnalyzer | AnalysisEstonianAnalyzer | AnalysisFinnishAnalyzer | AnalysisFrenchAnalyzer | AnalysisGalicianAnalyzer | AnalysisGermanAnalyzer | AnalysisGreekAnalyzer | AnalysisHindiAnalyzer | AnalysisHungarianAnalyzer | AnalysisIndonesianAnalyzer | AnalysisIrishAnalyzer | AnalysisItalianAnalyzer | AnalysisLatvianAnalyzer | AnalysisLithuanianAnalyzer | AnalysisNorwegianAnalyzer | AnalysisPersianAnalyzer | AnalysisPortugueseAnalyzer | AnalysisRomanianAnalyzer | AnalysisRussianAnalyzer | AnalysisSerbianAnalyzer | AnalysisSoraniAnalyzer | AnalysisSpanishAnalyzer | AnalysisSwedishAnalyzer | AnalysisTurkishAnalyzer | AnalysisThaiAnalyzer

export interface AnalysisArabicAnalyzer {
  type: 'arabic'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisArmenianAnalyzer {
  type: 'armenian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisAsciiFoldingTokenFilter extends AnalysisTokenFilterBase {
  type: 'asciifolding'
  preserve_original?: SpecUtilsStringified<boolean>
}

export interface AnalysisBasqueAnalyzer {
  type: 'basque'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisBengaliAnalyzer {
  type: 'bengali'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisBrazilianAnalyzer {
  type: 'brazilian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
}

export interface AnalysisBulgarianAnalyzer {
  type: 'bulgarian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisCatalanAnalyzer {
  type: 'catalan'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export type AnalysisCharFilter = string | AnalysisCharFilterDefinition

export interface AnalysisCharFilterBase {
  version?: VersionString
}

export type AnalysisCharFilterDefinition = AnalysisHtmlStripCharFilter | AnalysisMappingCharFilter | AnalysisPatternReplaceCharFilter | AnalysisIcuNormalizationCharFilter | AnalysisKuromojiIterationMarkCharFilter

export interface AnalysisCharGroupTokenizer extends AnalysisTokenizerBase {
  type: 'char_group'
  tokenize_on_chars: string[]
  max_token_length?: integer
}

export interface AnalysisChineseAnalyzer {
  type: 'chinese'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
}

export interface AnalysisCjkAnalyzer {
  type: 'cjk'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
}

export interface AnalysisClassicTokenizer extends AnalysisTokenizerBase {
  type: 'classic'
  max_token_length?: integer
}

export interface AnalysisCommonGramsTokenFilter extends AnalysisTokenFilterBase {
  type: 'common_grams'
  common_words?: string[]
  common_words_path?: string
  ignore_case?: boolean
  query_mode?: boolean
}

export interface AnalysisCompoundWordTokenFilterBase extends AnalysisTokenFilterBase {
  hyphenation_patterns_path?: string
  max_subword_size?: integer
  min_subword_size?: integer
  min_word_size?: integer
  only_longest_match?: boolean
  word_list?: string[]
  word_list_path?: string
}

export interface AnalysisConditionTokenFilter extends AnalysisTokenFilterBase {
  type: 'condition'
  filter: string[]
  script: Script | string
}

export interface AnalysisCustomAnalyzer {
  type: 'custom'
  char_filter?: string | string[]
  filter?: string | string[]
  position_increment_gap?: integer
  position_offset_gap?: integer
  tokenizer: string
}

export interface AnalysisCustomNormalizer {
  type: 'custom'
  char_filter?: string[]
  filter?: string[]
}

export interface AnalysisCzechAnalyzer {
  type: 'czech'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisDanishAnalyzer {
  type: 'danish'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
}

export type AnalysisDelimitedPayloadEncoding = 'int' | 'float' | 'identity'

export interface AnalysisDelimitedPayloadTokenFilter extends AnalysisTokenFilterBase {
  type: 'delimited_payload'
  delimiter?: string
  encoding?: AnalysisDelimitedPayloadEncoding
}

export interface AnalysisDictionaryDecompounderTokenFilter extends AnalysisCompoundWordTokenFilterBase {
  type: 'dictionary_decompounder'
}

export interface AnalysisDutchAnalyzer {
  type: 'dutch'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export type AnalysisEdgeNGramSide = 'front' | 'back'

export interface AnalysisEdgeNGramTokenFilter extends AnalysisTokenFilterBase {
  type: 'edge_ngram'
  max_gram?: integer
  min_gram?: integer
  side?: AnalysisEdgeNGramSide
  preserve_original?: SpecUtilsStringified<boolean>
}

export interface AnalysisEdgeNGramTokenizer extends AnalysisTokenizerBase {
  type: 'edge_ngram'
  custom_token_chars?: string
  max_gram?: integer
  min_gram?: integer
  token_chars?: AnalysisTokenChar[]
}

export interface AnalysisElisionTokenFilter extends AnalysisTokenFilterBase {
  type: 'elision'
  articles?: string[]
  articles_path?: string
  articles_case?: SpecUtilsStringified<boolean>
}

export interface AnalysisEnglishAnalyzer {
  type: 'english'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisEstonianAnalyzer {
  type: 'estonian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
}

export interface AnalysisFingerprintAnalyzer {
  type: 'fingerprint'
  version?: VersionString
  max_output_size?: integer
  separator?: string
  stopwords?: AnalysisStopWords
  stopwords_path?: string
}

export interface AnalysisFingerprintTokenFilter extends AnalysisTokenFilterBase {
  type: 'fingerprint'
  max_output_size?: integer
  separator?: string
}

export interface AnalysisFinnishAnalyzer {
  type: 'finnish'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisFrenchAnalyzer {
  type: 'french'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisGalicianAnalyzer {
  type: 'galician'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisGermanAnalyzer {
  type: 'german'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisGreekAnalyzer {
  type: 'greek'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
}

export interface AnalysisHindiAnalyzer {
  type: 'hindi'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisHtmlStripCharFilter extends AnalysisCharFilterBase {
  type: 'html_strip'
  escaped_tags?: string[]
}

export interface AnalysisHungarianAnalyzer {
  type: 'hungarian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisHunspellTokenFilter extends AnalysisTokenFilterBase {
  type: 'hunspell'
  dedup?: boolean
  dictionary?: string
  locale: string
  longest_only?: boolean
}

export interface AnalysisHyphenationDecompounderTokenFilter extends AnalysisCompoundWordTokenFilterBase {
  type: 'hyphenation_decompounder'
}

export interface AnalysisIcuAnalyzer {
  type: 'icu_analyzer'
  method: AnalysisIcuNormalizationType
  mode: AnalysisIcuNormalizationMode
}

export type AnalysisIcuCollationAlternate = 'shifted' | 'non-ignorable'

export type AnalysisIcuCollationCaseFirst = 'lower' | 'upper'

export type AnalysisIcuCollationDecomposition = 'no' | 'identical'

export type AnalysisIcuCollationStrength = 'primary' | 'secondary' | 'tertiary' | 'quaternary' | 'identical'

export interface AnalysisIcuCollationTokenFilter extends AnalysisTokenFilterBase {
  type: 'icu_collation'
  alternate?: AnalysisIcuCollationAlternate
  case_first?: AnalysisIcuCollationCaseFirst
  case_level?: boolean
  country?: string
  decomposition?: AnalysisIcuCollationDecomposition
  hiragana_quaternary_mode?: boolean
  language?: string
  numeric?: boolean
  rules?: string
  strength?: AnalysisIcuCollationStrength
  variable_top?: string
  variant?: string
}

export interface AnalysisIcuFoldingTokenFilter extends AnalysisTokenFilterBase {
  type: 'icu_folding'
  unicode_set_filter: string
}

export interface AnalysisIcuNormalizationCharFilter extends AnalysisCharFilterBase {
  type: 'icu_normalizer'
  mode?: AnalysisIcuNormalizationMode
  name?: AnalysisIcuNormalizationType
}

export type AnalysisIcuNormalizationMode = 'decompose' | 'compose'

export interface AnalysisIcuNormalizationTokenFilter extends AnalysisTokenFilterBase {
  type: 'icu_normalizer'
  name: AnalysisIcuNormalizationType
}

export type AnalysisIcuNormalizationType = 'nfc' | 'nfkc' | 'nfkc_cf'

export interface AnalysisIcuTokenizer extends AnalysisTokenizerBase {
  type: 'icu_tokenizer'
  rule_files: string
}

export type AnalysisIcuTransformDirection = 'forward' | 'reverse'

export interface AnalysisIcuTransformTokenFilter extends AnalysisTokenFilterBase {
  type: 'icu_transform'
  dir?: AnalysisIcuTransformDirection
  id: string
}

export interface AnalysisIndonesianAnalyzer {
  type: 'indonesian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisIrishAnalyzer {
  type: 'irish'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisItalianAnalyzer {
  type: 'italian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisKStemTokenFilter extends AnalysisTokenFilterBase {
  type: 'kstem'
}

export type AnalysisKeepTypesMode = 'include' | 'exclude'

export interface AnalysisKeepTypesTokenFilter extends AnalysisTokenFilterBase {
  type: 'keep_types'
  mode?: AnalysisKeepTypesMode
  types?: string[]
}

export interface AnalysisKeepWordsTokenFilter extends AnalysisTokenFilterBase {
  type: 'keep'
  keep_words?: string[]
  keep_words_case?: boolean
  keep_words_path?: string
}

export interface AnalysisKeywordAnalyzer {
  type: 'keyword'
  version?: VersionString
}

export interface AnalysisKeywordMarkerTokenFilter extends AnalysisTokenFilterBase {
  type: 'keyword_marker'
  ignore_case?: boolean
  keywords?: string | string[]
  keywords_path?: string
  keywords_pattern?: string
}

export interface AnalysisKeywordTokenizer extends AnalysisTokenizerBase {
  type: 'keyword'
  buffer_size?: integer
}

export interface AnalysisKuromojiAnalyzer {
  type: 'kuromoji'
  mode: AnalysisKuromojiTokenizationMode
  user_dictionary?: string
}

export interface AnalysisKuromojiIterationMarkCharFilter extends AnalysisCharFilterBase {
  type: 'kuromoji_iteration_mark'
  normalize_kana: boolean
  normalize_kanji: boolean
}

export interface AnalysisKuromojiPartOfSpeechTokenFilter extends AnalysisTokenFilterBase {
  type: 'kuromoji_part_of_speech'
  stoptags: string[]
}

export interface AnalysisKuromojiReadingFormTokenFilter extends AnalysisTokenFilterBase {
  type: 'kuromoji_readingform'
  use_romaji: boolean
}

export interface AnalysisKuromojiStemmerTokenFilter extends AnalysisTokenFilterBase {
  type: 'kuromoji_stemmer'
  minimum_length: integer
}

export type AnalysisKuromojiTokenizationMode = 'normal' | 'search' | 'extended'

export interface AnalysisKuromojiTokenizer extends AnalysisTokenizerBase {
  type: 'kuromoji_tokenizer'
  discard_punctuation?: boolean
  mode: AnalysisKuromojiTokenizationMode
  nbest_cost?: integer
  nbest_examples?: string
  user_dictionary?: string
  user_dictionary_rules?: string[]
  discard_compound_token?: boolean
}

export interface AnalysisLatvianAnalyzer {
  type: 'latvian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisLengthTokenFilter extends AnalysisTokenFilterBase {
  type: 'length'
  max?: integer
  min?: integer
}

export interface AnalysisLetterTokenizer extends AnalysisTokenizerBase {
  type: 'letter'
}

export interface AnalysisLimitTokenCountTokenFilter extends AnalysisTokenFilterBase {
  type: 'limit'
  consume_all_tokens?: boolean
  max_token_count?: SpecUtilsStringified<integer>
}

export interface AnalysisLithuanianAnalyzer {
  type: 'lithuanian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisLowercaseNormalizer {
  type: 'lowercase'
}

export interface AnalysisLowercaseTokenFilter extends AnalysisTokenFilterBase {
  type: 'lowercase'
  language?: string
}

export interface AnalysisLowercaseTokenizer extends AnalysisTokenizerBase {
  type: 'lowercase'
}

export interface AnalysisMappingCharFilter extends AnalysisCharFilterBase {
  type: 'mapping'
  mappings?: string[]
  mappings_path?: string
}

export interface AnalysisMultiplexerTokenFilter extends AnalysisTokenFilterBase {
  type: 'multiplexer'
  filters: string[]
  preserve_original?: SpecUtilsStringified<boolean>
}

export interface AnalysisNGramTokenFilter extends AnalysisTokenFilterBase {
  type: 'ngram'
  max_gram?: integer
  min_gram?: integer
  preserve_original?: SpecUtilsStringified<boolean>
}

export interface AnalysisNGramTokenizer extends AnalysisTokenizerBase {
  type: 'ngram'
  custom_token_chars?: string
  max_gram?: integer
  min_gram?: integer
  token_chars?: AnalysisTokenChar[]
}

export interface AnalysisNoriAnalyzer {
  type: 'nori'
  version?: VersionString
  decompound_mode?: AnalysisNoriDecompoundMode
  stoptags?: string[]
  user_dictionary?: string
}

export type AnalysisNoriDecompoundMode = 'discard' | 'none' | 'mixed'

export interface AnalysisNoriPartOfSpeechTokenFilter extends AnalysisTokenFilterBase {
  type: 'nori_part_of_speech'
  stoptags?: string[]
}

export interface AnalysisNoriTokenizer extends AnalysisTokenizerBase {
  type: 'nori_tokenizer'
  decompound_mode?: AnalysisNoriDecompoundMode
  discard_punctuation?: boolean
  user_dictionary?: string
  user_dictionary_rules?: string[]
}

export type AnalysisNormalizer = AnalysisLowercaseNormalizer | AnalysisCustomNormalizer

export interface AnalysisNorwegianAnalyzer {
  type: 'norwegian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisPathHierarchyTokenizer extends AnalysisTokenizerBase {
  type: 'path_hierarchy'
  buffer_size?: SpecUtilsStringified<integer>
  delimiter?: string
  replacement?: string
  reverse?: SpecUtilsStringified<boolean>
  skip?: SpecUtilsStringified<integer>
}

export interface AnalysisPatternAnalyzer {
  type: 'pattern'
  version?: VersionString
  flags?: string
  lowercase?: boolean
  pattern?: string
  stopwords?: AnalysisStopWords
  stopwords_path?: string
}

export interface AnalysisPatternCaptureTokenFilter extends AnalysisTokenFilterBase {
  type: 'pattern_capture'
  patterns: string[]
  preserve_original?: SpecUtilsStringified<boolean>
}

export interface AnalysisPatternReplaceCharFilter extends AnalysisCharFilterBase {
  type: 'pattern_replace'
  flags?: string
  pattern: string
  replacement?: string
}

export interface AnalysisPatternReplaceTokenFilter extends AnalysisTokenFilterBase {
  type: 'pattern_replace'
  all?: boolean
  flags?: string
  pattern: string
  replacement?: string
}

export interface AnalysisPatternTokenizer extends AnalysisTokenizerBase {
  type: 'pattern'
  flags?: string
  group?: integer
  pattern?: string
}

export interface AnalysisPersianAnalyzer {
  type: 'persian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
}

export type AnalysisPhoneticEncoder = 'metaphone' | 'double_metaphone' | 'soundex' | 'refined_soundex' | 'caverphone1' | 'caverphone2' | 'cologne' | 'nysiis' | 'koelnerphonetik' | 'haasephonetik' | 'beider_morse' | 'daitch_mokotoff'

export type AnalysisPhoneticLanguage = 'any' | 'common' | 'cyrillic' | 'english' | 'french' | 'german' | 'hebrew' | 'hungarian' | 'polish' | 'romanian' | 'russian' | 'spanish'

export type AnalysisPhoneticNameType = 'generic' | 'ashkenazi' | 'sephardic'

export type AnalysisPhoneticRuleType = 'approx' | 'exact'

export interface AnalysisPhoneticTokenFilter extends AnalysisTokenFilterBase {
  type: 'phonetic'
  encoder: AnalysisPhoneticEncoder
  languageset?: AnalysisPhoneticLanguage | AnalysisPhoneticLanguage[]
  max_code_len?: integer
  name_type?: AnalysisPhoneticNameType
  replace?: boolean
  rule_type?: AnalysisPhoneticRuleType
}

export interface AnalysisPorterStemTokenFilter extends AnalysisTokenFilterBase {
  type: 'porter_stem'
}

export interface AnalysisPortugueseAnalyzer {
  type: 'portuguese'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisPredicateTokenFilter extends AnalysisTokenFilterBase {
  type: 'predicate_token_filter'
  script: Script | string
}

export interface AnalysisRemoveDuplicatesTokenFilter extends AnalysisTokenFilterBase {
  type: 'remove_duplicates'
}

export interface AnalysisReverseTokenFilter extends AnalysisTokenFilterBase {
  type: 'reverse'
}

export interface AnalysisRomanianAnalyzer {
  type: 'romanian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisRussianAnalyzer {
  type: 'russian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisSerbianAnalyzer {
  type: 'serbian'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisShingleTokenFilter extends AnalysisTokenFilterBase {
  type: 'shingle'
  filler_token?: string
  max_shingle_size?: integer | string
  min_shingle_size?: integer | string
  output_unigrams?: boolean
  output_unigrams_if_no_shingles?: boolean
  token_separator?: string
}

export interface AnalysisSimpleAnalyzer {
  type: 'simple'
  version?: VersionString
}

export interface AnalysisSimplePatternSplitTokenizer extends AnalysisTokenizerBase {
  type: 'simple_pattern_split'
  pattern?: string
}

export interface AnalysisSimplePatternTokenizer extends AnalysisTokenizerBase {
  type: 'simple_pattern'
  pattern?: string
}

export interface AnalysisSnowballAnalyzer {
  type: 'snowball'
  version?: VersionString
  language: AnalysisSnowballLanguage
  stopwords?: AnalysisStopWords
}

export type AnalysisSnowballLanguage = 'Armenian' | 'Basque' | 'Catalan' | 'Danish' | 'Dutch' | 'English' | 'Finnish' | 'French' | 'German' | 'German2' | 'Hungarian' | 'Italian' | 'Kp' | 'Lovins' | 'Norwegian' | 'Porter' | 'Portuguese' | 'Romanian' | 'Russian' | 'Spanish' | 'Swedish' | 'Turkish'

export interface AnalysisSnowballTokenFilter extends AnalysisTokenFilterBase {
  type: 'snowball'
  language?: AnalysisSnowballLanguage
}

export interface AnalysisSoraniAnalyzer {
  type: 'sorani'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisSpanishAnalyzer {
  type: 'spanish'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisStandardAnalyzer {
  type: 'standard'
  max_token_length?: integer
  stopwords?: AnalysisStopWords
  stopwords_path?: string
}

export interface AnalysisStandardTokenizer extends AnalysisTokenizerBase {
  type: 'standard'
  max_token_length?: integer
}

export interface AnalysisStemmerOverrideTokenFilter extends AnalysisTokenFilterBase {
  type: 'stemmer_override'
  rules?: string[]
  rules_path?: string
}

export interface AnalysisStemmerTokenFilter extends AnalysisTokenFilterBase {
  type: 'stemmer'
  language?: string
  name?: string
}

export interface AnalysisStopAnalyzer {
  type: 'stop'
  version?: VersionString
  stopwords?: AnalysisStopWords
  stopwords_path?: string
}

export interface AnalysisStopTokenFilter extends AnalysisTokenFilterBase {
  type: 'stop'
  ignore_case?: boolean
  remove_trailing?: boolean
  stopwords?: AnalysisStopWords
  stopwords_path?: string
}

export type AnalysisStopWords = string | string[]

export interface AnalysisSwedishAnalyzer {
  type: 'swedish'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export type AnalysisSynonymFormat = 'solr' | 'wordnet'

export interface AnalysisSynonymGraphTokenFilter extends AnalysisTokenFilterBase {
  type: 'synonym_graph'
  expand?: boolean
  format?: AnalysisSynonymFormat
  lenient?: boolean
  synonyms?: string[]
  synonyms_path?: string
  synonyms_set?: string
  tokenizer?: string
  updateable?: boolean
}

export interface AnalysisSynonymTokenFilter extends AnalysisTokenFilterBase {
  type: 'synonym'
  expand?: boolean
  format?: AnalysisSynonymFormat
  lenient?: boolean
  synonyms?: string[]
  synonyms_path?: string
  synonyms_set?: string
  tokenizer?: string
  updateable?: boolean
}

export interface AnalysisThaiAnalyzer {
  type: 'thai'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
}

export interface AnalysisThaiTokenizer extends AnalysisTokenizerBase {
  type: 'thai'
}

export type AnalysisTokenChar = 'letter' | 'digit' | 'whitespace' | 'punctuation' | 'symbol' | 'custom'

export type AnalysisTokenFilter = string | AnalysisTokenFilterDefinition

export interface AnalysisTokenFilterBase {
  version?: VersionString
}

export type AnalysisTokenFilterDefinition = AnalysisAsciiFoldingTokenFilter | AnalysisCommonGramsTokenFilter | AnalysisConditionTokenFilter | AnalysisDelimitedPayloadTokenFilter | AnalysisEdgeNGramTokenFilter | AnalysisElisionTokenFilter | AnalysisFingerprintTokenFilter | AnalysisHunspellTokenFilter | AnalysisHyphenationDecompounderTokenFilter | AnalysisKeepTypesTokenFilter | AnalysisKeepWordsTokenFilter | AnalysisKeywordMarkerTokenFilter | AnalysisKStemTokenFilter | AnalysisLengthTokenFilter | AnalysisLimitTokenCountTokenFilter | AnalysisLowercaseTokenFilter | AnalysisMultiplexerTokenFilter | AnalysisNGramTokenFilter | AnalysisNoriPartOfSpeechTokenFilter | AnalysisPatternCaptureTokenFilter | AnalysisPatternReplaceTokenFilter | AnalysisPorterStemTokenFilter | AnalysisPredicateTokenFilter | AnalysisRemoveDuplicatesTokenFilter | AnalysisReverseTokenFilter | AnalysisShingleTokenFilter | AnalysisSnowballTokenFilter | AnalysisStemmerOverrideTokenFilter | AnalysisStemmerTokenFilter | AnalysisStopTokenFilter | AnalysisSynonymGraphTokenFilter | AnalysisSynonymTokenFilter | AnalysisTrimTokenFilter | AnalysisTruncateTokenFilter | AnalysisUniqueTokenFilter | AnalysisUppercaseTokenFilter | AnalysisWordDelimiterGraphTokenFilter | AnalysisWordDelimiterTokenFilter | AnalysisKuromojiStemmerTokenFilter | AnalysisKuromojiReadingFormTokenFilter | AnalysisKuromojiPartOfSpeechTokenFilter | AnalysisIcuCollationTokenFilter | AnalysisIcuFoldingTokenFilter | AnalysisIcuNormalizationTokenFilter | AnalysisIcuTransformTokenFilter | AnalysisPhoneticTokenFilter | AnalysisDictionaryDecompounderTokenFilter

export type AnalysisTokenizer = string | AnalysisTokenizerDefinition

export interface AnalysisTokenizerBase {
  version?: VersionString
}

export type AnalysisTokenizerDefinition = AnalysisCharGroupTokenizer | AnalysisClassicTokenizer | AnalysisEdgeNGramTokenizer | AnalysisKeywordTokenizer | AnalysisLetterTokenizer | AnalysisLowercaseTokenizer | AnalysisNGramTokenizer | AnalysisPathHierarchyTokenizer | AnalysisPatternTokenizer | AnalysisSimplePatternTokenizer | AnalysisSimplePatternSplitTokenizer | AnalysisStandardTokenizer | AnalysisThaiTokenizer | AnalysisUaxEmailUrlTokenizer | AnalysisWhitespaceTokenizer | AnalysisIcuTokenizer | AnalysisKuromojiTokenizer | AnalysisNoriTokenizer

export interface AnalysisTrimTokenFilter extends AnalysisTokenFilterBase {
  type: 'trim'
}

export interface AnalysisTruncateTokenFilter extends AnalysisTokenFilterBase {
  type: 'truncate'
  length?: integer
}

export interface AnalysisTurkishAnalyzer {
  type: 'turkish'
  stopwords?: AnalysisStopWords
  stopwords_path?: string
  stem_exclusion?: string[]
}

export interface AnalysisUaxEmailUrlTokenizer extends AnalysisTokenizerBase {
  type: 'uax_url_email'
  max_token_length?: integer
}

export interface AnalysisUniqueTokenFilter extends AnalysisTokenFilterBase {
  type: 'unique'
  only_on_same_position?: boolean
}

export interface AnalysisUppercaseTokenFilter extends AnalysisTokenFilterBase {
  type: 'uppercase'
}

export interface AnalysisWhitespaceAnalyzer {
  type: 'whitespace'
  version?: VersionString
}

export interface AnalysisWhitespaceTokenizer extends AnalysisTokenizerBase {
  type: 'whitespace'
  max_token_length?: integer
}

export interface AnalysisWordDelimiterGraphTokenFilter extends AnalysisTokenFilterBase {
  type: 'word_delimiter_graph'
  adjust_offsets?: boolean
  catenate_all?: boolean
  catenate_numbers?: boolean
  catenate_words?: boolean
  generate_number_parts?: boolean
  generate_word_parts?: boolean
  ignore_keywords?: boolean
  preserve_original?: SpecUtilsStringified<boolean>
  protected_words?: string[]
  protected_words_path?: string
  split_on_case_change?: boolean
  split_on_numerics?: boolean
  stem_english_possessive?: boolean
  type_table?: string[]
  type_table_path?: string
}

export interface AnalysisWordDelimiterTokenFilter extends AnalysisTokenFilterBase {
  type: 'word_delimiter'
  catenate_all?: boolean
  catenate_numbers?: boolean
  catenate_words?: boolean
  generate_number_parts?: boolean
  generate_word_parts?: boolean
  preserve_original?: SpecUtilsStringified<boolean>
  protected_words?: string[]
  protected_words_path?: string
  split_on_case_change?: boolean
  split_on_numerics?: boolean
  stem_english_possessive?: boolean
  type_table?: string[]
  type_table_path?: string
}

export interface MappingAggregateMetricDoubleProperty extends MappingPropertyBase {
  type: 'aggregate_metric_double'
  default_metric: string
  metrics: string[]
  time_series_metric?: MappingTimeSeriesMetricType
}

export interface MappingAllField {
  analyzer: string
  enabled: boolean
  omit_norms: boolean
  search_analyzer: string
  similarity: string
  store: boolean
  store_term_vector_offsets: boolean
  store_term_vector_payloads: boolean
  store_term_vector_positions: boolean
  store_term_vectors: boolean
}

export interface MappingBinaryProperty extends MappingDocValuesPropertyBase {
  type: 'binary'
}

export interface MappingBooleanProperty extends MappingDocValuesPropertyBase {
  boost?: double
  fielddata?: IndicesNumericFielddata
  index?: boolean
  null_value?: boolean
  type: 'boolean'
}

export interface MappingByteNumberProperty extends MappingNumberPropertyBase {
  type: 'byte'
  null_value?: byte
}

export interface MappingCompletionProperty extends MappingDocValuesPropertyBase {
  analyzer?: string
  contexts?: MappingSuggestContext[]
  max_input_length?: integer
  preserve_position_increments?: boolean
  preserve_separators?: boolean
  search_analyzer?: string
  type: 'completion'
}

export interface MappingCompositeSubField {
  type: MappingRuntimeFieldType
}

export interface MappingConstantKeywordProperty extends MappingPropertyBase {
  value?: any
  type: 'constant_keyword'
}

export interface MappingCorePropertyBase extends MappingPropertyBase {
  copy_to?: Fields
  store?: boolean
}

export interface MappingCountedKeywordProperty extends MappingPropertyBase {
  type: 'counted_keyword'
  index?: boolean
}

export interface MappingDataStreamTimestamp {
  enabled: boolean
}

export interface MappingDateNanosProperty extends MappingDocValuesPropertyBase {
  boost?: double
  format?: string
  ignore_malformed?: boolean
  index?: boolean
  script?: Script | string
  on_script_error?: MappingOnScriptError
  null_value?: DateTime
  precision_step?: integer
  type: 'date_nanos'
}

export interface MappingDateProperty extends MappingDocValuesPropertyBase {
  boost?: double
  fielddata?: IndicesNumericFielddata
  format?: string
  ignore_malformed?: boolean
  index?: boolean
  script?: Script | string
  on_script_error?: MappingOnScriptError
  null_value?: DateTime
  precision_step?: integer
  locale?: string
  type: 'date'
}

export interface MappingDateRangeProperty extends MappingRangePropertyBase {
  format?: string
  type: 'date_range'
}

export type MappingDenseVectorElementType = 'bit' | 'byte' | 'float'

export interface MappingDenseVectorIndexOptions {
  confidence_interval?: float
  ef_construction?: integer
  m?: integer
  type: MappingDenseVectorIndexOptionsType
}

export type MappingDenseVectorIndexOptionsType = 'flat' | 'hnsw' | 'int4_flat' | 'int4_hnsw' | 'int8_flat' | 'int8_hnsw'

export interface MappingDenseVectorProperty extends MappingPropertyBase {
  type: 'dense_vector'
  dims?: integer
  element_type?: MappingDenseVectorElementType
  index?: boolean
  index_options?: MappingDenseVectorIndexOptions
  similarity?: MappingDenseVectorSimilarity
}

export type MappingDenseVectorSimilarity = 'cosine' | 'dot_product' | 'l2_norm' | 'max_inner_product'

export interface MappingDocValuesPropertyBase extends MappingCorePropertyBase {
  doc_values?: boolean
}

export interface MappingDoubleNumberProperty extends MappingNumberPropertyBase {
  type: 'double'
  null_value?: double
}

export interface MappingDoubleRangeProperty extends MappingRangePropertyBase {
  type: 'double_range'
}

export type MappingDynamicMapping = boolean | 'strict' | 'runtime' | 'true' | 'false'

export interface MappingDynamicProperty extends MappingDocValuesPropertyBase {
  type: '{dynamic_type}'
  enabled?: boolean
  null_value?: FieldValue
  boost?: double
  coerce?: boolean
  script?: Script | string
  on_script_error?: MappingOnScriptError
  ignore_malformed?: boolean
  time_series_metric?: MappingTimeSeriesMetricType
  analyzer?: string
  eager_global_ordinals?: boolean
  index?: boolean
  index_options?: MappingIndexOptions
  index_phrases?: boolean
  index_prefixes?: MappingTextIndexPrefixes | null
  norms?: boolean
  position_increment_gap?: integer
  search_analyzer?: string
  search_quote_analyzer?: string
  term_vector?: MappingTermVectorOption
  format?: string
  precision_step?: integer
  locale?: string
}

export interface MappingDynamicTemplate {
  mapping?: MappingProperty
  runtime?: MappingRuntimeField
  match?: string | string[]
  path_match?: string | string[]
  unmatch?: string | string[]
  path_unmatch?: string | string[]
  match_mapping_type?: string | string[]
  unmatch_mapping_type?: string | string[]
  match_pattern?: MappingMatchType
}

export interface MappingFieldAliasProperty extends MappingPropertyBase {
  path?: Field
  type: 'alias'
}

export interface MappingFieldMapping {
  full_name: string
  mapping: Partial<Record<Field, MappingProperty>>
}

export interface MappingFieldNamesField {
  enabled: boolean
}

export type MappingFieldType = 'none' | 'geo_point' | 'geo_shape' | 'ip' | 'binary' | 'keyword' | 'text' | 'search_as_you_type' | 'date' | 'date_nanos' | 'boolean' | 'completion' | 'nested' | 'object' | 'passthrough' | 'version' | 'murmur3' | 'token_count' | 'percolator' | 'integer' | 'long' | 'short' | 'byte' | 'float' | 'half_float' | 'scaled_float' | 'double' | 'integer_range' | 'float_range' | 'long_range' | 'double_range' | 'date_range' | 'ip_range' | 'alias' | 'join' | 'rank_feature' | 'rank_features' | 'flattened' | 'shape' | 'histogram' | 'constant_keyword' | 'counted_keyword' | 'aggregate_metric_double' | 'dense_vector' | 'semantic_text' | 'sparse_vector' | 'match_only_text' | 'icu_collation_keyword'

export interface MappingFlattenedProperty extends MappingPropertyBase {
  boost?: double
  depth_limit?: integer
  doc_values?: boolean
  eager_global_ordinals?: boolean
  index?: boolean
  index_options?: MappingIndexOptions
  null_value?: string
  similarity?: string
  split_queries_on_whitespace?: boolean
  type: 'flattened'
}

export interface MappingFloatNumberProperty extends MappingNumberPropertyBase {
  type: 'float'
  null_value?: float
}

export interface MappingFloatRangeProperty extends MappingRangePropertyBase {
  type: 'float_range'
}

export type MappingGeoOrientation = 'right' | 'RIGHT' | 'counterclockwise' | 'ccw' | 'left' | 'LEFT' | 'clockwise' | 'cw'

export interface MappingGeoPointProperty extends MappingDocValuesPropertyBase {
  ignore_malformed?: boolean
  ignore_z_value?: boolean
  null_value?: GeoLocation
  index?: boolean
  on_script_error?: MappingOnScriptError
  script?: Script | string
  type: 'geo_point'
}

export interface MappingGeoShapeProperty extends MappingDocValuesPropertyBase {
  coerce?: boolean
  ignore_malformed?: boolean
  ignore_z_value?: boolean
  index?: boolean
  orientation?: MappingGeoOrientation
  strategy?: MappingGeoStrategy
  type: 'geo_shape'
}

export type MappingGeoStrategy = 'recursive' | 'term'

export interface MappingHalfFloatNumberProperty extends MappingNumberPropertyBase {
  type: 'half_float'
  null_value?: float
}

export interface MappingHistogramProperty extends MappingPropertyBase {
  ignore_malformed?: boolean
  type: 'histogram'
}

export interface MappingIcuCollationProperty extends MappingDocValuesPropertyBase {
  type: 'icu_collation_keyword'
  norms?: boolean
  index_options?: MappingIndexOptions
  index?: boolean
  null_value?: string
  rules?: string
  language?: string
  country?: string
  variant?: string
  strength?: AnalysisIcuCollationStrength
  decomposition?: AnalysisIcuCollationDecomposition
  alternate?: AnalysisIcuCollationAlternate
  case_level?: boolean
  case_first?: AnalysisIcuCollationCaseFirst
  numeric?: boolean
  variable_top?: string
  hiragana_quaternary_mode?: boolean
}

export interface MappingIndexField {
  enabled: boolean
}

export type MappingIndexOptions = 'docs' | 'freqs' | 'positions' | 'offsets'

export interface MappingIntegerNumberProperty extends MappingNumberPropertyBase {
  type: 'integer'
  null_value?: integer
}

export interface MappingIntegerRangeProperty extends MappingRangePropertyBase {
  type: 'integer_range'
}

export interface MappingIpProperty extends MappingDocValuesPropertyBase {
  boost?: double
  index?: boolean
  ignore_malformed?: boolean
  null_value?: string
  on_script_error?: MappingOnScriptError
  script?: Script | string
  time_series_dimension?: boolean
  type: 'ip'
}

export interface MappingIpRangeProperty extends MappingRangePropertyBase {
  type: 'ip_range'
}

export interface MappingJoinProperty extends MappingPropertyBase {
  relations?: Record<RelationName, RelationName | RelationName[]>
  eager_global_ordinals?: boolean
  type: 'join'
}

export interface MappingKeywordProperty extends MappingDocValuesPropertyBase {
  boost?: double
  eager_global_ordinals?: boolean
  index?: boolean
  index_options?: MappingIndexOptions
  script?: Script | string
  on_script_error?: MappingOnScriptError
  normalizer?: string
  norms?: boolean
  null_value?: string
  similarity?: string | null
  split_queries_on_whitespace?: boolean
  time_series_dimension?: boolean
  type: 'keyword'
}

export interface MappingLongNumberProperty extends MappingNumberPropertyBase {
  type: 'long'
  null_value?: long
}

export interface MappingLongRangeProperty extends MappingRangePropertyBase {
  type: 'long_range'
}

export interface MappingMatchOnlyTextProperty {
  type: 'match_only_text'
  fields?: Record<PropertyName, MappingProperty>
  meta?: Record<string, string>
  copy_to?: Fields
}

export type MappingMatchType = 'simple' | 'regex'

export interface MappingMurmur3HashProperty extends MappingDocValuesPropertyBase {
  type: 'murmur3'
}

export interface MappingNestedProperty extends MappingCorePropertyBase {
  enabled?: boolean
  include_in_parent?: boolean
  include_in_root?: boolean
  type: 'nested'
}

export interface MappingNumberPropertyBase extends MappingDocValuesPropertyBase {
  boost?: double
  coerce?: boolean
  ignore_malformed?: boolean
  index?: boolean
  on_script_error?: MappingOnScriptError
  script?: Script | string
  time_series_metric?: MappingTimeSeriesMetricType
  time_series_dimension?: boolean
}

export interface MappingObjectProperty extends MappingCorePropertyBase {
  enabled?: boolean
  subobjects?: MappingSubobjects
  type?: 'object'
}

export type MappingOnScriptError = 'fail' | 'continue'

export interface MappingPassthroughObjectProperty extends MappingCorePropertyBase {
  type?: 'passthrough'
  enabled?: boolean
  priority?: integer
  time_series_dimension?: boolean
}

export interface MappingPercolatorProperty extends MappingPropertyBase {
  type: 'percolator'
}

export interface MappingPointProperty extends MappingDocValuesPropertyBase {
  ignore_malformed?: boolean
  ignore_z_value?: boolean
  null_value?: string
  type: 'point'
}

export type MappingProperty = MappingBinaryProperty | MappingBooleanProperty | MappingDynamicProperty | MappingJoinProperty | MappingKeywordProperty | MappingMatchOnlyTextProperty | MappingPercolatorProperty | MappingRankFeatureProperty | MappingRankFeaturesProperty | MappingSearchAsYouTypeProperty | MappingTextProperty | MappingVersionProperty | MappingWildcardProperty | MappingDateNanosProperty | MappingDateProperty | MappingAggregateMetricDoubleProperty | MappingDenseVectorProperty | MappingFlattenedProperty | MappingNestedProperty | MappingObjectProperty | MappingPassthroughObjectProperty | MappingSemanticTextProperty | MappingSparseVectorProperty | MappingCompletionProperty | MappingConstantKeywordProperty | MappingCountedKeywordProperty | MappingFieldAliasProperty | MappingHistogramProperty | MappingIpProperty | MappingMurmur3HashProperty | MappingTokenCountProperty | MappingGeoPointProperty | MappingGeoShapeProperty | MappingPointProperty | MappingShapeProperty | MappingByteNumberProperty | MappingDoubleNumberProperty | MappingFloatNumberProperty | MappingHalfFloatNumberProperty | MappingIntegerNumberProperty | MappingLongNumberProperty | MappingScaledFloatNumberProperty | MappingShortNumberProperty | MappingUnsignedLongNumberProperty | MappingDateRangeProperty | MappingDoubleRangeProperty | MappingFloatRangeProperty | MappingIntegerRangeProperty | MappingIpRangeProperty | MappingLongRangeProperty | MappingIcuCollationProperty

export interface MappingPropertyBase {
  meta?: Record<string, string>
  properties?: Record<PropertyName, MappingProperty>
  ignore_above?: integer
  dynamic?: MappingDynamicMapping
  fields?: Record<PropertyName, MappingProperty>
  synthetic_source_keep?: MappingSyntheticSourceKeepEnum
}

export interface MappingRangePropertyBase extends MappingDocValuesPropertyBase {
  boost?: double
  coerce?: boolean
  index?: boolean
}

export interface MappingRankFeatureProperty extends MappingPropertyBase {
  positive_score_impact?: boolean
  type: 'rank_feature'
}

export interface MappingRankFeaturesProperty extends MappingPropertyBase {
  positive_score_impact?: boolean
  type: 'rank_features'
}

export interface MappingRoutingField {
  required: boolean
}

export interface MappingRuntimeField {
  fields?: Record<string, MappingCompositeSubField>
  fetch_fields?: (MappingRuntimeFieldFetchFields | Field)[]
  format?: string
  input_field?: Field
  target_field?: Field
  target_index?: IndexName
  script?: Script | string
  type: MappingRuntimeFieldType
}

export interface MappingRuntimeFieldFetchFields {
  field: Field
  format?: string
}

export type MappingRuntimeFieldType = 'boolean' | 'composite' | 'date' | 'double' | 'geo_point' | 'geo_shape' | 'ip' | 'keyword' | 'long' | 'lookup'

export type MappingRuntimeFields = Record<Field, MappingRuntimeField>

export interface MappingScaledFloatNumberProperty extends MappingNumberPropertyBase {
  type: 'scaled_float'
  null_value?: double
  scaling_factor?: double
}

export interface MappingSearchAsYouTypeProperty extends MappingCorePropertyBase {
  analyzer?: string
  index?: boolean
  index_options?: MappingIndexOptions
  max_shingle_size?: integer
  norms?: boolean
  search_analyzer?: string
  search_quote_analyzer?: string
  similarity?: string | null
  term_vector?: MappingTermVectorOption
  type: 'search_as_you_type'
}

export interface MappingSemanticTextProperty {
  type: 'semantic_text'
  meta?: Record<string, string>
  inference_id?: Id
  search_inference_id?: Id
}

export interface MappingShapeProperty extends MappingDocValuesPropertyBase {
  coerce?: boolean
  ignore_malformed?: boolean
  ignore_z_value?: boolean
  orientation?: MappingGeoOrientation
  type: 'shape'
}

export interface MappingShortNumberProperty extends MappingNumberPropertyBase {
  type: 'short'
  null_value?: short
}

export interface MappingSizeField {
  enabled: boolean
}

export interface MappingSourceField {
  compress?: boolean
  compress_threshold?: string
  enabled?: boolean
  excludes?: string[]
  includes?: string[]
  mode?: MappingSourceFieldMode
}

export type MappingSourceFieldMode = 'disabled' | 'stored' | 'synthetic'

export interface MappingSparseVectorProperty extends MappingPropertyBase {
  type: 'sparse_vector'
}

export type MappingSubobjects = boolean | 'true' | 'false' | 'auto'

export interface MappingSuggestContext {
  name: Name
  path?: Field
  type: string
  precision?: integer | string
}

export type MappingSyntheticSourceKeepEnum = 'none' | 'arrays' | 'all'

export type MappingTermVectorOption = 'no' | 'yes' | 'with_offsets' | 'with_positions' | 'with_positions_offsets' | 'with_positions_offsets_payloads' | 'with_positions_payloads'

export interface MappingTextIndexPrefixes {
  max_chars: integer
  min_chars: integer
}

export interface MappingTextProperty extends MappingCorePropertyBase {
  analyzer?: string
  boost?: double
  eager_global_ordinals?: boolean
  fielddata?: boolean
  fielddata_frequency_filter?: IndicesFielddataFrequencyFilter
  index?: boolean
  index_options?: MappingIndexOptions
  index_phrases?: boolean
  index_prefixes?: MappingTextIndexPrefixes | null
  norms?: boolean
  position_increment_gap?: integer
  search_analyzer?: string
  search_quote_analyzer?: string
  similarity?: string | null
  term_vector?: MappingTermVectorOption
  type: 'text'
}

export type MappingTimeSeriesMetricType = 'gauge' | 'counter' | 'summary' | 'histogram' | 'position'

export interface MappingTokenCountProperty extends MappingDocValuesPropertyBase {
  analyzer?: string
  boost?: double
  index?: boolean
  null_value?: double
  enable_position_increments?: boolean
  type: 'token_count'
}

export interface MappingTypeMapping {
  all_field?: MappingAllField
  date_detection?: boolean
  dynamic?: MappingDynamicMapping
  dynamic_date_formats?: string[]
  dynamic_templates?: Partial<Record<string, MappingDynamicTemplate>>[]
  _field_names?: MappingFieldNamesField
  index_field?: MappingIndexField
  _meta?: Metadata
  numeric_detection?: boolean
  properties?: Record<PropertyName, MappingProperty>
  _routing?: MappingRoutingField
  _size?: MappingSizeField
  _source?: MappingSourceField
  runtime?: Record<string, MappingRuntimeField>
  enabled?: boolean
  subobjects?: MappingSubobjects
  _data_stream_timestamp?: MappingDataStreamTimestamp
}

export interface MappingUnsignedLongNumberProperty extends MappingNumberPropertyBase {
  type: 'unsigned_long'
  null_value?: ulong
}

export interface MappingVersionProperty extends MappingDocValuesPropertyBase {
  type: 'version'
}

export interface MappingWildcardProperty extends MappingDocValuesPropertyBase {
  type: 'wildcard'
  null_value?: string
}

export interface QueryDslBoolQuery extends QueryDslQueryBase {
  filter?: QueryDslQueryContainer | QueryDslQueryContainer[]
  minimum_should_match?: MinimumShouldMatch
  must?: QueryDslQueryContainer | QueryDslQueryContainer[]
  must_not?: QueryDslQueryContainer | QueryDslQueryContainer[]
  should?: QueryDslQueryContainer | QueryDslQueryContainer[]
}

export interface QueryDslBoostingQuery extends QueryDslQueryBase {
  negative_boost: double
  negative: QueryDslQueryContainer
  positive: QueryDslQueryContainer
}

export type QueryDslChildScoreMode = 'none' | 'avg' | 'sum' | 'max' | 'min'

export type QueryDslCombinedFieldsOperator = 'or' | 'and'

export interface QueryDslCombinedFieldsQuery extends QueryDslQueryBase {
  fields: Field[]
  query: string
  auto_generate_synonyms_phrase_query?: boolean
  operator?: QueryDslCombinedFieldsOperator
  minimum_should_match?: MinimumShouldMatch
  zero_terms_query?: QueryDslCombinedFieldsZeroTerms
}

export type QueryDslCombinedFieldsZeroTerms = 'none' | 'all'

export interface QueryDslCommonTermsQuery extends QueryDslQueryBase {
  analyzer?: string
  cutoff_frequency?: double
  high_freq_operator?: QueryDslOperator
  low_freq_operator?: QueryDslOperator
  minimum_should_match?: MinimumShouldMatch
  query: string
}

export interface QueryDslConstantScoreQuery extends QueryDslQueryBase {
  filter: QueryDslQueryContainer
}

export interface QueryDslDateDecayFunctionKeys extends QueryDslDecayFunctionBase<DateMath, Duration> {
}
export type QueryDslDateDecayFunction = QueryDslDateDecayFunctionKeys
& { [property: string]: QueryDslDecayPlacement | QueryDslMultiValueMode }

export interface QueryDslDateDistanceFeatureQuery extends QueryDslDistanceFeatureQueryBase<DateMath, Duration> {
}

export interface QueryDslDateRangeQuery extends QueryDslRangeQueryBase<DateMath> {
  format?: DateFormat
  time_zone?: TimeZone
}

export type QueryDslDecayFunction = QueryDslUntypedDecayFunction | QueryDslDateDecayFunction | QueryDslNumericDecayFunction | QueryDslGeoDecayFunction

export interface QueryDslDecayFunctionBase<TOrigin = unknown, TScale = unknown> {
  multi_value_mode?: QueryDslMultiValueMode
}

export interface QueryDslDecayPlacement<TOrigin = unknown, TScale = unknown> {
  decay?: double
  offset?: TScale
  scale?: TScale
  origin?: TOrigin
}

export interface QueryDslDisMaxQuery extends QueryDslQueryBase {
  queries: QueryDslQueryContainer[]
  tie_breaker?: double
}

export type QueryDslDistanceFeatureQuery = QueryDslUntypedDistanceFeatureQuery | QueryDslGeoDistanceFeatureQuery | QueryDslDateDistanceFeatureQuery

export interface QueryDslDistanceFeatureQueryBase<TOrigin = unknown, TDistance = unknown> extends QueryDslQueryBase {
  origin: TOrigin
  pivot: TDistance
  field: Field
}

export interface QueryDslExistsQuery extends QueryDslQueryBase {
  field: Field
}

export interface QueryDslFieldAndFormat {
  field: Field
  format?: string
  include_unmapped?: boolean
}

export interface QueryDslFieldLookup {
  id: Id
  index?: IndexName
  path?: Field
  routing?: Routing
}

export type QueryDslFieldValueFactorModifier = 'none' | 'log' | 'log1p' | 'log2p' | 'ln' | 'ln1p' | 'ln2p' | 'square' | 'sqrt' | 'reciprocal'

export interface QueryDslFieldValueFactorScoreFunction {
  field: Field
  factor?: double
  missing?: double
  modifier?: QueryDslFieldValueFactorModifier
}

export type QueryDslFunctionBoostMode = 'multiply' | 'replace' | 'sum' | 'avg' | 'max' | 'min'

export interface QueryDslFunctionScoreContainer {
  exp?: QueryDslDecayFunction
  gauss?: QueryDslDecayFunction
  linear?: QueryDslDecayFunction
  field_value_factor?: QueryDslFieldValueFactorScoreFunction
  random_score?: QueryDslRandomScoreFunction
  script_score?: QueryDslScriptScoreFunction
  filter?: QueryDslQueryContainer
  weight?: double
}

export type QueryDslFunctionScoreMode = 'multiply' | 'sum' | 'avg' | 'first' | 'max' | 'min'

export interface QueryDslFunctionScoreQuery extends QueryDslQueryBase {
  boost_mode?: QueryDslFunctionBoostMode
  functions?: QueryDslFunctionScoreContainer[]
  max_boost?: double
  min_score?: double
  query?: QueryDslQueryContainer
  score_mode?: QueryDslFunctionScoreMode
}

export interface QueryDslFuzzyQuery extends QueryDslQueryBase {
  max_expansions?: integer
  prefix_length?: integer
  rewrite?: MultiTermQueryRewrite
  transpositions?: boolean
  fuzziness?: Fuzziness
  value: string | double | boolean
}

export interface QueryDslGeoBoundingBoxQueryKeys extends QueryDslQueryBase {
  type?: QueryDslGeoExecution
  validation_method?: QueryDslGeoValidationMethod
  ignore_unmapped?: boolean
}
export type QueryDslGeoBoundingBoxQuery = QueryDslGeoBoundingBoxQueryKeys
& { [property: string]: GeoBounds | QueryDslGeoExecution | QueryDslGeoValidationMethod | boolean | float | string }

export interface QueryDslGeoDecayFunctionKeys extends QueryDslDecayFunctionBase<GeoLocation, Distance> {
}
export type QueryDslGeoDecayFunction = QueryDslGeoDecayFunctionKeys
& { [property: string]: QueryDslDecayPlacement | QueryDslMultiValueMode }

export interface QueryDslGeoDistanceFeatureQuery extends QueryDslDistanceFeatureQueryBase<GeoLocation, Distance> {
}

export interface QueryDslGeoDistanceQueryKeys extends QueryDslQueryBase {
  distance: Distance
  distance_type?: GeoDistanceType
  validation_method?: QueryDslGeoValidationMethod
  ignore_unmapped?: boolean
}
export type QueryDslGeoDistanceQuery = QueryDslGeoDistanceQueryKeys
& { [property: string]: GeoLocation | Distance | GeoDistanceType | QueryDslGeoValidationMethod | boolean | float | string }

export type QueryDslGeoExecution = 'memory' | 'indexed'

export interface QueryDslGeoGridQuery extends QueryDslQueryBase {
  geogrid?: GeoTile
  geohash?: GeoHash
  geohex?: GeoHexCell
}

export interface QueryDslGeoPolygonPoints {
  points: GeoLocation[]
}

export interface QueryDslGeoPolygonQueryKeys extends QueryDslQueryBase {
  validation_method?: QueryDslGeoValidationMethod
  ignore_unmapped?: boolean
}
export type QueryDslGeoPolygonQuery = QueryDslGeoPolygonQueryKeys
& { [property: string]: QueryDslGeoPolygonPoints | QueryDslGeoValidationMethod | boolean | float | string }

export interface QueryDslGeoShapeFieldQuery {
  shape?: GeoShape
  indexed_shape?: QueryDslFieldLookup
  relation?: GeoShapeRelation
}

export interface QueryDslGeoShapeQueryKeys extends QueryDslQueryBase {
  ignore_unmapped?: boolean
}
export type QueryDslGeoShapeQuery = QueryDslGeoShapeQueryKeys
& { [property: string]: QueryDslGeoShapeFieldQuery | boolean | float | string }

export type QueryDslGeoValidationMethod = 'coerce' | 'ignore_malformed' | 'strict'

export interface QueryDslHasChildQuery extends QueryDslQueryBase {
  ignore_unmapped?: boolean
  inner_hits?: SearchInnerHits
  max_children?: integer
  min_children?: integer
  query: QueryDslQueryContainer
  score_mode?: QueryDslChildScoreMode
  type: RelationName
}

export interface QueryDslHasParentQuery extends QueryDslQueryBase {
  ignore_unmapped?: boolean
  inner_hits?: SearchInnerHits
  parent_type: RelationName
  query: QueryDslQueryContainer
  score?: boolean
}

export interface QueryDslIdsQuery extends QueryDslQueryBase {
  values?: Ids
}

export interface QueryDslIntervalsAllOf {
  intervals: QueryDslIntervalsContainer[]
  max_gaps?: integer
  ordered?: boolean
  filter?: QueryDslIntervalsFilter
}

export interface QueryDslIntervalsAnyOf {
  intervals: QueryDslIntervalsContainer[]
  filter?: QueryDslIntervalsFilter
}

export interface QueryDslIntervalsContainer {
  all_of?: QueryDslIntervalsAllOf
  any_of?: QueryDslIntervalsAnyOf
  fuzzy?: QueryDslIntervalsFuzzy
  match?: QueryDslIntervalsMatch
  prefix?: QueryDslIntervalsPrefix
  wildcard?: QueryDslIntervalsWildcard
}

export interface QueryDslIntervalsFilter {
  after?: QueryDslIntervalsContainer
  before?: QueryDslIntervalsContainer
  contained_by?: QueryDslIntervalsContainer
  containing?: QueryDslIntervalsContainer
  not_contained_by?: QueryDslIntervalsContainer
  not_containing?: QueryDslIntervalsContainer
  not_overlapping?: QueryDslIntervalsContainer
  overlapping?: QueryDslIntervalsContainer
  script?: Script | string
}

export interface QueryDslIntervalsFuzzy {
  analyzer?: string
  fuzziness?: Fuzziness
  prefix_length?: integer
  term: string
  transpositions?: boolean
  use_field?: Field
}

export interface QueryDslIntervalsMatch {
  analyzer?: string
  max_gaps?: integer
  ordered?: boolean
  query: string
  use_field?: Field
  filter?: QueryDslIntervalsFilter
}

export interface QueryDslIntervalsPrefix {
  analyzer?: string
  prefix: string
  use_field?: Field
}

export interface QueryDslIntervalsQuery extends QueryDslQueryBase {
  all_of?: QueryDslIntervalsAllOf
  any_of?: QueryDslIntervalsAnyOf
  fuzzy?: QueryDslIntervalsFuzzy
  match?: QueryDslIntervalsMatch
  prefix?: QueryDslIntervalsPrefix
  wildcard?: QueryDslIntervalsWildcard
}

export interface QueryDslIntervalsWildcard {
  analyzer?: string
  pattern: string
  use_field?: Field
}

export type QueryDslLike = string | QueryDslLikeDocument

export interface QueryDslLikeDocument {
  doc?: any
  fields?: Field[]
  _id?: Id
  _index?: IndexName
  per_field_analyzer?: Record<Field, string>
  routing?: Routing
  version?: VersionNumber
  version_type?: VersionType
}

export interface QueryDslMatchAllQuery extends QueryDslQueryBase {
}

export interface QueryDslMatchBoolPrefixQuery extends QueryDslQueryBase {
  analyzer?: string
  fuzziness?: Fuzziness
  fuzzy_rewrite?: MultiTermQueryRewrite
  fuzzy_transpositions?: boolean
  max_expansions?: integer
  minimum_should_match?: MinimumShouldMatch
  operator?: QueryDslOperator
  prefix_length?: integer
  query: string
}

export interface QueryDslMatchNoneQuery extends QueryDslQueryBase {
}

export interface QueryDslMatchPhrasePrefixQuery extends QueryDslQueryBase {
  analyzer?: string
  max_expansions?: integer
  query: string
  slop?: integer
  zero_terms_query?: QueryDslZeroTermsQuery
}

export interface QueryDslMatchPhraseQuery extends QueryDslQueryBase {
  analyzer?: string
  query: string
  slop?: integer
  zero_terms_query?: QueryDslZeroTermsQuery
}

export interface QueryDslMatchQuery extends QueryDslQueryBase {
  analyzer?: string
  auto_generate_synonyms_phrase_query?: boolean
  cutoff_frequency?: double
  fuzziness?: Fuzziness
  fuzzy_rewrite?: MultiTermQueryRewrite
  fuzzy_transpositions?: boolean
  lenient?: boolean
  max_expansions?: integer
  minimum_should_match?: MinimumShouldMatch
  operator?: QueryDslOperator
  prefix_length?: integer
  query: string | float | boolean
  zero_terms_query?: QueryDslZeroTermsQuery
}

export interface QueryDslMoreLikeThisQuery extends QueryDslQueryBase {
  analyzer?: string
  boost_terms?: double
  fail_on_unsupported_field?: boolean
  fields?: Field[]
  include?: boolean
  like: QueryDslLike | QueryDslLike[]
  max_doc_freq?: integer
  max_query_terms?: integer
  max_word_length?: integer
  min_doc_freq?: integer
  minimum_should_match?: MinimumShouldMatch
  min_term_freq?: integer
  min_word_length?: integer
  routing?: Routing
  stop_words?: AnalysisStopWords
  unlike?: QueryDslLike | QueryDslLike[]
  version?: VersionNumber
  version_type?: VersionType
}

export interface QueryDslMultiMatchQuery extends QueryDslQueryBase {
  analyzer?: string
  auto_generate_synonyms_phrase_query?: boolean
  cutoff_frequency?: double
  fields?: Fields
  fuzziness?: Fuzziness
  fuzzy_rewrite?: MultiTermQueryRewrite
  fuzzy_transpositions?: boolean
  lenient?: boolean
  max_expansions?: integer
  minimum_should_match?: MinimumShouldMatch
  operator?: QueryDslOperator
  prefix_length?: integer
  query: string
  slop?: integer
  tie_breaker?: double
  type?: QueryDslTextQueryType
  zero_terms_query?: QueryDslZeroTermsQuery
}

export type QueryDslMultiValueMode = 'min' | 'max' | 'avg' | 'sum'

export interface QueryDslNestedQuery extends QueryDslQueryBase {
  ignore_unmapped?: boolean
  inner_hits?: SearchInnerHits
  path: Field
  query: QueryDslQueryContainer
  score_mode?: QueryDslChildScoreMode
}

export interface QueryDslNumberRangeQuery extends QueryDslRangeQueryBase<double> {
}

export interface QueryDslNumericDecayFunctionKeys extends QueryDslDecayFunctionBase<double, double> {
}
export type QueryDslNumericDecayFunction = QueryDslNumericDecayFunctionKeys
& { [property: string]: QueryDslDecayPlacement | QueryDslMultiValueMode }

export type QueryDslOperator = 'and' | 'AND' | 'or' | 'OR'

export interface QueryDslParentIdQuery extends QueryDslQueryBase {
  id?: Id
  ignore_unmapped?: boolean
  type?: RelationName
}

export interface QueryDslPercolateQuery extends QueryDslQueryBase {
  document?: any
  documents?: any[]
  field: Field
  id?: Id
  index?: IndexName
  name?: string
  preference?: string
  routing?: Routing
  version?: VersionNumber
}

export interface QueryDslPinnedDoc {
  _id: Id
  _index?: IndexName
}

export interface QueryDslPinnedQuery extends QueryDslQueryBase {
  organic: QueryDslQueryContainer
  ids?: Id[]
  docs?: QueryDslPinnedDoc[]
}

export interface QueryDslPrefixQuery extends QueryDslQueryBase {
  rewrite?: MultiTermQueryRewrite
  value: string
  case_insensitive?: boolean
}

export interface QueryDslQueryBase {
  boost?: float
  _name?: string
}

export interface QueryDslQueryContainer {
  bool?: QueryDslBoolQuery
  boosting?: QueryDslBoostingQuery
  common?: Partial<Record<Field, QueryDslCommonTermsQuery | string>>
  combined_fields?: QueryDslCombinedFieldsQuery
  constant_score?: QueryDslConstantScoreQuery
  dis_max?: QueryDslDisMaxQuery
  distance_feature?: QueryDslDistanceFeatureQuery
  exists?: QueryDslExistsQuery
  function_score?: QueryDslFunctionScoreQuery | QueryDslFunctionScoreContainer[]
  fuzzy?: Partial<Record<Field, QueryDslFuzzyQuery | string | double | boolean>>
  geo_bounding_box?: QueryDslGeoBoundingBoxQuery
  geo_distance?: QueryDslGeoDistanceQuery
  geo_grid?: Partial<Record<Field, QueryDslGeoGridQuery>>
  geo_polygon?: QueryDslGeoPolygonQuery
  geo_shape?: QueryDslGeoShapeQuery
  has_child?: QueryDslHasChildQuery
  has_parent?: QueryDslHasParentQuery
  ids?: QueryDslIdsQuery
  intervals?: Partial<Record<Field, QueryDslIntervalsQuery>>
  knn?: KnnQuery
  match?: Partial<Record<Field, QueryDslMatchQuery | string | float | boolean>>
  match_all?: QueryDslMatchAllQuery
  match_bool_prefix?: Partial<Record<Field, QueryDslMatchBoolPrefixQuery | string>>
  match_none?: QueryDslMatchNoneQuery
  match_phrase?: Partial<Record<Field, QueryDslMatchPhraseQuery | string>>
  match_phrase_prefix?: Partial<Record<Field, QueryDslMatchPhrasePrefixQuery | string>>
  more_like_this?: QueryDslMoreLikeThisQuery
  multi_match?: QueryDslMultiMatchQuery
  nested?: QueryDslNestedQuery
  parent_id?: QueryDslParentIdQuery
  percolate?: QueryDslPercolateQuery
  pinned?: QueryDslPinnedQuery
  prefix?: Partial<Record<Field, QueryDslPrefixQuery | string>>
  query_string?: QueryDslQueryStringQuery
  range?: Partial<Record<Field, QueryDslRangeQuery>>
  rank_feature?: QueryDslRankFeatureQuery
  regexp?: Partial<Record<Field, QueryDslRegexpQuery | string>>
  rule?: QueryDslRuleQuery
  script?: QueryDslScriptQuery
  script_score?: QueryDslScriptScoreQuery
  semantic?: QueryDslSemanticQuery
  shape?: QueryDslShapeQuery
  simple_query_string?: QueryDslSimpleQueryStringQuery
  span_containing?: QueryDslSpanContainingQuery
  span_field_masking?: QueryDslSpanFieldMaskingQuery
  span_first?: QueryDslSpanFirstQuery
  span_multi?: QueryDslSpanMultiTermQuery
  span_near?: QueryDslSpanNearQuery
  span_not?: QueryDslSpanNotQuery
  span_or?: QueryDslSpanOrQuery
  span_term?: Partial<Record<Field, QueryDslSpanTermQuery | FieldValue>>
  span_within?: QueryDslSpanWithinQuery
  sparse_vector?: QueryDslSparseVectorQuery
  term?: Partial<Record<Field, QueryDslTermQuery | FieldValue>>
  terms?: QueryDslTermsQuery
  terms_set?: Partial<Record<Field, QueryDslTermsSetQuery>>
  text_expansion?: Partial<Record<Field, QueryDslTextExpansionQuery>>
  weighted_tokens?: Partial<Record<Field, QueryDslWeightedTokensQuery>>
  wildcard?: Partial<Record<Field, QueryDslWildcardQuery | string>>
  wrapper?: QueryDslWrapperQuery
  type?: QueryDslTypeQuery
}

export interface QueryDslQueryStringQuery extends QueryDslQueryBase {
  allow_leading_wildcard?: boolean
  analyzer?: string
  analyze_wildcard?: boolean
  auto_generate_synonyms_phrase_query?: boolean
  default_field?: Field
  default_operator?: QueryDslOperator
  enable_position_increments?: boolean
  escape?: boolean
  fields?: Field[]
  fuzziness?: Fuzziness
  fuzzy_max_expansions?: integer
  fuzzy_prefix_length?: integer
  fuzzy_rewrite?: MultiTermQueryRewrite
  fuzzy_transpositions?: boolean
  lenient?: boolean
  max_determinized_states?: integer
  minimum_should_match?: MinimumShouldMatch
  phrase_slop?: double
  query: string
  quote_analyzer?: string
  quote_field_suffix?: string
  rewrite?: MultiTermQueryRewrite
  tie_breaker?: double
  time_zone?: TimeZone
  type?: QueryDslTextQueryType
}

export interface QueryDslRandomScoreFunction {
  field?: Field
  seed?: long | string
}

export type QueryDslRangeQuery = QueryDslUntypedRangeQuery | QueryDslDateRangeQuery | QueryDslNumberRangeQuery | QueryDslTermRangeQuery

export interface QueryDslRangeQueryBase<T = unknown> extends QueryDslQueryBase {
  relation?: QueryDslRangeRelation
  gt?: T
  gte?: T
  lt?: T
  lte?: T
  from?: T | null
  to?: T | null
}

export type QueryDslRangeRelation = 'within' | 'contains' | 'intersects'

export interface QueryDslRankFeatureFunction {
}

export interface QueryDslRankFeatureFunctionLinear {
}

export interface QueryDslRankFeatureFunctionLogarithm {
  scaling_factor: float
}

export interface QueryDslRankFeatureFunctionSaturation {
  pivot?: float
}

export interface QueryDslRankFeatureFunctionSigmoid {
  pivot: float
  exponent: float
}

export interface QueryDslRankFeatureQuery extends QueryDslQueryBase {
  field: Field
  saturation?: QueryDslRankFeatureFunctionSaturation
  log?: QueryDslRankFeatureFunctionLogarithm
  linear?: QueryDslRankFeatureFunctionLinear
  sigmoid?: QueryDslRankFeatureFunctionSigmoid
}

export interface QueryDslRegexpQuery extends QueryDslQueryBase {
  case_insensitive?: boolean
  flags?: string
  max_determinized_states?: integer
  rewrite?: MultiTermQueryRewrite
  value: string
}

export interface QueryDslRuleQuery extends QueryDslQueryBase {
  organic: QueryDslQueryContainer
  ruleset_ids: Id[]
  match_criteria: any
}

export interface QueryDslScriptQuery extends QueryDslQueryBase {
  script: Script | string
}

export interface QueryDslScriptScoreFunction {
  script: Script | string
}

export interface QueryDslScriptScoreQuery extends QueryDslQueryBase {
  min_score?: float
  query: QueryDslQueryContainer
  script: Script | string
}

export interface QueryDslSemanticQuery extends QueryDslQueryBase {
  field: string
  query: string
}

export interface QueryDslShapeFieldQuery {
  indexed_shape?: QueryDslFieldLookup
  relation?: GeoShapeRelation
  shape?: GeoShape
}

export interface QueryDslShapeQueryKeys extends QueryDslQueryBase {
  ignore_unmapped?: boolean
}
export type QueryDslShapeQuery = QueryDslShapeQueryKeys
& { [property: string]: QueryDslShapeFieldQuery | boolean | float | string }

export type QueryDslSimpleQueryStringFlag = 'NONE' | 'AND' | 'NOT' | 'OR' | 'PREFIX' | 'PHRASE' | 'PRECEDENCE' | 'ESCAPE' | 'WHITESPACE' | 'FUZZY' | 'NEAR' | 'SLOP' | 'ALL'

export type QueryDslSimpleQueryStringFlags = SpecUtilsPipeSeparatedFlags<QueryDslSimpleQueryStringFlag>

export interface QueryDslSimpleQueryStringQuery extends QueryDslQueryBase {
  analyzer?: string
  analyze_wildcard?: boolean
  auto_generate_synonyms_phrase_query?: boolean
  default_operator?: QueryDslOperator
  fields?: Field[]
  flags?: QueryDslSimpleQueryStringFlags
  fuzzy_max_expansions?: integer
  fuzzy_prefix_length?: integer
  fuzzy_transpositions?: boolean
  lenient?: boolean
  minimum_should_match?: MinimumShouldMatch
  query: string
  quote_field_suffix?: string
}

export interface QueryDslSpanContainingQuery extends QueryDslQueryBase {
  big: QueryDslSpanQuery
  little: QueryDslSpanQuery
}

export interface QueryDslSpanFieldMaskingQuery extends QueryDslQueryBase {
  field: Field
  query: QueryDslSpanQuery
}

export interface QueryDslSpanFirstQuery extends QueryDslQueryBase {
  end: integer
  match: QueryDslSpanQuery
}

export type QueryDslSpanGapQuery = Partial<Record<Field, integer>>

export interface QueryDslSpanMultiTermQuery extends QueryDslQueryBase {
  match: QueryDslQueryContainer
}

export interface QueryDslSpanNearQuery extends QueryDslQueryBase {
  clauses: QueryDslSpanQuery[]
  in_order?: boolean
  slop?: integer
}

export interface QueryDslSpanNotQuery extends QueryDslQueryBase {
  dist?: integer
  exclude: QueryDslSpanQuery
  include: QueryDslSpanQuery
  post?: integer
  pre?: integer
}

export interface QueryDslSpanOrQuery extends QueryDslQueryBase {
  clauses: QueryDslSpanQuery[]
}

export interface QueryDslSpanQuery {
  span_containing?: QueryDslSpanContainingQuery
  span_field_masking?: QueryDslSpanFieldMaskingQuery
  span_first?: QueryDslSpanFirstQuery
  span_gap?: QueryDslSpanGapQuery
  span_multi?: QueryDslSpanMultiTermQuery
  span_near?: QueryDslSpanNearQuery
  span_not?: QueryDslSpanNotQuery
  span_or?: QueryDslSpanOrQuery
  span_term?: Partial<Record<Field, QueryDslSpanTermQuery | FieldValue>>
  span_within?: QueryDslSpanWithinQuery
}

export interface QueryDslSpanTermQuery extends QueryDslQueryBase {
  value: FieldValue
  term: FieldValue
}

export interface QueryDslSpanWithinQuery extends QueryDslQueryBase {
  big: QueryDslSpanQuery
  little: QueryDslSpanQuery
}

export interface QueryDslSparseVectorQuery extends QueryDslQueryBase {
  field: Field
  query_vector?: Record<string, float>
  inference_id?: Id
  query?: string
  prune?: boolean
  pruning_config?: QueryDslTokenPruningConfig
}

export interface QueryDslTermQuery extends QueryDslQueryBase {
  value: FieldValue
  case_insensitive?: boolean
}

export interface QueryDslTermRangeQuery extends QueryDslRangeQueryBase<string> {
}

export interface QueryDslTermsLookup {
  index: IndexName
  id: Id
  path: Field
  routing?: Routing
}

export interface QueryDslTermsQueryKeys extends QueryDslQueryBase {
}
export type QueryDslTermsQuery = QueryDslTermsQueryKeys
& { [property: string]: QueryDslTermsQueryField | float | string }

export type QueryDslTermsQueryField = FieldValue[] | QueryDslTermsLookup

export interface QueryDslTermsSetQuery extends QueryDslQueryBase {
  minimum_should_match?: MinimumShouldMatch
  minimum_should_match_field?: Field
  minimum_should_match_script?: Script | string
  terms: FieldValue[]
}

export interface QueryDslTextExpansionQuery extends QueryDslQueryBase {
  model_id: string
  model_text: string
  pruning_config?: QueryDslTokenPruningConfig
}

export type QueryDslTextQueryType = 'best_fields' | 'most_fields' | 'cross_fields' | 'phrase' | 'phrase_prefix' | 'bool_prefix'

export interface QueryDslTokenPruningConfig {
  tokens_freq_ratio_threshold?: integer
  tokens_weight_threshold?: float
  only_score_pruned_tokens?: boolean
}

export interface QueryDslTypeQuery extends QueryDslQueryBase {
  value: string
}

export interface QueryDslUntypedDecayFunctionKeys extends QueryDslDecayFunctionBase<any, any> {
}
export type QueryDslUntypedDecayFunction = QueryDslUntypedDecayFunctionKeys
& { [property: string]: QueryDslDecayPlacement | QueryDslMultiValueMode }

export interface QueryDslUntypedDistanceFeatureQuery extends QueryDslDistanceFeatureQueryBase<any, any> {
}

export interface QueryDslUntypedRangeQuery extends QueryDslRangeQueryBase<any> {
  format?: DateFormat
  time_zone?: TimeZone
}

export interface QueryDslWeightedTokensQuery extends QueryDslQueryBase {
  tokens: Record<string, float>
  pruning_config?: QueryDslTokenPruningConfig
}

export interface QueryDslWildcardQuery extends QueryDslQueryBase {
  case_insensitive?: boolean
  rewrite?: MultiTermQueryRewrite
  value?: string
  wildcard?: string
}

export interface QueryDslWrapperQuery extends QueryDslQueryBase {
  query: string
}

export type QueryDslZeroTermsQuery = 'all' | 'none'

export interface AsyncSearchAsyncSearch<TDocument = unknown, TAggregations = Record<AggregateName, AggregationsAggregate>> {
  aggregations?: TAggregations
  _clusters?: ClusterStatistics
  fields?: Record<string, any>
  hits: SearchHitsMetadata<TDocument>
  max_score?: double
  num_reduce_phases?: long
  profile?: SearchProfile
  pit_id?: Id
  _scroll_id?: ScrollId
  _shards: ShardStatistics
  suggest?: Record<SuggestionName, SearchSuggest<TDocument>[]>
  terminated_early?: boolean
  timed_out: boolean
  took: long
}

export interface AsyncSearchAsyncSearchDocumentResponseBase<TDocument = unknown, TAggregations = Record<AggregateName, AggregationsAggregate>> extends AsyncSearchAsyncSearchResponseBase {
  response: AsyncSearchAsyncSearch<TDocument, TAggregations>
}

export interface AsyncSearchAsyncSearchResponseBase {
  id?: Id
  is_partial: boolean
  is_running: boolean
  expiration_time?: DateTime
  expiration_time_in_millis: EpochTime<UnitMillis>
  start_time?: DateTime
  start_time_in_millis: EpochTime<UnitMillis>
  completion_time?: DateTime
  completion_time_in_millis?: EpochTime<UnitMillis>
}

export interface AsyncSearchDeleteRequest extends RequestBase {
/** A unique identifier for the async search. */
  id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export type AsyncSearchDeleteResponse = AcknowledgedResponseBase

export interface AsyncSearchGetRequest extends RequestBase {
/** A unique identifier for the async search. */
  id: Id
  /** The length of time that the async search should be available in the cluster. When not specified, the `keep_alive` set with the corresponding submit async request will be used. Otherwise, it is possible to override the value and extend the validity of the request. When this period expires, the search, if still running, is cancelled. If the search is completed, its saved results are deleted. */
  keep_alive?: Duration
  /** Specify whether aggregation and suggester names should be prefixed by their respective types in the response */
  typed_keys?: boolean
  /** Specifies to wait for the search to be completed up until the provided timeout. Final results will be returned if available before the timeout expires, otherwise the currently available results will be returned once the timeout expires. By default no timeout is set meaning that the currently available results will be returned without any additional wait. */
  wait_for_completion_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, keep_alive?: never, typed_keys?: never, wait_for_completion_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, keep_alive?: never, typed_keys?: never, wait_for_completion_timeout?: never }
}

export type AsyncSearchGetResponse<TDocument = unknown, TAggregations = Record<AggregateName, AggregationsAggregate>> = AsyncSearchAsyncSearchDocumentResponseBase<TDocument, TAggregations>

export interface AsyncSearchStatusRequest extends RequestBase {
/** A unique identifier for the async search. */
  id: Id
  /** The length of time that the async search needs to be available. Ongoing async searches and any saved search results are deleted after this period. */
  keep_alive?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, keep_alive?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, keep_alive?: never }
}

export type AsyncSearchStatusResponse = AsyncSearchStatusStatusResponseBase

export interface AsyncSearchStatusStatusResponseBase extends AsyncSearchAsyncSearchResponseBase {
  _shards: ShardStatistics
  _clusters?: ClusterStatistics
  completion_status?: integer
}

export interface AsyncSearchSubmitRequest extends RequestBase {
/** A comma-separated list of index names to search; use `_all` or empty string to perform the operation on all indices */
  index?: Indices
  /** Blocks and waits until the search is completed up to a certain timeout. When the async search completes within the timeout, the response won’t include the ID as the results are not stored in the cluster. */
  wait_for_completion_timeout?: Duration
  /** Specifies how long the async search needs to be available. Ongoing async searches and any saved search results are deleted after this period. */
  keep_alive?: Duration
  /** If `true`, results are stored for later retrieval when the search completes within the `wait_for_completion_timeout`. */
  keep_on_completion?: boolean
  /** Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes `_all` string or when no indices have been specified) */
  allow_no_indices?: boolean
  /** Indicate if an error should be returned if there is a partial search failure or timeout */
  allow_partial_search_results?: boolean
  /** The analyzer to use for the query string */
  analyzer?: string
  /** Specify whether wildcard and prefix queries should be analyzed (default: false) */
  analyze_wildcard?: boolean
  /** Affects how often partial results become available, which happens whenever shard results are reduced. A partial reduction is performed every time the coordinating node has received a certain number of new shard responses (5 by default). */
  batched_reduce_size?: long
  /** The default value is the only supported value. */
  ccs_minimize_roundtrips?: boolean
  /** The default operator for query string query (AND or OR) */
  default_operator?: QueryDslOperator
  /** The field to use as default where no field prefix is given in the query string */
  df?: string
  /** Whether to expand wildcard expression to concrete indices that are open, closed or both. */
  expand_wildcards?: ExpandWildcards
  /** Whether specified concrete, expanded or aliased indices should be ignored when throttled */
  ignore_throttled?: boolean
  /** Whether specified concrete indices should be ignored when unavailable (missing or closed) */
  ignore_unavailable?: boolean
  /** Specify whether format-based query failures (such as providing text to a numeric field) should be ignored */
  lenient?: boolean
  /** The number of concurrent shard requests per node this search executes concurrently. This value should be used to limit the impact of the search on the cluster in order to limit the number of concurrent shard requests */
  max_concurrent_shard_requests?: long
  /** Specify the node or shard the operation should be performed on (default: random) */
  preference?: string
  /** Specify if request cache should be used for this request or not, defaults to true */
  request_cache?: boolean
  /** A comma-separated list of specific routing values */
  routing?: Routing
  /** Search operation type */
  search_type?: SearchType
  /** Specifies which field to use for suggestions. */
  suggest_field?: Field
  /** Specify suggest mode */
  suggest_mode?: SuggestMode
  /** How many suggestions to return in response */
  suggest_size?: long
  /** The source text for which the suggestions should be returned. */
  suggest_text?: string
  /** Specify whether aggregation and suggester names should be prefixed by their respective types in the response */
  typed_keys?: boolean
  /** Indicates whether hits.total should be rendered as an integer or an object in the rest search response */
  rest_total_hits_as_int?: boolean
  /** A list of fields to exclude from the returned _source field */
  _source_excludes?: Fields
  /** A list of fields to extract and return from the _source field */
  _source_includes?: Fields
  /** Query in the Lucene query string syntax */
  q?: string
  aggregations?: Record<string, AggregationsAggregationContainer>
  /** @alias aggregations */
  aggs?: Record<string, AggregationsAggregationContainer>
  collapse?: SearchFieldCollapse
  /** If true, returns detailed information about score computation as part of a hit. */
  explain?: boolean
  /** Configuration of search extensions defined by Elasticsearch plugins. */
  ext?: Record<string, any>
  /** Starting document offset. By default, you cannot page through more than 10,000 hits using the from and size parameters. To page through more hits, use the search_after parameter. */
  from?: integer
  highlight?: SearchHighlight
  /** Number of hits matching the query to count accurately. If true, the exact number of hits is returned at the cost of some performance. If false, the response does not include the total number of hits matching the query. Defaults to 10,000 hits. */
  track_total_hits?: SearchTrackHits
  /** Boosts the _score of documents from specified indices. */
  indices_boost?: Record<IndexName, double>[]
  /** Array of wildcard (*) patterns. The request returns doc values for field names matching these patterns in the hits.fields property of the response. */
  docvalue_fields?: (QueryDslFieldAndFormat | Field)[]
  /** Defines the approximate kNN search to run. */
  knn?: KnnSearch | KnnSearch[]
  /** Minimum _score for matching documents. Documents with a lower _score are not included in the search results. */
  min_score?: double
  post_filter?: QueryDslQueryContainer
  profile?: boolean
  /** Defines the search definition using the Query DSL. */
  query?: QueryDslQueryContainer
  rescore?: SearchRescore | SearchRescore[]
  /** Retrieve a script evaluation (based on different fields) for each hit. */
  script_fields?: Record<string, ScriptField>
  search_after?: SortResults
  /** The number of hits to return. By default, you cannot page through more than 10,000 hits using the from and size parameters. To page through more hits, use the search_after parameter. */
  size?: integer
  slice?: SlicedScroll
  sort?: Sort
  /** Indicates which source fields are returned for matching documents. These fields are returned in the hits._source property of the search response. */
  _source?: SearchSourceConfig
  /** Array of wildcard (*) patterns. The request returns values for field names matching these patterns in the hits.fields property of the response. */
  fields?: (QueryDslFieldAndFormat | Field)[]
  suggest?: SearchSuggester
  /** Maximum number of documents to collect for each shard. If a query reaches this limit, Elasticsearch terminates the query early. Elasticsearch collects documents before sorting. Defaults to 0, which does not terminate query execution early. */
  terminate_after?: long
  /** Specifies the period of time to wait for a response from each shard. If no response is received before the timeout expires, the request fails and returns an error. Defaults to no timeout. */
  timeout?: string
  /** If true, calculate and return document scores, even if the scores are not used for sorting. */
  track_scores?: boolean
  /** If true, returns document version as part of a hit. */
  version?: boolean
  /** If true, returns sequence number and primary term of the last modification of each hit. See Optimistic concurrency control. */
  seq_no_primary_term?: boolean
  /** List of stored fields to return as part of a hit. If no fields are specified, no stored fields are included in the response. If this field is specified, the _source parameter defaults to false. You can pass _source: true to return both source fields and stored fields in the search response. */
  stored_fields?: Fields
  /** Limits the search to a point in time (PIT). If you provide a PIT, you cannot specify an <index> in the request path. */
  pit?: SearchPointInTimeReference
  /** Defines one or more runtime fields in the search request. These fields take precedence over mapped fields with the same name. */
  runtime_mappings?: MappingRuntimeFields
  /** Stats groups to associate with the search. Each group maintains a statistics aggregation for its associated searches. You can retrieve these stats using the indices stats API. */
  stats?: string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, wait_for_completion_timeout?: never, keep_alive?: never, keep_on_completion?: never, allow_no_indices?: never, allow_partial_search_results?: never, analyzer?: never, analyze_wildcard?: never, batched_reduce_size?: never, ccs_minimize_roundtrips?: never, default_operator?: never, df?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, lenient?: never, max_concurrent_shard_requests?: never, preference?: never, request_cache?: never, routing?: never, search_type?: never, suggest_field?: never, suggest_mode?: never, suggest_size?: never, suggest_text?: never, typed_keys?: never, rest_total_hits_as_int?: never, _source_excludes?: never, _source_includes?: never, q?: never, aggregations?: never, aggs?: never, collapse?: never, explain?: never, ext?: never, from?: never, highlight?: never, track_total_hits?: never, indices_boost?: never, docvalue_fields?: never, knn?: never, min_score?: never, post_filter?: never, profile?: never, query?: never, rescore?: never, script_fields?: never, search_after?: never, size?: never, slice?: never, sort?: never, _source?: never, fields?: never, suggest?: never, terminate_after?: never, timeout?: never, track_scores?: never, version?: never, seq_no_primary_term?: never, stored_fields?: never, pit?: never, runtime_mappings?: never, stats?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, wait_for_completion_timeout?: never, keep_alive?: never, keep_on_completion?: never, allow_no_indices?: never, allow_partial_search_results?: never, analyzer?: never, analyze_wildcard?: never, batched_reduce_size?: never, ccs_minimize_roundtrips?: never, default_operator?: never, df?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, lenient?: never, max_concurrent_shard_requests?: never, preference?: never, request_cache?: never, routing?: never, search_type?: never, suggest_field?: never, suggest_mode?: never, suggest_size?: never, suggest_text?: never, typed_keys?: never, rest_total_hits_as_int?: never, _source_excludes?: never, _source_includes?: never, q?: never, aggregations?: never, aggs?: never, collapse?: never, explain?: never, ext?: never, from?: never, highlight?: never, track_total_hits?: never, indices_boost?: never, docvalue_fields?: never, knn?: never, min_score?: never, post_filter?: never, profile?: never, query?: never, rescore?: never, script_fields?: never, search_after?: never, size?: never, slice?: never, sort?: never, _source?: never, fields?: never, suggest?: never, terminate_after?: never, timeout?: never, track_scores?: never, version?: never, seq_no_primary_term?: never, stored_fields?: never, pit?: never, runtime_mappings?: never, stats?: never }
}

export type AsyncSearchSubmitResponse<TDocument = unknown, TAggregations = Record<AggregateName, AggregationsAggregate>> = AsyncSearchAsyncSearchDocumentResponseBase<TDocument, TAggregations>

export interface AutoscalingAutoscalingPolicy {
  roles: string[]
  deciders: Record<string, any>
}

export interface AutoscalingDeleteAutoscalingPolicyRequest extends RequestBase {
/** the name of the autoscaling policy */
  name: Name
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
}

export type AutoscalingDeleteAutoscalingPolicyResponse = AcknowledgedResponseBase

export interface AutoscalingGetAutoscalingCapacityAutoscalingCapacity {
  node: AutoscalingGetAutoscalingCapacityAutoscalingResources
  total: AutoscalingGetAutoscalingCapacityAutoscalingResources
}

export interface AutoscalingGetAutoscalingCapacityAutoscalingDecider {
  required_capacity: AutoscalingGetAutoscalingCapacityAutoscalingCapacity
  reason_summary?: string
  reason_details?: any
}

export interface AutoscalingGetAutoscalingCapacityAutoscalingDeciders {
  required_capacity: AutoscalingGetAutoscalingCapacityAutoscalingCapacity
  current_capacity: AutoscalingGetAutoscalingCapacityAutoscalingCapacity
  current_nodes: AutoscalingGetAutoscalingCapacityAutoscalingNode[]
  deciders: Record<string, AutoscalingGetAutoscalingCapacityAutoscalingDecider>
}

export interface AutoscalingGetAutoscalingCapacityAutoscalingNode {
  name: NodeName
}

export interface AutoscalingGetAutoscalingCapacityAutoscalingResources {
  storage: integer
  memory: integer
}

export interface AutoscalingGetAutoscalingCapacityRequest extends RequestBase {
/** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never }
}

export interface AutoscalingGetAutoscalingCapacityResponse {
  policies: Record<string, AutoscalingGetAutoscalingCapacityAutoscalingDeciders>
}

export interface AutoscalingGetAutoscalingPolicyRequest extends RequestBase {
/** the name of the autoscaling policy */
  name: Name
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never }
}

export type AutoscalingGetAutoscalingPolicyResponse = AutoscalingAutoscalingPolicy

export interface AutoscalingPutAutoscalingPolicyRequest extends RequestBase {
/** the name of the autoscaling policy */
  name: Name
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  policy?: AutoscalingAutoscalingPolicy
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never, policy?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never, policy?: never }
}

export type AutoscalingPutAutoscalingPolicyResponse = AcknowledgedResponseBase

export type CatCatAnomalyDetectorColumn = 'assignment_explanation' | 'ae' | 'buckets.count' | 'bc' | 'bucketsCount' | 'buckets.time.exp_avg' | 'btea' | 'bucketsTimeExpAvg' | 'buckets.time.exp_avg_hour' | 'bteah' | 'bucketsTimeExpAvgHour' | 'buckets.time.max' | 'btmax' | 'bucketsTimeMax' | 'buckets.time.min' | 'btmin' | 'bucketsTimeMin' | 'buckets.time.total' | 'btt' | 'bucketsTimeTotal' | 'data.buckets' | 'db' | 'dataBuckets' | 'data.earliest_record' | 'der' | 'dataEarliestRecord' | 'data.empty_buckets' | 'deb' | 'dataEmptyBuckets' | 'data.input_bytes' | 'dib' | 'dataInputBytes' | 'data.input_fields' | 'dif' | 'dataInputFields' | 'data.input_records' | 'dir' | 'dataInputRecords' | 'data.invalid_dates' | 'did' | 'dataInvalidDates' | 'data.last' | 'dl' | 'dataLast' | 'data.last_empty_bucket' | 'dleb' | 'dataLastEmptyBucket' | 'data.last_sparse_bucket' | 'dlsb' | 'dataLastSparseBucket' | 'data.latest_record' | 'dlr' | 'dataLatestRecord' | 'data.missing_fields' | 'dmf' | 'dataMissingFields' | 'data.out_of_order_timestamps' | 'doot' | 'dataOutOfOrderTimestamps' | 'data.processed_fields' | 'dpf' | 'dataProcessedFields' | 'data.processed_records' | 'dpr' | 'dataProcessedRecords' | 'data.sparse_buckets' | 'dsb' | 'dataSparseBuckets' | 'forecasts.memory.avg' | 'fmavg' | 'forecastsMemoryAvg' | 'forecasts.memory.max' | 'fmmax' | 'forecastsMemoryMax' | 'forecasts.memory.min' | 'fmmin' | 'forecastsMemoryMin' | 'forecasts.memory.total' | 'fmt' | 'forecastsMemoryTotal' | 'forecasts.records.avg' | 'fravg' | 'forecastsRecordsAvg' | 'forecasts.records.max' | 'frmax' | 'forecastsRecordsMax' | 'forecasts.records.min' | 'frmin' | 'forecastsRecordsMin' | 'forecasts.records.total' | 'frt' | 'forecastsRecordsTotal' | 'forecasts.time.avg' | 'ftavg' | 'forecastsTimeAvg' | 'forecasts.time.max' | 'ftmax' | 'forecastsTimeMax' | 'forecasts.time.min' | 'ftmin' | 'forecastsTimeMin' | 'forecasts.time.total' | 'ftt' | 'forecastsTimeTotal' | 'forecasts.total' | 'ft' | 'forecastsTotal' | 'id' | 'model.bucket_allocation_failures' | 'mbaf' | 'modelBucketAllocationFailures' | 'model.by_fields' | 'mbf' | 'modelByFields' | 'model.bytes' | 'mb' | 'modelBytes' | 'model.bytes_exceeded' | 'mbe' | 'modelBytesExceeded' | 'model.categorization_status' | 'mcs' | 'modelCategorizationStatus' | 'model.categorized_doc_count' | 'mcdc' | 'modelCategorizedDocCount' | 'model.dead_category_count' | 'mdcc' | 'modelDeadCategoryCount' | 'model.failed_category_count' | 'mdcc' | 'modelFailedCategoryCount' | 'model.frequent_category_count' | 'mfcc' | 'modelFrequentCategoryCount' | 'model.log_time' | 'mlt' | 'modelLogTime' | 'model.memory_limit' | 'mml' | 'modelMemoryLimit' | 'model.memory_status' | 'mms' | 'modelMemoryStatus' | 'model.over_fields' | 'mof' | 'modelOverFields' | 'model.partition_fields' | 'mpf' | 'modelPartitionFields' | 'model.rare_category_count' | 'mrcc' | 'modelRareCategoryCount' | 'model.timestamp' | 'mt' | 'modelTimestamp' | 'model.total_category_count' | 'mtcc' | 'modelTotalCategoryCount' | 'node.address' | 'na' | 'nodeAddress' | 'node.ephemeral_id' | 'ne' | 'nodeEphemeralId' | 'node.id' | 'ni' | 'nodeId' | 'node.name' | 'nn' | 'nodeName' | 'opened_time' | 'ot' | 'state' | 's'

export type CatCatAnonalyDetectorColumns = CatCatAnomalyDetectorColumn | CatCatAnomalyDetectorColumn[]

export type CatCatDatafeedColumn = 'ae' | 'assignment_explanation' | 'bc' | 'buckets.count' | 'bucketsCount' | 'id' | 'na' | 'node.address' | 'nodeAddress' | 'ne' | 'node.ephemeral_id' | 'nodeEphemeralId' | 'ni' | 'node.id' | 'nodeId' | 'nn' | 'node.name' | 'nodeName' | 'sba' | 'search.bucket_avg' | 'searchBucketAvg' | 'sc' | 'search.count' | 'searchCount' | 'seah' | 'search.exp_avg_hour' | 'searchExpAvgHour' | 'st' | 'search.time' | 'searchTime' | 's' | 'state'

export type CatCatDatafeedColumns = CatCatDatafeedColumn | CatCatDatafeedColumn[]

export type CatCatDfaColumn = 'assignment_explanation' | 'ae' | 'create_time' | 'ct' | 'createTime' | 'description' | 'd' | 'dest_index' | 'di' | 'destIndex' | 'failure_reason' | 'fr' | 'failureReason' | 'id' | 'model_memory_limit' | 'mml' | 'modelMemoryLimit' | 'node.address' | 'na' | 'nodeAddress' | 'node.ephemeral_id' | 'ne' | 'nodeEphemeralId' | 'node.id' | 'ni' | 'nodeId' | 'node.name' | 'nn' | 'nodeName' | 'progress' | 'p' | 'source_index' | 'si' | 'sourceIndex' | 'state' | 's' | 'type' | 't' | 'version' | 'v'

export type CatCatDfaColumns = CatCatDfaColumn | CatCatDfaColumn[]

export interface CatCatRequestBase extends RequestBase, SpecUtilsCommonCatQueryParameters {
}

export type CatCatTrainedModelsColumn = 'create_time' | 'ct' | 'created_by' | 'c' | 'createdBy' | 'data_frame_analytics_id' | 'df' | 'dataFrameAnalytics' | 'dfid' | 'description' | 'd' | 'heap_size' | 'hs' | 'modelHeapSize' | 'id' | 'ingest.count' | 'ic' | 'ingestCount' | 'ingest.current' | 'icurr' | 'ingestCurrent' | 'ingest.failed' | 'if' | 'ingestFailed' | 'ingest.pipelines' | 'ip' | 'ingestPipelines' | 'ingest.time' | 'it' | 'ingestTime' | 'license' | 'l' | 'operations' | 'o' | 'modelOperations' | 'version' | 'v'

export type CatCatTrainedModelsColumns = CatCatTrainedModelsColumn | CatCatTrainedModelsColumn[]

export type CatCatTransformColumn = 'changes_last_detection_time' | 'cldt' | 'checkpoint' | 'cp' | 'checkpoint_duration_time_exp_avg' | 'cdtea' | 'checkpointTimeExpAvg' | 'checkpoint_progress' | 'c' | 'checkpointProgress' | 'create_time' | 'ct' | 'createTime' | 'delete_time' | 'dtime' | 'description' | 'd' | 'dest_index' | 'di' | 'destIndex' | 'documents_deleted' | 'docd' | 'documents_indexed' | 'doci' | 'docs_per_second' | 'dps' | 'documents_processed' | 'docp' | 'frequency' | 'f' | 'id' | 'index_failure' | 'if' | 'index_time' | 'itime' | 'index_total' | 'it' | 'indexed_documents_exp_avg' | 'idea' | 'last_search_time' | 'lst' | 'lastSearchTime' | 'max_page_search_size' | 'mpsz' | 'pages_processed' | 'pp' | 'pipeline' | 'p' | 'processed_documents_exp_avg' | 'pdea' | 'processing_time' | 'pt' | 'reason' | 'r' | 'search_failure' | 'sf' | 'search_time' | 'stime' | 'search_total' | 'st' | 'source_index' | 'si' | 'sourceIndex' | 'state' | 's' | 'transform_type' | 'tt' | 'trigger_count' | 'tc' | 'version' | 'v'

export type CatCatTransformColumns = CatCatTransformColumn | CatCatTransformColumn[]

export interface CatAliasesAliasesRecord {
  alias?: string
  a?: string
  index?: IndexName
  i?: IndexName
  idx?: IndexName
  filter?: string
  f?: string
  fi?: string
  'routing.index'?: string
  ri?: string
  routingIndex?: string
  'routing.search'?: string
  rs?: string
  routingSearch?: string
  is_write_index?: string
  w?: string
  isWriteIndex?: string
}

export interface CatAliasesRequest extends CatCatRequestBase {
/** A comma-separated list of aliases to retrieve. Supports wildcards (`*`). To retrieve all aliases, omit this parameter or use `*` or `_all`. */
  name?: Names
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** The type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. It supports comma-separated values, such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** The period to wait for a connection to the master node. If the master node is not available before the timeout expires, the request fails and returns an error. To indicated that the request should never timeout, you can set it to `-1`. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, h?: never, s?: never, expand_wildcards?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, h?: never, s?: never, expand_wildcards?: never, master_timeout?: never }
}

export type CatAliasesResponse = CatAliasesAliasesRecord[]

export interface CatAllocationAllocationRecord {
  shards?: string
  s?: string
  'shards.undesired'?: string | null
  'write_load.forecast'?: SpecUtilsStringified<double> | null
  wlf?: SpecUtilsStringified<double> | null
  writeLoadForecast?: SpecUtilsStringified<double> | null
  'disk.indices.forecast'?: ByteSize | null
  dif?: ByteSize | null
  diskIndicesForecast?: ByteSize | null
  'disk.indices'?: ByteSize | null
  di?: ByteSize | null
  diskIndices?: ByteSize | null
  'disk.used'?: ByteSize | null
  du?: ByteSize | null
  diskUsed?: ByteSize | null
  'disk.avail'?: ByteSize | null
  da?: ByteSize | null
  diskAvail?: ByteSize | null
  'disk.total'?: ByteSize | null
  dt?: ByteSize | null
  diskTotal?: ByteSize | null
  'disk.percent'?: Percentage | null
  dp?: Percentage | null
  diskPercent?: Percentage | null
  host?: Host | null
  h?: Host | null
  ip?: Ip | null
  node?: string
  n?: string
  'node.role'?: string | null
  r?: string | null
  role?: string | null
  nodeRole?: string | null
}

export interface CatAllocationRequest extends CatCatRequestBase {
/** A comma-separated list of node identifiers or names used to limit the returned information. */
  node_id?: NodeIds
  /** The unit used to display byte values. */
  bytes?: Bytes
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** If `true`, the request computes the list of selected nodes from the local cluster state. If `false` the list of selected nodes are computed from the cluster state of the master node. In both cases the coordinating node will send requests for further information to each selected node. */
  local?: boolean
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never, bytes?: never, h?: never, s?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never, bytes?: never, h?: never, s?: never, local?: never, master_timeout?: never }
}

export type CatAllocationResponse = CatAllocationAllocationRecord[]

export interface CatComponentTemplatesComponentTemplate {
  name: string
  version: string | null
  alias_count: string
  mapping_count: string
  settings_count: string
  metadata_count: string
  included_in: string
}

export interface CatComponentTemplatesRequest extends CatCatRequestBase {
/** The name of the component template. It accepts wildcard expressions. If it is omitted, all component templates are returned. */
  name?: string
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** If `true`, the request computes the list of selected nodes from the local cluster state. If `false` the list of selected nodes are computed from the cluster state of the master node. In both cases the coordinating node will send requests for further information to each selected node. */
  local?: boolean
  /** The period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, h?: never, s?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, h?: never, s?: never, local?: never, master_timeout?: never }
}

export type CatComponentTemplatesResponse = CatComponentTemplatesComponentTemplate[]

export interface CatCountCountRecord {
  epoch?: SpecUtilsStringified<EpochTime<UnitSeconds>>
  t?: SpecUtilsStringified<EpochTime<UnitSeconds>>
  time?: SpecUtilsStringified<EpochTime<UnitSeconds>>
  timestamp?: TimeOfDay
  ts?: TimeOfDay
  hms?: TimeOfDay
  hhmmss?: TimeOfDay
  count?: string
  dc?: string
  'docs.count'?: string
  docsCount?: string
}

export interface CatCountRequest extends CatCatRequestBase {
/** A comma-separated list of data streams, indices, and aliases used to limit the request. It supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, h?: never, s?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, h?: never, s?: never }
}

export type CatCountResponse = CatCountCountRecord[]

export interface CatFielddataFielddataRecord {
  id?: string
  host?: string
  h?: string
  ip?: string
  node?: string
  n?: string
  field?: string
  f?: string
  size?: string
}

export interface CatFielddataRequest extends CatCatRequestBase {
/** Comma-separated list of fields used to limit returned information. To retrieve all fields, omit this parameter. */
  fields?: Fields
  /** The unit used to display byte values. */
  bytes?: Bytes
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { fields?: never, bytes?: never, h?: never, s?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { fields?: never, bytes?: never, h?: never, s?: never }
}

export type CatFielddataResponse = CatFielddataFielddataRecord[]

export interface CatHealthHealthRecord {
  epoch?: SpecUtilsStringified<EpochTime<UnitSeconds>>
  time?: SpecUtilsStringified<EpochTime<UnitSeconds>>
  timestamp?: TimeOfDay
  ts?: TimeOfDay
  hms?: TimeOfDay
  hhmmss?: TimeOfDay
  cluster?: string
  cl?: string
  status?: string
  st?: string
  'node.total'?: string
  nt?: string
  nodeTotal?: string
  'node.data'?: string
  nd?: string
  nodeData?: string
  shards?: string
  t?: string
  sh?: string
  'shards.total'?: string
  shardsTotal?: string
  pri?: string
  p?: string
  'shards.primary'?: string
  shardsPrimary?: string
  relo?: string
  r?: string
  'shards.relocating'?: string
  shardsRelocating?: string
  init?: string
  i?: string
  'shards.initializing'?: string
  shardsInitializing?: string
  'unassign.pri'?: string
  up?: string
  'shards.unassigned.primary'?: string
  shardsUnassignedPrimary?: string
  unassign?: string
  u?: string
  'shards.unassigned'?: string
  shardsUnassigned?: string
  pending_tasks?: string
  pt?: string
  pendingTasks?: string
  max_task_wait_time?: string
  mtwt?: string
  maxTaskWaitTime?: string
  active_shards_percent?: string
  asp?: string
  activeShardsPercent?: string
}

export interface CatHealthRequest extends CatCatRequestBase {
/** The unit used to display time values. */
  time?: TimeUnit
  /** If true, returns `HH:MM:SS` and Unix epoch timestamps. */
  ts?: boolean
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { time?: never, ts?: never, h?: never, s?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { time?: never, ts?: never, h?: never, s?: never }
}

export type CatHealthResponse = CatHealthHealthRecord[]

export interface CatHelpRequest {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface CatHelpResponse {
}

export interface CatIndicesIndicesRecord {
  health?: string
  h?: string
  status?: string
  s?: string
  index?: string
  i?: string
  idx?: string
  uuid?: string
  id?: string
  pri?: string
  p?: string
  'shards.primary'?: string
  shardsPrimary?: string
  rep?: string
  r?: string
  'shards.replica'?: string
  shardsReplica?: string
  'docs.count'?: string | null
  dc?: string | null
  docsCount?: string | null
  'docs.deleted'?: string | null
  dd?: string | null
  docsDeleted?: string | null
  'creation.date'?: string
  cd?: string
  'creation.date.string'?: string
  cds?: string
  'store.size'?: string | null
  ss?: string | null
  storeSize?: string | null
  'pri.store.size'?: string | null
  'dataset.size'?: string | null
  'completion.size'?: string
  cs?: string
  completionSize?: string
  'pri.completion.size'?: string
  'fielddata.memory_size'?: string
  fm?: string
  fielddataMemory?: string
  'pri.fielddata.memory_size'?: string
  'fielddata.evictions'?: string
  fe?: string
  fielddataEvictions?: string
  'pri.fielddata.evictions'?: string
  'query_cache.memory_size'?: string
  qcm?: string
  queryCacheMemory?: string
  'pri.query_cache.memory_size'?: string
  'query_cache.evictions'?: string
  qce?: string
  queryCacheEvictions?: string
  'pri.query_cache.evictions'?: string
  'request_cache.memory_size'?: string
  rcm?: string
  requestCacheMemory?: string
  'pri.request_cache.memory_size'?: string
  'request_cache.evictions'?: string
  rce?: string
  requestCacheEvictions?: string
  'pri.request_cache.evictions'?: string
  'request_cache.hit_count'?: string
  rchc?: string
  requestCacheHitCount?: string
  'pri.request_cache.hit_count'?: string
  'request_cache.miss_count'?: string
  rcmc?: string
  requestCacheMissCount?: string
  'pri.request_cache.miss_count'?: string
  'flush.total'?: string
  ft?: string
  flushTotal?: string
  'pri.flush.total'?: string
  'flush.total_time'?: string
  ftt?: string
  flushTotalTime?: string
  'pri.flush.total_time'?: string
  'get.current'?: string
  gc?: string
  getCurrent?: string
  'pri.get.current'?: string
  'get.time'?: string
  gti?: string
  getTime?: string
  'pri.get.time'?: string
  'get.total'?: string
  gto?: string
  getTotal?: string
  'pri.get.total'?: string
  'get.exists_time'?: string
  geti?: string
  getExistsTime?: string
  'pri.get.exists_time'?: string
  'get.exists_total'?: string
  geto?: string
  getExistsTotal?: string
  'pri.get.exists_total'?: string
  'get.missing_time'?: string
  gmti?: string
  getMissingTime?: string
  'pri.get.missing_time'?: string
  'get.missing_total'?: string
  gmto?: string
  getMissingTotal?: string
  'pri.get.missing_total'?: string
  'indexing.delete_current'?: string
  idc?: string
  indexingDeleteCurrent?: string
  'pri.indexing.delete_current'?: string
  'indexing.delete_time'?: string
  idti?: string
  indexingDeleteTime?: string
  'pri.indexing.delete_time'?: string
  'indexing.delete_total'?: string
  idto?: string
  indexingDeleteTotal?: string
  'pri.indexing.delete_total'?: string
  'indexing.index_current'?: string
  iic?: string
  indexingIndexCurrent?: string
  'pri.indexing.index_current'?: string
  'indexing.index_time'?: string
  iiti?: string
  indexingIndexTime?: string
  'pri.indexing.index_time'?: string
  'indexing.index_total'?: string
  iito?: string
  indexingIndexTotal?: string
  'pri.indexing.index_total'?: string
  'indexing.index_failed'?: string
  iif?: string
  indexingIndexFailed?: string
  'pri.indexing.index_failed'?: string
  'merges.current'?: string
  mc?: string
  mergesCurrent?: string
  'pri.merges.current'?: string
  'merges.current_docs'?: string
  mcd?: string
  mergesCurrentDocs?: string
  'pri.merges.current_docs'?: string
  'merges.current_size'?: string
  mcs?: string
  mergesCurrentSize?: string
  'pri.merges.current_size'?: string
  'merges.total'?: string
  mt?: string
  mergesTotal?: string
  'pri.merges.total'?: string
  'merges.total_docs'?: string
  mtd?: string
  mergesTotalDocs?: string
  'pri.merges.total_docs'?: string
  'merges.total_size'?: string
  mts?: string
  mergesTotalSize?: string
  'pri.merges.total_size'?: string
  'merges.total_time'?: string
  mtt?: string
  mergesTotalTime?: string
  'pri.merges.total_time'?: string
  'refresh.total'?: string
  rto?: string
  refreshTotal?: string
  'pri.refresh.total'?: string
  'refresh.time'?: string
  rti?: string
  refreshTime?: string
  'pri.refresh.time'?: string
  'refresh.external_total'?: string
  reto?: string
  'pri.refresh.external_total'?: string
  'refresh.external_time'?: string
  reti?: string
  'pri.refresh.external_time'?: string
  'refresh.listeners'?: string
  rli?: string
  refreshListeners?: string
  'pri.refresh.listeners'?: string
  'search.fetch_current'?: string
  sfc?: string
  searchFetchCurrent?: string
  'pri.search.fetch_current'?: string
  'search.fetch_time'?: string
  sfti?: string
  searchFetchTime?: string
  'pri.search.fetch_time'?: string
  'search.fetch_total'?: string
  sfto?: string
  searchFetchTotal?: string
  'pri.search.fetch_total'?: string
  'search.open_contexts'?: string
  so?: string
  searchOpenContexts?: string
  'pri.search.open_contexts'?: string
  'search.query_current'?: string
  sqc?: string
  searchQueryCurrent?: string
  'pri.search.query_current'?: string
  'search.query_time'?: string
  sqti?: string
  searchQueryTime?: string
  'pri.search.query_time'?: string
  'search.query_total'?: string
  sqto?: string
  searchQueryTotal?: string
  'pri.search.query_total'?: string
  'search.scroll_current'?: string
  scc?: string
  searchScrollCurrent?: string
  'pri.search.scroll_current'?: string
  'search.scroll_time'?: string
  scti?: string
  searchScrollTime?: string
  'pri.search.scroll_time'?: string
  'search.scroll_total'?: string
  scto?: string
  searchScrollTotal?: string
  'pri.search.scroll_total'?: string
  'segments.count'?: string
  sc?: string
  segmentsCount?: string
  'pri.segments.count'?: string
  'segments.memory'?: string
  sm?: string
  segmentsMemory?: string
  'pri.segments.memory'?: string
  'segments.index_writer_memory'?: string
  siwm?: string
  segmentsIndexWriterMemory?: string
  'pri.segments.index_writer_memory'?: string
  'segments.version_map_memory'?: string
  svmm?: string
  segmentsVersionMapMemory?: string
  'pri.segments.version_map_memory'?: string
  'segments.fixed_bitset_memory'?: string
  sfbm?: string
  fixedBitsetMemory?: string
  'pri.segments.fixed_bitset_memory'?: string
  'warmer.current'?: string
  wc?: string
  warmerCurrent?: string
  'pri.warmer.current'?: string
  'warmer.total'?: string
  wto?: string
  warmerTotal?: string
  'pri.warmer.total'?: string
  'warmer.total_time'?: string
  wtt?: string
  warmerTotalTime?: string
  'pri.warmer.total_time'?: string
  'suggest.current'?: string
  suc?: string
  suggestCurrent?: string
  'pri.suggest.current'?: string
  'suggest.time'?: string
  suti?: string
  suggestTime?: string
  'pri.suggest.time'?: string
  'suggest.total'?: string
  suto?: string
  suggestTotal?: string
  'pri.suggest.total'?: string
  'memory.total'?: string
  tm?: string
  memoryTotal?: string
  'pri.memory.total'?: string
  'search.throttled'?: string
  sth?: string
  'bulk.total_operations'?: string
  bto?: string
  bulkTotalOperation?: string
  'pri.bulk.total_operations'?: string
  'bulk.total_time'?: string
  btti?: string
  bulkTotalTime?: string
  'pri.bulk.total_time'?: string
  'bulk.total_size_in_bytes'?: string
  btsi?: string
  bulkTotalSizeInBytes?: string
  'pri.bulk.total_size_in_bytes'?: string
  'bulk.avg_time'?: string
  bati?: string
  bulkAvgTime?: string
  'pri.bulk.avg_time'?: string
  'bulk.avg_size_in_bytes'?: string
  basi?: string
  bulkAvgSizeInBytes?: string
  'pri.bulk.avg_size_in_bytes'?: string
}

export interface CatIndicesRequest extends CatCatRequestBase {
/** Comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** The unit used to display byte values. */
  bytes?: Bytes
  /** The type of index that wildcard patterns can match. */
  expand_wildcards?: ExpandWildcards
  /** The health status used to limit returned indices. By default, the response includes indices of any health status. */
  health?: HealthStatus
  /** If true, the response includes information from segments that are not loaded into memory. */
  include_unloaded_segments?: boolean
  /** If true, the response only includes information from primary shards. */
  pri?: boolean
  /** The unit used to display time values. */
  time?: TimeUnit
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, bytes?: never, expand_wildcards?: never, health?: never, include_unloaded_segments?: never, pri?: never, time?: never, master_timeout?: never, h?: never, s?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, bytes?: never, expand_wildcards?: never, health?: never, include_unloaded_segments?: never, pri?: never, time?: never, master_timeout?: never, h?: never, s?: never }
}

export type CatIndicesResponse = CatIndicesIndicesRecord[]

export interface CatMasterMasterRecord {
  id?: string
  host?: string
  h?: string
  ip?: string
  node?: string
  n?: string
}

export interface CatMasterRequest extends CatCatRequestBase {
/** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** If `true`, the request computes the list of selected nodes from the local cluster state. If `false` the list of selected nodes are computed from the cluster state of the master node. In both cases the coordinating node will send requests for further information to each selected node. */
  local?: boolean
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { h?: never, s?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { h?: never, s?: never, local?: never, master_timeout?: never }
}

export type CatMasterResponse = CatMasterMasterRecord[]

export interface CatMlDataFrameAnalyticsDataFrameAnalyticsRecord {
  id?: Id
  type?: string
  t?: string
  create_time?: string
  ct?: string
  createTime?: string
  version?: VersionString
  v?: VersionString
  source_index?: IndexName
  si?: IndexName
  sourceIndex?: IndexName
  dest_index?: IndexName
  di?: IndexName
  destIndex?: IndexName
  description?: string
  d?: string
  model_memory_limit?: string
  mml?: string
  modelMemoryLimit?: string
  state?: string
  s?: string
  failure_reason?: string
  fr?: string
  failureReason?: string
  progress?: string
  p?: string
  assignment_explanation?: string
  ae?: string
  assignmentExplanation?: string
  'node.id'?: Id
  ni?: Id
  nodeId?: Id
  'node.name'?: Name
  nn?: Name
  nodeName?: Name
  'node.ephemeral_id'?: Id
  ne?: Id
  nodeEphemeralId?: Id
  'node.address'?: string
  na?: string
  nodeAddress?: string
}

export interface CatMlDataFrameAnalyticsRequest extends CatCatRequestBase {
/** The ID of the data frame analytics to fetch */
  id?: Id
  /** Whether to ignore if a wildcard expression matches no configs. (This includes `_all` string or when no configs have been specified) */
  allow_no_match?: boolean
  /** The unit in which to display byte values */
  bytes?: Bytes
  /** Comma-separated list of column names to display. */
  h?: CatCatDfaColumns
  /** Comma-separated list of column names or column aliases used to sort the response. */
  s?: CatCatDfaColumns
  /** Unit used to display time values. */
  time?: TimeUnit
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, allow_no_match?: never, bytes?: never, h?: never, s?: never, time?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, allow_no_match?: never, bytes?: never, h?: never, s?: never, time?: never }
}

export type CatMlDataFrameAnalyticsResponse = CatMlDataFrameAnalyticsDataFrameAnalyticsRecord[]

export interface CatMlDatafeedsDatafeedsRecord {
  id?: string
  state?: MlDatafeedState
  s?: MlDatafeedState
  assignment_explanation?: string
  ae?: string
  'buckets.count'?: string
  bc?: string
  bucketsCount?: string
  'search.count'?: string
  sc?: string
  searchCount?: string
  'search.time'?: string
  st?: string
  searchTime?: string
  'search.bucket_avg'?: string
  sba?: string
  searchBucketAvg?: string
  'search.exp_avg_hour'?: string
  seah?: string
  searchExpAvgHour?: string
  'node.id'?: string
  ni?: string
  nodeId?: string
  'node.name'?: string
  nn?: string
  nodeName?: string
  'node.ephemeral_id'?: string
  ne?: string
  nodeEphemeralId?: string
  'node.address'?: string
  na?: string
  nodeAddress?: string
}

export interface CatMlDatafeedsRequest extends CatCatRequestBase {
/** A numerical character string that uniquely identifies the datafeed. */
  datafeed_id?: Id
  /** Specifies what to do when the request: * Contains wildcard expressions and there are no datafeeds that match. * Contains the `_all` string or no identifiers and there are no matches. * Contains wildcard expressions and there are only partial matches. If `true`, the API returns an empty datafeeds array when there are no matches and the subset of results when there are partial matches. If `false`, the API returns a 404 status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** Comma-separated list of column names to display. */
  h?: CatCatDatafeedColumns
  /** Comma-separated list of column names or column aliases used to sort the response. */
  s?: CatCatDatafeedColumns
  /** The unit used to display time values. */
  time?: TimeUnit
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { datafeed_id?: never, allow_no_match?: never, h?: never, s?: never, time?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { datafeed_id?: never, allow_no_match?: never, h?: never, s?: never, time?: never }
}

export type CatMlDatafeedsResponse = CatMlDatafeedsDatafeedsRecord[]

export interface CatMlJobsJobsRecord {
  id?: Id
  state?: MlJobState
  s?: MlJobState
  opened_time?: string
  ot?: string
  assignment_explanation?: string
  ae?: string
  'data.processed_records'?: string
  dpr?: string
  dataProcessedRecords?: string
  'data.processed_fields'?: string
  dpf?: string
  dataProcessedFields?: string
  'data.input_bytes'?: ByteSize
  dib?: ByteSize
  dataInputBytes?: ByteSize
  'data.input_records'?: string
  dir?: string
  dataInputRecords?: string
  'data.input_fields'?: string
  dif?: string
  dataInputFields?: string
  'data.invalid_dates'?: string
  did?: string
  dataInvalidDates?: string
  'data.missing_fields'?: string
  dmf?: string
  dataMissingFields?: string
  'data.out_of_order_timestamps'?: string
  doot?: string
  dataOutOfOrderTimestamps?: string
  'data.empty_buckets'?: string
  deb?: string
  dataEmptyBuckets?: string
  'data.sparse_buckets'?: string
  dsb?: string
  dataSparseBuckets?: string
  'data.buckets'?: string
  db?: string
  dataBuckets?: string
  'data.earliest_record'?: string
  der?: string
  dataEarliestRecord?: string
  'data.latest_record'?: string
  dlr?: string
  dataLatestRecord?: string
  'data.last'?: string
  dl?: string
  dataLast?: string
  'data.last_empty_bucket'?: string
  dleb?: string
  dataLastEmptyBucket?: string
  'data.last_sparse_bucket'?: string
  dlsb?: string
  dataLastSparseBucket?: string
  'model.bytes'?: ByteSize
  mb?: ByteSize
  modelBytes?: ByteSize
  'model.memory_status'?: MlMemoryStatus
  mms?: MlMemoryStatus
  modelMemoryStatus?: MlMemoryStatus
  'model.bytes_exceeded'?: ByteSize
  mbe?: ByteSize
  modelBytesExceeded?: ByteSize
  'model.memory_limit'?: string
  mml?: string
  modelMemoryLimit?: string
  'model.by_fields'?: string
  mbf?: string
  modelByFields?: string
  'model.over_fields'?: string
  mof?: string
  modelOverFields?: string
  'model.partition_fields'?: string
  mpf?: string
  modelPartitionFields?: string
  'model.bucket_allocation_failures'?: string
  mbaf?: string
  modelBucketAllocationFailures?: string
  'model.categorization_status'?: MlCategorizationStatus
  mcs?: MlCategorizationStatus
  modelCategorizationStatus?: MlCategorizationStatus
  'model.categorized_doc_count'?: string
  mcdc?: string
  modelCategorizedDocCount?: string
  'model.total_category_count'?: string
  mtcc?: string
  modelTotalCategoryCount?: string
  'model.frequent_category_count'?: string
  modelFrequentCategoryCount?: string
  'model.rare_category_count'?: string
  mrcc?: string
  modelRareCategoryCount?: string
  'model.dead_category_count'?: string
  mdcc?: string
  modelDeadCategoryCount?: string
  'model.failed_category_count'?: string
  mfcc?: string
  modelFailedCategoryCount?: string
  'model.log_time'?: string
  mlt?: string
  modelLogTime?: string
  'model.timestamp'?: string
  mt?: string
  modelTimestamp?: string
  'forecasts.total'?: string
  ft?: string
  forecastsTotal?: string
  'forecasts.memory.min'?: string
  fmmin?: string
  forecastsMemoryMin?: string
  'forecasts.memory.max'?: string
  fmmax?: string
  forecastsMemoryMax?: string
  'forecasts.memory.avg'?: string
  fmavg?: string
  forecastsMemoryAvg?: string
  'forecasts.memory.total'?: string
  fmt?: string
  forecastsMemoryTotal?: string
  'forecasts.records.min'?: string
  frmin?: string
  forecastsRecordsMin?: string
  'forecasts.records.max'?: string
  frmax?: string
  forecastsRecordsMax?: string
  'forecasts.records.avg'?: string
  fravg?: string
  forecastsRecordsAvg?: string
  'forecasts.records.total'?: string
  frt?: string
  forecastsRecordsTotal?: string
  'forecasts.time.min'?: string
  ftmin?: string
  forecastsTimeMin?: string
  'forecasts.time.max'?: string
  ftmax?: string
  forecastsTimeMax?: string
  'forecasts.time.avg'?: string
  ftavg?: string
  forecastsTimeAvg?: string
  'forecasts.time.total'?: string
  ftt?: string
  forecastsTimeTotal?: string
  'node.id'?: NodeId
  ni?: NodeId
  nodeId?: NodeId
  'node.name'?: string
  nn?: string
  nodeName?: string
  'node.ephemeral_id'?: NodeId
  ne?: NodeId
  nodeEphemeralId?: NodeId
  'node.address'?: string
  na?: string
  nodeAddress?: string
  'buckets.count'?: string
  bc?: string
  bucketsCount?: string
  'buckets.time.total'?: string
  btt?: string
  bucketsTimeTotal?: string
  'buckets.time.min'?: string
  btmin?: string
  bucketsTimeMin?: string
  'buckets.time.max'?: string
  btmax?: string
  bucketsTimeMax?: string
  'buckets.time.exp_avg'?: string
  btea?: string
  bucketsTimeExpAvg?: string
  'buckets.time.exp_avg_hour'?: string
  bteah?: string
  bucketsTimeExpAvgHour?: string
}

export interface CatMlJobsRequest extends CatCatRequestBase {
/** Identifier for the anomaly detection job. */
  job_id?: Id
  /** Specifies what to do when the request: * Contains wildcard expressions and there are no jobs that match. * Contains the `_all` string or no identifiers and there are no matches. * Contains wildcard expressions and there are only partial matches. If `true`, the API returns an empty jobs array when there are no matches and the subset of results when there are partial matches. If `false`, the API returns a 404 status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** The unit used to display byte values. */
  bytes?: Bytes
  /** Comma-separated list of column names to display. */
  h?: CatCatAnonalyDetectorColumns
  /** Comma-separated list of column names or column aliases used to sort the response. */
  s?: CatCatAnonalyDetectorColumns
  /** The unit used to display time values. */
  time?: TimeUnit
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, allow_no_match?: never, bytes?: never, h?: never, s?: never, time?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, allow_no_match?: never, bytes?: never, h?: never, s?: never, time?: never }
}

export type CatMlJobsResponse = CatMlJobsJobsRecord[]

export interface CatMlTrainedModelsRequest extends CatCatRequestBase {
/** A unique identifier for the trained model. */
  model_id?: Id
  /** Specifies what to do when the request: contains wildcard expressions and there are no models that match; contains the `_all` string or no identifiers and there are no matches; contains wildcard expressions and there are only partial matches. If `true`, the API returns an empty array when there are no matches and the subset of results when there are partial matches. If `false`, the API returns a 404 status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** The unit used to display byte values. */
  bytes?: Bytes
  /** A comma-separated list of column names to display. */
  h?: CatCatTrainedModelsColumns
  /** A comma-separated list of column names or aliases used to sort the response. */
  s?: CatCatTrainedModelsColumns
  /** Skips the specified number of transforms. */
  from?: integer
  /** The maximum number of transforms to display. */
  size?: integer
  /** Unit used to display time values. */
  time?: TimeUnit
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_id?: never, allow_no_match?: never, bytes?: never, h?: never, s?: never, from?: never, size?: never, time?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_id?: never, allow_no_match?: never, bytes?: never, h?: never, s?: never, from?: never, size?: never, time?: never }
}

export type CatMlTrainedModelsResponse = CatMlTrainedModelsTrainedModelsRecord[]

export interface CatMlTrainedModelsTrainedModelsRecord {
  id?: Id
  created_by?: string
  c?: string
  createdBy?: string
  heap_size?: ByteSize
  hs?: ByteSize
  modelHeapSize?: ByteSize
  operations?: string
  o?: string
  modelOperations?: string
  license?: string
  l?: string
  create_time?: DateTime
  ct?: DateTime
  version?: VersionString
  v?: VersionString
  description?: string
  d?: string
  'ingest.pipelines'?: string
  ip?: string
  ingestPipelines?: string
  'ingest.count'?: string
  ic?: string
  ingestCount?: string
  'ingest.time'?: string
  it?: string
  ingestTime?: string
  'ingest.current'?: string
  icurr?: string
  ingestCurrent?: string
  'ingest.failed'?: string
  if?: string
  ingestFailed?: string
  'data_frame.id'?: string
  dfid?: string
  dataFrameAnalytics?: string
  'data_frame.create_time'?: string
  dft?: string
  dataFrameAnalyticsTime?: string
  'data_frame.source_index'?: string
  dfsi?: string
  dataFrameAnalyticsSrcIndex?: string
  'data_frame.analysis'?: string
  dfa?: string
  dataFrameAnalyticsAnalysis?: string
  type?: string
}

export interface CatNodeattrsNodeAttributesRecord {
  node?: string
  id?: string
  pid?: string
  host?: string
  h?: string
  ip?: string
  i?: string
  port?: string
  attr?: string
  value?: string
}

export interface CatNodeattrsRequest extends CatCatRequestBase {
/** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** If `true`, the request computes the list of selected nodes from the local cluster state. If `false` the list of selected nodes are computed from the cluster state of the master node. In both cases the coordinating node will send requests for further information to each selected node. */
  local?: boolean
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { h?: never, s?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { h?: never, s?: never, local?: never, master_timeout?: never }
}

export type CatNodeattrsResponse = CatNodeattrsNodeAttributesRecord[]

export interface CatNodesNodesRecord {
  id?: Id
  nodeId?: Id
  pid?: string
  p?: string
  ip?: string
  i?: string
  port?: string
  po?: string
  http_address?: string
  http?: string
  version?: VersionString
  v?: VersionString
  flavor?: string
  f?: string
  type?: string
  t?: string
  build?: string
  b?: string
  jdk?: string
  j?: string
  'disk.total'?: ByteSize
  dt?: ByteSize
  diskTotal?: ByteSize
  'disk.used'?: ByteSize
  du?: ByteSize
  diskUsed?: ByteSize
  'disk.avail'?: ByteSize
  d?: ByteSize
  da?: ByteSize
  disk?: ByteSize
  diskAvail?: ByteSize
  'disk.used_percent'?: Percentage
  dup?: Percentage
  diskUsedPercent?: Percentage
  'heap.current'?: string
  hc?: string
  heapCurrent?: string
  'heap.percent'?: Percentage
  hp?: Percentage
  heapPercent?: Percentage
  'heap.max'?: string
  hm?: string
  heapMax?: string
  'ram.current'?: string
  rc?: string
  ramCurrent?: string
  'ram.percent'?: Percentage
  rp?: Percentage
  ramPercent?: Percentage
  'ram.max'?: string
  rn?: string
  ramMax?: string
  'file_desc.current'?: string
  fdc?: string
  fileDescriptorCurrent?: string
  'file_desc.percent'?: Percentage
  fdp?: Percentage
  fileDescriptorPercent?: Percentage
  'file_desc.max'?: string
  fdm?: string
  fileDescriptorMax?: string
  cpu?: string
  load_1m?: string
  load_5m?: string
  load_15m?: string
  l?: string
  uptime?: string
  u?: string
  'node.role'?: string
  r?: string
  role?: string
  nodeRole?: string
  master?: string
  m?: string
  name?: Name
  n?: Name
  'completion.size'?: string
  cs?: string
  completionSize?: string
  'fielddata.memory_size'?: string
  fm?: string
  fielddataMemory?: string
  'fielddata.evictions'?: string
  fe?: string
  fielddataEvictions?: string
  'query_cache.memory_size'?: string
  qcm?: string
  queryCacheMemory?: string
  'query_cache.evictions'?: string
  qce?: string
  queryCacheEvictions?: string
  'query_cache.hit_count'?: string
  qchc?: string
  queryCacheHitCount?: string
  'query_cache.miss_count'?: string
  qcmc?: string
  queryCacheMissCount?: string
  'request_cache.memory_size'?: string
  rcm?: string
  requestCacheMemory?: string
  'request_cache.evictions'?: string
  rce?: string
  requestCacheEvictions?: string
  'request_cache.hit_count'?: string
  rchc?: string
  requestCacheHitCount?: string
  'request_cache.miss_count'?: string
  rcmc?: string
  requestCacheMissCount?: string
  'flush.total'?: string
  ft?: string
  flushTotal?: string
  'flush.total_time'?: string
  ftt?: string
  flushTotalTime?: string
  'get.current'?: string
  gc?: string
  getCurrent?: string
  'get.time'?: string
  gti?: string
  getTime?: string
  'get.total'?: string
  gto?: string
  getTotal?: string
  'get.exists_time'?: string
  geti?: string
  getExistsTime?: string
  'get.exists_total'?: string
  geto?: string
  getExistsTotal?: string
  'get.missing_time'?: string
  gmti?: string
  getMissingTime?: string
  'get.missing_total'?: string
  gmto?: string
  getMissingTotal?: string
  'indexing.delete_current'?: string
  idc?: string
  indexingDeleteCurrent?: string
  'indexing.delete_time'?: string
  idti?: string
  indexingDeleteTime?: string
  'indexing.delete_total'?: string
  idto?: string
  indexingDeleteTotal?: string
  'indexing.index_current'?: string
  iic?: string
  indexingIndexCurrent?: string
  'indexing.index_time'?: string
  iiti?: string
  indexingIndexTime?: string
  'indexing.index_total'?: string
  iito?: string
  indexingIndexTotal?: string
  'indexing.index_failed'?: string
  iif?: string
  indexingIndexFailed?: string
  'merges.current'?: string
  mc?: string
  mergesCurrent?: string
  'merges.current_docs'?: string
  mcd?: string
  mergesCurrentDocs?: string
  'merges.current_size'?: string
  mcs?: string
  mergesCurrentSize?: string
  'merges.total'?: string
  mt?: string
  mergesTotal?: string
  'merges.total_docs'?: string
  mtd?: string
  mergesTotalDocs?: string
  'merges.total_size'?: string
  mts?: string
  mergesTotalSize?: string
  'merges.total_time'?: string
  mtt?: string
  mergesTotalTime?: string
  'refresh.total'?: string
  'refresh.time'?: string
  'refresh.external_total'?: string
  rto?: string
  refreshTotal?: string
  'refresh.external_time'?: string
  rti?: string
  refreshTime?: string
  'refresh.listeners'?: string
  rli?: string
  refreshListeners?: string
  'script.compilations'?: string
  scrcc?: string
  scriptCompilations?: string
  'script.cache_evictions'?: string
  scrce?: string
  scriptCacheEvictions?: string
  'script.compilation_limit_triggered'?: string
  scrclt?: string
  scriptCacheCompilationLimitTriggered?: string
  'search.fetch_current'?: string
  sfc?: string
  searchFetchCurrent?: string
  'search.fetch_time'?: string
  sfti?: string
  searchFetchTime?: string
  'search.fetch_total'?: string
  sfto?: string
  searchFetchTotal?: string
  'search.open_contexts'?: string
  so?: string
  searchOpenContexts?: string
  'search.query_current'?: string
  sqc?: string
  searchQueryCurrent?: string
  'search.query_time'?: string
  sqti?: string
  searchQueryTime?: string
  'search.query_total'?: string
  sqto?: string
  searchQueryTotal?: string
  'search.scroll_current'?: string
  scc?: string
  searchScrollCurrent?: string
  'search.scroll_time'?: string
  scti?: string
  searchScrollTime?: string
  'search.scroll_total'?: string
  scto?: string
  searchScrollTotal?: string
  'segments.count'?: string
  sc?: string
  segmentsCount?: string
  'segments.memory'?: string
  sm?: string
  segmentsMemory?: string
  'segments.index_writer_memory'?: string
  siwm?: string
  segmentsIndexWriterMemory?: string
  'segments.version_map_memory'?: string
  svmm?: string
  segmentsVersionMapMemory?: string
  'segments.fixed_bitset_memory'?: string
  sfbm?: string
  fixedBitsetMemory?: string
  'suggest.current'?: string
  suc?: string
  suggestCurrent?: string
  'suggest.time'?: string
  suti?: string
  suggestTime?: string
  'suggest.total'?: string
  suto?: string
  suggestTotal?: string
  'bulk.total_operations'?: string
  bto?: string
  bulkTotalOperations?: string
  'bulk.total_time'?: string
  btti?: string
  bulkTotalTime?: string
  'bulk.total_size_in_bytes'?: string
  btsi?: string
  bulkTotalSizeInBytes?: string
  'bulk.avg_time'?: string
  bati?: string
  bulkAvgTime?: string
  'bulk.avg_size_in_bytes'?: string
  basi?: string
  bulkAvgSizeInBytes?: string
}

export interface CatNodesRequest extends CatCatRequestBase {
/** The unit used to display byte values. */
  bytes?: Bytes
  /** If `true`, return the full node ID. If `false`, return the shortened node ID. */
  full_id?: boolean | string
  /** If true, the response includes information from segments that are not loaded into memory. */
  include_unloaded_segments?: boolean
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** Unit used to display time values. */
  time?: TimeUnit
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { bytes?: never, full_id?: never, include_unloaded_segments?: never, h?: never, s?: never, master_timeout?: never, time?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { bytes?: never, full_id?: never, include_unloaded_segments?: never, h?: never, s?: never, master_timeout?: never, time?: never }
}

export type CatNodesResponse = CatNodesNodesRecord[]

export interface CatPendingTasksPendingTasksRecord {
  insertOrder?: string
  o?: string
  timeInQueue?: string
  t?: string
  priority?: string
  p?: string
  source?: string
  s?: string
}

export interface CatPendingTasksRequest extends CatCatRequestBase {
/** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** If `true`, the request computes the list of selected nodes from the local cluster state. If `false` the list of selected nodes are computed from the cluster state of the master node. In both cases the coordinating node will send requests for further information to each selected node. */
  local?: boolean
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** Unit used to display time values. */
  time?: TimeUnit
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { h?: never, s?: never, local?: never, master_timeout?: never, time?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { h?: never, s?: never, local?: never, master_timeout?: never, time?: never }
}

export type CatPendingTasksResponse = CatPendingTasksPendingTasksRecord[]

export interface CatPluginsPluginsRecord {
  id?: NodeId
  name?: Name
  n?: Name
  component?: string
  c?: string
  version?: VersionString
  v?: VersionString
  description?: string
  d?: string
  type?: string
  t?: string
}

export interface CatPluginsRequest extends CatCatRequestBase {
/** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** Include bootstrap plugins in the response */
  include_bootstrap?: boolean
  /** If `true`, the request computes the list of selected nodes from the local cluster state. If `false` the list of selected nodes are computed from the cluster state of the master node. In both cases the coordinating node will send requests for further information to each selected node. */
  local?: boolean
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { h?: never, s?: never, include_bootstrap?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { h?: never, s?: never, include_bootstrap?: never, local?: never, master_timeout?: never }
}

export type CatPluginsResponse = CatPluginsPluginsRecord[]

export interface CatRecoveryRecoveryRecord {
  index?: IndexName
  i?: IndexName
  idx?: IndexName
  shard?: string
  s?: string
  sh?: string
  start_time?: DateTime
  start?: DateTime
  start_time_millis?: EpochTime<UnitMillis>
  start_millis?: EpochTime<UnitMillis>
  stop_time?: DateTime
  stop?: DateTime
  stop_time_millis?: EpochTime<UnitMillis>
  stop_millis?: EpochTime<UnitMillis>
  time?: Duration
  t?: Duration
  ti?: Duration
  type?: string
  ty?: string
  stage?: string
  st?: string
  source_host?: string
  shost?: string
  source_node?: string
  snode?: string
  target_host?: string
  thost?: string
  target_node?: string
  tnode?: string
  repository?: string
  rep?: string
  snapshot?: string
  snap?: string
  files?: string
  f?: string
  files_recovered?: string
  fr?: string
  files_percent?: Percentage
  fp?: Percentage
  files_total?: string
  tf?: string
  bytes?: string
  b?: string
  bytes_recovered?: string
  br?: string
  bytes_percent?: Percentage
  bp?: Percentage
  bytes_total?: string
  tb?: string
  translog_ops?: string
  to?: string
  translog_ops_recovered?: string
  tor?: string
  translog_ops_percent?: Percentage
  top?: Percentage
}

export interface CatRecoveryRequest extends CatCatRequestBase {
/** A comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `true`, the response only includes ongoing shard recoveries. */
  active_only?: boolean
  /** The unit used to display byte values. */
  bytes?: Bytes
  /** If `true`, the response includes detailed information about shard recoveries. */
  detailed?: boolean
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** Unit used to display time values. */
  time?: TimeUnit
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, active_only?: never, bytes?: never, detailed?: never, h?: never, s?: never, time?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, active_only?: never, bytes?: never, detailed?: never, h?: never, s?: never, time?: never }
}

export type CatRecoveryResponse = CatRecoveryRecoveryRecord[]

export interface CatRepositoriesRepositoriesRecord {
  id?: string
  repoId?: string
  type?: string
  t?: string
}

export interface CatRepositoriesRequest extends CatCatRequestBase {
/** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** If `true`, the request computes the list of selected nodes from the local cluster state. If `false` the list of selected nodes are computed from the cluster state of the master node. In both cases the coordinating node will send requests for further information to each selected node. */
  local?: boolean
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { h?: never, s?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { h?: never, s?: never, local?: never, master_timeout?: never }
}

export type CatRepositoriesResponse = CatRepositoriesRepositoriesRecord[]

export interface CatSegmentsRequest extends CatCatRequestBase {
/** A comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** The unit used to display byte values. */
  bytes?: Bytes
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** If `true`, the request computes the list of selected nodes from the local cluster state. If `false` the list of selected nodes are computed from the cluster state of the master node. In both cases the coordinating node will send requests for further information to each selected node. */
  local?: boolean
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, bytes?: never, h?: never, s?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, bytes?: never, h?: never, s?: never, local?: never, master_timeout?: never }
}

export type CatSegmentsResponse = CatSegmentsSegmentsRecord[]

export interface CatSegmentsSegmentsRecord {
  index?: IndexName
  i?: IndexName
  idx?: IndexName
  shard?: string
  s?: string
  sh?: string
  prirep?: string
  p?: string
  pr?: string
  primaryOrReplica?: string
  ip?: string
  id?: NodeId
  segment?: string
  seg?: string
  generation?: string
  g?: string
  gen?: string
  'docs.count'?: string
  dc?: string
  docsCount?: string
  'docs.deleted'?: string
  dd?: string
  docsDeleted?: string
  size?: ByteSize
  si?: ByteSize
  'size.memory'?: ByteSize
  sm?: ByteSize
  sizeMemory?: ByteSize
  committed?: string
  ic?: string
  isCommitted?: string
  searchable?: string
  is?: string
  isSearchable?: string
  version?: VersionString
  v?: VersionString
  compound?: string
  ico?: string
  isCompound?: string
}

export interface CatShardsRequest extends CatCatRequestBase {
/** A comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** The unit used to display byte values. */
  bytes?: Bytes
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** Unit used to display time values. */
  time?: TimeUnit
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, bytes?: never, h?: never, s?: never, master_timeout?: never, time?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, bytes?: never, h?: never, s?: never, master_timeout?: never, time?: never }
}

export type CatShardsResponse = CatShardsShardsRecord[]

export interface CatShardsShardsRecord {
  index?: string
  i?: string
  idx?: string
  shard?: string
  s?: string
  sh?: string
  prirep?: string
  p?: string
  pr?: string
  primaryOrReplica?: string
  state?: string
  st?: string
  docs?: string | null
  d?: string | null
  dc?: string | null
  store?: string | null
  sto?: string | null
  dataset?: string | null
  ip?: string | null
  id?: string
  node?: string | null
  n?: string | null
  sync_id?: string
  'unassigned.reason'?: string
  ur?: string
  'unassigned.at'?: string
  ua?: string
  'unassigned.for'?: string
  uf?: string
  'unassigned.details'?: string
  ud?: string
  'recoverysource.type'?: string
  rs?: string
  'completion.size'?: string
  cs?: string
  completionSize?: string
  'fielddata.memory_size'?: string
  fm?: string
  fielddataMemory?: string
  'fielddata.evictions'?: string
  fe?: string
  fielddataEvictions?: string
  'query_cache.memory_size'?: string
  qcm?: string
  queryCacheMemory?: string
  'query_cache.evictions'?: string
  qce?: string
  queryCacheEvictions?: string
  'flush.total'?: string
  ft?: string
  flushTotal?: string
  'flush.total_time'?: string
  ftt?: string
  flushTotalTime?: string
  'get.current'?: string
  gc?: string
  getCurrent?: string
  'get.time'?: string
  gti?: string
  getTime?: string
  'get.total'?: string
  gto?: string
  getTotal?: string
  'get.exists_time'?: string
  geti?: string
  getExistsTime?: string
  'get.exists_total'?: string
  geto?: string
  getExistsTotal?: string
  'get.missing_time'?: string
  gmti?: string
  getMissingTime?: string
  'get.missing_total'?: string
  gmto?: string
  getMissingTotal?: string
  'indexing.delete_current'?: string
  idc?: string
  indexingDeleteCurrent?: string
  'indexing.delete_time'?: string
  idti?: string
  indexingDeleteTime?: string
  'indexing.delete_total'?: string
  idto?: string
  indexingDeleteTotal?: string
  'indexing.index_current'?: string
  iic?: string
  indexingIndexCurrent?: string
  'indexing.index_time'?: string
  iiti?: string
  indexingIndexTime?: string
  'indexing.index_total'?: string
  iito?: string
  indexingIndexTotal?: string
  'indexing.index_failed'?: string
  iif?: string
  indexingIndexFailed?: string
  'merges.current'?: string
  mc?: string
  mergesCurrent?: string
  'merges.current_docs'?: string
  mcd?: string
  mergesCurrentDocs?: string
  'merges.current_size'?: string
  mcs?: string
  mergesCurrentSize?: string
  'merges.total'?: string
  mt?: string
  mergesTotal?: string
  'merges.total_docs'?: string
  mtd?: string
  mergesTotalDocs?: string
  'merges.total_size'?: string
  mts?: string
  mergesTotalSize?: string
  'merges.total_time'?: string
  mtt?: string
  mergesTotalTime?: string
  'refresh.total'?: string
  'refresh.time'?: string
  'refresh.external_total'?: string
  rto?: string
  refreshTotal?: string
  'refresh.external_time'?: string
  rti?: string
  refreshTime?: string
  'refresh.listeners'?: string
  rli?: string
  refreshListeners?: string
  'search.fetch_current'?: string
  sfc?: string
  searchFetchCurrent?: string
  'search.fetch_time'?: string
  sfti?: string
  searchFetchTime?: string
  'search.fetch_total'?: string
  sfto?: string
  searchFetchTotal?: string
  'search.open_contexts'?: string
  so?: string
  searchOpenContexts?: string
  'search.query_current'?: string
  sqc?: string
  searchQueryCurrent?: string
  'search.query_time'?: string
  sqti?: string
  searchQueryTime?: string
  'search.query_total'?: string
  sqto?: string
  searchQueryTotal?: string
  'search.scroll_current'?: string
  scc?: string
  searchScrollCurrent?: string
  'search.scroll_time'?: string
  scti?: string
  searchScrollTime?: string
  'search.scroll_total'?: string
  scto?: string
  searchScrollTotal?: string
  'segments.count'?: string
  sc?: string
  segmentsCount?: string
  'segments.memory'?: string
  sm?: string
  segmentsMemory?: string
  'segments.index_writer_memory'?: string
  siwm?: string
  segmentsIndexWriterMemory?: string
  'segments.version_map_memory'?: string
  svmm?: string
  segmentsVersionMapMemory?: string
  'segments.fixed_bitset_memory'?: string
  sfbm?: string
  fixedBitsetMemory?: string
  'seq_no.max'?: string
  sqm?: string
  maxSeqNo?: string
  'seq_no.local_checkpoint'?: string
  sql?: string
  localCheckpoint?: string
  'seq_no.global_checkpoint'?: string
  sqg?: string
  globalCheckpoint?: string
  'warmer.current'?: string
  wc?: string
  warmerCurrent?: string
  'warmer.total'?: string
  wto?: string
  warmerTotal?: string
  'warmer.total_time'?: string
  wtt?: string
  warmerTotalTime?: string
  'path.data'?: string
  pd?: string
  dataPath?: string
  'path.state'?: string
  ps?: string
  statsPath?: string
  'bulk.total_operations'?: string
  bto?: string
  bulkTotalOperations?: string
  'bulk.total_time'?: string
  btti?: string
  bulkTotalTime?: string
  'bulk.total_size_in_bytes'?: string
  btsi?: string
  bulkTotalSizeInBytes?: string
  'bulk.avg_time'?: string
  bati?: string
  bulkAvgTime?: string
  'bulk.avg_size_in_bytes'?: string
  basi?: string
  bulkAvgSizeInBytes?: string
}

export interface CatSnapshotsRequest extends CatCatRequestBase {
/** A comma-separated list of snapshot repositories used to limit the request. Accepts wildcard expressions. `_all` returns all repositories. If any repository fails during the request, Elasticsearch returns an error. */
  repository?: Names
  /** If `true`, the response does not include information from unavailable snapshots. */
  ignore_unavailable?: boolean
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** Unit used to display time values. */
  time?: TimeUnit
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { repository?: never, ignore_unavailable?: never, h?: never, s?: never, master_timeout?: never, time?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { repository?: never, ignore_unavailable?: never, h?: never, s?: never, master_timeout?: never, time?: never }
}

export type CatSnapshotsResponse = CatSnapshotsSnapshotsRecord[]

export interface CatSnapshotsSnapshotsRecord {
  id?: string
  snapshot?: string
  repository?: string
  re?: string
  repo?: string
  status?: string
  s?: string
  start_epoch?: SpecUtilsStringified<EpochTime<UnitSeconds>>
  ste?: SpecUtilsStringified<EpochTime<UnitSeconds>>
  startEpoch?: SpecUtilsStringified<EpochTime<UnitSeconds>>
  start_time?: WatcherScheduleTimeOfDay
  sti?: WatcherScheduleTimeOfDay
  startTime?: WatcherScheduleTimeOfDay
  end_epoch?: SpecUtilsStringified<EpochTime<UnitSeconds>>
  ete?: SpecUtilsStringified<EpochTime<UnitSeconds>>
  endEpoch?: SpecUtilsStringified<EpochTime<UnitSeconds>>
  end_time?: TimeOfDay
  eti?: TimeOfDay
  endTime?: TimeOfDay
  duration?: Duration
  dur?: Duration
  indices?: string
  i?: string
  successful_shards?: string
  ss?: string
  failed_shards?: string
  fs?: string
  total_shards?: string
  ts?: string
  reason?: string
  r?: string
}

export interface CatTasksRequest extends CatCatRequestBase {
/** The task action names, which are used to limit the response. */
  actions?: string[]
  /** If `true`, the response includes detailed information about shard recoveries. */
  detailed?: boolean
  /** Unique node identifiers, which are used to limit the response. */
  nodes?: string[]
  /** The parent task identifier, which is used to limit the response. */
  parent_task_id?: string
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** Unit used to display time values. */
  time?: TimeUnit
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** If `true`, the request blocks until the task has completed. */
  wait_for_completion?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { actions?: never, detailed?: never, nodes?: never, parent_task_id?: never, h?: never, s?: never, time?: never, timeout?: never, wait_for_completion?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { actions?: never, detailed?: never, nodes?: never, parent_task_id?: never, h?: never, s?: never, time?: never, timeout?: never, wait_for_completion?: never }
}

export type CatTasksResponse = CatTasksTasksRecord[]

export interface CatTasksTasksRecord {
  id?: Id
  action?: string
  ac?: string
  task_id?: Id
  ti?: Id
  parent_task_id?: string
  pti?: string
  type?: string
  ty?: string
  start_time?: string
  start?: string
  timestamp?: string
  ts?: string
  hms?: string
  hhmmss?: string
  running_time_ns?: string
  running_time?: string
  time?: string
  node_id?: NodeId
  ni?: NodeId
  ip?: string
  i?: string
  port?: string
  po?: string
  node?: string
  n?: string
  version?: VersionString
  v?: VersionString
  x_opaque_id?: string
  x?: string
  description?: string
  desc?: string
}

export interface CatTemplatesRequest extends CatCatRequestBase {
/** The name of the template to return. Accepts wildcard expressions. If omitted, all templates are returned. */
  name?: Name
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** If `true`, the request computes the list of selected nodes from the local cluster state. If `false` the list of selected nodes are computed from the cluster state of the master node. In both cases the coordinating node will send requests for further information to each selected node. */
  local?: boolean
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, h?: never, s?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, h?: never, s?: never, local?: never, master_timeout?: never }
}

export type CatTemplatesResponse = CatTemplatesTemplatesRecord[]

export interface CatTemplatesTemplatesRecord {
  name?: Name
  n?: Name
  index_patterns?: string
  t?: string
  order?: string
  o?: string
  p?: string
  version?: VersionString | null
  v?: VersionString | null
  composed_of?: string
  c?: string
}

export interface CatThreadPoolRequest extends CatCatRequestBase {
/** A comma-separated list of thread pool names used to limit the request. Accepts wildcard expressions. */
  thread_pool_patterns?: Names
  /** List of columns to appear in the response. Supports simple wildcards. */
  h?: Names
  /** List of columns that determine how the table should be sorted. Sorting defaults to ascending and can be changed by setting `:asc` or `:desc` as a suffix to the column name. */
  s?: Names
  /** The unit used to display time values. */
  time?: TimeUnit
  /** If `true`, the request computes the list of selected nodes from the local cluster state. If `false` the list of selected nodes are computed from the cluster state of the master node. In both cases the coordinating node will send requests for further information to each selected node. */
  local?: boolean
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { thread_pool_patterns?: never, h?: never, s?: never, time?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { thread_pool_patterns?: never, h?: never, s?: never, time?: never, local?: never, master_timeout?: never }
}

export type CatThreadPoolResponse = CatThreadPoolThreadPoolRecord[]

export interface CatThreadPoolThreadPoolRecord {
  node_name?: string
  nn?: string
  node_id?: NodeId
  id?: NodeId
  ephemeral_node_id?: string
  eid?: string
  pid?: string
  p?: string
  host?: string
  h?: string
  ip?: string
  i?: string
  port?: string
  po?: string
  name?: string
  n?: string
  type?: string
  t?: string
  active?: string
  a?: string
  pool_size?: string
  psz?: string
  queue?: string
  q?: string
  queue_size?: string
  qs?: string
  rejected?: string
  r?: string
  largest?: string
  l?: string
  completed?: string
  c?: string
  core?: string | null
  cr?: string | null
  max?: string | null
  mx?: string | null
  size?: string | null
  sz?: string | null
  keep_alive?: string | null
  ka?: string | null
}

export interface CatTransformsRequest extends CatCatRequestBase {
/** A transform identifier or a wildcard expression. If you do not specify one of these options, the API returns information for all transforms. */
  transform_id?: Id
  /** Specifies what to do when the request: contains wildcard expressions and there are no transforms that match; contains the `_all` string or no identifiers and there are no matches; contains wildcard expressions and there are only partial matches. If `true`, it returns an empty transforms array when there are no matches and the subset of results when there are partial matches. If `false`, the request returns a 404 status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** Skips the specified number of transforms. */
  from?: integer
  /** Comma-separated list of column names to display. */
  h?: CatCatTransformColumns
  /** Comma-separated list of column names or column aliases used to sort the response. */
  s?: CatCatTransformColumns
  /** The unit used to display time values. */
  time?: TimeUnit
  /** The maximum number of transforms to obtain. */
  size?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { transform_id?: never, allow_no_match?: never, from?: never, h?: never, s?: never, time?: never, size?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { transform_id?: never, allow_no_match?: never, from?: never, h?: never, s?: never, time?: never, size?: never }
}

export type CatTransformsResponse = CatTransformsTransformsRecord[]

export interface CatTransformsTransformsRecord {
  id?: Id
  state?: string
  s?: string
  checkpoint?: string
  c?: string
  documents_processed?: string
  docp?: string
  documentsProcessed?: string
  checkpoint_progress?: string | null
  cp?: string | null
  checkpointProgress?: string | null
  last_search_time?: string | null
  lst?: string | null
  lastSearchTime?: string | null
  changes_last_detection_time?: string | null
  cldt?: string | null
  create_time?: string
  ct?: string
  createTime?: string
  version?: VersionString
  v?: VersionString
  source_index?: string
  si?: string
  sourceIndex?: string
  dest_index?: string
  di?: string
  destIndex?: string
  pipeline?: string
  p?: string
  description?: string
  d?: string
  transform_type?: string
  tt?: string
  frequency?: string
  f?: string
  max_page_search_size?: string
  mpsz?: string
  docs_per_second?: string
  dps?: string
  reason?: string
  r?: string
  search_total?: string
  st?: string
  search_failure?: string
  sf?: string
  search_time?: string
  stime?: string
  index_total?: string
  it?: string
  index_failure?: string
  if?: string
  index_time?: string
  itime?: string
  documents_indexed?: string
  doci?: string
  delete_time?: string
  dtime?: string
  documents_deleted?: string
  docd?: string
  trigger_count?: string
  tc?: string
  pages_processed?: string
  pp?: string
  processing_time?: string
  pt?: string
  checkpoint_duration_time_exp_avg?: string
  cdtea?: string
  checkpointTimeExpAvg?: string
  indexed_documents_exp_avg?: string
  idea?: string
  processed_documents_exp_avg?: string
  pdea?: string
}

export interface CcrFollowIndexStats {
  index: IndexName
  shards: CcrShardStats[]
}

export interface CcrReadException {
  exception: ErrorCause
  from_seq_no: SequenceNumber
  retries: integer
}

export interface CcrShardStats {
  bytes_read: long
  failed_read_requests: long
  failed_write_requests: long
  fatal_exception?: ErrorCause
  follower_aliases_version: VersionNumber
  follower_global_checkpoint: long
  follower_index: string
  follower_mapping_version: VersionNumber
  follower_max_seq_no: SequenceNumber
  follower_settings_version: VersionNumber
  last_requested_seq_no: SequenceNumber
  leader_global_checkpoint: long
  leader_index: string
  leader_max_seq_no: SequenceNumber
  operations_read: long
  operations_written: long
  outstanding_read_requests: integer
  outstanding_write_requests: integer
  read_exceptions: CcrReadException[]
  remote_cluster: string
  shard_id: integer
  successful_read_requests: long
  successful_write_requests: long
  time_since_last_read?: Duration
  time_since_last_read_millis: DurationValue<UnitMillis>
  total_read_remote_exec_time?: Duration
  total_read_remote_exec_time_millis: DurationValue<UnitMillis>
  total_read_time?: Duration
  total_read_time_millis: DurationValue<UnitMillis>
  total_write_time?: Duration
  total_write_time_millis: DurationValue<UnitMillis>
  write_buffer_operation_count: long
  write_buffer_size_in_bytes: ByteSize
}

export interface CcrDeleteAutoFollowPatternRequest extends RequestBase {
/** The auto-follow pattern collection to delete. */
  name: Name
  /** The period to wait for a connection to the master node. If the master node is not available before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never }
}

export type CcrDeleteAutoFollowPatternResponse = AcknowledgedResponseBase

export interface CcrFollowRequest extends RequestBase {
/** The name of the follower index. */
  index: IndexName
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** Specifies the number of shards to wait on being active before responding. This defaults to waiting on none of the shards to be active. A shard must be restored from the leader index before being active. Restoring a follower shard requires transferring all the remote Lucene segment files to the follower index. */
  wait_for_active_shards?: WaitForActiveShards
  /** If the leader index is part of a data stream, the name to which the local data stream for the followed index should be renamed. */
  data_stream_name?: string
  /** The name of the index in the leader cluster to follow. */
  leader_index: IndexName
  /** The maximum number of outstanding reads requests from the remote cluster. */
  max_outstanding_read_requests?: long
  /** The maximum number of outstanding write requests on the follower. */
  max_outstanding_write_requests?: integer
  /** The maximum number of operations to pull per read from the remote cluster. */
  max_read_request_operation_count?: integer
  /** The maximum size in bytes of per read of a batch of operations pulled from the remote cluster. */
  max_read_request_size?: ByteSize
  /** The maximum time to wait before retrying an operation that failed exceptionally. An exponential backoff strategy is employed when retrying. */
  max_retry_delay?: Duration
  /** The maximum number of operations that can be queued for writing. When this limit is reached, reads from the remote cluster will be deferred until the number of queued operations goes below the limit. */
  max_write_buffer_count?: integer
  /** The maximum total bytes of operations that can be queued for writing. When this limit is reached, reads from the remote cluster will be deferred until the total bytes of queued operations goes below the limit. */
  max_write_buffer_size?: ByteSize
  /** The maximum number of operations per bulk write request executed on the follower. */
  max_write_request_operation_count?: integer
  /** The maximum total bytes of operations per bulk write request executed on the follower. */
  max_write_request_size?: ByteSize
  /** The maximum time to wait for new operations on the remote cluster when the follower index is synchronized with the leader index. When the timeout has elapsed, the poll for operations will return to the follower so that it can update some statistics. Then the follower will immediately attempt to read from the leader again. */
  read_poll_timeout?: Duration
  /** The remote cluster containing the leader index. */
  remote_cluster: string
  /** Settings to override from the leader index. */
  settings?: IndicesIndexSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, master_timeout?: never, wait_for_active_shards?: never, data_stream_name?: never, leader_index?: never, max_outstanding_read_requests?: never, max_outstanding_write_requests?: never, max_read_request_operation_count?: never, max_read_request_size?: never, max_retry_delay?: never, max_write_buffer_count?: never, max_write_buffer_size?: never, max_write_request_operation_count?: never, max_write_request_size?: never, read_poll_timeout?: never, remote_cluster?: never, settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, master_timeout?: never, wait_for_active_shards?: never, data_stream_name?: never, leader_index?: never, max_outstanding_read_requests?: never, max_outstanding_write_requests?: never, max_read_request_operation_count?: never, max_read_request_size?: never, max_retry_delay?: never, max_write_buffer_count?: never, max_write_buffer_size?: never, max_write_request_operation_count?: never, max_write_request_size?: never, read_poll_timeout?: never, remote_cluster?: never, settings?: never }
}

export interface CcrFollowResponse {
  follow_index_created: boolean
  follow_index_shards_acked: boolean
  index_following_started: boolean
}

export interface CcrFollowInfoFollowerIndex {
  follower_index: IndexName
  leader_index: IndexName
  parameters?: CcrFollowInfoFollowerIndexParameters
  remote_cluster: Name
  status: CcrFollowInfoFollowerIndexStatus
}

export interface CcrFollowInfoFollowerIndexParameters {
  max_outstanding_read_requests?: long
  max_outstanding_write_requests?: integer
  max_read_request_operation_count?: integer
  max_read_request_size?: ByteSize
  max_retry_delay?: Duration
  max_write_buffer_count?: integer
  max_write_buffer_size?: ByteSize
  max_write_request_operation_count?: integer
  max_write_request_size?: ByteSize
  read_poll_timeout?: Duration
}

export type CcrFollowInfoFollowerIndexStatus = 'active' | 'paused'

export interface CcrFollowInfoRequest extends RequestBase {
/** A comma-delimited list of follower index patterns. */
  index: Indices
  /** The period to wait for a connection to the master node. If the master node is not available before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, master_timeout?: never }
}

export interface CcrFollowInfoResponse {
  follower_indices: CcrFollowInfoFollowerIndex[]
}

export interface CcrFollowStatsRequest extends RequestBase {
/** A comma-delimited list of index patterns. */
  index: Indices
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, timeout?: never }
}

export interface CcrFollowStatsResponse {
  indices: CcrFollowIndexStats[]
}

export interface CcrForgetFollowerRequest extends RequestBase {
/** the name of the leader index for which specified follower retention leases should be removed */
  index: IndexName
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  follower_cluster?: string
  follower_index?: IndexName
  follower_index_uuid?: Uuid
  leader_remote_cluster?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, timeout?: never, follower_cluster?: never, follower_index?: never, follower_index_uuid?: never, leader_remote_cluster?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, timeout?: never, follower_cluster?: never, follower_index?: never, follower_index_uuid?: never, leader_remote_cluster?: never }
}

export interface CcrForgetFollowerResponse {
  _shards: ShardStatistics
}

export interface CcrGetAutoFollowPatternAutoFollowPattern {
  name: Name
  pattern: CcrGetAutoFollowPatternAutoFollowPatternSummary
}

export interface CcrGetAutoFollowPatternAutoFollowPatternSummary {
  active: boolean
  remote_cluster: string
  follow_index_pattern?: IndexPattern
  leader_index_patterns: IndexPatterns
  leader_index_exclusion_patterns: IndexPatterns
  max_outstanding_read_requests: integer
}

export interface CcrGetAutoFollowPatternRequest extends RequestBase {
/** The auto-follow pattern collection that you want to retrieve. If you do not specify a name, the API returns information for all collections. */
  name?: Name
  /** The period to wait for a connection to the master node. If the master node is not available before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never }
}

export interface CcrGetAutoFollowPatternResponse {
  patterns: CcrGetAutoFollowPatternAutoFollowPattern[]
}

export interface CcrPauseAutoFollowPatternRequest extends RequestBase {
/** The name of the auto-follow pattern to pause. */
  name: Name
  /** The period to wait for a connection to the master node. If the master node is not available before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never }
}

export type CcrPauseAutoFollowPatternResponse = AcknowledgedResponseBase

export interface CcrPauseFollowRequest extends RequestBase {
/** The name of the follower index. */
  index: IndexName
  /** The period to wait for a connection to the master node. If the master node is not available before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, master_timeout?: never }
}

export type CcrPauseFollowResponse = AcknowledgedResponseBase

export interface CcrPutAutoFollowPatternRequest extends RequestBase {
/** The name of the collection of auto-follow patterns. */
  name: Name
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** The remote cluster containing the leader indices to match against. */
  remote_cluster: string
  /** The name of follower index. The template {{leader_index}} can be used to derive the name of the follower index from the name of the leader index. When following a data stream, use {{leader_index}}; CCR does not support changes to the names of a follower data stream’s backing indices. */
  follow_index_pattern?: IndexPattern
  /** An array of simple index patterns to match against indices in the remote cluster specified by the remote_cluster field. */
  leader_index_patterns?: IndexPatterns
  /** An array of simple index patterns that can be used to exclude indices from being auto-followed. Indices in the remote cluster whose names are matching one or more leader_index_patterns and one or more leader_index_exclusion_patterns won’t be followed. */
  leader_index_exclusion_patterns?: IndexPatterns
  /** The maximum number of outstanding reads requests from the remote cluster. */
  max_outstanding_read_requests?: integer
  /** Settings to override from the leader index. Note that certain settings can not be overrode (e.g., index.number_of_shards). */
  settings?: Record<string, any>
  /** The maximum number of outstanding reads requests from the remote cluster. */
  max_outstanding_write_requests?: integer
  /** The maximum time to wait for new operations on the remote cluster when the follower index is synchronized with the leader index. When the timeout has elapsed, the poll for operations will return to the follower so that it can update some statistics. Then the follower will immediately attempt to read from the leader again. */
  read_poll_timeout?: Duration
  /** The maximum number of operations to pull per read from the remote cluster. */
  max_read_request_operation_count?: integer
  /** The maximum size in bytes of per read of a batch of operations pulled from the remote cluster. */
  max_read_request_size?: ByteSize
  /** The maximum time to wait before retrying an operation that failed exceptionally. An exponential backoff strategy is employed when retrying. */
  max_retry_delay?: Duration
  /** The maximum number of operations that can be queued for writing. When this limit is reached, reads from the remote cluster will be deferred until the number of queued operations goes below the limit. */
  max_write_buffer_count?: integer
  /** The maximum total bytes of operations that can be queued for writing. When this limit is reached, reads from the remote cluster will be deferred until the total bytes of queued operations goes below the limit. */
  max_write_buffer_size?: ByteSize
  /** The maximum number of operations per bulk write request executed on the follower. */
  max_write_request_operation_count?: integer
  /** The maximum total bytes of operations per bulk write request executed on the follower. */
  max_write_request_size?: ByteSize
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, remote_cluster?: never, follow_index_pattern?: never, leader_index_patterns?: never, leader_index_exclusion_patterns?: never, max_outstanding_read_requests?: never, settings?: never, max_outstanding_write_requests?: never, read_poll_timeout?: never, max_read_request_operation_count?: never, max_read_request_size?: never, max_retry_delay?: never, max_write_buffer_count?: never, max_write_buffer_size?: never, max_write_request_operation_count?: never, max_write_request_size?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, remote_cluster?: never, follow_index_pattern?: never, leader_index_patterns?: never, leader_index_exclusion_patterns?: never, max_outstanding_read_requests?: never, settings?: never, max_outstanding_write_requests?: never, read_poll_timeout?: never, max_read_request_operation_count?: never, max_read_request_size?: never, max_retry_delay?: never, max_write_buffer_count?: never, max_write_buffer_size?: never, max_write_request_operation_count?: never, max_write_request_size?: never }
}

export type CcrPutAutoFollowPatternResponse = AcknowledgedResponseBase

export interface CcrResumeAutoFollowPatternRequest extends RequestBase {
/** The name of the auto-follow pattern to resume. */
  name: Name
  /** The period to wait for a connection to the master node. If the master node is not available before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never }
}

export type CcrResumeAutoFollowPatternResponse = AcknowledgedResponseBase

export interface CcrResumeFollowRequest extends RequestBase {
/** The name of the follow index to resume following. */
  index: IndexName
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  max_outstanding_read_requests?: long
  max_outstanding_write_requests?: long
  max_read_request_operation_count?: long
  max_read_request_size?: string
  max_retry_delay?: Duration
  max_write_buffer_count?: long
  max_write_buffer_size?: string
  max_write_request_operation_count?: long
  max_write_request_size?: string
  read_poll_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, master_timeout?: never, max_outstanding_read_requests?: never, max_outstanding_write_requests?: never, max_read_request_operation_count?: never, max_read_request_size?: never, max_retry_delay?: never, max_write_buffer_count?: never, max_write_buffer_size?: never, max_write_request_operation_count?: never, max_write_request_size?: never, read_poll_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, master_timeout?: never, max_outstanding_read_requests?: never, max_outstanding_write_requests?: never, max_read_request_operation_count?: never, max_read_request_size?: never, max_retry_delay?: never, max_write_buffer_count?: never, max_write_buffer_size?: never, max_write_request_operation_count?: never, max_write_request_size?: never, read_poll_timeout?: never }
}

export type CcrResumeFollowResponse = AcknowledgedResponseBase

export interface CcrStatsAutoFollowStats {
  auto_followed_clusters: CcrStatsAutoFollowedCluster[]
  number_of_failed_follow_indices: long
  number_of_failed_remote_cluster_state_requests: long
  number_of_successful_follow_indices: long
  recent_auto_follow_errors: ErrorCause[]
}

export interface CcrStatsAutoFollowedCluster {
  cluster_name: Name
  last_seen_metadata_version: VersionNumber
  time_since_last_check_millis: DurationValue<UnitMillis>
}

export interface CcrStatsFollowStats {
  indices: CcrFollowIndexStats[]
}

export interface CcrStatsRequest extends RequestBase {
/** The period to wait for a connection to the master node. If the master node is not available before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never, timeout?: never }
}

export interface CcrStatsResponse {
  auto_follow_stats: CcrStatsAutoFollowStats
  follow_stats: CcrStatsFollowStats
}

export interface CcrUnfollowRequest extends RequestBase {
/** The name of the follower index. */
  index: IndexName
  /** The period to wait for a connection to the master node. If the master node is not available before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, master_timeout?: never }
}

export type CcrUnfollowResponse = AcknowledgedResponseBase

export interface ClusterComponentTemplate {
  name: Name
  component_template: ClusterComponentTemplateNode
}

export interface ClusterComponentTemplateNode {
  template: ClusterComponentTemplateSummary
  version?: VersionNumber
  _meta?: Metadata
  deprecated?: boolean
}

export interface ClusterComponentTemplateSummary {
  _meta?: Metadata
  version?: VersionNumber
  settings?: Record<IndexName, IndicesIndexSettings>
  mappings?: MappingTypeMapping
  aliases?: Record<string, IndicesAliasDefinition>
  lifecycle?: IndicesDataStreamLifecycleWithRollover
}

export interface ClusterAllocationExplainAllocationDecision {
  decider: string
  decision: ClusterAllocationExplainAllocationExplainDecision
  explanation: string
}

export type ClusterAllocationExplainAllocationExplainDecision = 'NO' | 'YES' | 'THROTTLE' | 'ALWAYS'

export interface ClusterAllocationExplainAllocationStore {
  allocation_id: string
  found: boolean
  in_sync: boolean
  matching_size_in_bytes: long
  matching_sync_id: boolean
  store_exception: string
}

export interface ClusterAllocationExplainClusterInfo {
  nodes: Record<string, ClusterAllocationExplainNodeDiskUsage>
  shard_sizes: Record<string, long>
  shard_data_set_sizes?: Record<string, string>
  shard_paths: Record<string, string>
  reserved_sizes: ClusterAllocationExplainReservedSize[]
}

export interface ClusterAllocationExplainCurrentNode {
  id: Id
  name: Name
  roles: NodeRoles
  attributes: Record<string, string>
  transport_address: TransportAddress
  weight_ranking: integer
}

export type ClusterAllocationExplainDecision = 'yes' | 'no' | 'worse_balance' | 'throttled' | 'awaiting_info' | 'allocation_delayed' | 'no_valid_shard_copy' | 'no_attempt'

export interface ClusterAllocationExplainDiskUsage {
  path: string
  total_bytes: long
  used_bytes: long
  free_bytes: long
  free_disk_percent: double
  used_disk_percent: double
}

export interface ClusterAllocationExplainNodeAllocationExplanation {
  deciders: ClusterAllocationExplainAllocationDecision[]
  node_attributes: Record<string, string>
  node_decision: ClusterAllocationExplainDecision
  node_id: Id
  node_name: Name
  roles: NodeRoles
  store?: ClusterAllocationExplainAllocationStore
  transport_address: TransportAddress
  weight_ranking: integer
}

export interface ClusterAllocationExplainNodeDiskUsage {
  node_name: Name
  least_available: ClusterAllocationExplainDiskUsage
  most_available: ClusterAllocationExplainDiskUsage
}

export interface ClusterAllocationExplainRequest extends RequestBase {
/** If true, returns information about disk usage and shard sizes. */
  include_disk_info?: boolean
  /** If true, returns YES decisions in explanation. */
  include_yes_decisions?: boolean
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** Specifies the node ID or the name of the node to only explain a shard that is currently located on the specified node. */
  current_node?: string
  /** Specifies the name of the index that you would like an explanation for. */
  index?: IndexName
  /** If true, returns explanation for the primary shard for the given shard ID. */
  primary?: boolean
  /** Specifies the ID of the shard that you would like an explanation for. */
  shard?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { include_disk_info?: never, include_yes_decisions?: never, master_timeout?: never, current_node?: never, index?: never, primary?: never, shard?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { include_disk_info?: never, include_yes_decisions?: never, master_timeout?: never, current_node?: never, index?: never, primary?: never, shard?: never }
}

export interface ClusterAllocationExplainReservedSize {
  node_id: Id
  path: string
  total: long
  shards: string[]
}

export interface ClusterAllocationExplainResponse {
  allocate_explanation?: string
  allocation_delay?: Duration
  allocation_delay_in_millis?: DurationValue<UnitMillis>
  can_allocate?: ClusterAllocationExplainDecision
  can_move_to_other_node?: ClusterAllocationExplainDecision
  can_rebalance_cluster?: ClusterAllocationExplainDecision
  can_rebalance_cluster_decisions?: ClusterAllocationExplainAllocationDecision[]
  can_rebalance_to_other_node?: ClusterAllocationExplainDecision
  can_remain_decisions?: ClusterAllocationExplainAllocationDecision[]
  can_remain_on_current_node?: ClusterAllocationExplainDecision
  cluster_info?: ClusterAllocationExplainClusterInfo
  configured_delay?: Duration
  configured_delay_in_millis?: DurationValue<UnitMillis>
  current_node?: ClusterAllocationExplainCurrentNode
  current_state: string
  index: IndexName
  move_explanation?: string
  node_allocation_decisions?: ClusterAllocationExplainNodeAllocationExplanation[]
  primary: boolean
  rebalance_explanation?: string
  remaining_delay?: Duration
  remaining_delay_in_millis?: DurationValue<UnitMillis>
  shard: integer
  unassigned_info?: ClusterAllocationExplainUnassignedInformation
  note?: string
}

export interface ClusterAllocationExplainUnassignedInformation {
  at: DateTime
  last_allocation_status?: string
  reason: ClusterAllocationExplainUnassignedInformationReason
  details?: string
  failed_allocation_attempts?: integer
  delayed?: boolean
  allocation_status?: string
}

export type ClusterAllocationExplainUnassignedInformationReason = 'INDEX_CREATED' | 'CLUSTER_RECOVERED' | 'INDEX_REOPENED' | 'DANGLING_INDEX_IMPORTED' | 'NEW_INDEX_RESTORED' | 'EXISTING_INDEX_RESTORED' | 'REPLICA_ADDED' | 'ALLOCATION_FAILED' | 'NODE_LEFT' | 'REROUTE_CANCELLED' | 'REINITIALIZED' | 'REALLOCATED_REPLICA' | 'PRIMARY_FAILED' | 'FORCED_EMPTY_PRIMARY' | 'MANUAL_ALLOCATION'

export interface ClusterDeleteComponentTemplateRequest extends RequestBase {
/** Comma-separated list or wildcard expression of component template names used to limit the request. */
  name: Names
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
}

export type ClusterDeleteComponentTemplateResponse = AcknowledgedResponseBase

export interface ClusterDeleteVotingConfigExclusionsRequest extends RequestBase {
/** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** Specifies whether to wait for all excluded nodes to be removed from the cluster before clearing the voting configuration exclusions list. Defaults to true, meaning that all excluded nodes must be removed from the cluster before this API takes any action. If set to false then the voting configuration exclusions list is cleared even if some excluded nodes are still in the cluster. */
  wait_for_removal?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never, wait_for_removal?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never, wait_for_removal?: never }
}

export type ClusterDeleteVotingConfigExclusionsResponse = boolean

export interface ClusterExistsComponentTemplateRequest extends RequestBase {
/** Comma-separated list of component template names used to limit the request. Wildcard (*) expressions are supported. */
  name: Names
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** If true, the request retrieves information from the local node only. Defaults to false, which means information is retrieved from the master node. */
  local?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, local?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, local?: never }
}

export type ClusterExistsComponentTemplateResponse = boolean

export interface ClusterGetComponentTemplateRequest extends RequestBase {
/** Comma-separated list of component template names used to limit the request. Wildcard (`*`) expressions are supported. */
  name?: Name
  /** If `true`, returns settings in flat format. */
  flat_settings?: boolean
  /** Return all default configurations for the component template (default: false) */
  include_defaults?: boolean
  /** If `true`, the request retrieves information from the local node only. If `false`, information is retrieved from the master node. */
  local?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, flat_settings?: never, include_defaults?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, flat_settings?: never, include_defaults?: never, local?: never, master_timeout?: never }
}

export interface ClusterGetComponentTemplateResponse {
  component_templates: ClusterComponentTemplate[]
}

export interface ClusterGetSettingsRequest extends RequestBase {
/** If `true`, returns settings in flat format. */
  flat_settings?: boolean
  /** If `true`, returns default cluster settings from the local node. */
  include_defaults?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { flat_settings?: never, include_defaults?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { flat_settings?: never, include_defaults?: never, master_timeout?: never, timeout?: never }
}

export interface ClusterGetSettingsResponse {
  persistent: Record<string, any>
  transient: Record<string, any>
  defaults?: Record<string, any>
}

export interface ClusterHealthHealthResponseBody {
  active_primary_shards: integer
  active_shards: integer
  active_shards_percent_as_number: Percentage
  cluster_name: Name
  delayed_unassigned_shards: integer
  indices?: Record<IndexName, ClusterHealthIndexHealthStats>
  initializing_shards: integer
  number_of_data_nodes: integer
  number_of_in_flight_fetch: integer
  number_of_nodes: integer
  number_of_pending_tasks: integer
  relocating_shards: integer
  status: HealthStatus
  task_max_waiting_in_queue?: Duration
  task_max_waiting_in_queue_millis: DurationValue<UnitMillis>
  timed_out: boolean
  unassigned_primary_shards: integer
  unassigned_shards: integer
}

export interface ClusterHealthIndexHealthStats {
  active_primary_shards: integer
  active_shards: integer
  initializing_shards: integer
  number_of_replicas: integer
  number_of_shards: integer
  relocating_shards: integer
  shards?: Record<string, ClusterHealthShardHealthStats>
  status: HealthStatus
  unassigned_shards: integer
  unassigned_primary_shards: integer
}

export interface ClusterHealthRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and index aliases used to limit the request. Wildcard expressions (`*`) are supported. To target all data streams and indices in a cluster, omit this parameter or use _all or `*`. */
  index?: Indices
  /** Whether to expand wildcard expression to concrete indices that are open, closed or both. */
  expand_wildcards?: ExpandWildcards
  /** Can be one of cluster, indices or shards. Controls the details level of the health information returned. */
  level?: Level
  /** If true, the request retrieves information from the local node only. Defaults to false, which means information is retrieved from the master node. */
  local?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** A number controlling to how many active shards to wait for, all to wait for all shards in the cluster to be active, or 0 to not wait. */
  wait_for_active_shards?: WaitForActiveShards
  /** Can be one of immediate, urgent, high, normal, low, languid. Wait until all currently queued events with the given priority are processed. */
  wait_for_events?: WaitForEvents
  /** The request waits until the specified number N of nodes is available. It also accepts >=N, <=N, >N and <N. Alternatively, it is possible to use ge(N), le(N), gt(N) and lt(N) notation. */
  wait_for_nodes?: string | integer
  /** A boolean value which controls whether to wait (until the timeout provided) for the cluster to have no shard initializations. Defaults to false, which means it will not wait for initializing shards. */
  wait_for_no_initializing_shards?: boolean
  /** A boolean value which controls whether to wait (until the timeout provided) for the cluster to have no shard relocations. Defaults to false, which means it will not wait for relocating shards. */
  wait_for_no_relocating_shards?: boolean
  /** One of green, yellow or red. Will wait (until the timeout provided) until the status of the cluster changes to the one provided or better, i.e. green > yellow > red. By default, will not wait for any status. */
  wait_for_status?: HealthStatus
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, expand_wildcards?: never, level?: never, local?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never, wait_for_events?: never, wait_for_nodes?: never, wait_for_no_initializing_shards?: never, wait_for_no_relocating_shards?: never, wait_for_status?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, expand_wildcards?: never, level?: never, local?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never, wait_for_events?: never, wait_for_nodes?: never, wait_for_no_initializing_shards?: never, wait_for_no_relocating_shards?: never, wait_for_status?: never }
}

export type ClusterHealthResponse = ClusterHealthHealthResponseBody

export interface ClusterHealthShardHealthStats {
  active_shards: integer
  initializing_shards: integer
  primary_active: boolean
  relocating_shards: integer
  status: HealthStatus
  unassigned_shards: integer
  unassigned_primary_shards: integer
}

export interface ClusterInfoRequest extends RequestBase {
/** Limits the information returned to the specific target. Supports a comma-separated list, such as http,ingest. */
  target: ClusterInfoTargets
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { target?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { target?: never }
}

export interface ClusterInfoResponse {
  cluster_name: Name
  http?: NodesHttp
  ingest?: NodesIngest
  thread_pool?: Record<string, NodesThreadCount>
  script?: NodesScripting
}

export interface ClusterPendingTasksPendingTask {
  executing: boolean
  insert_order: integer
  priority: string
  source: string
  time_in_queue?: Duration
  time_in_queue_millis: DurationValue<UnitMillis>
}

export interface ClusterPendingTasksRequest extends RequestBase {
/** If `true`, the request retrieves information from the local node only. If `false`, information is retrieved from the master node. */
  local?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { local?: never, master_timeout?: never }
}

export interface ClusterPendingTasksResponse {
  tasks: ClusterPendingTasksPendingTask[]
}

export interface ClusterPostVotingConfigExclusionsRequest extends RequestBase {
/** A comma-separated list of the names of the nodes to exclude from the voting configuration. If specified, you may not also specify node_ids. */
  node_names?: Names
  /** A comma-separated list of the persistent ids of the nodes to exclude from the voting configuration. If specified, you may not also specify node_names. */
  node_ids?: Ids
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** When adding a voting configuration exclusion, the API waits for the specified nodes to be excluded from the voting configuration before returning. If the timeout expires before the appropriate condition is satisfied, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_names?: never, node_ids?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_names?: never, node_ids?: never, master_timeout?: never, timeout?: never }
}

export type ClusterPostVotingConfigExclusionsResponse = boolean

export interface ClusterPutComponentTemplateRequest extends RequestBase {
/** Name of the component template to create. Elasticsearch includes the following built-in component templates: `logs-mappings`; `logs-settings`; `metrics-mappings`; `metrics-settings`;`synthetics-mapping`; `synthetics-settings`. Elastic Agent uses these templates to configure backing indices for its data streams. If you use Elastic Agent and want to overwrite one of these templates, set the `version` for your replacement template higher than the current version. If you don’t use Elastic Agent and want to disable all built-in component and index templates, set `stack.templates.enabled` to `false` using the cluster update settings API. */
  name: Name
  /** If `true`, this request cannot replace or update existing component templates. */
  create?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** The template to be applied which includes mappings, settings, or aliases configuration. */
  template: IndicesIndexState
  /** Version number used to manage component templates externally. This number isn't automatically generated or incremented by Elasticsearch. To unset a version, replace the template without specifying a version. */
  version?: VersionNumber
  /** Optional user metadata about the component template. It may have any contents. This map is not automatically generated by Elasticsearch. This information is stored in the cluster state, so keeping it short is preferable. To unset `_meta`, replace the template without specifying this information. */
  _meta?: Metadata
  /** Marks this index template as deprecated. When creating or updating a non-deprecated index template that uses deprecated components, Elasticsearch will emit a deprecation warning. */
  deprecated?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, create?: never, master_timeout?: never, template?: never, version?: never, _meta?: never, deprecated?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, create?: never, master_timeout?: never, template?: never, version?: never, _meta?: never, deprecated?: never }
}

export type ClusterPutComponentTemplateResponse = AcknowledgedResponseBase

export interface ClusterPutSettingsRequest extends RequestBase {
/** Return settings in flat format (default: false) */
  flat_settings?: boolean
  /** Explicit operation timeout for connection to master node */
  master_timeout?: Duration
  /** Explicit operation timeout */
  timeout?: Duration
  persistent?: Record<string, any>
  transient?: Record<string, any>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { flat_settings?: never, master_timeout?: never, timeout?: never, persistent?: never, transient?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { flat_settings?: never, master_timeout?: never, timeout?: never, persistent?: never, transient?: never }
}

export interface ClusterPutSettingsResponse {
  acknowledged: boolean
  persistent: Record<string, any>
  transient: Record<string, any>
}

export type ClusterRemoteInfoClusterRemoteInfo = ClusterRemoteInfoClusterRemoteSniffInfo | ClusterRemoteInfoClusterRemoteProxyInfo

export interface ClusterRemoteInfoClusterRemoteProxyInfo {
  mode: 'proxy'
  connected: boolean
  initial_connect_timeout: Duration
  skip_unavailable: boolean
  proxy_address: string
  server_name: string
  num_proxy_sockets_connected: integer
  max_proxy_socket_connections: integer
  cluster_credentials?: string
}

export interface ClusterRemoteInfoClusterRemoteSniffInfo {
  mode: 'sniff'
  connected: boolean
  max_connections_per_cluster: integer
  num_nodes_connected: long
  initial_connect_timeout: Duration
  skip_unavailable: boolean
  seeds: string[]
}

export interface ClusterRemoteInfoRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export type ClusterRemoteInfoResponse = Record<string, ClusterRemoteInfoClusterRemoteInfo>

export interface ClusterRerouteCommand {
  cancel?: ClusterRerouteCommandCancelAction
  move?: ClusterRerouteCommandMoveAction
  allocate_replica?: ClusterRerouteCommandAllocateReplicaAction
  allocate_stale_primary?: ClusterRerouteCommandAllocatePrimaryAction
  allocate_empty_primary?: ClusterRerouteCommandAllocatePrimaryAction
}

export interface ClusterRerouteCommandAllocatePrimaryAction {
  index: IndexName
  shard: integer
  node: string
  accept_data_loss: boolean
}

export interface ClusterRerouteCommandAllocateReplicaAction {
  index: IndexName
  shard: integer
  node: string
}

export interface ClusterRerouteCommandCancelAction {
  index: IndexName
  shard: integer
  node: string
  allow_primary?: boolean
}

export interface ClusterRerouteCommandMoveAction {
  index: IndexName
  shard: integer
  from_node: string
  to_node: string
}

export interface ClusterRerouteRequest extends RequestBase {
/** If true, then the request simulates the operation. It will calculate the result of applying the commands to the current cluster state and return the resulting cluster state after the commands (and rebalancing) have been applied; it will not actually perform the requested changes. */
  dry_run?: boolean
  /** If true, then the response contains an explanation of why the commands can or cannot run. */
  explain?: boolean
  /** Limits the information returned to the specified metrics. */
  metric?: Metrics
  /** If true, then retries allocation of shards that are blocked due to too many subsequent allocation failures. */
  retry_failed?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** Defines the commands to perform. */
  commands?: ClusterRerouteCommand[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { dry_run?: never, explain?: never, metric?: never, retry_failed?: never, master_timeout?: never, timeout?: never, commands?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { dry_run?: never, explain?: never, metric?: never, retry_failed?: never, master_timeout?: never, timeout?: never, commands?: never }
}

export interface ClusterRerouteRerouteDecision {
  decider: string
  decision: string
  explanation: string
}

export interface ClusterRerouteRerouteExplanation {
  command: string
  decisions: ClusterRerouteRerouteDecision[]
  parameters: ClusterRerouteRerouteParameters
}

export interface ClusterRerouteRerouteParameters {
  allow_primary: boolean
  index: IndexName
  node: NodeName
  shard: integer
  from_node?: NodeName
  to_node?: NodeName
}

export interface ClusterRerouteResponse {
  acknowledged: boolean
  explanations?: ClusterRerouteRerouteExplanation[]
  state?: any
}

export interface ClusterStateRequest extends RequestBase {
/** Limit the information returned to the specified metrics */
  metric?: Metrics
  /** A comma-separated list of index names; use `_all` or empty string to perform the operation on all indices */
  index?: Indices
  /** Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes `_all` string or when no indices have been specified) */
  allow_no_indices?: boolean
  /** Whether to expand wildcard expression to concrete indices that are open, closed or both. */
  expand_wildcards?: ExpandWildcards
  /** Return settings in flat format (default: false) */
  flat_settings?: boolean
  /** Whether specified concrete indices should be ignored when unavailable (missing or closed) */
  ignore_unavailable?: boolean
  /** Return local information, do not retrieve the state from master node (default: false) */
  local?: boolean
  /** Specify timeout for connection to master */
  master_timeout?: Duration
  /** Wait for the metadata version to be equal or greater than the specified metadata version */
  wait_for_metadata_version?: VersionNumber
  /** The maximum time to wait for wait_for_metadata_version before timing out */
  wait_for_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { metric?: never, index?: never, allow_no_indices?: never, expand_wildcards?: never, flat_settings?: never, ignore_unavailable?: never, local?: never, master_timeout?: never, wait_for_metadata_version?: never, wait_for_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { metric?: never, index?: never, allow_no_indices?: never, expand_wildcards?: never, flat_settings?: never, ignore_unavailable?: never, local?: never, master_timeout?: never, wait_for_metadata_version?: never, wait_for_timeout?: never }
}

export type ClusterStateResponse = any

export interface ClusterStatsCharFilterTypes {
  analyzer_types: ClusterStatsFieldTypes[]
  built_in_analyzers: ClusterStatsFieldTypes[]
  built_in_char_filters: ClusterStatsFieldTypes[]
  built_in_filters: ClusterStatsFieldTypes[]
  built_in_tokenizers: ClusterStatsFieldTypes[]
  char_filter_types: ClusterStatsFieldTypes[]
  filter_types: ClusterStatsFieldTypes[]
  tokenizer_types: ClusterStatsFieldTypes[]
}

export interface ClusterStatsClusterFileSystem {
  available_in_bytes: long
  free_in_bytes: long
  total_in_bytes: long
}

export interface ClusterStatsClusterIndices {
  analysis: ClusterStatsCharFilterTypes
  completion: CompletionStats
  count: long
  docs: DocStats
  fielddata: FielddataStats
  query_cache: QueryCacheStats
  segments: SegmentsStats
  shards: ClusterStatsClusterIndicesShards
  store: StoreStats
  mappings: ClusterStatsFieldTypesMappings
  versions?: ClusterStatsIndicesVersions[]
}

export interface ClusterStatsClusterIndicesShards {
  index?: ClusterStatsClusterIndicesShardsIndex
  primaries?: double
  replication?: double
  total?: double
}

export interface ClusterStatsClusterIndicesShardsIndex {
  primaries: ClusterStatsClusterShardMetrics
  replication: ClusterStatsClusterShardMetrics
  shards: ClusterStatsClusterShardMetrics
}

export interface ClusterStatsClusterIngest {
  number_of_pipelines: integer
  processor_stats: Record<string, ClusterStatsClusterProcessor>
}

export interface ClusterStatsClusterJvm {
  max_uptime_in_millis: DurationValue<UnitMillis>
  mem: ClusterStatsClusterJvmMemory
  threads: long
  versions: ClusterStatsClusterJvmVersion[]
}

export interface ClusterStatsClusterJvmMemory {
  heap_max_in_bytes: long
  heap_used_in_bytes: long
}

export interface ClusterStatsClusterJvmVersion {
  bundled_jdk: boolean
  count: integer
  using_bundled_jdk: boolean
  version: VersionString
  vm_name: string
  vm_vendor: string
  vm_version: VersionString
}

export interface ClusterStatsClusterNetworkTypes {
  http_types: Record<string, integer>
  transport_types: Record<string, integer>
}

export interface ClusterStatsClusterNodeCount {
  coordinating_only: integer
  data: integer
  data_cold: integer
  data_content: integer
  data_frozen?: integer
  data_hot: integer
  data_warm: integer
  ingest: integer
  master: integer
  ml: integer
  remote_cluster_client: integer
  total: integer
  transform: integer
  voting_only: integer
}

export interface ClusterStatsClusterNodes {
  count: ClusterStatsClusterNodeCount
  discovery_types: Record<string, integer>
  fs: ClusterStatsClusterFileSystem
  indexing_pressure: ClusterStatsIndexingPressure
  ingest: ClusterStatsClusterIngest
  jvm: ClusterStatsClusterJvm
  network_types: ClusterStatsClusterNetworkTypes
  os: ClusterStatsClusterOperatingSystem
  packaging_types: ClusterStatsNodePackagingType[]
  plugins: PluginStats[]
  process: ClusterStatsClusterProcess
  versions: VersionString[]
}

export interface ClusterStatsClusterOperatingSystem {
  allocated_processors: integer
  architectures?: ClusterStatsClusterOperatingSystemArchitecture[]
  available_processors: integer
  mem: ClusterStatsOperatingSystemMemoryInfo
  names: ClusterStatsClusterOperatingSystemName[]
  pretty_names: ClusterStatsClusterOperatingSystemPrettyName[]
}

export interface ClusterStatsClusterOperatingSystemArchitecture {
  arch: string
  count: integer
}

export interface ClusterStatsClusterOperatingSystemName {
  count: integer
  name: Name
}

export interface ClusterStatsClusterOperatingSystemPrettyName {
  count: integer
  pretty_name: Name
}

export interface ClusterStatsClusterProcess {
  cpu: ClusterStatsClusterProcessCpu
  open_file_descriptors: ClusterStatsClusterProcessOpenFileDescriptors
}

export interface ClusterStatsClusterProcessCpu {
  percent: integer
}

export interface ClusterStatsClusterProcessOpenFileDescriptors {
  avg: long
  max: long
  min: long
}

export interface ClusterStatsClusterProcessor {
  count: long
  current: long
  failed: long
  time?: Duration
  time_in_millis: DurationValue<UnitMillis>
}

export interface ClusterStatsClusterShardMetrics {
  avg: double
  max: double
  min: double
}

export interface ClusterStatsFieldTypes {
  name: Name
  count: integer
  index_count: integer
  indexed_vector_count?: long
  indexed_vector_dim_max?: long
  indexed_vector_dim_min?: long
  script_count?: integer
}

export interface ClusterStatsFieldTypesMappings {
  field_types: ClusterStatsFieldTypes[]
  runtime_field_types?: ClusterStatsRuntimeFieldTypes[]
  total_field_count?: integer
  total_deduplicated_field_count?: integer
  total_deduplicated_mapping_size?: ByteSize
  total_deduplicated_mapping_size_in_bytes?: long
}

export interface ClusterStatsIndexingPressure {
  memory: ClusterStatsIndexingPressureMemory
}

export interface ClusterStatsIndexingPressureMemory {
  current: ClusterStatsIndexingPressureMemorySummary
  limit_in_bytes: long
  total: ClusterStatsIndexingPressureMemorySummary
}

export interface ClusterStatsIndexingPressureMemorySummary {
  all_in_bytes: long
  combined_coordinating_and_primary_in_bytes: long
  coordinating_in_bytes: long
  coordinating_rejections?: long
  primary_in_bytes: long
  primary_rejections?: long
  replica_in_bytes: long
  replica_rejections?: long
}

export interface ClusterStatsIndicesVersions {
  index_count: integer
  primary_shard_count: integer
  total_primary_bytes: long
  version: VersionString
}

export interface ClusterStatsNodePackagingType {
  count: integer
  flavor: string
  type: string
}

export interface ClusterStatsOperatingSystemMemoryInfo {
  adjusted_total_in_bytes?: long
  free_in_bytes: long
  free_percent: integer
  total_in_bytes: long
  used_in_bytes: long
  used_percent: integer
}

export interface ClusterStatsRequest extends RequestBase {
/** Comma-separated list of node filters used to limit returned information. Defaults to all nodes in the cluster. */
  node_id?: NodeIds
  /** Include remote cluster data into the response */
  include_remotes?: boolean
  /** Period to wait for each node to respond. If a node does not respond before its timeout expires, the response does not include its stats. However, timed out nodes are included in the response’s `_nodes.failed` property. Defaults to no timeout. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never, include_remotes?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never, include_remotes?: never, timeout?: never }
}

export type ClusterStatsResponse = ClusterStatsStatsResponseBase

export interface ClusterStatsRuntimeFieldTypes {
  chars_max: integer
  chars_total: integer
  count: integer
  doc_max: integer
  doc_total: integer
  index_count: integer
  lang: string[]
  lines_max: integer
  lines_total: integer
  name: Name
  scriptless_count: integer
  shadowed_count: integer
  source_max: integer
  source_total: integer
}

export interface ClusterStatsStatsResponseBase extends NodesNodesResponseBase {
  cluster_name: Name
  cluster_uuid: Uuid
  indices: ClusterStatsClusterIndices
  nodes: ClusterStatsClusterNodes
  status: HealthStatus
  timestamp: long
}

export interface ConnectorConnector {
  api_key_id?: string
  api_key_secret_id?: string
  configuration: ConnectorConnectorConfiguration
  custom_scheduling: ConnectorConnectorCustomScheduling
  deleted: boolean
  description?: string
  error?: string | null
  features?: ConnectorConnectorFeatures
  filtering: ConnectorFilteringConfig[]
  id?: Id
  index_name?: IndexName | null
  is_native: boolean
  language?: string
  last_access_control_sync_error?: string
  last_access_control_sync_scheduled_at?: DateTime
  last_access_control_sync_status?: ConnectorSyncStatus
  last_deleted_document_count?: long
  last_incremental_sync_scheduled_at?: DateTime
  last_indexed_document_count?: long
  last_seen?: DateTime
  last_sync_error?: string
  last_sync_scheduled_at?: DateTime
  last_sync_status?: ConnectorSyncStatus
  last_synced?: DateTime
  name?: string
  pipeline?: ConnectorIngestPipelineParams
  scheduling: ConnectorSchedulingConfiguration
  service_type?: string
  status: ConnectorConnectorStatus
  sync_cursor?: any
  sync_now: boolean
}

export interface ConnectorConnectorConfigProperties {
  category?: string
  default_value: ScalarValue
  depends_on: ConnectorDependency[]
  display: ConnectorDisplayType
  label: string
  options: ConnectorSelectOption[]
  order?: integer
  placeholder?: string
  required: boolean
  sensitive: boolean
  tooltip?: string | null
  type?: ConnectorConnectorFieldType
  ui_restrictions?: string[]
  validations?: ConnectorValidation[]
  value: any
}

export type ConnectorConnectorConfiguration = Record<string, ConnectorConnectorConfigProperties>

export type ConnectorConnectorCustomScheduling = Record<string, ConnectorCustomScheduling>

export interface ConnectorConnectorFeatures {
  document_level_security?: ConnectorFeatureEnabled
  incremental_sync?: ConnectorFeatureEnabled
  native_connector_api_keys?: ConnectorFeatureEnabled
  sync_rules?: ConnectorSyncRulesFeature
}

export type ConnectorConnectorFieldType = 'str' | 'int' | 'list' | 'bool'

export interface ConnectorConnectorScheduling {
  enabled: boolean
  interval: string
}

export type ConnectorConnectorStatus = 'created' | 'needs_configuration' | 'configured' | 'connected' | 'error'

export interface ConnectorConnectorSyncJob {
  cancelation_requested_at?: DateTime
  canceled_at?: DateTime
  completed_at?: DateTime
  connector: ConnectorSyncJobConnectorReference
  created_at: DateTime
  deleted_document_count: long
  error?: string
  id: Id
  indexed_document_count: long
  indexed_document_volume: long
  job_type: ConnectorSyncJobType
  last_seen?: DateTime
  metadata: Record<string, any>
  started_at?: DateTime
  status: ConnectorSyncStatus
  total_document_count: long
  trigger_method: ConnectorSyncJobTriggerMethod
  worker_hostname?: string
}

export interface ConnectorCustomScheduling {
  configuration_overrides: ConnectorCustomSchedulingConfigurationOverrides
  enabled: boolean
  interval: string
  last_synced?: DateTime
  name: string
}

export interface ConnectorCustomSchedulingConfigurationOverrides {
  max_crawl_depth?: integer
  sitemap_discovery_disabled?: boolean
  domain_allowlist?: string[]
  sitemap_urls?: string[]
  seed_urls?: string[]
}

export interface ConnectorDependency {
  field: string
  value: ScalarValue
}

export type ConnectorDisplayType = 'textbox' | 'textarea' | 'numeric' | 'toggle' | 'dropdown'

export interface ConnectorFeatureEnabled {
  enabled: boolean
}

export interface ConnectorFilteringAdvancedSnippet {
  created_at?: DateTime
  updated_at?: DateTime
  value: any
}

export interface ConnectorFilteringConfig {
  active: ConnectorFilteringRules
  domain?: string
  draft: ConnectorFilteringRules
}

export type ConnectorFilteringPolicy = 'exclude' | 'include'

export interface ConnectorFilteringRule {
  created_at?: DateTime
  field: Field
  id: Id
  order: integer
  policy: ConnectorFilteringPolicy
  rule: ConnectorFilteringRuleRule
  updated_at?: DateTime
  value: string
}

export type ConnectorFilteringRuleRule = 'contains' | 'ends_with' | 'equals' | 'regex' | 'starts_with' | '>' | '<'

export interface ConnectorFilteringRules {
  advanced_snippet: ConnectorFilteringAdvancedSnippet
  rules: ConnectorFilteringRule[]
  validation: ConnectorFilteringRulesValidation
}

export interface ConnectorFilteringRulesValidation {
  errors: ConnectorFilteringValidation[]
  state: ConnectorFilteringValidationState
}

export interface ConnectorFilteringValidation {
  ids: Id[]
  messages: string[]
}

export type ConnectorFilteringValidationState = 'edited' | 'invalid' | 'valid'

export interface ConnectorGreaterThanValidation {
  type: 'greater_than'
  constraint: double
}

export interface ConnectorIncludedInValidation {
  type: 'included_in'
  constraint: ScalarValue[]
}

export interface ConnectorIngestPipelineParams {
  extract_binary_content: boolean
  name: string
  reduce_whitespace: boolean
  run_ml_inference: boolean
}

export interface ConnectorLessThanValidation {
  type: 'less_than'
  constraint: double
}

export interface ConnectorListTypeValidation {
  type: 'list_type'
  constraint: string
}

export interface ConnectorRegexValidation {
  type: 'regex'
  constraint: string
}

export interface ConnectorSchedulingConfiguration {
  access_control?: ConnectorConnectorScheduling
  full?: ConnectorConnectorScheduling
  incremental?: ConnectorConnectorScheduling
}

export interface ConnectorSelectOption {
  label: string
  value: ScalarValue
}

export interface ConnectorSyncJobConnectorReference {
  configuration: ConnectorConnectorConfiguration
  filtering: ConnectorFilteringRules
  id: Id
  index_name: string
  language?: string
  pipeline?: ConnectorIngestPipelineParams
  service_type: string
  sync_cursor?: any
}

export type ConnectorSyncJobTriggerMethod = 'on_demand' | 'scheduled'

export type ConnectorSyncJobType = 'full' | 'incremental' | 'access_control'

export interface ConnectorSyncRulesFeature {
  advanced?: ConnectorFeatureEnabled
  basic?: ConnectorFeatureEnabled
}

export type ConnectorSyncStatus = 'canceling' | 'canceled' | 'completed' | 'error' | 'in_progress' | 'pending' | 'suspended'

export type ConnectorValidation = ConnectorLessThanValidation | ConnectorGreaterThanValidation | ConnectorListTypeValidation | ConnectorIncludedInValidation | ConnectorRegexValidation

export interface ConnectorCheckInRequest extends RequestBase {
/** The unique identifier of the connector to be checked in */
  connector_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never }
}

export interface ConnectorCheckInResponse {
  result: Result
}

export interface ConnectorDeleteRequest extends RequestBase {
/** The unique identifier of the connector to be deleted */
  connector_id: Id
  /** A flag indicating if associated sync jobs should be also removed. Defaults to false. */
  delete_sync_jobs?: boolean
  /** A flag indicating if the connector should be hard deleted. */
  hard?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, delete_sync_jobs?: never, hard?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, delete_sync_jobs?: never, hard?: never }
}

export type ConnectorDeleteResponse = AcknowledgedResponseBase

export interface ConnectorGetRequest extends RequestBase {
/** The unique identifier of the connector */
  connector_id: Id
  /** A flag to indicate if the desired connector should be fetched, even if it was soft-deleted. */
  include_deleted?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, include_deleted?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, include_deleted?: never }
}

export type ConnectorGetResponse = ConnectorConnector

export interface ConnectorLastSyncRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  last_access_control_sync_error?: string
  last_access_control_sync_scheduled_at?: DateTime
  last_access_control_sync_status?: ConnectorSyncStatus
  last_deleted_document_count?: long
  last_incremental_sync_scheduled_at?: DateTime
  last_indexed_document_count?: long
  last_seen?: DateTime
  last_sync_error?: string
  last_sync_scheduled_at?: DateTime
  last_sync_status?: ConnectorSyncStatus
  last_synced?: DateTime
  sync_cursor?: any
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, last_access_control_sync_error?: never, last_access_control_sync_scheduled_at?: never, last_access_control_sync_status?: never, last_deleted_document_count?: never, last_incremental_sync_scheduled_at?: never, last_indexed_document_count?: never, last_seen?: never, last_sync_error?: never, last_sync_scheduled_at?: never, last_sync_status?: never, last_synced?: never, sync_cursor?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, last_access_control_sync_error?: never, last_access_control_sync_scheduled_at?: never, last_access_control_sync_status?: never, last_deleted_document_count?: never, last_incremental_sync_scheduled_at?: never, last_indexed_document_count?: never, last_seen?: never, last_sync_error?: never, last_sync_scheduled_at?: never, last_sync_status?: never, last_synced?: never, sync_cursor?: never }
}

export interface ConnectorLastSyncResponse {
  result: Result
}

export interface ConnectorListRequest extends RequestBase {
/** Starting offset (default: 0) */
  from?: integer
  /** Specifies a max number of results to get */
  size?: integer
  /** A comma-separated list of connector index names to fetch connector documents for */
  index_name?: Indices
  /** A comma-separated list of connector names to fetch connector documents for */
  connector_name?: Names
  /** A comma-separated list of connector service types to fetch connector documents for */
  service_type?: Names
  /** A flag to indicate if the desired connector should be fetched, even if it was soft-deleted. */
  include_deleted?: boolean
  /** A wildcard query string that filters connectors with matching name, description or index name */
  query?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { from?: never, size?: never, index_name?: never, connector_name?: never, service_type?: never, include_deleted?: never, query?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { from?: never, size?: never, index_name?: never, connector_name?: never, service_type?: never, include_deleted?: never, query?: never }
}

export interface ConnectorListResponse {
  count: long
  results: ConnectorConnector[]
}

export interface ConnectorPostRequest extends RequestBase {
  description?: string
  index_name?: IndexName
  is_native?: boolean
  language?: string
  name?: string
  service_type?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { description?: never, index_name?: never, is_native?: never, language?: never, name?: never, service_type?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { description?: never, index_name?: never, is_native?: never, language?: never, name?: never, service_type?: never }
}

export interface ConnectorPostResponse {
  result: Result
  id: Id
}

export interface ConnectorPutRequest extends RequestBase {
/** The unique identifier of the connector to be created or updated. ID is auto-generated if not provided. */
  connector_id?: Id
  description?: string
  index_name?: IndexName
  is_native?: boolean
  language?: string
  name?: string
  service_type?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, description?: never, index_name?: never, is_native?: never, language?: never, name?: never, service_type?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, description?: never, index_name?: never, is_native?: never, language?: never, name?: never, service_type?: never }
}

export interface ConnectorPutResponse {
  result: Result
  id: Id
}

export interface ConnectorSyncJobCancelRequest extends RequestBase {
/** The unique identifier of the connector sync job */
  connector_sync_job_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_sync_job_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_sync_job_id?: never }
}

export interface ConnectorSyncJobCancelResponse {
  result: Result
}

export interface ConnectorSyncJobCheckInRequest extends RequestBase {
/** The unique identifier of the connector sync job to be checked in. */
  connector_sync_job_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_sync_job_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_sync_job_id?: never }
}

export interface ConnectorSyncJobCheckInResponse {
}

export interface ConnectorSyncJobClaimRequest extends RequestBase {
/** The unique identifier of the connector sync job. */
  connector_sync_job_id: Id
  /** The cursor object from the last incremental sync job. This should reference the `sync_cursor` field in the connector state for which the job runs. */
  sync_cursor?: any
  /** The host name of the current system that will run the job. */
  worker_hostname: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_sync_job_id?: never, sync_cursor?: never, worker_hostname?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_sync_job_id?: never, sync_cursor?: never, worker_hostname?: never }
}

export interface ConnectorSyncJobClaimResponse {
}

export interface ConnectorSyncJobDeleteRequest extends RequestBase {
/** The unique identifier of the connector sync job to be deleted */
  connector_sync_job_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_sync_job_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_sync_job_id?: never }
}

export type ConnectorSyncJobDeleteResponse = AcknowledgedResponseBase

export interface ConnectorSyncJobErrorRequest extends RequestBase {
/** The unique identifier for the connector sync job. */
  connector_sync_job_id: Id
  /** The error for the connector sync job error field. */
  error: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_sync_job_id?: never, error?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_sync_job_id?: never, error?: never }
}

export interface ConnectorSyncJobErrorResponse {
}

export interface ConnectorSyncJobGetRequest extends RequestBase {
/** The unique identifier of the connector sync job */
  connector_sync_job_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_sync_job_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_sync_job_id?: never }
}

export type ConnectorSyncJobGetResponse = ConnectorConnectorSyncJob

export interface ConnectorSyncJobListRequest extends RequestBase {
/** Starting offset (default: 0) */
  from?: integer
  /** Specifies a max number of results to get */
  size?: integer
  /** A sync job status to fetch connector sync jobs for */
  status?: ConnectorSyncStatus
  /** A connector id to fetch connector sync jobs for */
  connector_id?: Id
  /** A comma-separated list of job types to fetch the sync jobs for */
  job_type?: ConnectorSyncJobType | ConnectorSyncJobType[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { from?: never, size?: never, status?: never, connector_id?: never, job_type?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { from?: never, size?: never, status?: never, connector_id?: never, job_type?: never }
}

export interface ConnectorSyncJobListResponse {
  count: long
  results: ConnectorConnectorSyncJob[]
}

export interface ConnectorSyncJobPostRequest extends RequestBase {
/** The id of the associated connector */
  id: Id
  job_type?: ConnectorSyncJobType
  trigger_method?: ConnectorSyncJobTriggerMethod
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, job_type?: never, trigger_method?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, job_type?: never, trigger_method?: never }
}

export interface ConnectorSyncJobPostResponse {
  id: Id
}

export interface ConnectorSyncJobUpdateStatsRequest extends RequestBase {
/** The unique identifier of the connector sync job. */
  connector_sync_job_id: Id
  /** The number of documents the sync job deleted. */
  deleted_document_count: long
  /** The number of documents the sync job indexed. */
  indexed_document_count: long
  /** The total size of the data (in MiB) the sync job indexed. */
  indexed_document_volume: long
  /** The timestamp to use in the `last_seen` property for the connector sync job. */
  last_seen?: Duration
  /** The connector-specific metadata. */
  metadata?: Metadata
  /** The total number of documents in the target index after the sync job finished. */
  total_document_count?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_sync_job_id?: never, deleted_document_count?: never, indexed_document_count?: never, indexed_document_volume?: never, last_seen?: never, metadata?: never, total_document_count?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_sync_job_id?: never, deleted_document_count?: never, indexed_document_count?: never, indexed_document_volume?: never, last_seen?: never, metadata?: never, total_document_count?: never }
}

export interface ConnectorSyncJobUpdateStatsResponse {
}

export interface ConnectorUpdateActiveFilteringRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never }
}

export interface ConnectorUpdateActiveFilteringResponse {
  result: Result
}

export interface ConnectorUpdateApiKeyIdRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  api_key_id?: string
  api_key_secret_id?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, api_key_id?: never, api_key_secret_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, api_key_id?: never, api_key_secret_id?: never }
}

export interface ConnectorUpdateApiKeyIdResponse {
  result: Result
}

export interface ConnectorUpdateConfigurationRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  configuration?: ConnectorConnectorConfiguration
  values?: Record<string, any>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, configuration?: never, values?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, configuration?: never, values?: never }
}

export interface ConnectorUpdateConfigurationResponse {
  result: Result
}

export interface ConnectorUpdateErrorRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  error: SpecUtilsWithNullValue<string>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, error?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, error?: never }
}

export interface ConnectorUpdateErrorResponse {
  result: Result
}

export interface ConnectorUpdateFeaturesRequest extends RequestBase {
/** The unique identifier of the connector to be updated. */
  connector_id: Id
  features: ConnectorConnectorFeatures
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, features?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, features?: never }
}

export interface ConnectorUpdateFeaturesResponse {
  result: Result
}

export interface ConnectorUpdateFilteringRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  filtering?: ConnectorFilteringConfig[]
  rules?: ConnectorFilteringRule[]
  advanced_snippet?: ConnectorFilteringAdvancedSnippet
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, filtering?: never, rules?: never, advanced_snippet?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, filtering?: never, rules?: never, advanced_snippet?: never }
}

export interface ConnectorUpdateFilteringResponse {
  result: Result
}

export interface ConnectorUpdateFilteringValidationRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  validation: ConnectorFilteringRulesValidation
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, validation?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, validation?: never }
}

export interface ConnectorUpdateFilteringValidationResponse {
  result: Result
}

export interface ConnectorUpdateIndexNameRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  index_name: SpecUtilsWithNullValue<IndexName>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, index_name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, index_name?: never }
}

export interface ConnectorUpdateIndexNameResponse {
  result: Result
}

export interface ConnectorUpdateNameRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  name?: string
  description?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, name?: never, description?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, name?: never, description?: never }
}

export interface ConnectorUpdateNameResponse {
  result: Result
}

export interface ConnectorUpdateNativeRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  is_native: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, is_native?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, is_native?: never }
}

export interface ConnectorUpdateNativeResponse {
  result: Result
}

export interface ConnectorUpdatePipelineRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  pipeline: ConnectorIngestPipelineParams
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, pipeline?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, pipeline?: never }
}

export interface ConnectorUpdatePipelineResponse {
  result: Result
}

export interface ConnectorUpdateSchedulingRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  scheduling: ConnectorSchedulingConfiguration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, scheduling?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, scheduling?: never }
}

export interface ConnectorUpdateSchedulingResponse {
  result: Result
}

export interface ConnectorUpdateServiceTypeRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  service_type: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, service_type?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, service_type?: never }
}

export interface ConnectorUpdateServiceTypeResponse {
  result: Result
}

export interface ConnectorUpdateStatusRequest extends RequestBase {
/** The unique identifier of the connector to be updated */
  connector_id: Id
  status: ConnectorConnectorStatus
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { connector_id?: never, status?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { connector_id?: never, status?: never }
}

export interface ConnectorUpdateStatusResponse {
  result: Result
}

export interface DanglingIndicesDeleteDanglingIndexRequest extends RequestBase {
/** The UUID of the index to delete. Use the get dangling indices API to find the UUID. */
  index_uuid: Uuid
  /** This parameter must be set to true to acknowledge that it will no longer be possible to recove data from the dangling index. */
  accept_data_loss: boolean
  /** Specify timeout for connection to master */
  master_timeout?: Duration
  /** Explicit operation timeout */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index_uuid?: never, accept_data_loss?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index_uuid?: never, accept_data_loss?: never, master_timeout?: never, timeout?: never }
}

export type DanglingIndicesDeleteDanglingIndexResponse = AcknowledgedResponseBase

export interface DanglingIndicesImportDanglingIndexRequest extends RequestBase {
/** The UUID of the index to import. Use the get dangling indices API to locate the UUID. */
  index_uuid: Uuid
  /** This parameter must be set to true to import a dangling index. Because Elasticsearch cannot know where the dangling index data came from or determine which shard copies are fresh and which are stale, it cannot guarantee that the imported data represents the latest state of the index when it was last in the cluster. */
  accept_data_loss: boolean
  /** Specify timeout for connection to master */
  master_timeout?: Duration
  /** Explicit operation timeout */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index_uuid?: never, accept_data_loss?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index_uuid?: never, accept_data_loss?: never, master_timeout?: never, timeout?: never }
}

export type DanglingIndicesImportDanglingIndexResponse = AcknowledgedResponseBase

export interface DanglingIndicesListDanglingIndicesDanglingIndex {
  index_name: string
  index_uuid: string
  creation_date_millis: EpochTime<UnitMillis>
  node_ids: Ids
}

export interface DanglingIndicesListDanglingIndicesRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface DanglingIndicesListDanglingIndicesResponse {
  dangling_indices: DanglingIndicesListDanglingIndicesDanglingIndex[]
}

export interface EnrichPolicy {
  enrich_fields: Fields
  indices: Indices
  match_field: Field
  query?: QueryDslQueryContainer
  name?: Name
  elasticsearch_version?: string
}

export type EnrichPolicyType = 'geo_match' | 'match' | 'range'

export interface EnrichSummary {
  config: Partial<Record<EnrichPolicyType, EnrichPolicy>>
}

export interface EnrichDeletePolicyRequest extends RequestBase {
/** Enrich policy to delete. */
  name: Name
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never }
}

export type EnrichDeletePolicyResponse = AcknowledgedResponseBase

export type EnrichExecutePolicyEnrichPolicyPhase = 'SCHEDULED' | 'RUNNING' | 'COMPLETE' | 'FAILED'

export interface EnrichExecutePolicyExecuteEnrichPolicyStatus {
  phase: EnrichExecutePolicyEnrichPolicyPhase
}

export interface EnrichExecutePolicyRequest extends RequestBase {
/** Enrich policy to execute. */
  name: Name
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** If `true`, the request blocks other enrich policy execution requests until complete. */
  wait_for_completion?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, wait_for_completion?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, wait_for_completion?: never }
}

export interface EnrichExecutePolicyResponse {
  status?: EnrichExecutePolicyExecuteEnrichPolicyStatus
  task_id?: TaskId
}

export interface EnrichGetPolicyRequest extends RequestBase {
/** Comma-separated list of enrich policy names used to limit the request. To return information for all enrich policies, omit this parameter. */
  name?: Names
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never }
}

export interface EnrichGetPolicyResponse {
  policies: EnrichSummary[]
}

export interface EnrichPutPolicyRequest extends RequestBase {
/** Name of the enrich policy to create or update. */
  name: Name
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** Matches enrich data to incoming documents based on a `geo_shape` query. */
  geo_match?: EnrichPolicy
  /** Matches enrich data to incoming documents based on a `term` query. */
  match?: EnrichPolicy
  /** Matches a number, date, or IP address in incoming documents to a range in the enrich index based on a `term` query. */
  range?: EnrichPolicy
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, geo_match?: never, match?: never, range?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, geo_match?: never, match?: never, range?: never }
}

export type EnrichPutPolicyResponse = AcknowledgedResponseBase

export interface EnrichStatsCacheStats {
  node_id: Id
  count: integer
  hits: integer
  hits_time_in_millis: DurationValue<UnitMillis>
  misses: integer
  misses_time_in_millis: DurationValue<UnitMillis>
  evictions: integer
  size_in_bytes: long
}

export interface EnrichStatsCoordinatorStats {
  executed_searches_total: long
  node_id: Id
  queue_size: integer
  remote_requests_current: integer
  remote_requests_total: long
}

export interface EnrichStatsExecutingPolicy {
  name: Name
  task: TasksTaskInfo
}

export interface EnrichStatsRequest extends RequestBase {
/** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never }
}

export interface EnrichStatsResponse {
  coordinator_stats: EnrichStatsCoordinatorStats[]
  executing_policies: EnrichStatsExecutingPolicy[]
  cache_stats?: EnrichStatsCacheStats[]
}

export interface EqlEqlHits<TEvent = unknown> {
  total?: SearchTotalHits
  events?: EqlHitsEvent<TEvent>[]
  sequences?: EqlHitsSequence<TEvent>[]
}

export interface EqlEqlSearchResponseBase<TEvent = unknown> {
  id?: Id
  is_partial?: boolean
  is_running?: boolean
  took?: DurationValue<UnitMillis>
  timed_out?: boolean
  hits: EqlEqlHits<TEvent>
  shard_failures?: ShardFailure[]
}

export interface EqlHitsEvent<TEvent = unknown> {
  _index: IndexName
  _id: Id
  _source: TEvent
  missing?: boolean
  fields?: Record<Field, any[]>
}

export interface EqlHitsSequence<TEvent = unknown> {
  events: EqlHitsEvent<TEvent>[]
  join_keys?: any[]
}

export interface EqlDeleteRequest extends RequestBase {
/** Identifier for the search to delete. A search ID is provided in the EQL search API's response for an async search. A search ID is also provided if the request’s `keep_on_completion` parameter is `true`. */
  id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export type EqlDeleteResponse = AcknowledgedResponseBase

export interface EqlGetRequest extends RequestBase {
/** Identifier for the search. */
  id: Id
  /** Period for which the search and its results are stored on the cluster. Defaults to the keep_alive value set by the search’s EQL search API request. */
  keep_alive?: Duration
  /** Timeout duration to wait for the request to finish. Defaults to no timeout, meaning the request waits for complete search results. */
  wait_for_completion_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, keep_alive?: never, wait_for_completion_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, keep_alive?: never, wait_for_completion_timeout?: never }
}

export type EqlGetResponse<TEvent = unknown> = EqlEqlSearchResponseBase<TEvent>

export interface EqlGetStatusRequest extends RequestBase {
/** Identifier for the search. */
  id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export interface EqlGetStatusResponse {
  id: Id
  is_partial: boolean
  is_running: boolean
  start_time_in_millis?: EpochTime<UnitMillis>
  expiration_time_in_millis?: EpochTime<UnitMillis>
  completion_status?: integer
}

export interface EqlSearchRequest extends RequestBase {
/** The name of the index to scope the operation */
  index: Indices
  allow_no_indices?: boolean
  expand_wildcards?: ExpandWildcards
  /** If true, missing or closed indices are not included in the response. */
  ignore_unavailable?: boolean
  /** EQL query you wish to run. */
  query: string
  case_sensitive?: boolean
  /** Field containing the event classification, such as process, file, or network. */
  event_category_field?: Field
  /** Field used to sort hits with the same timestamp in ascending order */
  tiebreaker_field?: Field
  /** Field containing event timestamp. Default "@timestamp" */
  timestamp_field?: Field
  /** Maximum number of events to search at a time for sequence queries. */
  fetch_size?: uint
  /** Query, written in Query DSL, used to filter the events on which the EQL query runs. */
  filter?: QueryDslQueryContainer | QueryDslQueryContainer[]
  keep_alive?: Duration
  keep_on_completion?: boolean
  wait_for_completion_timeout?: Duration
  /** Allow query execution also in case of shard failures. If true, the query will keep running and will return results based on the available shards. For sequences, the behavior can be further refined using allow_partial_sequence_results */
  allow_partial_search_results?: boolean
  /** This flag applies only to sequences and has effect only if allow_partial_search_results=true. If true, the sequence query will return results based on the available shards, ignoring the others. If false, the sequence query will return successfully, but will always have empty results. */
  allow_partial_sequence_results?: boolean
  /** For basic queries, the maximum number of matching events to return. Defaults to 10 */
  size?: uint
  /** Array of wildcard (*) patterns. The response returns values for field names matching these patterns in the fields property of each hit. */
  fields?: QueryDslFieldAndFormat | Field | (QueryDslFieldAndFormat | Field)[]
  result_position?: EqlSearchResultPosition
  runtime_mappings?: MappingRuntimeFields
  /** By default, the response of a sample query contains up to `10` samples, with one sample per unique set of join keys. Use the `size` parameter to get a smaller or larger set of samples. To retrieve more than one sample per set of join keys, use the `max_samples_per_key` parameter. Pipes are not supported for sample queries. */
  max_samples_per_key?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, query?: never, case_sensitive?: never, event_category_field?: never, tiebreaker_field?: never, timestamp_field?: never, fetch_size?: never, filter?: never, keep_alive?: never, keep_on_completion?: never, wait_for_completion_timeout?: never, allow_partial_search_results?: never, allow_partial_sequence_results?: never, size?: never, fields?: never, result_position?: never, runtime_mappings?: never, max_samples_per_key?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, query?: never, case_sensitive?: never, event_category_field?: never, tiebreaker_field?: never, timestamp_field?: never, fetch_size?: never, filter?: never, keep_alive?: never, keep_on_completion?: never, wait_for_completion_timeout?: never, allow_partial_search_results?: never, allow_partial_sequence_results?: never, size?: never, fields?: never, result_position?: never, runtime_mappings?: never, max_samples_per_key?: never }
}

export type EqlSearchResponse<TEvent = unknown> = EqlEqlSearchResponseBase<TEvent>

export type EqlSearchResultPosition = 'tail' | 'head'

export type EsqlEsqlFormat = 'csv' | 'json' | 'tsv' | 'txt' | 'yaml' | 'cbor' | 'smile' | 'arrow'

export interface EsqlTableValuesContainer {
  integer?: EsqlTableValuesIntegerValue[]
  keyword?: EsqlTableValuesKeywordValue[]
  long?: EsqlTableValuesLongValue[]
  double?: EsqlTableValuesLongDouble[]
}

export type EsqlTableValuesIntegerValue = integer | integer[]

export type EsqlTableValuesKeywordValue = string | string[]

export type EsqlTableValuesLongDouble = double | double[]

export type EsqlTableValuesLongValue = long | long[]

export interface EsqlAsyncQueryRequest extends RequestBase {
/** If `true`, partial results will be returned if there are shard failures, but the query can continue to execute on other clusters and shards. */
  allow_partial_results?: boolean
  /** The character to use between values within a CSV row. It is valid only for the CSV format. */
  delimiter?: string
  /** Indicates whether columns that are entirely `null` will be removed from the `columns` and `values` portion of the results. If `true`, the response will include an extra section under the name `all_columns` which has the name of all the columns. */
  drop_null_columns?: boolean
  /** A short version of the Accept header, for example `json` or `yaml`. */
  format?: EsqlEsqlFormat
  /** The period for which the query and its results are stored in the cluster. The default period is five days. When this period expires, the query and its results are deleted, even if the query is still ongoing. If the `keep_on_completion` parameter is false, Elasticsearch only stores async queries that do not complete within the period set by the `wait_for_completion_timeout` parameter, regardless of this value. */
  keep_alive?: Duration
  /** Indicates whether the query and its results are stored in the cluster. If false, the query and its results are stored in the cluster only if the request does not complete during the period set by the `wait_for_completion_timeout` parameter. */
  keep_on_completion?: boolean
  /** By default, ES|QL returns results as rows. For example, FROM returns each individual document as one row. For the JSON, YAML, CBOR and smile formats, ES|QL can return the results in a columnar fashion where one row represents all the values of a certain column in the results. */
  columnar?: boolean
  /** Specify a Query DSL query in the filter parameter to filter the set of documents that an ES|QL query runs on. */
  filter?: QueryDslQueryContainer
  locale?: string
  /** To avoid any attempts of hacking or code injection, extract the values in a separate list of parameters. Use question mark placeholders (?) in the query string for each of the parameters. */
  params?: FieldValue[]
  /** If provided and `true` the response will include an extra `profile` object with information on how the query was executed. This information is for human debugging and its format can change at any time but it can give some insight into the performance of each part of the query. */
  profile?: boolean
  /** The ES|QL query API accepts an ES|QL query string in the query parameter, runs it, and returns the results. */
  query: string
  /** Tables to use with the LOOKUP operation. The top level key is the table name and the next level key is the column name. */
  tables?: Record<string, Record<string, EsqlTableValuesContainer>>
  /** When set to `true` and performing a cross-cluster query, the response will include an extra `_clusters` object with information about the clusters that participated in the search along with info such as shards count. */
  include_ccs_metadata?: boolean
  /** The period to wait for the request to finish. By default, the request waits for 1 second for the query results. If the query completes during this period, results are returned Otherwise, a query ID is returned that can later be used to retrieve the results. */
  wait_for_completion_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { allow_partial_results?: never, delimiter?: never, drop_null_columns?: never, format?: never, keep_alive?: never, keep_on_completion?: never, columnar?: never, filter?: never, locale?: never, params?: never, profile?: never, query?: never, tables?: never, include_ccs_metadata?: never, wait_for_completion_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { allow_partial_results?: never, delimiter?: never, drop_null_columns?: never, format?: never, keep_alive?: never, keep_on_completion?: never, columnar?: never, filter?: never, locale?: never, params?: never, profile?: never, query?: never, tables?: never, include_ccs_metadata?: never, wait_for_completion_timeout?: never }
}

export type EsqlAsyncQueryResponse = EsqlResult

export interface EsqlAsyncQueryDeleteRequest extends RequestBase {
/** The unique identifier of the query. A query ID is provided in the ES|QL async query API response for a query that does not complete in the designated time. A query ID is also provided when the request was submitted with the `keep_on_completion` parameter set to `true`. */
  id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export type EsqlAsyncQueryDeleteResponse = AcknowledgedResponseBase

export interface EsqlAsyncQueryGetRequest extends RequestBase {
/** The unique identifier of the query. A query ID is provided in the ES|QL async query API response for a query that does not complete in the designated time. A query ID is also provided when the request was submitted with the `keep_on_completion` parameter set to `true`. */
  id: Id
  /** Indicates whether columns that are entirely `null` will be removed from the `columns` and `values` portion of the results. If `true`, the response will include an extra section under the name `all_columns` which has the name of all the columns. */
  drop_null_columns?: boolean
  /** The period for which the query and its results are stored in the cluster. When this period expires, the query and its results are deleted, even if the query is still ongoing. */
  keep_alive?: Duration
  /** The period to wait for the request to finish. By default, the request waits for complete query results. If the request completes during the period specified in this parameter, complete query results are returned. Otherwise, the response returns an `is_running` value of `true` and no results. */
  wait_for_completion_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, drop_null_columns?: never, keep_alive?: never, wait_for_completion_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, drop_null_columns?: never, keep_alive?: never, wait_for_completion_timeout?: never }
}

export type EsqlAsyncQueryGetResponse = EsqlResult

export interface EsqlAsyncQueryStopRequest extends RequestBase {
/** The unique identifier of the query. A query ID is provided in the ES|QL async query API response for a query that does not complete in the designated time. A query ID is also provided when the request was submitted with the `keep_on_completion` parameter set to `true`. */
  id: Id
  /** Indicates whether columns that are entirely `null` will be removed from the `columns` and `values` portion of the results. If `true`, the response will include an extra section under the name `all_columns` which has the name of all the columns. */
  drop_null_columns?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, drop_null_columns?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, drop_null_columns?: never }
}

export type EsqlAsyncQueryStopResponse = EsqlResult

export interface EsqlQueryRequest extends RequestBase {
/** A short version of the Accept header, e.g. json, yaml. */
  format?: EsqlEsqlFormat
  /** The character to use between values within a CSV row. Only valid for the CSV format. */
  delimiter?: string
  /** Should columns that are entirely `null` be removed from the `columns` and `values` portion of the results? Defaults to `false`. If `true` then the response will include an extra section under the name `all_columns` which has the name of all columns. */
  drop_null_columns?: boolean
  /** If `true`, partial results will be returned if there are shard failures, but the query can continue to execute on other clusters and shards. */
  allow_partial_results?: boolean
  /** By default, ES|QL returns results as rows. For example, FROM returns each individual document as one row. For the JSON, YAML, CBOR and smile formats, ES|QL can return the results in a columnar fashion where one row represents all the values of a certain column in the results. */
  columnar?: boolean
  /** Specify a Query DSL query in the filter parameter to filter the set of documents that an ES|QL query runs on. */
  filter?: QueryDslQueryContainer
  locale?: string
  /** To avoid any attempts of hacking or code injection, extract the values in a separate list of parameters. Use question mark placeholders (?) in the query string for each of the parameters. */
  params?: FieldValue[]
  /** If provided and `true` the response will include an extra `profile` object with information on how the query was executed. This information is for human debugging and its format can change at any time but it can give some insight into the performance of each part of the query. */
  profile?: boolean
  /** The ES|QL query API accepts an ES|QL query string in the query parameter, runs it, and returns the results. */
  query: string
  /** Tables to use with the LOOKUP operation. The top level key is the table name and the next level key is the column name. */
  tables?: Record<string, Record<string, EsqlTableValuesContainer>>
  /** When set to `true` and performing a cross-cluster query, the response will include an extra `_clusters` object with information about the clusters that participated in the search along with info such as shards count. */
  include_ccs_metadata?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { format?: never, delimiter?: never, drop_null_columns?: never, allow_partial_results?: never, columnar?: never, filter?: never, locale?: never, params?: never, profile?: never, query?: never, tables?: never, include_ccs_metadata?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { format?: never, delimiter?: never, drop_null_columns?: never, allow_partial_results?: never, columnar?: never, filter?: never, locale?: never, params?: never, profile?: never, query?: never, tables?: never, include_ccs_metadata?: never }
}

export type EsqlQueryResponse = EsqlResult

export interface FeaturesFeature {
  name: string
  description: string
}

export interface FeaturesGetFeaturesRequest extends RequestBase {
/** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never }
}

export interface FeaturesGetFeaturesResponse {
  features: FeaturesFeature[]
}

export interface FeaturesResetFeaturesRequest extends RequestBase {
/** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never }
}

export interface FeaturesResetFeaturesResponse {
  features: FeaturesFeature[]
}

export type FleetCheckpoint = long

export interface FleetGlobalCheckpointsRequest extends RequestBase {
/** A single index or index alias that resolves to a single index. */
  index: IndexName | IndexAlias
  /** A boolean value which controls whether to wait (until the timeout) for the global checkpoints to advance past the provided `checkpoints`. */
  wait_for_advance?: boolean
  /** A boolean value which controls whether to wait (until the timeout) for the target index to exist and all primary shards be active. Can only be true when `wait_for_advance` is true. */
  wait_for_index?: boolean
  /** A comma separated list of previous global checkpoints. When used in combination with `wait_for_advance`, the API will only return once the global checkpoints advances past the checkpoints. Providing an empty list will cause Elasticsearch to immediately return the current global checkpoints. */
  checkpoints?: FleetCheckpoint[]
  /** Period to wait for a global checkpoints to advance past `checkpoints`. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, wait_for_advance?: never, wait_for_index?: never, checkpoints?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, wait_for_advance?: never, wait_for_index?: never, checkpoints?: never, timeout?: never }
}

export interface FleetGlobalCheckpointsResponse {
  global_checkpoints: FleetCheckpoint[]
  timed_out: boolean
}

export interface FleetMsearchRequest extends RequestBase {
/** A single target to search. If the target is an index alias, it must resolve to a single index. */
  index?: IndexName | IndexAlias
  /** If false, the request returns an error if any wildcard expression, index alias, or _all value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting foo*,bar* returns an error if an index starts with foo but no index starts with bar. */
  allow_no_indices?: boolean
  /** If true, network roundtrips between the coordinating node and remote clusters are minimized for cross-cluster search requests. */
  ccs_minimize_roundtrips?: boolean
  /** Type of index that wildcard expressions can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. */
  expand_wildcards?: ExpandWildcards
  /** If true, concrete, expanded or aliased indices are ignored when frozen. */
  ignore_throttled?: boolean
  /** If true, missing or closed indices are not included in the response. */
  ignore_unavailable?: boolean
  /** Maximum number of concurrent searches the multi search API can execute. */
  max_concurrent_searches?: long
  /** Maximum number of concurrent shard requests that each sub-search request executes per node. */
  max_concurrent_shard_requests?: long
  /** Defines a threshold that enforces a pre-filter roundtrip to prefilter search shards based on query rewriting if the number of shards the search request expands to exceeds the threshold. This filter roundtrip can limit the number of shards significantly if for instance a shard can not match any documents based on its rewrite method i.e., if date filters are mandatory to match but the shard bounds and the query are disjoint. */
  pre_filter_shard_size?: long
  /** Indicates whether global term and document frequencies should be used when scoring returned documents. */
  search_type?: SearchType
  /** If true, hits.total are returned as an integer in the response. Defaults to false, which returns an object. */
  rest_total_hits_as_int?: boolean
  /** Specifies whether aggregation and suggester names should be prefixed by their respective types in the response. */
  typed_keys?: boolean
  /** A comma separated list of checkpoints. When configured, the search API will only be executed on a shard after the relevant checkpoint has become visible for search. Defaults to an empty list which will cause Elasticsearch to immediately execute the search. */
  wait_for_checkpoints?: FleetCheckpoint[]
  /** If true, returns partial results if there are shard request timeouts or [shard failures](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-replication.html#shard-failures). If false, returns an error with no partial results. Defaults to the configured cluster setting `search.default_allow_partial_results` which is true by default. */
  allow_partial_search_results?: boolean
  searches?: MsearchRequestItem[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, ccs_minimize_roundtrips?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, max_concurrent_searches?: never, max_concurrent_shard_requests?: never, pre_filter_shard_size?: never, search_type?: never, rest_total_hits_as_int?: never, typed_keys?: never, wait_for_checkpoints?: never, allow_partial_search_results?: never, searches?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, ccs_minimize_roundtrips?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, max_concurrent_searches?: never, max_concurrent_shard_requests?: never, pre_filter_shard_size?: never, search_type?: never, rest_total_hits_as_int?: never, typed_keys?: never, wait_for_checkpoints?: never, allow_partial_search_results?: never, searches?: never }
}

export interface FleetMsearchResponse<TDocument = unknown> {
  docs: MsearchResponseItem<TDocument>[]
}

export interface FleetSearchRequest extends RequestBase {
/** A single target to search. If the target is an index alias, it must resolve to a single index. */
  index: IndexName | IndexAlias
  allow_no_indices?: boolean
  analyzer?: string
  analyze_wildcard?: boolean
  batched_reduce_size?: long
  ccs_minimize_roundtrips?: boolean
  default_operator?: QueryDslOperator
  df?: string
  expand_wildcards?: ExpandWildcards
  ignore_throttled?: boolean
  ignore_unavailable?: boolean
  lenient?: boolean
  max_concurrent_shard_requests?: long
  preference?: string
  pre_filter_shard_size?: long
  request_cache?: boolean
  routing?: Routing
  scroll?: Duration
  search_type?: SearchType
  /** Specifies which field to use for suggestions. */
  suggest_field?: Field
  suggest_mode?: SuggestMode
  suggest_size?: long
  /** The source text for which the suggestions should be returned. */
  suggest_text?: string
  typed_keys?: boolean
  rest_total_hits_as_int?: boolean
  _source_excludes?: Fields
  _source_includes?: Fields
  q?: string
  /** A comma separated list of checkpoints. When configured, the search API will only be executed on a shard after the relevant checkpoint has become visible for search. Defaults to an empty list which will cause Elasticsearch to immediately execute the search. */
  wait_for_checkpoints?: FleetCheckpoint[]
  /** If true, returns partial results if there are shard request timeouts or [shard failures](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-replication.html#shard-failures). If false, returns an error with no partial results. Defaults to the configured cluster setting `search.default_allow_partial_results` which is true by default. */
  allow_partial_search_results?: boolean
  aggregations?: Record<string, AggregationsAggregationContainer>
  /** @alias aggregations */
  aggs?: Record<string, AggregationsAggregationContainer>
  collapse?: SearchFieldCollapse
  /** If true, returns detailed information about score computation as part of a hit. */
  explain?: boolean
  /** Configuration of search extensions defined by Elasticsearch plugins. */
  ext?: Record<string, any>
  /** Starting document offset. By default, you cannot page through more than 10,000 hits using the from and size parameters. To page through more hits, use the search_after parameter. */
  from?: integer
  highlight?: SearchHighlight
  /** Number of hits matching the query to count accurately. If true, the exact number of hits is returned at the cost of some performance. If false, the response does not include the total number of hits matching the query. Defaults to 10,000 hits. */
  track_total_hits?: SearchTrackHits
  /** Boosts the _score of documents from specified indices. */
  indices_boost?: Record<IndexName, double>[]
  /** Array of wildcard (*) patterns. The request returns doc values for field names matching these patterns in the hits.fields property of the response. */
  docvalue_fields?: (QueryDslFieldAndFormat | Field)[]
  /** Minimum _score for matching documents. Documents with a lower _score are not included in the search results. */
  min_score?: double
  post_filter?: QueryDslQueryContainer
  profile?: boolean
  /** Defines the search definition using the Query DSL. */
  query?: QueryDslQueryContainer
  rescore?: SearchRescore | SearchRescore[]
  /** Retrieve a script evaluation (based on different fields) for each hit. */
  script_fields?: Record<string, ScriptField>
  search_after?: SortResults
  /** The number of hits to return. By default, you cannot page through more than 10,000 hits using the from and size parameters. To page through more hits, use the search_after parameter. */
  size?: integer
  slice?: SlicedScroll
  sort?: Sort
  /** Indicates which source fields are returned for matching documents. These fields are returned in the hits._source property of the search response. */
  _source?: SearchSourceConfig
  /** Array of wildcard (*) patterns. The request returns values for field names matching these patterns in the hits.fields property of the response. */
  fields?: (QueryDslFieldAndFormat | Field)[]
  suggest?: SearchSuggester
  /** Maximum number of documents to collect for each shard. If a query reaches this limit, Elasticsearch terminates the query early. Elasticsearch collects documents before sorting. Defaults to 0, which does not terminate query execution early. */
  terminate_after?: long
  /** Specifies the period of time to wait for a response from each shard. If no response is received before the timeout expires, the request fails and returns an error. Defaults to no timeout. */
  timeout?: string
  /** If true, calculate and return document scores, even if the scores are not used for sorting. */
  track_scores?: boolean
  /** If true, returns document version as part of a hit. */
  version?: boolean
  /** If true, returns sequence number and primary term of the last modification of each hit. See Optimistic concurrency control. */
  seq_no_primary_term?: boolean
  /** List of stored fields to return as part of a hit. If no fields are specified, no stored fields are included in the response. If this field is specified, the _source parameter defaults to false. You can pass _source: true to return both source fields and stored fields in the search response. */
  stored_fields?: Fields
  /** Limits the search to a point in time (PIT). If you provide a PIT, you cannot specify an <index> in the request path. */
  pit?: SearchPointInTimeReference
  /** Defines one or more runtime fields in the search request. These fields take precedence over mapped fields with the same name. */
  runtime_mappings?: MappingRuntimeFields
  /** Stats groups to associate with the search. Each group maintains a statistics aggregation for its associated searches. You can retrieve these stats using the indices stats API. */
  stats?: string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, analyzer?: never, analyze_wildcard?: never, batched_reduce_size?: never, ccs_minimize_roundtrips?: never, default_operator?: never, df?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, lenient?: never, max_concurrent_shard_requests?: never, preference?: never, pre_filter_shard_size?: never, request_cache?: never, routing?: never, scroll?: never, search_type?: never, suggest_field?: never, suggest_mode?: never, suggest_size?: never, suggest_text?: never, typed_keys?: never, rest_total_hits_as_int?: never, _source_excludes?: never, _source_includes?: never, q?: never, wait_for_checkpoints?: never, allow_partial_search_results?: never, aggregations?: never, aggs?: never, collapse?: never, explain?: never, ext?: never, from?: never, highlight?: never, track_total_hits?: never, indices_boost?: never, docvalue_fields?: never, min_score?: never, post_filter?: never, profile?: never, query?: never, rescore?: never, script_fields?: never, search_after?: never, size?: never, slice?: never, sort?: never, _source?: never, fields?: never, suggest?: never, terminate_after?: never, timeout?: never, track_scores?: never, version?: never, seq_no_primary_term?: never, stored_fields?: never, pit?: never, runtime_mappings?: never, stats?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, analyzer?: never, analyze_wildcard?: never, batched_reduce_size?: never, ccs_minimize_roundtrips?: never, default_operator?: never, df?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, lenient?: never, max_concurrent_shard_requests?: never, preference?: never, pre_filter_shard_size?: never, request_cache?: never, routing?: never, scroll?: never, search_type?: never, suggest_field?: never, suggest_mode?: never, suggest_size?: never, suggest_text?: never, typed_keys?: never, rest_total_hits_as_int?: never, _source_excludes?: never, _source_includes?: never, q?: never, wait_for_checkpoints?: never, allow_partial_search_results?: never, aggregations?: never, aggs?: never, collapse?: never, explain?: never, ext?: never, from?: never, highlight?: never, track_total_hits?: never, indices_boost?: never, docvalue_fields?: never, min_score?: never, post_filter?: never, profile?: never, query?: never, rescore?: never, script_fields?: never, search_after?: never, size?: never, slice?: never, sort?: never, _source?: never, fields?: never, suggest?: never, terminate_after?: never, timeout?: never, track_scores?: never, version?: never, seq_no_primary_term?: never, stored_fields?: never, pit?: never, runtime_mappings?: never, stats?: never }
}

export interface FleetSearchResponse<TDocument = unknown> {
  took: long
  timed_out: boolean
  _shards: ShardStatistics
  hits: SearchHitsMetadata<TDocument>
  aggregations?: Record<AggregateName, AggregationsAggregate>
  _clusters?: ClusterStatistics
  fields?: Record<string, any>
  max_score?: double
  num_reduce_phases?: long
  profile?: SearchProfile
  pit_id?: Id
  _scroll_id?: ScrollId
  suggest?: Record<SuggestionName, SearchSuggest<TDocument>[]>
  terminated_early?: boolean
}

export interface GraphConnection {
  doc_count: long
  source: long
  target: long
  weight: double
}

export interface GraphExploreControls {
  sample_diversity?: GraphSampleDiversity
  sample_size?: integer
  timeout?: Duration
  use_significance: boolean
}

export interface GraphHop {
  connections?: GraphHop
  query?: QueryDslQueryContainer
  vertices: GraphVertexDefinition[]
}

export interface GraphSampleDiversity {
  field: Field
  max_docs_per_value: integer
}

export interface GraphVertex {
  depth: long
  field: Field
  term: string
  weight: double
}

export interface GraphVertexDefinition {
  exclude?: string[]
  field: Field
  include?: (GraphVertexInclude | string)[]
  min_doc_count?: long
  shard_min_doc_count?: long
  size?: integer
}

export interface GraphVertexInclude {
  boost?: double
  term: string
}

export interface GraphExploreRequest extends RequestBase {
/** Name of the index. */
  index: Indices
  /** Custom value used to route operations to a specific shard. */
  routing?: Routing
  /** Specifies the period of time to wait for a response from each shard. If no response is received before the timeout expires, the request fails and returns an error. Defaults to no timeout. */
  timeout?: Duration
  /** Specifies or more fields from which you want to extract terms that are associated with the specified vertices. */
  connections?: GraphHop
  /** Direct the Graph API how to build the graph. */
  controls?: GraphExploreControls
  /** A seed query that identifies the documents of interest. Can be any valid Elasticsearch query. */
  query?: QueryDslQueryContainer
  /** Specifies one or more fields that contain the terms you want to include in the graph as vertices. */
  vertices?: GraphVertexDefinition[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, routing?: never, timeout?: never, connections?: never, controls?: never, query?: never, vertices?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, routing?: never, timeout?: never, connections?: never, controls?: never, query?: never, vertices?: never }
}

export interface GraphExploreResponse {
  connections: GraphConnection[]
  failures: ShardFailure[]
  timed_out: boolean
  took: long
  vertices: GraphVertex[]
}

export interface IlmActions {
  allocate?: IlmAllocateAction
  delete?: IlmDeleteAction
  downsample?: IlmDownsampleAction
  freeze?: EmptyObject
  forcemerge?: IlmForceMergeAction
  migrate?: IlmMigrateAction
  readonly?: EmptyObject
  rollover?: IlmRolloverAction
  set_priority?: IlmSetPriorityAction
  searchable_snapshot?: IlmSearchableSnapshotAction
  shrink?: IlmShrinkAction
  unfollow?: EmptyObject
  wait_for_snapshot?: IlmWaitForSnapshotAction
}

export interface IlmAllocateAction {
  number_of_replicas?: integer
  total_shards_per_node?: integer
  include?: Record<string, string>
  exclude?: Record<string, string>
  require?: Record<string, string>
}

export interface IlmDeleteAction {
  delete_searchable_snapshot?: boolean
}

export interface IlmDownsampleAction {
  fixed_interval: DurationLarge
  wait_timeout?: Duration
}

export interface IlmForceMergeAction {
  max_num_segments: integer
  index_codec?: string
}

export interface IlmMigrateAction {
  enabled?: boolean
}

export interface IlmPhase {
  actions?: IlmActions
  min_age?: Duration
}

export interface IlmPhases {
  cold?: IlmPhase
  delete?: IlmPhase
  frozen?: IlmPhase
  hot?: IlmPhase
  warm?: IlmPhase
}

export interface IlmPolicy {
  phases: IlmPhases
  _meta?: Metadata
}

export interface IlmRolloverAction {
  max_size?: ByteSize
  max_primary_shard_size?: ByteSize
  max_age?: Duration
  max_docs?: long
  max_primary_shard_docs?: long
  min_size?: ByteSize
  min_primary_shard_size?: ByteSize
  min_age?: Duration
  min_docs?: long
  min_primary_shard_docs?: long
}

export interface IlmSearchableSnapshotAction {
  snapshot_repository: string
  force_merge_index?: boolean
}

export interface IlmSetPriorityAction {
  priority?: integer
}

export interface IlmShrinkAction {
  number_of_shards?: integer
  max_primary_shard_size?: ByteSize
  allow_write_after_shrink?: boolean
}

export interface IlmWaitForSnapshotAction {
  policy: string
}

export interface IlmDeleteLifecycleRequest extends RequestBase {
/** Identifier for the policy. */
  name: Name
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
}

export type IlmDeleteLifecycleResponse = AcknowledgedResponseBase

export type IlmExplainLifecycleLifecycleExplain = IlmExplainLifecycleLifecycleExplainManaged | IlmExplainLifecycleLifecycleExplainUnmanaged

export interface IlmExplainLifecycleLifecycleExplainManaged {
  action?: Name
  action_time?: DateTime
  action_time_millis?: EpochTime<UnitMillis>
  age?: Duration
  failed_step?: Name
  failed_step_retry_count?: integer
  index: IndexName
  index_creation_date?: DateTime
  index_creation_date_millis?: EpochTime<UnitMillis>
  is_auto_retryable_error?: boolean
  lifecycle_date?: DateTime
  lifecycle_date_millis?: EpochTime<UnitMillis>
  managed: true
  phase: Name
  phase_time?: DateTime
  phase_time_millis?: EpochTime<UnitMillis>
  policy?: Name
  previous_step_info?: Record<string, any>
  repository_name?: string
  snapshot_name?: string
  shrink_index_name?: string
  step?: Name
  step_info?: Record<string, any>
  step_time?: DateTime
  step_time_millis?: EpochTime<UnitMillis>
  phase_execution?: IlmExplainLifecycleLifecycleExplainPhaseExecution
  time_since_index_creation?: Duration
}

export interface IlmExplainLifecycleLifecycleExplainPhaseExecution {
  phase_definition?: IlmPhase
  policy: Name
  version: VersionNumber
  modified_date_in_millis: EpochTime<UnitMillis>
}

export interface IlmExplainLifecycleLifecycleExplainUnmanaged {
  index: IndexName
  managed: false
}

export interface IlmExplainLifecycleRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and aliases to target. Supports wildcards (`*`). To target all data streams and indices, use `*` or `_all`. */
  index: IndexName
  /** Filters the returned indices to only indices that are managed by ILM and are in an error state, either due to an encountering an error while executing the policy, or attempting to use a policy that does not exist. */
  only_errors?: boolean
  /** Filters the returned indices to only indices that are managed by ILM. */
  only_managed?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, only_errors?: never, only_managed?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, only_errors?: never, only_managed?: never, master_timeout?: never }
}

export interface IlmExplainLifecycleResponse {
  indices: Record<IndexName, IlmExplainLifecycleLifecycleExplain>
}

export interface IlmGetLifecycleLifecycle {
  modified_date: DateTime
  policy: IlmPolicy
  version: VersionNumber
}

export interface IlmGetLifecycleRequest extends RequestBase {
/** Identifier for the policy. */
  name?: Name
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
}

export type IlmGetLifecycleResponse = Record<string, IlmGetLifecycleLifecycle>

export interface IlmGetStatusRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface IlmGetStatusResponse {
  operation_mode: LifecycleOperationMode
}

export interface IlmMigrateToDataTiersRequest extends RequestBase {
/** If true, simulates the migration from node attributes based allocation filters to data tiers, but does not perform the migration. This provides a way to retrieve the indices and ILM policies that need to be migrated. */
  dry_run?: boolean
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  legacy_template_to_delete?: string
  node_attribute?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { dry_run?: never, master_timeout?: never, legacy_template_to_delete?: never, node_attribute?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { dry_run?: never, master_timeout?: never, legacy_template_to_delete?: never, node_attribute?: never }
}

export interface IlmMigrateToDataTiersResponse {
  dry_run: boolean
  removed_legacy_template: string
  migrated_ilm_policies: string[]
  migrated_indices: Indices
  migrated_legacy_templates: string[]
  migrated_composable_templates: string[]
  migrated_component_templates: string[]
}

export interface IlmMoveToStepRequest extends RequestBase {
/** The name of the index whose lifecycle step is to change */
  index: IndexName
  /** The step that the index is expected to be in. */
  current_step: IlmMoveToStepStepKey
  /** The step that you want to run. */
  next_step: IlmMoveToStepStepKey
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, current_step?: never, next_step?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, current_step?: never, next_step?: never }
}

export type IlmMoveToStepResponse = AcknowledgedResponseBase

export interface IlmMoveToStepStepKey {
  action?: string
  name?: string
  phase: string
}

export interface IlmPutLifecycleRequest extends RequestBase {
/** Identifier for the policy. */
  name: Name
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  policy?: IlmPolicy
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never, policy?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never, policy?: never }
}

export type IlmPutLifecycleResponse = AcknowledgedResponseBase

export interface IlmRemovePolicyRequest extends RequestBase {
/** The name of the index to remove policy on */
  index: IndexName
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never }
}

export interface IlmRemovePolicyResponse {
  failed_indexes: IndexName[]
  has_failures: boolean
}

export interface IlmRetryRequest extends RequestBase {
/** The name of the indices (comma-separated) whose failed lifecycle step is to be retry */
  index: IndexName
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never }
}

export type IlmRetryResponse = AcknowledgedResponseBase

export interface IlmStartRequest extends RequestBase {
/** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never, timeout?: never }
}

export type IlmStartResponse = AcknowledgedResponseBase

export interface IlmStopRequest extends RequestBase {
/** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never, timeout?: never }
}

export type IlmStopResponse = AcknowledgedResponseBase

export interface IndicesAlias {
  filter?: QueryDslQueryContainer
  index_routing?: Routing
  is_hidden?: boolean
  is_write_index?: boolean
  routing?: Routing
  search_routing?: Routing
}

export interface IndicesAliasDefinition {
  filter?: QueryDslQueryContainer
  index_routing?: string
  is_write_index?: boolean
  routing?: string
  search_routing?: string
  is_hidden?: boolean
}

export interface IndicesCacheQueries {
  enabled: boolean
}

export interface IndicesDataStream {
  _meta?: Metadata
  allow_custom_routing?: boolean
  failure_store?: IndicesFailureStore
  generation: integer
  hidden: boolean
  ilm_policy?: Name
  next_generation_managed_by: IndicesManagedBy
  prefer_ilm: boolean
  indices: IndicesDataStreamIndex[]
  lifecycle?: IndicesDataStreamLifecycleWithRollover
  name: DataStreamName
  replicated?: boolean
  rollover_on_write: boolean
  status: HealthStatus
  system?: boolean
  template: Name
  timestamp_field: IndicesDataStreamTimestampField
  index_mode?: IndicesIndexMode
}

export interface IndicesDataStreamIndex {
  index_name: IndexName
  index_uuid: Uuid
  ilm_policy?: Name
  managed_by?: IndicesManagedBy
  prefer_ilm?: boolean
  index_mode?: IndicesIndexMode
}

export interface IndicesDataStreamLifecycle {
  data_retention?: Duration
  downsampling?: IndicesDataStreamLifecycleDownsampling
  enabled?: boolean
}

export interface IndicesDataStreamLifecycleDownsampling {
  rounds: IndicesDownsamplingRound[]
}

export interface IndicesDataStreamLifecycleRolloverConditions {
  min_age?: Duration
  max_age?: string
  min_docs?: long
  max_docs?: long
  min_size?: ByteSize
  max_size?: ByteSize
  min_primary_shard_size?: ByteSize
  max_primary_shard_size?: ByteSize
  min_primary_shard_docs?: long
  max_primary_shard_docs?: long
}

export interface IndicesDataStreamLifecycleWithRollover extends IndicesDataStreamLifecycle {
  rollover?: IndicesDataStreamLifecycleRolloverConditions
}

export interface IndicesDataStreamTimestampField {
  name: Field
}

export interface IndicesDataStreamVisibility {
  hidden?: boolean
  allow_custom_routing?: boolean
}

export interface IndicesDownsampleConfig {
  fixed_interval: DurationLarge
}

export interface IndicesDownsamplingRound {
  after: Duration
  config: IndicesDownsampleConfig
}

export interface IndicesFailureStore {
  enabled: boolean
  indices: IndicesDataStreamIndex[]
  rollover_on_write: boolean
}

export interface IndicesFielddataFrequencyFilter {
  max: double
  min: double
  min_segment_size: integer
}

export type IndicesIndexCheckOnStartup = boolean | 'true' | 'false' | 'checksum'

export type IndicesIndexMode = 'standard' | 'time_series' | 'logsdb' | 'lookup'

export interface IndicesIndexRouting {
  allocation?: IndicesIndexRoutingAllocation
  rebalance?: IndicesIndexRoutingRebalance
}

export interface IndicesIndexRoutingAllocation {
  enable?: IndicesIndexRoutingAllocationOptions
  include?: IndicesIndexRoutingAllocationInclude
  initial_recovery?: IndicesIndexRoutingAllocationInitialRecovery
  disk?: IndicesIndexRoutingAllocationDisk
}

export interface IndicesIndexRoutingAllocationDisk {
  threshold_enabled?: boolean | string
}

export interface IndicesIndexRoutingAllocationInclude {
  _tier_preference?: string
  _id?: Id
}

export interface IndicesIndexRoutingAllocationInitialRecovery {
  _id?: Id
}

export type IndicesIndexRoutingAllocationOptions = 'all' | 'primaries' | 'new_primaries' | 'none'

export interface IndicesIndexRoutingRebalance {
  enable: IndicesIndexRoutingRebalanceOptions
}

export type IndicesIndexRoutingRebalanceOptions = 'all' | 'primaries' | 'replicas' | 'none'

export interface IndicesIndexSegmentSort {
  field?: Fields
  order?: IndicesSegmentSortOrder | IndicesSegmentSortOrder[]
  mode?: IndicesSegmentSortMode | IndicesSegmentSortMode[]
  missing?: IndicesSegmentSortMissing | IndicesSegmentSortMissing[]
}

export interface IndicesIndexSettingBlocks {
  read_only?: SpecUtilsStringified<boolean>
  read_only_allow_delete?: SpecUtilsStringified<boolean>
  read?: SpecUtilsStringified<boolean>
  write?: SpecUtilsStringified<boolean>
  metadata?: SpecUtilsStringified<boolean>
}

export interface IndicesIndexSettingsKeys {
  index?: IndicesIndexSettings
  mode?: string
  routing_path?: string | string[]
  soft_deletes?: IndicesSoftDeletes
  sort?: IndicesIndexSegmentSort
  number_of_shards?: integer | string
  number_of_replicas?: integer | string
  number_of_routing_shards?: integer
  check_on_startup?: IndicesIndexCheckOnStartup
  codec?: string
  routing_partition_size?: SpecUtilsStringified<integer>
  load_fixed_bitset_filters_eagerly?: boolean
  hidden?: boolean | string
  auto_expand_replicas?: SpecUtilsWithNullValue<string>
  merge?: IndicesMerge
  search?: IndicesSettingsSearch
  refresh_interval?: Duration
  max_result_window?: integer
  max_inner_result_window?: integer
  max_rescore_window?: integer
  max_docvalue_fields_search?: integer
  max_script_fields?: integer
  max_ngram_diff?: integer
  max_shingle_diff?: integer
  blocks?: IndicesIndexSettingBlocks
  max_refresh_listeners?: integer
  analyze?: IndicesSettingsAnalyze
  highlight?: IndicesSettingsHighlight
  max_terms_count?: integer
  max_regex_length?: integer
  routing?: IndicesIndexRouting
  gc_deletes?: Duration
  default_pipeline?: PipelineName
  final_pipeline?: PipelineName
  lifecycle?: IndicesIndexSettingsLifecycle
  provided_name?: Name
  creation_date?: SpecUtilsStringified<EpochTime<UnitMillis>>
  creation_date_string?: DateTime
  uuid?: Uuid
  version?: IndicesIndexVersioning
  verified_before_close?: boolean | string
  format?: string | integer
  max_slices_per_scroll?: integer
  translog?: IndicesTranslog
  query_string?: IndicesSettingsQueryString
  priority?: integer | string
  top_metrics_max_size?: integer
  analysis?: IndicesIndexSettingsAnalysis
  settings?: IndicesIndexSettings
  time_series?: IndicesIndexSettingsTimeSeries
  queries?: IndicesQueries
  similarity?: Record<string, IndicesSettingsSimilarity>
  mapping?: IndicesMappingLimitSettings
  'indexing.slowlog'?: IndicesIndexingSlowlogSettings
  indexing_pressure?: IndicesIndexingPressure
  store?: IndicesStorage
}
export type IndicesIndexSettings = IndicesIndexSettingsKeys
& { [property: string]: any }

export interface IndicesIndexSettingsAnalysis {
  analyzer?: Record<string, AnalysisAnalyzer>
  char_filter?: Record<string, AnalysisCharFilter>
  filter?: Record<string, AnalysisTokenFilter>
  normalizer?: Record<string, AnalysisNormalizer>
  tokenizer?: Record<string, AnalysisTokenizer>
}

export interface IndicesIndexSettingsLifecycle {
  name?: Name
  indexing_complete?: SpecUtilsStringified<boolean>
  origination_date?: long
  parse_origination_date?: boolean
  step?: IndicesIndexSettingsLifecycleStep
  rollover_alias?: string
  prefer_ilm?: boolean | string
}

export interface IndicesIndexSettingsLifecycleStep {
  wait_time_threshold?: Duration
}

export interface IndicesIndexSettingsTimeSeries {
  end_time?: DateTime
  start_time?: DateTime
}

export interface IndicesIndexState {
  aliases?: Record<IndexName, IndicesAlias>
  mappings?: MappingTypeMapping
  settings?: IndicesIndexSettings
  defaults?: IndicesIndexSettings
  data_stream?: DataStreamName
  lifecycle?: IndicesDataStreamLifecycle
}

export interface IndicesIndexTemplate {
  index_patterns: Names
  composed_of: Name[]
  template?: IndicesIndexTemplateSummary
  version?: VersionNumber
  priority?: long
  _meta?: Metadata
  allow_auto_create?: boolean
  data_stream?: IndicesIndexTemplateDataStreamConfiguration
  deprecated?: boolean
  ignore_missing_component_templates?: Names
}

export interface IndicesIndexTemplateDataStreamConfiguration {
  hidden?: boolean
  allow_custom_routing?: boolean
}

export interface IndicesIndexTemplateSummary {
  aliases?: Record<IndexName, IndicesAlias>
  mappings?: MappingTypeMapping
  settings?: IndicesIndexSettings
  lifecycle?: IndicesDataStreamLifecycleWithRollover
}

export interface IndicesIndexVersioning {
  created?: VersionString
  created_string?: string
}

export interface IndicesIndexingPressure {
  memory: IndicesIndexingPressureMemory
}

export interface IndicesIndexingPressureMemory {
  limit?: integer
}

export interface IndicesIndexingSlowlogSettings {
  level?: string
  source?: integer
  reformat?: boolean
  threshold?: IndicesIndexingSlowlogTresholds
}

export interface IndicesIndexingSlowlogTresholds {
  index?: IndicesSlowlogTresholdLevels
}

export type IndicesManagedBy = 'Index Lifecycle Management' | 'Data stream lifecycle' | 'Unmanaged'

export interface IndicesMappingLimitSettings {
  coerce?: boolean
  total_fields?: IndicesMappingLimitSettingsTotalFields
  depth?: IndicesMappingLimitSettingsDepth
  nested_fields?: IndicesMappingLimitSettingsNestedFields
  nested_objects?: IndicesMappingLimitSettingsNestedObjects
  field_name_length?: IndicesMappingLimitSettingsFieldNameLength
  dimension_fields?: IndicesMappingLimitSettingsDimensionFields
  source?: IndicesMappingLimitSettingsSourceFields
  ignore_malformed?: boolean | string
}

export interface IndicesMappingLimitSettingsDepth {
  limit?: long
}

export interface IndicesMappingLimitSettingsDimensionFields {
  limit?: long
}

export interface IndicesMappingLimitSettingsFieldNameLength {
  limit?: long
}

export interface IndicesMappingLimitSettingsNestedFields {
  limit?: long
}

export interface IndicesMappingLimitSettingsNestedObjects {
  limit?: long
}

export interface IndicesMappingLimitSettingsSourceFields {
  mode: IndicesSourceMode
}

export interface IndicesMappingLimitSettingsTotalFields {
  limit?: long | string
  ignore_dynamic_beyond_limit?: boolean | string
}

export interface IndicesMerge {
  scheduler?: IndicesMergeScheduler
}

export interface IndicesMergeScheduler {
  max_thread_count?: SpecUtilsStringified<integer>
  max_merge_count?: SpecUtilsStringified<integer>
}

export interface IndicesNumericFielddata {
  format: IndicesNumericFielddataFormat
}

export type IndicesNumericFielddataFormat = 'array' | 'disabled'

export interface IndicesQueries {
  cache?: IndicesCacheQueries
}

export interface IndicesRetentionLease {
  period: Duration
}

export interface IndicesSearchIdle {
  after?: Duration
}

export type IndicesSegmentSortMissing = '_last' | '_first'

export type IndicesSegmentSortMode = 'min' | 'MIN' | 'max' | 'MAX'

export type IndicesSegmentSortOrder = 'asc' | 'ASC' | 'desc' | 'DESC'

export interface IndicesSettingsAnalyze {
  max_token_count?: SpecUtilsStringified<integer>
}

export interface IndicesSettingsHighlight {
  max_analyzed_offset?: integer
}

export interface IndicesSettingsQueryString {
  lenient: SpecUtilsStringified<boolean>
}

export interface IndicesSettingsSearch {
  idle?: IndicesSearchIdle
  slowlog?: IndicesSlowlogSettings
}

export type IndicesSettingsSimilarity = IndicesSettingsSimilarityBm25 | IndicesSettingsSimilarityBoolean | IndicesSettingsSimilarityDfi | IndicesSettingsSimilarityDfr | IndicesSettingsSimilarityIb | IndicesSettingsSimilarityLmd | IndicesSettingsSimilarityLmj | IndicesSettingsSimilarityScripted

export interface IndicesSettingsSimilarityBm25 {
  type: 'BM25'
  b?: double
  discount_overlaps?: boolean
  k1?: double
}

export interface IndicesSettingsSimilarityBoolean {
  type: 'boolean'
}

export interface IndicesSettingsSimilarityDfi {
  type: 'DFI'
  independence_measure: DFIIndependenceMeasure
}

export interface IndicesSettingsSimilarityDfr {
  type: 'DFR'
  after_effect: DFRAfterEffect
  basic_model: DFRBasicModel
  normalization: Normalization
}

export interface IndicesSettingsSimilarityIb {
  type: 'IB'
  distribution: IBDistribution
  lambda: IBLambda
  normalization: Normalization
}

export interface IndicesSettingsSimilarityLmd {
  type: 'LMDirichlet'
  mu?: double
}

export interface IndicesSettingsSimilarityLmj {
  type: 'LMJelinekMercer'
  lambda?: double
}

export interface IndicesSettingsSimilarityScripted {
  type: 'scripted'
  script: Script | string
  weight_script?: Script | string
}

export interface IndicesSlowlogSettings {
  level?: string
  source?: integer
  reformat?: boolean
  threshold?: IndicesSlowlogTresholds
}

export interface IndicesSlowlogTresholdLevels {
  warn?: Duration
  info?: Duration
  debug?: Duration
  trace?: Duration
}

export interface IndicesSlowlogTresholds {
  query?: IndicesSlowlogTresholdLevels
  fetch?: IndicesSlowlogTresholdLevels
}

export interface IndicesSoftDeletes {
  enabled?: boolean
  retention_lease?: IndicesRetentionLease
}

export type IndicesSourceMode = 'disabled' | 'stored' | 'synthetic'

export interface IndicesStorage {
  type: IndicesStorageType
  allow_mmap?: boolean
}

export type IndicesStorageType = 'fs' | 'niofs' | 'mmapfs' | 'hybridfs' | string

export interface IndicesTemplateMapping {
  aliases: Record<IndexName, IndicesAlias>
  index_patterns: Name[]
  mappings: MappingTypeMapping
  order: integer
  settings: Record<string, any>
  version?: VersionNumber
}

export interface IndicesTranslog {
  sync_interval?: Duration
  durability?: IndicesTranslogDurability
  flush_threshold_size?: ByteSize
  retention?: IndicesTranslogRetention
}

export type IndicesTranslogDurability = 'request' | 'REQUEST' | 'async' | 'ASYNC'

export interface IndicesTranslogRetention {
  size?: ByteSize
  age?: Duration
}

export type IndicesAddBlockIndicesBlockOptions = 'metadata' | 'read' | 'read_only' | 'write'

export interface IndicesAddBlockIndicesBlockStatus {
  name: IndexName
  blocked: boolean
}

export interface IndicesAddBlockRequest extends RequestBase {
/** A comma-separated list or wildcard expression of index names used to limit the request. By default, you must explicitly name the indices you are adding blocks to. To allow the adding of blocks to indices with `_all`, `*`, or other wildcard expressions, change the `action.destructive_requires_name` setting to `false`. You can update this setting in the `elasticsearch.yml` file or by using the cluster update settings API. */
  index: IndexName
  /** The block type to add to the index. */
  block: IndicesAddBlockIndicesBlockOptions
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. */
  allow_no_indices?: boolean
  /** The type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. It supports comma-separated values, such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** The period to wait for the master node. If the master node is not available before the timeout expires, the request fails and returns an error. It can also be set to `-1` to indicate that the request should never timeout. */
  master_timeout?: Duration
  /** The period to wait for a response from all relevant nodes in the cluster after updating the cluster metadata. If no response is received before the timeout expires, the cluster metadata update still applies but the response will indicate that it was not completely acknowledged. It can also be set to `-1` to indicate that the request should never timeout. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, block?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, block?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never, timeout?: never }
}

export interface IndicesAddBlockResponse {
  acknowledged: boolean
  shards_acknowledged: boolean
  indices: IndicesAddBlockIndicesBlockStatus[]
}

export interface IndicesAnalyzeAnalyzeDetail {
  analyzer?: IndicesAnalyzeAnalyzerDetail
  charfilters?: IndicesAnalyzeCharFilterDetail[]
  custom_analyzer: boolean
  tokenfilters?: IndicesAnalyzeTokenDetail[]
  tokenizer?: IndicesAnalyzeTokenDetail
}

export interface IndicesAnalyzeAnalyzeToken {
  end_offset: long
  position: long
  positionLength?: long
  start_offset: long
  token: string
  type: string
}

export interface IndicesAnalyzeAnalyzerDetail {
  name: string
  tokens: IndicesAnalyzeExplainAnalyzeToken[]
}

export interface IndicesAnalyzeCharFilterDetail {
  filtered_text: string[]
  name: string
}

export interface IndicesAnalyzeExplainAnalyzeTokenKeys {
  bytes: string
  end_offset: long
  keyword?: boolean
  position: long
  positionLength: long
  start_offset: long
  termFrequency: long
  token: string
  type: string
}
export type IndicesAnalyzeExplainAnalyzeToken = IndicesAnalyzeExplainAnalyzeTokenKeys
& { [property: string]: any }

export interface IndicesAnalyzeRequest extends RequestBase {
/** Index used to derive the analyzer. If specified, the `analyzer` or field parameter overrides this value. If no index is specified or the index does not have a default analyzer, the analyze API uses the standard analyzer. */
  index?: IndexName
  /** The name of the analyzer that should be applied to the provided `text`. This could be a built-in analyzer, or an analyzer that’s been configured in the index. */
  analyzer?: string
  /** Array of token attributes used to filter the output of the `explain` parameter. */
  attributes?: string[]
  /** Array of character filters used to preprocess characters before the tokenizer. */
  char_filter?: AnalysisCharFilter[]
  /** If `true`, the response includes token attributes and additional details. */
  explain?: boolean
  /** Field used to derive the analyzer. To use this parameter, you must specify an index. If specified, the `analyzer` parameter overrides this value. */
  field?: Field
  /** Array of token filters used to apply after the tokenizer. */
  filter?: AnalysisTokenFilter[]
  /** Normalizer to use to convert text into a single token. */
  normalizer?: string
  /** Text to analyze. If an array of strings is provided, it is analyzed as a multi-value field. */
  text?: IndicesAnalyzeTextToAnalyze
  /** Tokenizer to use to convert text into tokens. */
  tokenizer?: AnalysisTokenizer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, analyzer?: never, attributes?: never, char_filter?: never, explain?: never, field?: never, filter?: never, normalizer?: never, text?: never, tokenizer?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, analyzer?: never, attributes?: never, char_filter?: never, explain?: never, field?: never, filter?: never, normalizer?: never, text?: never, tokenizer?: never }
}

export interface IndicesAnalyzeResponse {
  detail?: IndicesAnalyzeAnalyzeDetail
  tokens?: IndicesAnalyzeAnalyzeToken[]
}

export type IndicesAnalyzeTextToAnalyze = string | string[]

export interface IndicesAnalyzeTokenDetail {
  name: string
  tokens: IndicesAnalyzeExplainAnalyzeToken[]
}

export interface IndicesCancelMigrateReindexRequest extends RequestBase {
/** The index or data stream name */
  index: Indices
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never }
}

export type IndicesCancelMigrateReindexResponse = AcknowledgedResponseBase

export interface IndicesClearCacheRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, clears the fields cache. Use the `fields` parameter to clear the cache of specific fields only. */
  fielddata?: boolean
  /** Comma-separated list of field names used to limit the `fielddata` parameter. */
  fields?: Fields
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** If `true`, clears the query cache. */
  query?: boolean
  /** If `true`, clears the request cache. */
  request?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, fielddata?: never, fields?: never, ignore_unavailable?: never, query?: never, request?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, fielddata?: never, fields?: never, ignore_unavailable?: never, query?: never, request?: never }
}

export type IndicesClearCacheResponse = ShardsOperationResponseBase

export interface IndicesCloneRequest extends RequestBase {
/** Name of the source index to clone. */
  index: IndexName
  /** Name of the target index to create. */
  target: Name
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** The number of shard copies that must be active before proceeding with the operation. Set to `all` or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). */
  wait_for_active_shards?: WaitForActiveShards
  /** Aliases for the resulting index. */
  aliases?: Record<IndexName, IndicesAlias>
  /** Configuration options for the target index. */
  settings?: Record<string, any>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, target?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never, aliases?: never, settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, target?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never, aliases?: never, settings?: never }
}

export interface IndicesCloneResponse {
  acknowledged: boolean
  index: IndexName
  shards_acknowledged: boolean
}

export interface IndicesCloseCloseIndexResult {
  closed: boolean
  shards?: Record<string, IndicesCloseCloseShardResult>
}

export interface IndicesCloseCloseShardResult {
  failures: ShardFailure[]
}

export interface IndicesCloseRequest extends RequestBase {
/** Comma-separated list or wildcard expression of index names used to limit the request. */
  index: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** The number of shard copies that must be active before proceeding with the operation. Set to `all` or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). */
  wait_for_active_shards?: WaitForActiveShards
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never }
}

export interface IndicesCloseResponse {
  acknowledged: boolean
  indices: Record<IndexName, IndicesCloseCloseIndexResult>
  shards_acknowledged: boolean
}

export interface IndicesCreateRequest extends RequestBase {
/** Name of the index you wish to create. */
  index: IndexName
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** The number of shard copies that must be active before proceeding with the operation. Set to `all` or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). */
  wait_for_active_shards?: WaitForActiveShards
  /** Aliases for the index. */
  aliases?: Record<Name, IndicesAlias>
  /** Mapping for fields in the index. If specified, this mapping can include: - Field names - Field data types - Mapping parameters */
  mappings?: MappingTypeMapping
  /** Configuration options for the index. */
  settings?: IndicesIndexSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never, aliases?: never, mappings?: never, settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never, aliases?: never, mappings?: never, settings?: never }
}

export interface IndicesCreateResponse {
  index: IndexName
  shards_acknowledged: boolean
  acknowledged: boolean
}

export interface IndicesCreateDataStreamRequest extends RequestBase {
/** Name of the data stream, which must meet the following criteria: Lowercase only; Cannot include `\`, `/`, `*`, `?`, `"`, `<`, `>`, `|`, `,`, `#`, `:`, or a space character; Cannot start with `-`, `_`, `+`, or `.ds-`; Cannot be `.` or `..`; Cannot be longer than 255 bytes. Multi-byte characters count towards this limit faster. */
  name: DataStreamName
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
}

export type IndicesCreateDataStreamResponse = AcknowledgedResponseBase

export interface IndicesCreateFromCreateFrom {
  mappings_override?: MappingTypeMapping
  settings_override?: IndicesIndexSettings
  remove_index_blocks?: boolean
}

export interface IndicesCreateFromRequest extends RequestBase {
/** The source index or data stream name */
  source: IndexName
  /** The destination index or data stream name */
  dest: IndexName
  create_from?: IndicesCreateFromCreateFrom
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { source?: never, dest?: never, create_from?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { source?: never, dest?: never, create_from?: never }
}

export interface IndicesCreateFromResponse {
  acknowledged: boolean
  index: IndexName
  shards_acknowledged: boolean
}

export interface IndicesDataStreamsStatsDataStreamsStatsItem {
  backing_indices: integer
  data_stream: Name
  maximum_timestamp: EpochTime<UnitMillis>
  store_size?: ByteSize
  store_size_bytes: long
}

export interface IndicesDataStreamsStatsRequest extends RequestBase {
/** Comma-separated list of data streams used to limit the request. Wildcard expressions (`*`) are supported. To target all data streams in a cluster, omit this parameter or use `*`. */
  name?: IndexName
  /** Type of data stream that wildcard patterns can match. Supports comma-separated values, such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, expand_wildcards?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, expand_wildcards?: never }
}

export interface IndicesDataStreamsStatsResponse {
  _shards: ShardStatistics
  backing_indices: integer
  data_stream_count: integer
  data_streams: IndicesDataStreamsStatsDataStreamsStatsItem[]
  total_store_sizes?: ByteSize
  total_store_size_bytes: long
}

export interface IndicesDeleteRequest extends RequestBase {
/** Comma-separated list of indices to delete. You cannot specify index aliases. By default, this parameter does not support wildcards (`*`) or `_all`. To use wildcards or `_all`, set the `action.destructive_requires_name` cluster setting to `false`. */
  index: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never, timeout?: never }
}

export type IndicesDeleteResponse = IndicesResponseBase

export interface IndicesDeleteAliasRequest extends RequestBase {
/** Comma-separated list of data streams or indices used to limit the request. Supports wildcards (`*`). */
  index: Indices
  /** Comma-separated list of aliases to remove. Supports wildcards (`*`). To remove all aliases, use `*` or `_all`. */
  name: Names
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, name?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, name?: never, master_timeout?: never, timeout?: never }
}

export type IndicesDeleteAliasResponse = AcknowledgedResponseBase

export interface IndicesDeleteDataLifecycleRequest extends RequestBase {
/** A comma-separated list of data streams of which the data stream lifecycle will be deleted; use `*` to get all data streams */
  name: DataStreamNames
  /** Whether wildcard expressions should get expanded to open or closed indices (default: open) */
  expand_wildcards?: ExpandWildcards
  /** Specify timeout for connection to master */
  master_timeout?: Duration
  /** Explicit timestamp for the document */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, expand_wildcards?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, expand_wildcards?: never, master_timeout?: never, timeout?: never }
}

export type IndicesDeleteDataLifecycleResponse = AcknowledgedResponseBase

export interface IndicesDeleteDataStreamRequest extends RequestBase {
/** Comma-separated list of data streams to delete. Wildcard (`*`) expressions are supported. */
  name: DataStreamNames
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Type of data stream that wildcard patterns can match. Supports comma-separated values,such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, expand_wildcards?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, expand_wildcards?: never }
}

export type IndicesDeleteDataStreamResponse = AcknowledgedResponseBase

export interface IndicesDeleteIndexTemplateRequest extends RequestBase {
/** Comma-separated list of index template names used to limit the request. Wildcard (*) expressions are supported. */
  name: Names
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
}

export type IndicesDeleteIndexTemplateResponse = AcknowledgedResponseBase

export interface IndicesDeleteTemplateRequest extends RequestBase {
/** The name of the legacy index template to delete. Wildcard (`*`) expressions are supported. */
  name: Name
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
}

export type IndicesDeleteTemplateResponse = AcknowledgedResponseBase

export interface IndicesDiskUsageRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and aliases used to limit the request. It’s recommended to execute this API with a single index (or the latest backing index of a data stream) as the API consumes resources significantly. */
  index: Indices
  /** If false, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, the API performs a flush before analysis. If `false`, the response may not include uncommitted data. */
  flush?: boolean
  /** If `true`, missing or closed indices are not included in the response. */
  ignore_unavailable?: boolean
  /** Analyzing field disk usage is resource-intensive. To use the API, this parameter must be set to `true`. */
  run_expensive_tasks?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, flush?: never, ignore_unavailable?: never, run_expensive_tasks?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, flush?: never, ignore_unavailable?: never, run_expensive_tasks?: never }
}

export type IndicesDiskUsageResponse = any

export interface IndicesDownsampleRequest extends RequestBase {
/** Name of the time series index to downsample. */
  index: IndexName
  /** Name of the index to create. */
  target_index: IndexName
  config?: IndicesDownsampleConfig
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, target_index?: never, config?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, target_index?: never, config?: never }
}

export type IndicesDownsampleResponse = any

export interface IndicesExistsRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and aliases. Supports wildcards (`*`). */
  index: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, returns settings in flat format. */
  flat_settings?: boolean
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** If `true`, return all default settings in the response. */
  include_defaults?: boolean
  /** If `true`, the request retrieves information from the local node only. */
  local?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, flat_settings?: never, ignore_unavailable?: never, include_defaults?: never, local?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, flat_settings?: never, ignore_unavailable?: never, include_defaults?: never, local?: never }
}

export type IndicesExistsResponse = boolean

export interface IndicesExistsAliasRequest extends RequestBase {
/** Comma-separated list of aliases to check. Supports wildcards (`*`). */
  name: Names
  /** Comma-separated list of data streams or indices used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `false`, requests that include a missing data stream or index in the target indices or data streams return an error. */
  ignore_unavailable?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never }
}

export type IndicesExistsAliasResponse = boolean

export interface IndicesExistsIndexTemplateRequest extends RequestBase {
/** Comma-separated list of index template names used to limit the request. Wildcard (*) expressions are supported. */
  name: Name
  /** If true, the request retrieves information from the local node only. Defaults to false, which means information is retrieved from the master node. */
  local?: boolean
  /** If true, returns settings in flat format. */
  flat_settings?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, local?: never, flat_settings?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, local?: never, flat_settings?: never, master_timeout?: never }
}

export type IndicesExistsIndexTemplateResponse = boolean

export interface IndicesExistsTemplateRequest extends RequestBase {
/** A comma-separated list of index template names used to limit the request. Wildcard (`*`) expressions are supported. */
  name: Names
  /** Indicates whether to use a flat format for the response. */
  flat_settings?: boolean
  /** Indicates whether to get information from the local node only. */
  local?: boolean
  /** The period to wait for the master node. If the master node is not available before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, flat_settings?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, flat_settings?: never, local?: never, master_timeout?: never }
}

export type IndicesExistsTemplateResponse = boolean

export interface IndicesExplainDataLifecycleDataStreamLifecycleExplain {
  index: IndexName
  managed_by_lifecycle: boolean
  index_creation_date_millis?: EpochTime<UnitMillis>
  time_since_index_creation?: Duration
  rollover_date_millis?: EpochTime<UnitMillis>
  time_since_rollover?: Duration
  lifecycle?: IndicesDataStreamLifecycleWithRollover
  generation_time?: Duration
  error?: string
}

export interface IndicesExplainDataLifecycleRequest extends RequestBase {
/** The name of the index to explain */
  index: Indices
  /** indicates if the API should return the default values the system uses for the index's lifecycle */
  include_defaults?: boolean
  /** Specify timeout for connection to master */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, include_defaults?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, include_defaults?: never, master_timeout?: never }
}

export interface IndicesExplainDataLifecycleResponse {
  indices: Record<IndexName, IndicesExplainDataLifecycleDataStreamLifecycleExplain>
}

export interface IndicesFieldUsageStatsFieldSummary {
  any: uint
  stored_fields: uint
  doc_values: uint
  points: uint
  norms: uint
  term_vectors: uint
  knn_vectors: uint
  inverted_index: IndicesFieldUsageStatsInvertedIndex
}

export interface IndicesFieldUsageStatsFieldsUsageBodyKeys {
  _shards: ShardStatistics
}
export type IndicesFieldUsageStatsFieldsUsageBody = IndicesFieldUsageStatsFieldsUsageBodyKeys
& { [property: string]: IndicesFieldUsageStatsUsageStatsIndex | ShardStatistics }

export interface IndicesFieldUsageStatsInvertedIndex {
  terms: uint
  postings: uint
  proximity: uint
  positions: uint
  term_frequencies: uint
  offsets: uint
  payloads: uint
}

export interface IndicesFieldUsageStatsRequest extends RequestBase {
/** Comma-separated list or wildcard expression of index names used to limit the request. */
  index: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, missing or closed indices are not included in the response. */
  ignore_unavailable?: boolean
  /** Comma-separated list or wildcard expressions of fields to include in the statistics. */
  fields?: Fields
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, fields?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, fields?: never }
}

export type IndicesFieldUsageStatsResponse = IndicesFieldUsageStatsFieldsUsageBody

export interface IndicesFieldUsageStatsShardsStats {
  all_fields: IndicesFieldUsageStatsFieldSummary
  fields: Record<Field, IndicesFieldUsageStatsFieldSummary>
}

export interface IndicesFieldUsageStatsUsageStatsIndex {
  shards: IndicesFieldUsageStatsUsageStatsShards[]
}

export interface IndicesFieldUsageStatsUsageStatsShards {
  routing: IndicesStatsShardRouting
  stats: IndicesFieldUsageStatsShardsStats
  tracking_id: string
  tracking_started_at_millis: EpochTime<UnitMillis>
}

export interface IndicesFlushRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and aliases to flush. Supports wildcards (`*`). To flush all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, the request forces a flush even if there are no changes to commit to the index. */
  force?: boolean
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** If `true`, the flush operation blocks until execution when another flush operation is running. If `false`, Elasticsearch returns an error if you request a flush when another flush operation is running. */
  wait_if_ongoing?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, force?: never, ignore_unavailable?: never, wait_if_ongoing?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, force?: never, ignore_unavailable?: never, wait_if_ongoing?: never }
}

export type IndicesFlushResponse = ShardsOperationResponseBase

export interface IndicesForcemergeRequest extends RequestBase {
/** A comma-separated list of index names; use `_all` or empty string to perform the operation on all indices */
  index?: Indices
  /** Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes `_all` string or when no indices have been specified) */
  allow_no_indices?: boolean
  /** Whether to expand wildcard expression to concrete indices that are open, closed or both. */
  expand_wildcards?: ExpandWildcards
  /** Specify whether the index should be flushed after performing the operation (default: true) */
  flush?: boolean
  /** Whether specified concrete indices should be ignored when unavailable (missing or closed) */
  ignore_unavailable?: boolean
  /** The number of segments the index should be merged into (default: dynamic) */
  max_num_segments?: long
  /** Specify whether the operation should only expunge deleted documents */
  only_expunge_deletes?: boolean
  /** Should the request wait until the force merge is completed. */
  wait_for_completion?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, flush?: never, ignore_unavailable?: never, max_num_segments?: never, only_expunge_deletes?: never, wait_for_completion?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, flush?: never, ignore_unavailable?: never, max_num_segments?: never, only_expunge_deletes?: never, wait_for_completion?: never }
}

export type IndicesForcemergeResponse = IndicesForcemergeForceMergeResponseBody

export interface IndicesForcemergeForceMergeResponseBody extends ShardsOperationResponseBase {
  task?: string
}

export type IndicesGetFeature = 'aliases' | 'mappings' | 'settings'

export type IndicesGetFeatures = IndicesGetFeature | IndicesGetFeature[]

export interface IndicesGetRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and index aliases used to limit the request. Wildcard expressions (*) are supported. */
  index: Indices
  /** If false, the request returns an error if any wildcard expression, index alias, or _all value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting foo*,bar* returns an error if an index starts with foo but no index starts with bar. */
  allow_no_indices?: boolean
  /** Type of index that wildcard expressions can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as open,hidden. */
  expand_wildcards?: ExpandWildcards
  /** If true, returns settings in flat format. */
  flat_settings?: boolean
  /** If false, requests that target a missing index return an error. */
  ignore_unavailable?: boolean
  /** If true, return all default settings in the response. */
  include_defaults?: boolean
  /** If true, the request retrieves information from the local node only. Defaults to false, which means information is retrieved from the master node. */
  local?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Return only information on specified index features */
  features?: IndicesGetFeatures
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, flat_settings?: never, ignore_unavailable?: never, include_defaults?: never, local?: never, master_timeout?: never, features?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, flat_settings?: never, ignore_unavailable?: never, include_defaults?: never, local?: never, master_timeout?: never, features?: never }
}

export type IndicesGetResponse = Record<IndexName, IndicesIndexState>

export interface IndicesGetAliasIndexAliases {
  aliases: Record<string, IndicesAliasDefinition>
}

export interface IndicesGetAliasRequest extends RequestBase {
/** Comma-separated list of aliases to retrieve. Supports wildcards (`*`). To retrieve all aliases, omit this parameter or use `*` or `_all`. */
  name?: Names
  /** Comma-separated list of data streams or indices used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never }
}

export type IndicesGetAliasResponse = Record<IndexName, IndicesGetAliasIndexAliases>

export interface IndicesGetDataLifecycleDataStreamWithLifecycle {
  name: DataStreamName
  lifecycle?: IndicesDataStreamLifecycleWithRollover
}

export interface IndicesGetDataLifecycleRequest extends RequestBase {
/** Comma-separated list of data streams to limit the request. Supports wildcards (`*`). To target all data streams, omit this parameter or use `*` or `_all`. */
  name: DataStreamNames
  /** Type of data stream that wildcard patterns can match. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, return all default settings in the response. */
  include_defaults?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, expand_wildcards?: never, include_defaults?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, expand_wildcards?: never, include_defaults?: never, master_timeout?: never }
}

export interface IndicesGetDataLifecycleResponse {
  data_streams: IndicesGetDataLifecycleDataStreamWithLifecycle[]
}

export interface IndicesGetDataLifecycleStatsDataStreamStats {
  backing_indices_in_error: integer
  backing_indices_in_total: integer
  name: DataStreamName
}

export interface IndicesGetDataLifecycleStatsRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface IndicesGetDataLifecycleStatsResponse {
  data_stream_count: integer
  data_streams: IndicesGetDataLifecycleStatsDataStreamStats[]
  last_run_duration_in_millis?: DurationValue<UnitMillis>
  time_between_starts_in_millis?: DurationValue<UnitMillis>
}

export interface IndicesGetDataStreamRequest extends RequestBase {
/** Comma-separated list of data stream names used to limit the request. Wildcard (`*`) expressions are supported. If omitted, all data streams are returned. */
  name?: DataStreamNames
  /** Type of data stream that wildcard patterns can match. Supports comma-separated values, such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** If true, returns all relevant default configurations for the index template. */
  include_defaults?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Whether the maximum timestamp for each data stream should be calculated and returned. */
  verbose?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, expand_wildcards?: never, include_defaults?: never, master_timeout?: never, verbose?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, expand_wildcards?: never, include_defaults?: never, master_timeout?: never, verbose?: never }
}

export interface IndicesGetDataStreamResponse {
  data_streams: IndicesDataStream[]
}

export interface IndicesGetFieldMappingRequest extends RequestBase {
/** Comma-separated list or wildcard expression of fields used to limit returned information. Supports wildcards (`*`). */
  fields: Fields
  /** Comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** If `true`, return all default settings in the response. */
  include_defaults?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { fields?: never, index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, include_defaults?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { fields?: never, index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, include_defaults?: never }
}

export type IndicesGetFieldMappingResponse = Record<IndexName, IndicesGetFieldMappingTypeFieldMappings>

export interface IndicesGetFieldMappingTypeFieldMappings {
  mappings: Record<Field, MappingFieldMapping>
}

export interface IndicesGetIndexTemplateIndexTemplateItem {
  name: Name
  index_template: IndicesIndexTemplate
}

export interface IndicesGetIndexTemplateRequest extends RequestBase {
/** Comma-separated list of index template names used to limit the request. Wildcard (*) expressions are supported. */
  name?: Name
  /** If true, the request retrieves information from the local node only. Defaults to false, which means information is retrieved from the master node. */
  local?: boolean
  /** If true, returns settings in flat format. */
  flat_settings?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** If true, returns all relevant default configurations for the index template. */
  include_defaults?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, local?: never, flat_settings?: never, master_timeout?: never, include_defaults?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, local?: never, flat_settings?: never, master_timeout?: never, include_defaults?: never }
}

export interface IndicesGetIndexTemplateResponse {
  index_templates: IndicesGetIndexTemplateIndexTemplateItem[]
}

export interface IndicesGetMappingIndexMappingRecord {
  item?: MappingTypeMapping
  mappings: MappingTypeMapping
}

export interface IndicesGetMappingRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** If `true`, the request retrieves information from the local node only. */
  local?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, local?: never, master_timeout?: never }
}

export type IndicesGetMappingResponse = Record<IndexName, IndicesGetMappingIndexMappingRecord>

export interface IndicesGetMigrateReindexStatusRequest extends RequestBase {
/** The index or data stream name. */
  index: Indices
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never }
}

export interface IndicesGetMigrateReindexStatusResponse {
  start_time?: DateTime
  start_time_millis: EpochTime<UnitMillis>
  complete: boolean
  total_indices_in_data_stream: integer
  total_indices_requiring_upgrade: integer
  successes: integer
  in_progress: IndicesGetMigrateReindexStatusStatusInProgress[]
  pending: integer
  errors: IndicesGetMigrateReindexStatusStatusError[]
  exception?: string
}

export interface IndicesGetMigrateReindexStatusStatusError {
  index: string
  message: string
}

export interface IndicesGetMigrateReindexStatusStatusInProgress {
  index: string
  total_doc_count: long
  reindexed_doc_count: long
}

export interface IndicesGetSettingsRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** Comma-separated list or wildcard expression of settings to retrieve. */
  name?: Names
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with foo but no index starts with `bar`. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, returns settings in flat format. */
  flat_settings?: boolean
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** If `true`, return all default settings in the response. */
  include_defaults?: boolean
  /** If `true`, the request retrieves information from the local node only. If `false`, information is retrieved from the master node. */
  local?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, name?: never, allow_no_indices?: never, expand_wildcards?: never, flat_settings?: never, ignore_unavailable?: never, include_defaults?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, name?: never, allow_no_indices?: never, expand_wildcards?: never, flat_settings?: never, ignore_unavailable?: never, include_defaults?: never, local?: never, master_timeout?: never }
}

export type IndicesGetSettingsResponse = Record<IndexName, IndicesIndexState>

export interface IndicesGetTemplateRequest extends RequestBase {
/** Comma-separated list of index template names used to limit the request. Wildcard (`*`) expressions are supported. To return all index templates, omit this parameter or use a value of `_all` or `*`. */
  name?: Names
  /** If `true`, returns settings in flat format. */
  flat_settings?: boolean
  /** If `true`, the request retrieves information from the local node only. */
  local?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, flat_settings?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, flat_settings?: never, local?: never, master_timeout?: never }
}

export type IndicesGetTemplateResponse = Record<string, IndicesTemplateMapping>

export interface IndicesMigrateReindexMigrateReindex {
  mode: IndicesMigrateReindexModeEnum
  source: IndicesMigrateReindexSourceIndex
}

export type IndicesMigrateReindexModeEnum = 'upgrade'

export interface IndicesMigrateReindexRequest extends RequestBase {
  reindex?: IndicesMigrateReindexMigrateReindex
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { reindex?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { reindex?: never }
}

export type IndicesMigrateReindexResponse = AcknowledgedResponseBase

export interface IndicesMigrateReindexSourceIndex {
  index: IndexName
}

export interface IndicesMigrateToDataStreamRequest extends RequestBase {
/** Name of the index alias to convert to a data stream. */
  name: IndexName
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
}

export type IndicesMigrateToDataStreamResponse = AcknowledgedResponseBase

export interface IndicesModifyDataStreamAction {
  add_backing_index?: IndicesModifyDataStreamIndexAndDataStreamAction
  remove_backing_index?: IndicesModifyDataStreamIndexAndDataStreamAction
}

export interface IndicesModifyDataStreamIndexAndDataStreamAction {
  data_stream: DataStreamName
  index: IndexName
}

export interface IndicesModifyDataStreamRequest extends RequestBase {
/** Actions to perform. */
  actions: IndicesModifyDataStreamAction[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { actions?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { actions?: never }
}

export type IndicesModifyDataStreamResponse = AcknowledgedResponseBase

export interface IndicesOpenRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (`*`). By default, you must explicitly name the indices you using to limit the request. To limit a request using `_all`, `*`, or other wildcard expressions, change the `action.destructive_requires_name` setting to false. You can update this setting in the `elasticsearch.yml` file or using the cluster update settings API. */
  index: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** The number of shard copies that must be active before proceeding with the operation. Set to `all` or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). */
  wait_for_active_shards?: WaitForActiveShards
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never }
}

export interface IndicesOpenResponse {
  acknowledged: boolean
  shards_acknowledged: boolean
}

export interface IndicesPromoteDataStreamRequest extends RequestBase {
/** The name of the data stream */
  name: IndexName
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never }
}

export type IndicesPromoteDataStreamResponse = any

export interface IndicesPutAliasRequest extends RequestBase {
/** Comma-separated list of data streams or indices to add. Supports wildcards (`*`). Wildcard patterns that match both data streams and indices return an error. */
  index: Indices
  /** Alias to update. If the alias doesn’t exist, the request creates it. Index alias names support date math. */
  name: Name
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** Query used to limit documents the alias can access. */
  filter?: QueryDslQueryContainer
  /** Value used to route indexing operations to a specific shard. If specified, this overwrites the `routing` value for indexing operations. Data stream aliases don’t support this parameter. */
  index_routing?: Routing
  /** If `true`, sets the write index or data stream for the alias. If an alias points to multiple indices or data streams and `is_write_index` isn’t set, the alias rejects write requests. If an index alias points to one index and `is_write_index` isn’t set, the index automatically acts as the write index. Data stream aliases don’t automatically set a write data stream, even if the alias points to one data stream. */
  is_write_index?: boolean
  /** Value used to route indexing and search operations to a specific shard. Data stream aliases don’t support this parameter. */
  routing?: Routing
  /** Value used to route search operations to a specific shard. If specified, this overwrites the `routing` value for search operations. Data stream aliases don’t support this parameter. */
  search_routing?: Routing
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, name?: never, master_timeout?: never, timeout?: never, filter?: never, index_routing?: never, is_write_index?: never, routing?: never, search_routing?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, name?: never, master_timeout?: never, timeout?: never, filter?: never, index_routing?: never, is_write_index?: never, routing?: never, search_routing?: never }
}

export type IndicesPutAliasResponse = AcknowledgedResponseBase

export interface IndicesPutDataLifecycleRequest extends RequestBase {
/** Comma-separated list of data streams used to limit the request. Supports wildcards (`*`). To target all data streams use `*` or `_all`. */
  name: DataStreamNames
  /** Type of data stream that wildcard patterns can match. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `hidden`, `open`, `closed`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** If defined, every document added to this data stream will be stored at least for this time frame. Any time after this duration the document could be deleted. When empty, every document in this data stream will be stored indefinitely. */
  data_retention?: Duration
  /** The downsampling configuration to execute for the managed backing index after rollover. */
  downsampling?: IndicesDataStreamLifecycleDownsampling
  /** If defined, it turns data stream lifecycle on/off (`true`/`false`) for this data stream. A data stream lifecycle that's disabled (enabled: `false`) will have no effect on the data stream. */
  enabled?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, expand_wildcards?: never, master_timeout?: never, timeout?: never, data_retention?: never, downsampling?: never, enabled?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, expand_wildcards?: never, master_timeout?: never, timeout?: never, data_retention?: never, downsampling?: never, enabled?: never }
}

export type IndicesPutDataLifecycleResponse = AcknowledgedResponseBase

export interface IndicesPutIndexTemplateIndexTemplateMapping {
  aliases?: Record<IndexName, IndicesAlias>
  mappings?: MappingTypeMapping
  settings?: IndicesIndexSettings
  lifecycle?: IndicesDataStreamLifecycle
}

export interface IndicesPutIndexTemplateRequest extends RequestBase {
/** Index or template name */
  name: Name
  /** If `true`, this request cannot replace or update existing index templates. */
  create?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** User defined reason for creating/updating the index template */
  cause?: string
  /** Name of the index template to create. */
  index_patterns?: Indices
  /** An ordered list of component template names. Component templates are merged in the order specified, meaning that the last component template specified has the highest precedence. */
  composed_of?: Name[]
  /** Template to be applied. It may optionally include an `aliases`, `mappings`, or `settings` configuration. */
  template?: IndicesPutIndexTemplateIndexTemplateMapping
  /** If this object is included, the template is used to create data streams and their backing indices. Supports an empty object. Data streams require a matching index template with a `data_stream` object. */
  data_stream?: IndicesDataStreamVisibility
  /** Priority to determine index template precedence when a new data stream or index is created. The index template with the highest priority is chosen. If no priority is specified the template is treated as though it is of priority 0 (lowest priority). This number is not automatically generated by Elasticsearch. */
  priority?: long
  /** Version number used to manage index templates externally. This number is not automatically generated by Elasticsearch. External systems can use these version numbers to simplify template management. To unset a version, replace the template without specifying one. */
  version?: VersionNumber
  /** Optional user metadata about the index template. It may have any contents. It is not automatically generated or used by Elasticsearch. This user-defined object is stored in the cluster state, so keeping it short is preferable To unset the metadata, replace the template without specifying it. */
  _meta?: Metadata
  /** This setting overrides the value of the `action.auto_create_index` cluster setting. If set to `true` in a template, then indices can be automatically created using that template even if auto-creation of indices is disabled via `actions.auto_create_index`. If set to `false`, then indices or data streams matching the template must always be explicitly created, and may never be automatically created. */
  allow_auto_create?: boolean
  /** The configuration option ignore_missing_component_templates can be used when an index template references a component template that might not exist */
  ignore_missing_component_templates?: string[]
  /** Marks this index template as deprecated. When creating or updating a non-deprecated index template that uses deprecated components, Elasticsearch will emit a deprecation warning. */
  deprecated?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, create?: never, master_timeout?: never, cause?: never, index_patterns?: never, composed_of?: never, template?: never, data_stream?: never, priority?: never, version?: never, _meta?: never, allow_auto_create?: never, ignore_missing_component_templates?: never, deprecated?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, create?: never, master_timeout?: never, cause?: never, index_patterns?: never, composed_of?: never, template?: never, data_stream?: never, priority?: never, version?: never, _meta?: never, allow_auto_create?: never, ignore_missing_component_templates?: never, deprecated?: never }
}

export type IndicesPutIndexTemplateResponse = AcknowledgedResponseBase

export interface IndicesPutMappingRequest extends RequestBase {
/** A comma-separated list of index names the mapping should be added to (supports wildcards); use `_all` or omit to add the mapping on all indices. */
  index: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** If `true`, the mappings are applied only to the current write index for the target. */
  write_index_only?: boolean
  /** Controls whether dynamic date detection is enabled. */
  date_detection?: boolean
  /** Controls whether new fields are added dynamically. */
  dynamic?: MappingDynamicMapping
  /** If date detection is enabled then new string fields are checked against 'dynamic_date_formats' and if the value matches then a new date field is added instead of string. */
  dynamic_date_formats?: string[]
  /** Specify dynamic templates for the mapping. */
  dynamic_templates?: Partial<Record<string, MappingDynamicTemplate>>[]
  /** Control whether field names are enabled for the index. */
  _field_names?: MappingFieldNamesField
  /** A mapping type can have custom meta data associated with it. These are not used at all by Elasticsearch, but can be used to store application-specific metadata. */
  _meta?: Metadata
  /** Automatically map strings into numeric data types for all fields. */
  numeric_detection?: boolean
  /** Mapping for a field. For new fields, this mapping can include: - Field name - Field data type - Mapping parameters */
  properties?: Record<PropertyName, MappingProperty>
  /** Enable making a routing value required on indexed documents. */
  _routing?: MappingRoutingField
  /** Control whether the _source field is enabled on the index. */
  _source?: MappingSourceField
  /** Mapping of runtime fields for the index. */
  runtime?: MappingRuntimeFields
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never, timeout?: never, write_index_only?: never, date_detection?: never, dynamic?: never, dynamic_date_formats?: never, dynamic_templates?: never, _field_names?: never, _meta?: never, numeric_detection?: never, properties?: never, _routing?: never, _source?: never, runtime?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, master_timeout?: never, timeout?: never, write_index_only?: never, date_detection?: never, dynamic?: never, dynamic_date_formats?: never, dynamic_templates?: never, _field_names?: never, _meta?: never, numeric_detection?: never, properties?: never, _routing?: never, _source?: never, runtime?: never }
}

export type IndicesPutMappingResponse = IndicesResponseBase

export interface IndicesPutSettingsRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, returns settings in flat format. */
  flat_settings?: boolean
  /** If `true`, returns settings in flat format. */
  ignore_unavailable?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** If `true`, existing index settings remain unchanged. */
  preserve_existing?: boolean
  /** Whether to close and reopen the index to apply non-dynamic settings. If set to `true` the indices to which the settings are being applied will be closed temporarily and then reopened in order to apply the changes. */
  reopen?: boolean
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  settings?: IndicesIndexSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, flat_settings?: never, ignore_unavailable?: never, master_timeout?: never, preserve_existing?: never, reopen?: never, timeout?: never, settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, flat_settings?: never, ignore_unavailable?: never, master_timeout?: never, preserve_existing?: never, reopen?: never, timeout?: never, settings?: never }
}

export type IndicesPutSettingsResponse = AcknowledgedResponseBase

export interface IndicesPutTemplateRequest extends RequestBase {
/** The name of the template */
  name: Name
  /** If true, this request cannot replace or update existing index templates. */
  create?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** User defined reason for creating/updating the index template */
  cause?: string
  /** Aliases for the index. */
  aliases?: Record<IndexName, IndicesAlias>
  /** Array of wildcard expressions used to match the names of indices during creation. */
  index_patterns?: string | string[]
  /** Mapping for fields in the index. */
  mappings?: MappingTypeMapping
  /** Order in which Elasticsearch applies this template if index matches multiple templates. Templates with lower 'order' values are merged first. Templates with higher 'order' values are merged later, overriding templates with lower values. */
  order?: integer
  /** Configuration options for the index. */
  settings?: IndicesIndexSettings
  /** Version number used to manage index templates externally. This number is not automatically generated by Elasticsearch. To unset a version, replace the template without specifying one. */
  version?: VersionNumber
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, create?: never, master_timeout?: never, cause?: never, aliases?: never, index_patterns?: never, mappings?: never, order?: never, settings?: never, version?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, create?: never, master_timeout?: never, cause?: never, aliases?: never, index_patterns?: never, mappings?: never, order?: never, settings?: never, version?: never }
}

export type IndicesPutTemplateResponse = AcknowledgedResponseBase

export interface IndicesRecoveryFileDetails {
  length: long
  name: string
  recovered: long
}

export interface IndicesRecoveryRecoveryBytes {
  percent: Percentage
  recovered?: ByteSize
  recovered_in_bytes: ByteSize
  recovered_from_snapshot?: ByteSize
  recovered_from_snapshot_in_bytes?: ByteSize
  reused?: ByteSize
  reused_in_bytes: ByteSize
  total?: ByteSize
  total_in_bytes: ByteSize
}

export interface IndicesRecoveryRecoveryFiles {
  details?: IndicesRecoveryFileDetails[]
  percent: Percentage
  recovered: long
  reused: long
  total: long
}

export interface IndicesRecoveryRecoveryIndexStatus {
  bytes?: IndicesRecoveryRecoveryBytes
  files: IndicesRecoveryRecoveryFiles
  size: IndicesRecoveryRecoveryBytes
  source_throttle_time?: Duration
  source_throttle_time_in_millis: DurationValue<UnitMillis>
  target_throttle_time?: Duration
  target_throttle_time_in_millis: DurationValue<UnitMillis>
  total_time?: Duration
  total_time_in_millis: DurationValue<UnitMillis>
}

export interface IndicesRecoveryRecoveryOrigin {
  hostname?: string
  host?: Host
  transport_address?: TransportAddress
  id?: Id
  ip?: Ip
  name?: Name
  bootstrap_new_history_uuid?: boolean
  repository?: Name
  snapshot?: Name
  version?: VersionString
  restoreUUID?: Uuid
  index?: IndexName
}

export interface IndicesRecoveryRecoveryStartStatus {
  check_index_time?: Duration
  check_index_time_in_millis: DurationValue<UnitMillis>
  total_time?: Duration
  total_time_in_millis: DurationValue<UnitMillis>
}

export interface IndicesRecoveryRecoveryStatus {
  shards: IndicesRecoveryShardRecovery[]
}

export interface IndicesRecoveryRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `true`, the response only includes ongoing shard recoveries. */
  active_only?: boolean
  /** If `true`, the response includes detailed information about shard recoveries. */
  detailed?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, active_only?: never, detailed?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, active_only?: never, detailed?: never }
}

export type IndicesRecoveryResponse = Record<IndexName, IndicesRecoveryRecoveryStatus>

export interface IndicesRecoveryShardRecovery {
  id: long
  index: IndicesRecoveryRecoveryIndexStatus
  primary: boolean
  source: IndicesRecoveryRecoveryOrigin
  stage: string
  start?: IndicesRecoveryRecoveryStartStatus
  start_time?: DateTime
  start_time_in_millis: EpochTime<UnitMillis>
  stop_time?: DateTime
  stop_time_in_millis?: EpochTime<UnitMillis>
  target: IndicesRecoveryRecoveryOrigin
  total_time?: Duration
  total_time_in_millis: DurationValue<UnitMillis>
  translog: IndicesRecoveryTranslogStatus
  type: string
  verify_index: IndicesRecoveryVerifyIndex
}

export interface IndicesRecoveryTranslogStatus {
  percent: Percentage
  recovered: long
  total: long
  total_on_start: long
  total_time?: Duration
  total_time_in_millis: DurationValue<UnitMillis>
}

export interface IndicesRecoveryVerifyIndex {
  check_index_time?: Duration
  check_index_time_in_millis: DurationValue<UnitMillis>
  total_time?: Duration
  total_time_in_millis: DurationValue<UnitMillis>
}

export interface IndicesRefreshRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never }
}

export type IndicesRefreshResponse = ShardsOperationResponseBase

export interface IndicesReloadSearchAnalyzersReloadDetails {
  index: string
  reloaded_analyzers: string[]
  reloaded_node_ids: string[]
}

export interface IndicesReloadSearchAnalyzersReloadResult {
  reload_details: IndicesReloadSearchAnalyzersReloadDetails[]
  _shards: ShardStatistics
}

export interface IndicesReloadSearchAnalyzersRequest extends RequestBase {
/** A comma-separated list of index names to reload analyzers for */
  index: Indices
  /** Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes `_all` string or when no indices have been specified) */
  allow_no_indices?: boolean
  /** Whether to expand wildcard expression to concrete indices that are open, closed or both. */
  expand_wildcards?: ExpandWildcards
  /** Whether specified concrete indices should be ignored when unavailable (missing or closed) */
  ignore_unavailable?: boolean
  /** Changed resource to reload analyzers from if applicable */
  resource?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, resource?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, resource?: never }
}

export type IndicesReloadSearchAnalyzersResponse = IndicesReloadSearchAnalyzersReloadResult

export interface IndicesResolveClusterRequest extends RequestBase {
/** A comma-separated list of names or index patterns for the indices, aliases, and data streams to resolve. Resources on remote clusters can be specified using the `<cluster>`:`<name>` syntax. Index and cluster exclusions (e.g., `-cluster1:*`) are also supported. If no index expression is specified, information about all remote clusters configured on the local cluster is returned without doing any index matching */
  name?: Names
  /** If false, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. NOTE: This option is only supported when specifying an index expression. You will get an error if you specify index options to the `_resolve/cluster` API endpoint that takes no index expression. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. NOTE: This option is only supported when specifying an index expression. You will get an error if you specify index options to the `_resolve/cluster` API endpoint that takes no index expression. */
  expand_wildcards?: ExpandWildcards
  /** If true, concrete, expanded, or aliased indices are ignored when frozen. NOTE: This option is only supported when specifying an index expression. You will get an error if you specify index options to the `_resolve/cluster` API endpoint that takes no index expression. */
  ignore_throttled?: boolean
  /** If false, the request returns an error if it targets a missing or closed index. NOTE: This option is only supported when specifying an index expression. You will get an error if you specify index options to the `_resolve/cluster` API endpoint that takes no index expression. */
  ignore_unavailable?: boolean
  /** The maximum time to wait for remote clusters to respond. If a remote cluster does not respond within this timeout period, the API response will show the cluster as not connected and include an error message that the request timed out. The default timeout is unset and the query can take as long as the networking layer is configured to wait for remote clusters that are not responding (typically 30 seconds). */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, timeout?: never }
}

export interface IndicesResolveClusterResolveClusterInfo {
  connected: boolean
  skip_unavailable: boolean
  matching_indices?: boolean
  error?: string
  version?: ElasticsearchVersionMinInfo
}

export type IndicesResolveClusterResponse = Record<ClusterAlias, IndicesResolveClusterResolveClusterInfo>

export interface IndicesResolveIndexRequest extends RequestBase {
/** Comma-separated name(s) or index pattern(s) of the indices, aliases, and data streams to resolve. Resources on remote clusters can be specified using the `<cluster>`:`<name>` syntax. */
  name: Names
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. For example, a request targeting `foo*,bar*` returns an error if an index starts with `foo` but no index starts with `bar`. */
  allow_no_indices?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, expand_wildcards?: never, ignore_unavailable?: never, allow_no_indices?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, expand_wildcards?: never, ignore_unavailable?: never, allow_no_indices?: never }
}

export interface IndicesResolveIndexResolveIndexAliasItem {
  name: Name
  indices: Indices
}

export interface IndicesResolveIndexResolveIndexDataStreamsItem {
  name: DataStreamName
  timestamp_field: Field
  backing_indices: Indices
}

export interface IndicesResolveIndexResolveIndexItem {
  name: Name
  aliases?: string[]
  attributes: string[]
  data_stream?: DataStreamName
}

export interface IndicesResolveIndexResponse {
  indices: IndicesResolveIndexResolveIndexItem[]
  aliases: IndicesResolveIndexResolveIndexAliasItem[]
  data_streams: IndicesResolveIndexResolveIndexDataStreamsItem[]
}

export interface IndicesRolloverRequest extends RequestBase {
/** Name of the data stream or index alias to roll over. */
  alias: IndexAlias
  /** Name of the index to create. Supports date math. Data streams do not support this parameter. */
  new_index?: IndexName
  /** If `true`, checks whether the current index satisfies the specified conditions but does not perform a rollover. */
  dry_run?: boolean
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** The number of shard copies that must be active before proceeding with the operation. Set to all or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). */
  wait_for_active_shards?: WaitForActiveShards
  /** If set to true, the rollover action will only mark a data stream to signal that it needs to be rolled over at the next write. Only allowed on data streams. */
  lazy?: boolean
  /** Aliases for the target index. Data streams do not support this parameter. */
  aliases?: Record<IndexName, IndicesAlias>
  /** Conditions for the rollover. If specified, Elasticsearch only performs the rollover if the current index satisfies these conditions. If this parameter is not specified, Elasticsearch performs the rollover unconditionally. If conditions are specified, at least one of them must be a `max_*` condition. The index will rollover if any `max_*` condition is satisfied and all `min_*` conditions are satisfied. */
  conditions?: IndicesRolloverRolloverConditions
  /** Mapping for fields in the index. If specified, this mapping can include field names, field data types, and mapping paramaters. */
  mappings?: MappingTypeMapping
  /** Configuration options for the index. Data streams do not support this parameter. */
  settings?: Record<string, any>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { alias?: never, new_index?: never, dry_run?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never, lazy?: never, aliases?: never, conditions?: never, mappings?: never, settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { alias?: never, new_index?: never, dry_run?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never, lazy?: never, aliases?: never, conditions?: never, mappings?: never, settings?: never }
}

export interface IndicesRolloverResponse {
  acknowledged: boolean
  conditions: Record<string, boolean>
  dry_run: boolean
  new_index: string
  old_index: string
  rolled_over: boolean
  shards_acknowledged: boolean
}

export interface IndicesRolloverRolloverConditions {
  min_age?: Duration
  max_age?: Duration
  max_age_millis?: DurationValue<UnitMillis>
  min_docs?: long
  max_docs?: long
  max_size?: ByteSize
  max_size_bytes?: long
  min_size?: ByteSize
  min_size_bytes?: long
  max_primary_shard_size?: ByteSize
  max_primary_shard_size_bytes?: long
  min_primary_shard_size?: ByteSize
  min_primary_shard_size_bytes?: long
  max_primary_shard_docs?: long
  min_primary_shard_docs?: long
}

export interface IndicesSegmentsIndexSegment {
  shards: Record<string, IndicesSegmentsShardsSegment | IndicesSegmentsShardsSegment[]>
}

export interface IndicesSegmentsRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and aliases used to limit the request. Supports wildcards (`*`). To target all data streams and indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never }
}

export interface IndicesSegmentsResponse {
  indices: Record<string, IndicesSegmentsIndexSegment>
  _shards: ShardStatistics
}

export interface IndicesSegmentsSegment {
  attributes: Record<string, string>
  committed: boolean
  compound: boolean
  deleted_docs: long
  generation: integer
  search: boolean
  size_in_bytes: double
  num_docs: long
  version: VersionString
}

export interface IndicesSegmentsShardSegmentRouting {
  node: string
  primary: boolean
  state: string
}

export interface IndicesSegmentsShardsSegment {
  num_committed_segments: integer
  routing: IndicesSegmentsShardSegmentRouting
  num_search_segments: integer
  segments: Record<string, IndicesSegmentsSegment>
}

export interface IndicesShardStoresIndicesShardStores {
  shards: Record<string, IndicesShardStoresShardStoreWrapper>
}

export interface IndicesShardStoresRequest extends RequestBase {
/** List of data streams, indices, and aliases used to limit the request. */
  index?: Indices
  /** If false, the request returns an error if any wildcard expression, index alias, or _all value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. */
  expand_wildcards?: ExpandWildcards
  /** If true, missing or closed indices are not included in the response. */
  ignore_unavailable?: boolean
  /** List of shard health statuses used to limit the request. */
  status?: IndicesShardStoresShardStoreStatus | IndicesShardStoresShardStoreStatus[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, status?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_unavailable?: never, status?: never }
}

export interface IndicesShardStoresResponse {
  indices: Record<IndexName, IndicesShardStoresIndicesShardStores>
}

export interface IndicesShardStoresShardStoreKeys {
  allocation: IndicesShardStoresShardStoreAllocation
  allocation_id?: Id
  store_exception?: IndicesShardStoresShardStoreException
}
export type IndicesShardStoresShardStore = IndicesShardStoresShardStoreKeys
& { [property: string]: IndicesShardStoresShardStoreNode | IndicesShardStoresShardStoreAllocation | Id | IndicesShardStoresShardStoreException }

export type IndicesShardStoresShardStoreAllocation = 'primary' | 'replica' | 'unused'

export interface IndicesShardStoresShardStoreException {
  reason: string
  type: string
}

export interface IndicesShardStoresShardStoreNode {
  attributes: Record<string, string>
  ephemeral_id?: string
  external_id?: string
  name: Name
  roles: string[]
  transport_address: TransportAddress
}

export type IndicesShardStoresShardStoreStatus = 'green' | 'yellow' | 'red' | 'all'

export interface IndicesShardStoresShardStoreWrapper {
  stores: IndicesShardStoresShardStore[]
}

export interface IndicesShrinkRequest extends RequestBase {
/** Name of the source index to shrink. */
  index: IndexName
  /** Name of the target index to create. */
  target: IndexName
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** The number of shard copies that must be active before proceeding with the operation. Set to `all` or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). */
  wait_for_active_shards?: WaitForActiveShards
  /** The key is the alias name. Index alias names support date math. */
  aliases?: Record<IndexName, IndicesAlias>
  /** Configuration options for the target index. */
  settings?: Record<string, any>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, target?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never, aliases?: never, settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, target?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never, aliases?: never, settings?: never }
}

export interface IndicesShrinkResponse {
  acknowledged: boolean
  shards_acknowledged: boolean
  index: IndexName
}

export interface IndicesSimulateIndexTemplateRequest extends RequestBase {
/** Name of the index to simulate */
  name: Name
  /** Whether the index template we optionally defined in the body should only be dry-run added if new or can also replace an existing one */
  create?: boolean
  /** User defined reason for dry-run creating the new template for simulation purposes */
  cause?: string
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** If true, returns all relevant default configurations for the index template. */
  include_defaults?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, create?: never, cause?: never, master_timeout?: never, include_defaults?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, create?: never, cause?: never, master_timeout?: never, include_defaults?: never }
}

export interface IndicesSimulateIndexTemplateResponse {
  overlapping?: IndicesSimulateTemplateOverlapping[]
  template: IndicesSimulateTemplateTemplate
}

export interface IndicesSimulateTemplateOverlapping {
  name: Name
  index_patterns: string[]
}

export interface IndicesSimulateTemplateRequest extends RequestBase {
/** Name of the index template to simulate. To test a template configuration before you add it to the cluster, omit this parameter and specify the template configuration in the request body. */
  name?: Name
  /** If true, the template passed in the body is only used if no existing templates match the same index patterns. If false, the simulation uses the template with the highest priority. Note that the template is not permanently added or updated in either case; it is only used for the simulation. */
  create?: boolean
  /** User defined reason for dry-run creating the new template for simulation purposes */
  cause?: string
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** If true, returns all relevant default configurations for the index template. */
  include_defaults?: boolean
  /** This setting overrides the value of the `action.auto_create_index` cluster setting. If set to `true` in a template, then indices can be automatically created using that template even if auto-creation of indices is disabled via `actions.auto_create_index`. If set to `false`, then indices or data streams matching the template must always be explicitly created, and may never be automatically created. */
  allow_auto_create?: boolean
  /** Array of wildcard (`*`) expressions used to match the names of data streams and indices during creation. */
  index_patterns?: Indices
  /** An ordered list of component template names. Component templates are merged in the order specified, meaning that the last component template specified has the highest precedence. */
  composed_of?: Name[]
  /** Template to be applied. It may optionally include an `aliases`, `mappings`, or `settings` configuration. */
  template?: IndicesPutIndexTemplateIndexTemplateMapping
  /** If this object is included, the template is used to create data streams and their backing indices. Supports an empty object. Data streams require a matching index template with a `data_stream` object. */
  data_stream?: IndicesDataStreamVisibility
  /** Priority to determine index template precedence when a new data stream or index is created. The index template with the highest priority is chosen. If no priority is specified the template is treated as though it is of priority 0 (lowest priority). This number is not automatically generated by Elasticsearch. */
  priority?: long
  /** Version number used to manage index templates externally. This number is not automatically generated by Elasticsearch. */
  version?: VersionNumber
  /** Optional user metadata about the index template. May have any contents. This map is not automatically generated by Elasticsearch. */
  _meta?: Metadata
  /** The configuration option ignore_missing_component_templates can be used when an index template references a component template that might not exist */
  ignore_missing_component_templates?: string[]
  /** Marks this index template as deprecated. When creating or updating a non-deprecated index template that uses deprecated components, Elasticsearch will emit a deprecation warning. */
  deprecated?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, create?: never, cause?: never, master_timeout?: never, include_defaults?: never, allow_auto_create?: never, index_patterns?: never, composed_of?: never, template?: never, data_stream?: never, priority?: never, version?: never, _meta?: never, ignore_missing_component_templates?: never, deprecated?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, create?: never, cause?: never, master_timeout?: never, include_defaults?: never, allow_auto_create?: never, index_patterns?: never, composed_of?: never, template?: never, data_stream?: never, priority?: never, version?: never, _meta?: never, ignore_missing_component_templates?: never, deprecated?: never }
}

export interface IndicesSimulateTemplateResponse {
  overlapping?: IndicesSimulateTemplateOverlapping[]
  template: IndicesSimulateTemplateTemplate
}

export interface IndicesSimulateTemplateTemplate {
  aliases: Record<IndexName, IndicesAlias>
  mappings: MappingTypeMapping
  settings: IndicesIndexSettings
}

export interface IndicesSplitRequest extends RequestBase {
/** Name of the source index to split. */
  index: IndexName
  /** Name of the target index to create. */
  target: IndexName
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** The number of shard copies that must be active before proceeding with the operation. Set to `all` or any positive integer up to the total number of shards in the index (`number_of_replicas+1`). */
  wait_for_active_shards?: WaitForActiveShards
  /** Aliases for the resulting index. */
  aliases?: Record<IndexName, IndicesAlias>
  /** Configuration options for the target index. */
  settings?: Record<string, any>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, target?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never, aliases?: never, settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, target?: never, master_timeout?: never, timeout?: never, wait_for_active_shards?: never, aliases?: never, settings?: never }
}

export interface IndicesSplitResponse {
  acknowledged: boolean
  shards_acknowledged: boolean
  index: IndexName
}

export type IndicesStatsIndexMetadataState = 'open' | 'close'

export interface IndicesStatsIndexStats {
  completion?: CompletionStats
  docs?: DocStats
  fielddata?: FielddataStats
  flush?: FlushStats
  get?: GetStats
  indexing?: IndexingStats
  indices?: IndicesStatsIndicesStats
  merges?: MergesStats
  query_cache?: QueryCacheStats
  recovery?: RecoveryStats
  refresh?: RefreshStats
  request_cache?: RequestCacheStats
  search?: SearchStats
  segments?: SegmentsStats
  store?: StoreStats
  translog?: TranslogStats
  warmer?: WarmerStats
  bulk?: BulkStats
  shard_stats?: IndicesStatsShardsTotalStats
}

export interface IndicesStatsIndicesStats {
  primaries?: IndicesStatsIndexStats
  shards?: Record<string, IndicesStatsShardStats[]>
  total?: IndicesStatsIndexStats
  uuid?: Uuid
  health?: HealthStatus
  status?: IndicesStatsIndexMetadataState
}

export interface IndicesStatsMappingStats {
  total_count: long
  total_estimated_overhead?: ByteSize
  total_estimated_overhead_in_bytes: long
}

export interface IndicesStatsRequest extends RequestBase {
/** Limit the information returned the specific metrics. */
  metric?: Metrics
  /** A comma-separated list of index names; use `_all` or empty string to perform the operation on all indices */
  index?: Indices
  /** Comma-separated list or wildcard expressions of fields to include in fielddata and suggest statistics. */
  completion_fields?: Fields
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** Comma-separated list or wildcard expressions of fields to include in fielddata statistics. */
  fielddata_fields?: Fields
  /** Comma-separated list or wildcard expressions of fields to include in the statistics. */
  fields?: Fields
  /** If true, statistics are not collected from closed indices. */
  forbid_closed_indices?: boolean
  /** Comma-separated list of search groups to include in the search statistics. */
  groups?: string | string[]
  /** If true, the call reports the aggregated disk usage of each one of the Lucene index files (only applies if segment stats are requested). */
  include_segment_file_sizes?: boolean
  /** If true, the response includes information from segments that are not loaded into memory. */
  include_unloaded_segments?: boolean
  /** Indicates whether statistics are aggregated at the cluster, index, or shard level. */
  level?: Level
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { metric?: never, index?: never, completion_fields?: never, expand_wildcards?: never, fielddata_fields?: never, fields?: never, forbid_closed_indices?: never, groups?: never, include_segment_file_sizes?: never, include_unloaded_segments?: never, level?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { metric?: never, index?: never, completion_fields?: never, expand_wildcards?: never, fielddata_fields?: never, fields?: never, forbid_closed_indices?: never, groups?: never, include_segment_file_sizes?: never, include_unloaded_segments?: never, level?: never }
}

export interface IndicesStatsResponse {
  indices?: Record<string, IndicesStatsIndicesStats>
  _shards: ShardStatistics
  _all: IndicesStatsIndicesStats
}

export interface IndicesStatsShardCommit {
  generation: integer
  id: Id
  num_docs: long
  user_data: Record<string, string>
}

export interface IndicesStatsShardFileSizeInfo {
  description: string
  size_in_bytes: long
  min_size_in_bytes?: long
  max_size_in_bytes?: long
  average_size_in_bytes?: long
  count?: long
}

export interface IndicesStatsShardLease {
  id: Id
  retaining_seq_no: SequenceNumber
  timestamp: long
  source: string
}

export interface IndicesStatsShardPath {
  data_path: string
  is_custom_data_path: boolean
  state_path: string
}

export interface IndicesStatsShardQueryCache {
  cache_count: long
  cache_size: long
  evictions: long
  hit_count: long
  memory_size_in_bytes: long
  miss_count: long
  total_count: long
}

export interface IndicesStatsShardRetentionLeases {
  primary_term: long
  version: VersionNumber
  leases: IndicesStatsShardLease[]
}

export interface IndicesStatsShardRouting {
  node: string
  primary: boolean
  relocating_node?: string | null
  state: IndicesStatsShardRoutingState
}

export type IndicesStatsShardRoutingState = 'UNASSIGNED' | 'INITIALIZING' | 'STARTED' | 'RELOCATING'

export interface IndicesStatsShardSequenceNumber {
  global_checkpoint: long
  local_checkpoint: long
  max_seq_no: SequenceNumber
}

export interface IndicesStatsShardStats {
  commit?: IndicesStatsShardCommit
  completion?: CompletionStats
  docs?: DocStats
  fielddata?: FielddataStats
  flush?: FlushStats
  get?: GetStats
  indexing?: IndexingStats
  mappings?: IndicesStatsMappingStats
  merges?: MergesStats
  shard_path?: IndicesStatsShardPath
  query_cache?: IndicesStatsShardQueryCache
  recovery?: RecoveryStats
  refresh?: RefreshStats
  request_cache?: RequestCacheStats
  retention_leases?: IndicesStatsShardRetentionLeases
  routing?: IndicesStatsShardRouting
  search?: SearchStats
  segments?: SegmentsStats
  seq_no?: IndicesStatsShardSequenceNumber
  store?: StoreStats
  translog?: TranslogStats
  warmer?: WarmerStats
  bulk?: BulkStats
  shards?: Record<IndexName, any>
  shard_stats?: IndicesStatsShardsTotalStats
  indices?: IndicesStatsIndicesStats
}

export interface IndicesStatsShardsTotalStats {
  total_count: long
}

export interface IndicesUpdateAliasesAction {
  add?: IndicesUpdateAliasesAddAction
  remove?: IndicesUpdateAliasesRemoveAction
  remove_index?: IndicesUpdateAliasesRemoveIndexAction
}

export interface IndicesUpdateAliasesAddAction {
  alias?: IndexAlias
  aliases?: IndexAlias | IndexAlias[]
  filter?: QueryDslQueryContainer
  index?: IndexName
  indices?: Indices
  index_routing?: Routing
  is_hidden?: boolean
  is_write_index?: boolean
  routing?: Routing
  search_routing?: Routing
  must_exist?: boolean
}

export interface IndicesUpdateAliasesRemoveAction {
  alias?: IndexAlias
  aliases?: IndexAlias | IndexAlias[]
  index?: IndexName
  indices?: Indices
  must_exist?: boolean
}

export interface IndicesUpdateAliasesRemoveIndexAction {
  index?: IndexName
  indices?: Indices
  must_exist?: boolean
}

export interface IndicesUpdateAliasesRequest extends RequestBase {
/** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** Actions to perform. */
  actions?: IndicesUpdateAliasesAction[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never, timeout?: never, actions?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never, timeout?: never, actions?: never }
}

export type IndicesUpdateAliasesResponse = AcknowledgedResponseBase

export interface IndicesValidateQueryIndicesValidationExplanation {
  error?: string
  explanation?: string
  index: IndexName
  valid: boolean
}

export interface IndicesValidateQueryRequest extends RequestBase {
/** Comma-separated list of data streams, indices, and aliases to search. Supports wildcards (`*`). To search all data streams or indices, omit this parameter or use `*` or `_all`. */
  index?: Indices
  /** If `false`, the request returns an error if any wildcard expression, index alias, or `_all` value targets only missing or closed indices. This behavior applies even if the request targets other open indices. */
  allow_no_indices?: boolean
  /** If `true`, the validation is executed on all shards instead of one random shard per index. */
  all_shards?: boolean
  /** Analyzer to use for the query string. This parameter can only be used when the `q` query string parameter is specified. */
  analyzer?: string
  /** If `true`, wildcard and prefix queries are analyzed. */
  analyze_wildcard?: boolean
  /** The default operator for query string query: `AND` or `OR`. */
  default_operator?: QueryDslOperator
  /** Field to use as default where no field prefix is given in the query string. This parameter can only be used when the `q` query string parameter is specified. */
  df?: string
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values, such as `open,hidden`. Valid values are: `all`, `open`, `closed`, `hidden`, `none`. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, the response returns detailed information if an error has occurred. */
  explain?: boolean
  /** If `false`, the request returns an error if it targets a missing or closed index. */
  ignore_unavailable?: boolean
  /** If `true`, format-based query failures (such as providing text to a numeric field) in the query string will be ignored. */
  lenient?: boolean
  /** If `true`, returns a more detailed explanation showing the actual Lucene query that will be executed. */
  rewrite?: boolean
  /** Query in the Lucene query string syntax. */
  q?: string
  /** Query in the Lucene query string syntax. */
  query?: QueryDslQueryContainer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, allow_no_indices?: never, all_shards?: never, analyzer?: never, analyze_wildcard?: never, default_operator?: never, df?: never, expand_wildcards?: never, explain?: never, ignore_unavailable?: never, lenient?: never, rewrite?: never, q?: never, query?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, allow_no_indices?: never, all_shards?: never, analyzer?: never, analyze_wildcard?: never, default_operator?: never, df?: never, expand_wildcards?: never, explain?: never, ignore_unavailable?: never, lenient?: never, rewrite?: never, q?: never, query?: never }
}

export interface IndicesValidateQueryResponse {
  explanations?: IndicesValidateQueryIndicesValidationExplanation[]
  _shards?: ShardStatistics
  valid: boolean
  error?: string
}

export interface InferenceCompletionInferenceResult {
  completion: InferenceCompletionResult[]
}

export interface InferenceCompletionResult {
  result: string
}

export interface InferenceDeleteInferenceEndpointResult extends AcknowledgedResponseBase {
  pipelines: string[]
}

export type InferenceDenseByteVector = byte[]

export type InferenceDenseVector = float[]

export interface InferenceInferenceChunkingSettings extends InferenceInferenceEndpoint {
  max_chunk_size?: integer
  overlap?: integer
  sentence_overlap?: integer
  strategy?: string
}

export interface InferenceInferenceEndpoint {
  chunking_settings?: InferenceInferenceChunkingSettings
  service: string
  service_settings: InferenceServiceSettings
  task_settings?: InferenceTaskSettings
}

export interface InferenceInferenceEndpointInfo extends InferenceInferenceEndpoint {
  inference_id: string
  task_type: InferenceTaskType
}

export interface InferenceRankedDocument {
  index: integer
  relevance_score: float
  text?: string
}

export interface InferenceRateLimitSetting {
  requests_per_minute?: integer
}

export interface InferenceRequestChatCompletionBase extends RequestBase {
  messages: InferenceChatCompletionUnifiedMessage[]
  model?: string
  max_completion_tokens?: long
  stop?: string[]
  temperature?: float
  tool_choice?: InferenceChatCompletionUnifiedCompletionToolType
  tools?: InferenceChatCompletionUnifiedCompletionTool[]
  top_p?: float
}

export interface InferenceRerankedInferenceResult {
  rerank: InferenceRankedDocument[]
}

export type InferenceServiceSettings = any

export interface InferenceSparseEmbeddingInferenceResult {
  sparse_embedding: InferenceSparseEmbeddingResult[]
}

export interface InferenceSparseEmbeddingResult {
  embedding: InferenceSparseVector
}

export type InferenceSparseVector = Record<string, float>

export type InferenceTaskSettings = any

export type InferenceTaskType = 'sparse_embedding' | 'text_embedding' | 'rerank' | 'completion' | 'chat_completion'

export interface InferenceTextEmbeddingByteResult {
  embedding: InferenceDenseByteVector
}

export interface InferenceTextEmbeddingInferenceResult {
  text_embedding_bytes?: InferenceTextEmbeddingByteResult[]
  text_embedding_bits?: InferenceTextEmbeddingByteResult[]
  text_embedding?: InferenceTextEmbeddingResult[]
}

export interface InferenceTextEmbeddingResult {
  embedding: InferenceDenseVector
}

export interface InferenceChatCompletionUnifiedCompletionTool {
  type: string
  function: InferenceChatCompletionUnifiedCompletionToolFunction
}

export interface InferenceChatCompletionUnifiedCompletionToolChoice {
  type: string
  function: InferenceChatCompletionUnifiedCompletionToolChoiceFunction
}

export interface InferenceChatCompletionUnifiedCompletionToolChoiceFunction {
  name: string
}

export interface InferenceChatCompletionUnifiedCompletionToolFunction {
  description?: string
  name: string
  parameters?: any
  strict?: boolean
}

export type InferenceChatCompletionUnifiedCompletionToolType = string | InferenceChatCompletionUnifiedCompletionToolChoice

export interface InferenceChatCompletionUnifiedContentObject {
  text: string
  type: string
}

export interface InferenceChatCompletionUnifiedMessage {
  content?: InferenceChatCompletionUnifiedMessageContent
  role: string
  tool_call_id?: Id
  tool_calls?: InferenceChatCompletionUnifiedToolCall[]
}

export type InferenceChatCompletionUnifiedMessageContent = string | InferenceChatCompletionUnifiedContentObject[]

export interface InferenceChatCompletionUnifiedRequest extends InferenceRequestChatCompletionBase {
/** The inference Id */
  inference_id: Id
  /** Specifies the amount of time to wait for the inference request to complete. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { inference_id?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { inference_id?: never, timeout?: never }
}

export type InferenceChatCompletionUnifiedResponse = StreamResult

export interface InferenceChatCompletionUnifiedToolCall {
  id: Id
  function: InferenceChatCompletionUnifiedToolCallFunction
  type: string
}

export interface InferenceChatCompletionUnifiedToolCallFunction {
  arguments: string
  name: string
}

export interface InferenceCompletionRequest extends RequestBase {
/** The inference Id */
  inference_id: Id
  /** Specifies the amount of time to wait for the inference request to complete. */
  timeout?: Duration
  /** Inference input. Either a string or an array of strings. */
  input: string | string[]
  /** Optional task settings */
  task_settings?: InferenceTaskSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { inference_id?: never, timeout?: never, input?: never, task_settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { inference_id?: never, timeout?: never, input?: never, task_settings?: never }
}

export type InferenceCompletionResponse = InferenceCompletionInferenceResult

export interface InferenceDeleteRequest extends RequestBase {
/** The task type */
  task_type?: InferenceTaskType
  /** The inference identifier. */
  inference_id: Id
  /** When true, the endpoint is not deleted and a list of ingest processors which reference this endpoint is returned. */
  dry_run?: boolean
  /** When true, the inference endpoint is forcefully deleted even if it is still being used by ingest processors or semantic text fields. */
  force?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { task_type?: never, inference_id?: never, dry_run?: never, force?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { task_type?: never, inference_id?: never, dry_run?: never, force?: never }
}

export type InferenceDeleteResponse = InferenceDeleteInferenceEndpointResult

export interface InferenceGetRequest extends RequestBase {
/** The task type */
  task_type?: InferenceTaskType
  /** The inference Id */
  inference_id?: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { task_type?: never, inference_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { task_type?: never, inference_id?: never }
}

export interface InferenceGetResponse {
  endpoints: InferenceInferenceEndpointInfo[]
}

export interface InferencePostEisChatCompletionRequest extends InferenceRequestChatCompletionBase {
/** The unique identifier of the inference endpoint. */
  eis_inference_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { eis_inference_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { eis_inference_id?: never }
}

export type InferencePostEisChatCompletionResponse = StreamResult

export interface InferencePutRequest extends RequestBase {
/** The task type */
  task_type?: InferenceTaskType
  /** The inference Id */
  inference_id: Id
  inference_config?: InferenceInferenceEndpoint
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { task_type?: never, inference_id?: never, inference_config?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { task_type?: never, inference_id?: never, inference_config?: never }
}

export type InferencePutResponse = InferenceInferenceEndpointInfo

export interface InferencePutEisEisServiceSettings {
  model_id: string
  rate_limit?: InferenceRateLimitSetting
}

export type InferencePutEisEisTaskType = 'chat_completion'

export interface InferencePutEisRequest extends RequestBase {
/** The type of the inference task that the model will perform. NOTE: The `chat_completion` task type only supports streaming and only through the _stream API. */
  task_type: InferencePutEisEisTaskType
  /** The unique identifier of the inference endpoint. */
  eis_inference_id: Id
  /** The type of service supported for the specified task type. In this case, `elastic`. */
  service: InferencePutEisServiceType
  /** Settings used to install the inference model. These settings are specific to the `elastic` service. */
  service_settings: InferencePutEisEisServiceSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { task_type?: never, eis_inference_id?: never, service?: never, service_settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { task_type?: never, eis_inference_id?: never, service?: never, service_settings?: never }
}

export type InferencePutEisResponse = InferenceInferenceEndpointInfo

export type InferencePutEisServiceType = 'elastic'

export interface InferencePutOpenaiOpenAIServiceSettings {
  api_key: string
  dimensions?: integer
  model_id: string
  organization_id?: string
  rate_limit?: InferenceRateLimitSetting
  url?: string
}

export interface InferencePutOpenaiOpenAITaskSettings {
  user?: string
}

export type InferencePutOpenaiOpenAITaskType = 'chat_completion' | 'completion' | 'text_embedding'

export interface InferencePutOpenaiRequest extends RequestBase {
/** The type of the inference task that the model will perform. NOTE: The `chat_completion` task type only supports streaming and only through the _stream API. */
  task_type: InferencePutOpenaiOpenAITaskType
  /** The unique identifier of the inference endpoint. */
  openai_inference_id: Id
  /** The chunking configuration object. */
  chunking_settings?: InferenceInferenceChunkingSettings
  /** The type of service supported for the specified task type. In this case, `openai`. */
  service: InferencePutOpenaiServiceType
  /** Settings used to install the inference model. These settings are specific to the `openai` service. */
  service_settings: InferencePutOpenaiOpenAIServiceSettings
  /** Settings to configure the inference task. These settings are specific to the task type you specified. */
  task_settings?: InferencePutOpenaiOpenAITaskSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { task_type?: never, openai_inference_id?: never, chunking_settings?: never, service?: never, service_settings?: never, task_settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { task_type?: never, openai_inference_id?: never, chunking_settings?: never, service?: never, service_settings?: never, task_settings?: never }
}

export type InferencePutOpenaiResponse = InferenceInferenceEndpointInfo

export type InferencePutOpenaiServiceType = 'openai'

export interface InferencePutVoyageaiRequest extends RequestBase {
/** The type of the inference task that the model will perform. */
  task_type: InferencePutVoyageaiVoyageAITaskType
  /** The unique identifier of the inference endpoint. */
  voyageai_inference_id: Id
  /** The chunking configuration object. */
  chunking_settings?: InferenceInferenceChunkingSettings
  /** The type of service supported for the specified task type. In this case, `voyageai`. */
  service: InferencePutVoyageaiServiceType
  /** Settings used to install the inference model. These settings are specific to the `voyageai` service. */
  service_settings: InferencePutVoyageaiVoyageAIServiceSettings
  /** Settings to configure the inference task. These settings are specific to the task type you specified. */
  task_settings?: InferencePutVoyageaiVoyageAITaskSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { task_type?: never, voyageai_inference_id?: never, chunking_settings?: never, service?: never, service_settings?: never, task_settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { task_type?: never, voyageai_inference_id?: never, chunking_settings?: never, service?: never, service_settings?: never, task_settings?: never }
}

export type InferencePutVoyageaiResponse = InferenceInferenceEndpointInfo

export type InferencePutVoyageaiServiceType = 'voyageai'

export interface InferencePutVoyageaiVoyageAIServiceSettings {
  dimensions?: integer
  model_id: string
  rate_limit?: InferenceRateLimitSetting
  embedding_type?: float
}

export interface InferencePutVoyageaiVoyageAITaskSettings {
  input_type?: string
  return_documents?: boolean
  top_k?: integer
  truncation?: boolean
}

export type InferencePutVoyageaiVoyageAITaskType = 'text_embedding' | 'rerank'

export interface InferencePutWatsonxRequest extends RequestBase {
/** The task type. The only valid task type for the model to perform is `text_embedding`. */
  task_type: InferencePutWatsonxWatsonxTaskType
  /** The unique identifier of the inference endpoint. */
  watsonx_inference_id: Id
  /** The type of service supported for the specified task type. In this case, `watsonxai`. */
  service: InferencePutWatsonxServiceType
  /** Settings used to install the inference model. These settings are specific to the `watsonxai` service. */
  service_settings: InferencePutWatsonxWatsonxServiceSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { task_type?: never, watsonx_inference_id?: never, service?: never, service_settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { task_type?: never, watsonx_inference_id?: never, service?: never, service_settings?: never }
}

export type InferencePutWatsonxResponse = InferenceInferenceEndpointInfo

export type InferencePutWatsonxServiceType = 'watsonxai'

export interface InferencePutWatsonxWatsonxServiceSettings {
  api_key: string
  api_version: string
  model_id: string
  project_id: string
  rate_limit?: InferenceRateLimitSetting
  url: string
}

export type InferencePutWatsonxWatsonxTaskType = 'text_embedding'

export interface InferenceRerankRequest extends RequestBase {
/** The unique identifier for the inference endpoint. */
  inference_id: Id
  /** The amount of time to wait for the inference request to complete. */
  timeout?: Duration
  /** Query input. */
  query: string
  /** The text on which you want to perform the inference task. It can be a single string or an array. > info > Inference endpoints for the `completion` task type currently only support a single string as input. */
  input: string | string[]
  /** Task settings for the individual inference request. These settings are specific to the task type you specified and override the task settings specified when initializing the service. */
  task_settings?: InferenceTaskSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { inference_id?: never, timeout?: never, query?: never, input?: never, task_settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { inference_id?: never, timeout?: never, query?: never, input?: never, task_settings?: never }
}

export type InferenceRerankResponse = InferenceRerankedInferenceResult

export interface InferenceSparseEmbeddingRequest extends RequestBase {
/** The inference Id */
  inference_id: Id
  /** Specifies the amount of time to wait for the inference request to complete. */
  timeout?: Duration
  /** Inference input. Either a string or an array of strings. */
  input: string | string[]
  /** Optional task settings */
  task_settings?: InferenceTaskSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { inference_id?: never, timeout?: never, input?: never, task_settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { inference_id?: never, timeout?: never, input?: never, task_settings?: never }
}

export type InferenceSparseEmbeddingResponse = InferenceSparseEmbeddingInferenceResult

export interface InferenceStreamCompletionRequest extends RequestBase {
/** The unique identifier for the inference endpoint. */
  inference_id: Id
  /** The text on which you want to perform the inference task. It can be a single string or an array. NOTE: Inference endpoints for the completion task type currently only support a single string as input. */
  input: string | string[]
  /** Optional task settings */
  task_settings?: InferenceTaskSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { inference_id?: never, input?: never, task_settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { inference_id?: never, input?: never, task_settings?: never }
}

export type InferenceStreamCompletionResponse = StreamResult

export interface InferenceTextEmbeddingRequest extends RequestBase {
/** The inference Id */
  inference_id: Id
  /** Specifies the amount of time to wait for the inference request to complete. */
  timeout?: Duration
  /** Inference input. Either a string or an array of strings. */
  input: string | string[]
  /** Optional task settings */
  task_settings?: InferenceTaskSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { inference_id?: never, timeout?: never, input?: never, task_settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { inference_id?: never, timeout?: never, input?: never, task_settings?: never }
}

export type InferenceTextEmbeddingResponse = InferenceTextEmbeddingInferenceResult

export interface InferenceUpdateRequest extends RequestBase {
/** The unique identifier of the inference endpoint. */
  inference_id: Id
  /** The type of inference task that the model performs. */
  task_type?: InferenceTaskType
  inference_config?: InferenceInferenceEndpoint
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { inference_id?: never, task_type?: never, inference_config?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { inference_id?: never, task_type?: never, inference_config?: never }
}

export type InferenceUpdateResponse = InferenceInferenceEndpointInfo

export interface IngestAppendProcessor extends IngestProcessorBase {
  field: Field
  value: any | any[]
  allow_duplicates?: boolean
}

export interface IngestAttachmentProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  indexed_chars?: long
  indexed_chars_field?: Field
  properties?: string[]
  target_field?: Field
  remove_binary?: boolean
  resource_name?: string
}

export interface IngestBytesProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  target_field?: Field
}

export interface IngestCircleProcessor extends IngestProcessorBase {
  error_distance: double
  field: Field
  ignore_missing?: boolean
  shape_type: IngestShapeType
  target_field?: Field
}

export interface IngestCommunityIDProcessor extends IngestProcessorBase {
  source_ip?: Field
  source_port?: Field
  destination_ip?: Field
  destination_port?: Field
  iana_number?: Field
  icmp_type?: Field
  icmp_code?: Field
  transport?: Field
  target_field?: Field
  seed?: integer
  ignore_missing?: boolean
}

export interface IngestConvertProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  target_field?: Field
  type: IngestConvertType
}

export type IngestConvertType = 'integer' | 'long' | 'double' | 'float' | 'boolean' | 'ip' | 'string' | 'auto'

export interface IngestCsvProcessor extends IngestProcessorBase {
  empty_value?: any
  field: Field
  ignore_missing?: boolean
  quote?: string
  separator?: string
  target_fields: Fields
  trim?: boolean
}

export interface IngestDatabaseConfiguration {
  name: Name
  maxmind?: IngestMaxmind
  ipinfo?: IngestIpinfo
}

export interface IngestDatabaseConfigurationFull {
  web?: IngestWeb
  local?: IngestLocal
  name: Name
  maxmind?: IngestMaxmind
  ipinfo?: IngestIpinfo
}

export interface IngestDateIndexNameProcessor extends IngestProcessorBase {
  date_formats?: string[]
  date_rounding: string
  field: Field
  index_name_format?: string
  index_name_prefix?: string
  locale?: string
  timezone?: string
}

export interface IngestDateProcessor extends IngestProcessorBase {
  field: Field
  formats: string[]
  locale?: string
  target_field?: Field
  timezone?: string
  output_format?: string
}

export interface IngestDissectProcessor extends IngestProcessorBase {
  append_separator?: string
  field: Field
  ignore_missing?: boolean
  pattern: string
}

export interface IngestDocument {
  _id?: Id
  _index?: IndexName
  _source: any
}

export interface IngestDocumentSimulationKeys {
  _id: Id
  _index: IndexName
  _ingest: IngestIngest
  _routing?: string
  _source: Record<string, any>
  _version?: SpecUtilsStringified<VersionNumber>
  _version_type?: VersionType
}
export type IngestDocumentSimulation = IngestDocumentSimulationKeys
& { [property: string]: string | Id | IndexName | IngestIngest | Record<string, any> | SpecUtilsStringified<VersionNumber> | VersionType }

export interface IngestDotExpanderProcessor extends IngestProcessorBase {
  field: Field
  override?: boolean
  path?: string
}

export interface IngestDropProcessor extends IngestProcessorBase {
}

export interface IngestEnrichProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  max_matches?: integer
  override?: boolean
  policy_name: string
  shape_relation?: GeoShapeRelation
  target_field: Field
}

export interface IngestFailProcessor extends IngestProcessorBase {
  message: string
}

export type IngestFingerprintDigest = 'MD5' | 'SHA-1' | 'SHA-256' | 'SHA-512' | 'MurmurHash3'

export interface IngestFingerprintProcessor extends IngestProcessorBase {
  fields: Fields
  target_field?: Field
  salt?: string
  method?: IngestFingerprintDigest
  ignore_missing?: boolean
}

export interface IngestForeachProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  processor: IngestProcessorContainer
}

export interface IngestGeoGridProcessor extends IngestProcessorBase {
  field: string
  tile_type: IngestGeoGridTileType
  target_field?: Field
  parent_field?: Field
  children_field?: Field
  non_children_field?: Field
  precision_field?: Field
  ignore_missing?: boolean
  target_format?: IngestGeoGridTargetFormat
}

export type IngestGeoGridTargetFormat = 'geojson' | 'wkt'

export type IngestGeoGridTileType = 'geotile' | 'geohex' | 'geohash'

export interface IngestGeoIpProcessor extends IngestProcessorBase {
  database_file?: string
  field: Field
  first_only?: boolean
  ignore_missing?: boolean
  properties?: string[]
  target_field?: Field
  download_database_on_pipeline_creation?: boolean
}

export interface IngestGrokProcessor extends IngestProcessorBase {
  ecs_compatibility?: string
  field: Field
  ignore_missing?: boolean
  pattern_definitions?: Record<string, string>
  patterns: GrokPattern[]
  trace_match?: boolean
}

export interface IngestGsubProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  pattern: string
  replacement: string
  target_field?: Field
}

export interface IngestHtmlStripProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  target_field?: Field
}

export interface IngestInferenceConfig {
  regression?: IngestInferenceConfigRegression
  classification?: IngestInferenceConfigClassification
}

export interface IngestInferenceConfigClassification {
  num_top_classes?: integer
  num_top_feature_importance_values?: integer
  results_field?: Field
  top_classes_results_field?: Field
  prediction_field_type?: string
}

export interface IngestInferenceConfigRegression {
  results_field?: Field
  num_top_feature_importance_values?: integer
}

export interface IngestInferenceProcessor extends IngestProcessorBase {
  model_id: Id
  target_field?: Field
  field_map?: Record<Field, any>
  inference_config?: IngestInferenceConfig
}

export interface IngestIngest {
  _redact?: IngestRedact
  timestamp: DateTime
  pipeline?: Name
}

export interface IngestIpLocationProcessor extends IngestProcessorBase {
  database_file?: string
  field: Field
  first_only?: boolean
  ignore_missing?: boolean
  properties?: string[]
  target_field?: Field
  download_database_on_pipeline_creation?: boolean
}

export interface IngestIpinfo {
}

export interface IngestJoinProcessor extends IngestProcessorBase {
  field: Field
  separator: string
  target_field?: Field
}

export interface IngestJsonProcessor extends IngestProcessorBase {
  add_to_root?: boolean
  add_to_root_conflict_strategy?: IngestJsonProcessorConflictStrategy
  allow_duplicate_keys?: boolean
  field: Field
  target_field?: Field
}

export type IngestJsonProcessorConflictStrategy = 'replace' | 'merge'

export interface IngestKeyValueProcessor extends IngestProcessorBase {
  exclude_keys?: string[]
  field: Field
  field_split: string
  ignore_missing?: boolean
  include_keys?: string[]
  prefix?: string
  strip_brackets?: boolean
  target_field?: Field
  trim_key?: string
  trim_value?: string
  value_split: string
}

export interface IngestLocal {
  type: string
}

export interface IngestLowercaseProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  target_field?: Field
}

export interface IngestMaxmind {
  account_id: Id
}

export interface IngestNetworkDirectionProcessor extends IngestProcessorBase {
  source_ip?: Field
  destination_ip?: Field
  target_field?: Field
  internal_networks?: string[]
  internal_networks_field?: Field
  ignore_missing?: boolean
}

export interface IngestPipeline {
  description?: string
  on_failure?: IngestProcessorContainer[]
  processors?: IngestProcessorContainer[]
  version?: VersionNumber
  deprecated?: boolean
  _meta?: Metadata
}

export interface IngestPipelineConfig {
  description?: string
  version?: VersionNumber
  processors: IngestProcessorContainer[]
}

export interface IngestPipelineProcessor extends IngestProcessorBase {
  name: Name
  ignore_missing_pipeline?: boolean
}

export interface IngestPipelineSimulation {
  doc?: IngestDocumentSimulation
  tag?: string
  processor_type?: string
  status?: WatcherActionStatusOptions
  description?: string
  ignored_error?: ErrorCause
  error?: ErrorCause
}

export interface IngestProcessorBase {
  description?: string
  if?: Script | string
  ignore_failure?: boolean
  on_failure?: IngestProcessorContainer[]
  tag?: string
}

export interface IngestProcessorContainer {
  append?: IngestAppendProcessor
  attachment?: IngestAttachmentProcessor
  bytes?: IngestBytesProcessor
  circle?: IngestCircleProcessor
  community_id?: IngestCommunityIDProcessor
  convert?: IngestConvertProcessor
  csv?: IngestCsvProcessor
  date?: IngestDateProcessor
  date_index_name?: IngestDateIndexNameProcessor
  dissect?: IngestDissectProcessor
  dot_expander?: IngestDotExpanderProcessor
  drop?: IngestDropProcessor
  enrich?: IngestEnrichProcessor
  fail?: IngestFailProcessor
  fingerprint?: IngestFingerprintProcessor
  foreach?: IngestForeachProcessor
  ip_location?: IngestIpLocationProcessor
  geo_grid?: IngestGeoGridProcessor
  geoip?: IngestGeoIpProcessor
  grok?: IngestGrokProcessor
  gsub?: IngestGsubProcessor
  html_strip?: IngestHtmlStripProcessor
  inference?: IngestInferenceProcessor
  join?: IngestJoinProcessor
  json?: IngestJsonProcessor
  kv?: IngestKeyValueProcessor
  lowercase?: IngestLowercaseProcessor
  network_direction?: IngestNetworkDirectionProcessor
  pipeline?: IngestPipelineProcessor
  redact?: IngestRedactProcessor
  registered_domain?: IngestRegisteredDomainProcessor
  remove?: IngestRemoveProcessor
  rename?: IngestRenameProcessor
  reroute?: IngestRerouteProcessor
  script?: IngestScriptProcessor
  set?: IngestSetProcessor
  set_security_user?: IngestSetSecurityUserProcessor
  sort?: IngestSortProcessor
  split?: IngestSplitProcessor
  terminate?: IngestTerminateProcessor
  trim?: IngestTrimProcessor
  uppercase?: IngestUppercaseProcessor
  urldecode?: IngestUrlDecodeProcessor
  uri_parts?: IngestUriPartsProcessor
  user_agent?: IngestUserAgentProcessor
}

export interface IngestRedact {
  _is_redacted: boolean
}

export interface IngestRedactProcessor extends IngestProcessorBase {
  field: Field
  patterns: GrokPattern[]
  pattern_definitions?: Record<string, string>
  prefix?: string
  suffix?: string
  ignore_missing?: boolean
  skip_if_unlicensed?: boolean
  trace_redact?: boolean
}

export interface IngestRegisteredDomainProcessor extends IngestProcessorBase {
  field: Field
  target_field?: Field
  ignore_missing?: boolean
}

export interface IngestRemoveProcessor extends IngestProcessorBase {
  field: Fields
  keep?: Fields
  ignore_missing?: boolean
}

export interface IngestRenameProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  target_field: Field
}

export interface IngestRerouteProcessor extends IngestProcessorBase {
  destination?: string
  dataset?: string | string[]
  namespace?: string | string[]
}

export interface IngestScriptProcessor extends IngestProcessorBase {
  id?: Id
  lang?: string
  params?: Record<string, any>
  source?: string
}

export interface IngestSetProcessor extends IngestProcessorBase {
  copy_from?: Field
  field: Field
  ignore_empty_value?: boolean
  media_type?: string
  override?: boolean
  value?: any
}

export interface IngestSetSecurityUserProcessor extends IngestProcessorBase {
  field: Field
  properties?: string[]
}

export type IngestShapeType = 'geo_shape' | 'shape'

export interface IngestSimulateDocumentResult {
  doc?: IngestDocumentSimulation
  error?: ErrorCause
  processor_results?: IngestPipelineSimulation[]
}

export interface IngestSortProcessor extends IngestProcessorBase {
  field: Field
  order?: SortOrder
  target_field?: Field
}

export interface IngestSplitProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  preserve_trailing?: boolean
  separator: string
  target_field?: Field
}

export interface IngestTerminateProcessor extends IngestProcessorBase {
}

export interface IngestTrimProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  target_field?: Field
}

export interface IngestUppercaseProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  target_field?: Field
}

export interface IngestUriPartsProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  keep_original?: boolean
  remove_if_successful?: boolean
  target_field?: Field
}

export interface IngestUrlDecodeProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  target_field?: Field
}

export interface IngestUserAgentProcessor extends IngestProcessorBase {
  field: Field
  ignore_missing?: boolean
  regex_file?: string
  target_field?: Field
  properties?: IngestUserAgentProperty[]
  extract_device_type?: boolean
}

export type IngestUserAgentProperty = 'name' | 'os' | 'device' | 'original' | 'version'

export interface IngestWeb {
}

export interface IngestDeleteGeoipDatabaseRequest extends RequestBase {
/** A comma-separated list of geoip database configurations to delete */
  id: Ids
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never }
}

export type IngestDeleteGeoipDatabaseResponse = AcknowledgedResponseBase

export interface IngestDeleteIpLocationDatabaseRequest extends RequestBase {
/** A comma-separated list of IP location database configurations. */
  id: Ids
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. A value of `-1` indicates that the request should never time out. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. A value of `-1` indicates that the request should never time out. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never }
}

export type IngestDeleteIpLocationDatabaseResponse = AcknowledgedResponseBase

export interface IngestDeletePipelineRequest extends RequestBase {
/** Pipeline ID or wildcard expression of pipeline IDs used to limit the request. To delete all ingest pipelines in a cluster, use a value of `*`. */
  id: Id
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never }
}

export type IngestDeletePipelineResponse = AcknowledgedResponseBase

export interface IngestGeoIpStatsGeoIpDownloadStatistics {
  successful_downloads: integer
  failed_downloads: integer
  total_download_time: DurationValue<UnitMillis>
  databases_count: integer
  skipped_updates: integer
  expired_databases: integer
}

export interface IngestGeoIpStatsGeoIpNodeDatabaseName {
  name: Name
}

export interface IngestGeoIpStatsGeoIpNodeDatabases {
  databases: IngestGeoIpStatsGeoIpNodeDatabaseName[]
  files_in_temp: string[]
}

export interface IngestGeoIpStatsRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface IngestGeoIpStatsResponse {
  stats: IngestGeoIpStatsGeoIpDownloadStatistics
  nodes: Record<Id, IngestGeoIpStatsGeoIpNodeDatabases>
}

export interface IngestGetGeoipDatabaseDatabaseConfigurationMetadata {
  id: Id
  version: long
  modified_date_millis: EpochTime<UnitMillis>
  database: IngestDatabaseConfiguration
}

export interface IngestGetGeoipDatabaseRequest extends RequestBase {
/** A comma-separated list of database configuration IDs to retrieve. Wildcard (`*`) expressions are supported. To get all database configurations, omit this parameter or use `*`. */
  id?: Ids
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export interface IngestGetGeoipDatabaseResponse {
  databases: IngestGetGeoipDatabaseDatabaseConfigurationMetadata[]
}

export interface IngestGetIpLocationDatabaseDatabaseConfigurationMetadata {
  id: Id
  version: VersionNumber
  modified_date_millis?: EpochTime<UnitMillis>
  modified_date?: EpochTime<UnitMillis>
  database: IngestDatabaseConfigurationFull
}

export interface IngestGetIpLocationDatabaseRequest extends RequestBase {
/** Comma-separated list of database configuration IDs to retrieve. Wildcard (`*`) expressions are supported. To get all database configurations, omit this parameter or use `*`. */
  id?: Ids
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. A value of `-1` indicates that the request should never time out. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, master_timeout?: never }
}

export interface IngestGetIpLocationDatabaseResponse {
  databases: IngestGetIpLocationDatabaseDatabaseConfigurationMetadata[]
}

export interface IngestGetPipelineRequest extends RequestBase {
/** Comma-separated list of pipeline IDs to retrieve. Wildcard (`*`) expressions are supported. To get all ingest pipelines, omit this parameter or use `*`. */
  id?: Id
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Return pipelines without their definitions (default: false) */
  summary?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, master_timeout?: never, summary?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, master_timeout?: never, summary?: never }
}

export type IngestGetPipelineResponse = Record<string, IngestPipeline>

export interface IngestProcessorGrokRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface IngestProcessorGrokResponse {
  patterns: Record<string, string>
}

export interface IngestPutGeoipDatabaseRequest extends RequestBase {
/** ID of the database configuration to create or update. */
  id: Id
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** The provider-assigned name of the IP geolocation database to download. */
  name: Name
  /** The configuration necessary to identify which IP geolocation provider to use to download the database, as well as any provider-specific configuration necessary for such downloading. At present, the only supported provider is maxmind, and the maxmind provider requires that an account_id (string) is configured. */
  maxmind: IngestMaxmind
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never, name?: never, maxmind?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never, name?: never, maxmind?: never }
}

export type IngestPutGeoipDatabaseResponse = AcknowledgedResponseBase

export interface IngestPutIpLocationDatabaseRequest extends RequestBase {
/** The database configuration identifier. */
  id: Id
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. A value of `-1` indicates that the request should never time out. */
  master_timeout?: Duration
  /** The period to wait for a response from all relevant nodes in the cluster after updating the cluster metadata. If no response is received before the timeout expires, the cluster metadata update still applies but the response indicates that it was not completely acknowledged. A value of `-1` indicates that the request should never time out. */
  timeout?: Duration
  configuration?: IngestDatabaseConfiguration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never, configuration?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never, configuration?: never }
}

export type IngestPutIpLocationDatabaseResponse = AcknowledgedResponseBase

export interface IngestPutPipelineRequest extends RequestBase {
/** ID of the ingest pipeline to create or update. */
  id: Id
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** Required version for optimistic concurrency control for pipeline updates */
  if_version?: VersionNumber
  /** Optional metadata about the ingest pipeline. May have any contents. This map is not automatically generated by Elasticsearch. */
  _meta?: Metadata
  /** Description of the ingest pipeline. */
  description?: string
  /** Processors to run immediately after a processor failure. Each processor supports a processor-level `on_failure` value. If a processor without an `on_failure` value fails, Elasticsearch uses this pipeline-level parameter as a fallback. The processors in this parameter run sequentially in the order specified. Elasticsearch will not attempt to run the pipeline's remaining processors. */
  on_failure?: IngestProcessorContainer[]
  /** Processors used to perform transformations on documents before indexing. Processors run sequentially in the order specified. */
  processors?: IngestProcessorContainer[]
  /** Version number used by external systems to track ingest pipelines. This parameter is intended for external systems only. Elasticsearch does not use or validate pipeline version numbers. */
  version?: VersionNumber
  /** Marks this ingest pipeline as deprecated. When a deprecated ingest pipeline is referenced as the default or final pipeline when creating or updating a non-deprecated index template, Elasticsearch will emit a deprecation warning. */
  deprecated?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never, if_version?: never, _meta?: never, description?: never, on_failure?: never, processors?: never, version?: never, deprecated?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, master_timeout?: never, timeout?: never, if_version?: never, _meta?: never, description?: never, on_failure?: never, processors?: never, version?: never, deprecated?: never }
}

export type IngestPutPipelineResponse = AcknowledgedResponseBase

export interface IngestSimulateRequest extends RequestBase {
/** The pipeline to test. If you don't specify a `pipeline` in the request body, this parameter is required. */
  id?: Id
  /** If `true`, the response includes output data for each processor in the executed pipeline. */
  verbose?: boolean
  /** Sample documents to test in the pipeline. */
  docs: IngestDocument[]
  /** The pipeline to test. If you don't specify the `pipeline` request path parameter, this parameter is required. If you specify both this and the request path parameter, the API only uses the request path parameter. */
  pipeline?: IngestPipeline
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, verbose?: never, docs?: never, pipeline?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, verbose?: never, docs?: never, pipeline?: never }
}

export interface IngestSimulateResponse {
  docs: IngestSimulateDocumentResult[]
}

export interface LicenseLicense {
  expiry_date_in_millis: EpochTime<UnitMillis>
  issue_date_in_millis: EpochTime<UnitMillis>
  start_date_in_millis?: EpochTime<UnitMillis>
  issued_to: string
  issuer: string
  max_nodes?: long | null
  max_resource_units?: long
  signature: string
  type: LicenseLicenseType
  uid: string
}

export type LicenseLicenseStatus = 'active' | 'valid' | 'invalid' | 'expired'

export type LicenseLicenseType = 'missing' | 'trial' | 'basic' | 'standard' | 'dev' | 'silver' | 'gold' | 'platinum' | 'enterprise'

export interface LicenseDeleteRequest extends RequestBase {
/** The period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never, timeout?: never }
}

export type LicenseDeleteResponse = AcknowledgedResponseBase

export interface LicenseGetLicenseInformation {
  expiry_date?: DateTime
  expiry_date_in_millis?: EpochTime<UnitMillis>
  issue_date: DateTime
  issue_date_in_millis: EpochTime<UnitMillis>
  issued_to: string
  issuer: string
  max_nodes: long | null
  max_resource_units?: integer | null
  status: LicenseLicenseStatus
  type: LicenseLicenseType
  uid: Uuid
  start_date_in_millis: EpochTime<UnitMillis>
}

export interface LicenseGetRequest extends RequestBase {
/** If `true`, this parameter returns enterprise for Enterprise license types. If `false`, this parameter returns platinum for both platinum and enterprise license types. This behavior is maintained for backwards compatibility. This parameter is deprecated and will always be set to true in 8.x. */
  accept_enterprise?: boolean
  /** Specifies whether to retrieve local information. The default value is `false`, which means the information is retrieved from the master node. */
  local?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { accept_enterprise?: never, local?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { accept_enterprise?: never, local?: never }
}

export interface LicenseGetResponse {
  license: LicenseGetLicenseInformation
}

export interface LicenseGetBasicStatusRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface LicenseGetBasicStatusResponse {
  eligible_to_start_basic: boolean
}

export interface LicenseGetTrialStatusRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface LicenseGetTrialStatusResponse {
  eligible_to_start_trial: boolean
}

export interface LicensePostAcknowledgement {
  license: string[]
  message: string
}

export interface LicensePostRequest extends RequestBase {
/** Specifies whether you acknowledge the license changes. */
  acknowledge?: boolean
  /** The period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  license?: LicenseLicense
  /** A sequence of one or more JSON documents containing the license information. */
  licenses?: LicenseLicense[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { acknowledge?: never, master_timeout?: never, timeout?: never, license?: never, licenses?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { acknowledge?: never, master_timeout?: never, timeout?: never, license?: never, licenses?: never }
}

export interface LicensePostResponse {
  acknowledge?: LicensePostAcknowledgement
  acknowledged: boolean
  license_status: LicenseLicenseStatus
}

export interface LicensePostStartBasicRequest extends RequestBase {
/** whether the user has acknowledged acknowledge messages (default: false) */
  acknowledge?: boolean
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { acknowledge?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { acknowledge?: never, master_timeout?: never, timeout?: never }
}

export interface LicensePostStartBasicResponse {
  acknowledged: boolean
  basic_was_started: boolean
  error_message?: string
  type?: LicenseLicenseType
  acknowledge?: Record<string, string | string[]>
}

export interface LicensePostStartTrialRequest extends RequestBase {
/** whether the user has acknowledged acknowledge messages (default: false) */
  acknowledge?: boolean
  type_query_string?: string
  /** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { acknowledge?: never, type_query_string?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { acknowledge?: never, type_query_string?: never, master_timeout?: never }
}

export interface LicensePostStartTrialResponse {
  acknowledged: boolean
  error_message?: string
  trial_was_started: boolean
  type?: LicenseLicenseType
}

export interface LogstashPipeline {
  description: string
  last_modified: DateTime
  pipeline: string
  pipeline_metadata: LogstashPipelineMetadata
  pipeline_settings: LogstashPipelineSettings
  username: string
}

export interface LogstashPipelineMetadata {
  type: string
  version: string
}

export interface LogstashPipelineSettings {
  'pipeline.workers': integer
  'pipeline.batch.size': integer
  'pipeline.batch.delay': integer
  'queue.type': string
  'queue.max_bytes.number': integer
  'queue.max_bytes.units': string
  'queue.checkpoint.writes': integer
}

export interface LogstashDeletePipelineRequest extends RequestBase {
/** An identifier for the pipeline. */
  id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export type LogstashDeletePipelineResponse = boolean

export interface LogstashGetPipelineRequest extends RequestBase {
/** A comma-separated list of pipeline identifiers. */
  id?: Ids
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export type LogstashGetPipelineResponse = Record<Id, LogstashPipeline>

export interface LogstashPutPipelineRequest extends RequestBase {
/** An identifier for the pipeline. */
  id: Id
  pipeline?: LogstashPipeline
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, pipeline?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, pipeline?: never }
}

export type LogstashPutPipelineResponse = boolean

export interface MigrationDeprecationsDeprecation {
  details?: string
  level: MigrationDeprecationsDeprecationLevel
  message: string
  url: string
  resolve_during_rolling_upgrade: boolean
  _meta?: Record<string, any>
}

export type MigrationDeprecationsDeprecationLevel = 'none' | 'info' | 'warning' | 'critical'

export interface MigrationDeprecationsRequest extends RequestBase {
/** Comma-separate list of data streams or indices to check. Wildcard (*) expressions are supported. */
  index?: IndexName
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never }
}

export interface MigrationDeprecationsResponse {
  cluster_settings: MigrationDeprecationsDeprecation[]
  index_settings: Record<string, MigrationDeprecationsDeprecation[]>
  data_streams: Record<string, MigrationDeprecationsDeprecation[]>
  node_settings: MigrationDeprecationsDeprecation[]
  ml_settings: MigrationDeprecationsDeprecation[]
  templates: Record<string, MigrationDeprecationsDeprecation[]>
  ilm_policies: Record<string, MigrationDeprecationsDeprecation[]>
}

export interface MigrationGetFeatureUpgradeStatusMigrationFeature {
  feature_name: string
  minimum_index_version: VersionString
  migration_status: MigrationGetFeatureUpgradeStatusMigrationStatus
  indices: MigrationGetFeatureUpgradeStatusMigrationFeatureIndexInfo[]
}

export interface MigrationGetFeatureUpgradeStatusMigrationFeatureIndexInfo {
  index: IndexName
  version: VersionString
  failure_cause?: ErrorCause
}

export type MigrationGetFeatureUpgradeStatusMigrationStatus = 'NO_MIGRATION_NEEDED' | 'MIGRATION_NEEDED' | 'IN_PROGRESS' | 'ERROR'

export interface MigrationGetFeatureUpgradeStatusRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface MigrationGetFeatureUpgradeStatusResponse {
  features: MigrationGetFeatureUpgradeStatusMigrationFeature[]
  migration_status: MigrationGetFeatureUpgradeStatusMigrationStatus
}

export interface MigrationPostFeatureUpgradeMigrationFeature {
  feature_name: string
}

export interface MigrationPostFeatureUpgradeRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface MigrationPostFeatureUpgradeResponse {
  accepted: boolean
  features: MigrationPostFeatureUpgradeMigrationFeature[]
}

export interface MlAdaptiveAllocationsSettings {
  enabled: boolean
  min_number_of_allocations?: integer
  max_number_of_allocations?: integer
}

export interface MlAnalysisConfig {
  bucket_span?: Duration
  categorization_analyzer?: MlCategorizationAnalyzer
  categorization_field_name?: Field
  categorization_filters?: string[]
  detectors: MlDetector[]
  influencers?: Field[]
  latency?: Duration
  model_prune_window?: Duration
  multivariate_by_fields?: boolean
  per_partition_categorization?: MlPerPartitionCategorization
  summary_count_field_name?: Field
}

export interface MlAnalysisConfigRead {
  bucket_span: Duration
  categorization_analyzer?: MlCategorizationAnalyzer
  categorization_field_name?: Field
  categorization_filters?: string[]
  detectors: MlDetectorRead[]
  influencers: Field[]
  model_prune_window?: Duration
  latency?: Duration
  multivariate_by_fields?: boolean
  per_partition_categorization?: MlPerPartitionCategorization
  summary_count_field_name?: Field
}

export interface MlAnalysisLimits {
  categorization_examples_limit?: long
  model_memory_limit?: ByteSize
}

export interface MlAnalysisMemoryLimit {
  model_memory_limit: string
}

export interface MlAnomaly {
  actual?: double[]
  anomaly_score_explanation?: MlAnomalyExplanation
  bucket_span: DurationValue<UnitSeconds>
  by_field_name?: string
  by_field_value?: string
  causes?: MlAnomalyCause[]
  detector_index: integer
  field_name?: string
  function?: string
  function_description?: string
  geo_results?: MlGeoResults
  influencers?: MlInfluence[]
  initial_record_score: double
  is_interim: boolean
  job_id: string
  over_field_name?: string
  over_field_value?: string
  partition_field_name?: string
  partition_field_value?: string
  probability: double
  record_score: double
  result_type: string
  timestamp: EpochTime<UnitMillis>
  typical?: double[]
}

export interface MlAnomalyCause {
  actual?: double[]
  by_field_name?: Name
  by_field_value?: string
  correlated_by_field_value?: string
  field_name?: Field
  function?: string
  function_description?: string
  geo_results?: MlGeoResults
  influencers?: MlInfluence[]
  over_field_name?: Name
  over_field_value?: string
  partition_field_name?: string
  partition_field_value?: string
  probability: double
  typical?: double[]
}

export interface MlAnomalyExplanation {
  anomaly_characteristics_impact?: integer
  anomaly_length?: integer
  anomaly_type?: string
  high_variance_penalty?: boolean
  incomplete_bucket_penalty?: boolean
  lower_confidence_bound?: double
  multi_bucket_impact?: integer
  single_bucket_impact?: integer
  typical_value?: double
  upper_confidence_bound?: double
}

export interface MlApiKeyAuthorization {
  id: string
  name: string
}

export type MlAppliesTo = 'actual' | 'typical' | 'diff_from_typical' | 'time'

export interface MlBucketInfluencer {
  anomaly_score: double
  bucket_span: DurationValue<UnitSeconds>
  influencer_field_name: Field
  initial_anomaly_score: double
  is_interim: boolean
  job_id: Id
  probability: double
  raw_anomaly_score: double
  result_type: string
  timestamp: EpochTime<UnitMillis>
  timestamp_string?: DateTime
}

export interface MlBucketSummary {
  anomaly_score: double
  bucket_influencers: MlBucketInfluencer[]
  bucket_span: DurationValue<UnitSeconds>
  event_count: long
  initial_anomaly_score: double
  is_interim: boolean
  job_id: Id
  processing_time_ms: DurationValue<UnitMillis>
  result_type: string
  timestamp: EpochTime<UnitMillis>
  timestamp_string?: DateTime
}

export interface MlCalendarEvent {
  calendar_id?: Id
  event_id?: Id
  description: string
  end_time: DateTime
  start_time: DateTime
  skip_result?: boolean
  skip_model_update?: boolean
  force_time_shift?: integer
}

export type MlCategorizationAnalyzer = string | MlCategorizationAnalyzerDefinition

export interface MlCategorizationAnalyzerDefinition {
  char_filter?: AnalysisCharFilter[]
  filter?: AnalysisTokenFilter[]
  tokenizer?: AnalysisTokenizer
}

export type MlCategorizationStatus = 'ok' | 'warn'

export interface MlCategory {
  category_id: ulong
  examples: string[]
  grok_pattern?: GrokPattern
  job_id: Id
  max_matching_length: ulong
  partition_field_name?: string
  partition_field_value?: string
  regex: string
  terms: string
  num_matches?: long
  preferred_to_categories?: Id[]
  p?: string
  result_type: string
  mlcategory: string
}

export interface MlChunkingConfig {
  mode: MlChunkingMode
  time_span?: Duration
}

export type MlChunkingMode = 'auto' | 'manual' | 'off'

export interface MlClassificationInferenceOptions {
  num_top_classes?: integer
  num_top_feature_importance_values?: integer
  prediction_field_type?: string
  results_field?: string
  top_classes_results_field?: string
}

export interface MlCommonTokenizationConfig {
  do_lower_case?: boolean
  max_sequence_length?: integer
  span?: integer
  truncate?: MlTokenizationTruncate
  with_special_tokens?: boolean
}

export type MlConditionOperator = 'gt' | 'gte' | 'lt' | 'lte'

export type MlCustomSettings = any

export interface MlDataCounts {
  bucket_count: long
  earliest_record_timestamp?: long
  empty_bucket_count: long
  input_bytes: long
  input_field_count: long
  input_record_count: long
  invalid_date_count: long
  job_id: Id
  last_data_time?: long
  latest_empty_bucket_timestamp?: long
  latest_record_timestamp?: long
  latest_sparse_bucket_timestamp?: long
  latest_bucket_timestamp?: long
  log_time?: long
  missing_field_count: long
  out_of_order_timestamp_count: long
  processed_field_count: long
  processed_record_count: long
  sparse_bucket_count: long
}

export interface MlDataDescription {
  format?: string
  time_field?: Field
  time_format?: string
  field_delimiter?: string
}

export interface MlDatafeed {
  aggregations?: Record<string, AggregationsAggregationContainer>
  aggs?: Record<string, AggregationsAggregationContainer>
  authorization?: MlDatafeedAuthorization
  chunking_config?: MlChunkingConfig
  datafeed_id: Id
  frequency?: Duration
  indices: string[]
  indexes?: string[]
  job_id: Id
  max_empty_searches?: integer
  query: QueryDslQueryContainer
  query_delay?: Duration
  script_fields?: Record<string, ScriptField>
  scroll_size?: integer
  delayed_data_check_config: MlDelayedDataCheckConfig
  runtime_mappings?: MappingRuntimeFields
  indices_options?: IndicesOptions
}

export interface MlDatafeedAuthorization {
  api_key?: MlApiKeyAuthorization
  roles?: string[]
  service_account?: string
}

export interface MlDatafeedConfig {
  aggregations?: Record<string, AggregationsAggregationContainer>
  aggs?: Record<string, AggregationsAggregationContainer>
  chunking_config?: MlChunkingConfig
  datafeed_id?: Id
  delayed_data_check_config?: MlDelayedDataCheckConfig
  frequency?: Duration
  indices?: Indices
  indexes?: Indices
  indices_options?: IndicesOptions
  job_id?: Id
  max_empty_searches?: integer
  query?: QueryDslQueryContainer
  query_delay?: Duration
  runtime_mappings?: MappingRuntimeFields
  script_fields?: Record<string, ScriptField>
  scroll_size?: integer
}

export interface MlDatafeedRunningState {
  real_time_configured: boolean
  real_time_running: boolean
  search_interval?: MlRunningStateSearchInterval
}

export type MlDatafeedState = 'started' | 'stopped' | 'starting' | 'stopping'

export interface MlDatafeedStats {
  assignment_explanation?: string
  datafeed_id: Id
  node?: MlDiscoveryNodeCompact
  state: MlDatafeedState
  timing_stats?: MlDatafeedTimingStats
  running_state?: MlDatafeedRunningState
}

export interface MlDatafeedTimingStats {
  bucket_count: long
  exponential_average_search_time_per_hour_ms: DurationValue<UnitFloatMillis>
  exponential_average_calculation_context?: MlExponentialAverageCalculationContext
  job_id: Id
  search_count: long
  total_search_time_ms: DurationValue<UnitFloatMillis>
  average_search_time_per_bucket_ms?: DurationValue<UnitFloatMillis>
}

export interface MlDataframeAnalysis {
  alpha?: double
  dependent_variable: string
  downsample_factor?: double
  early_stopping_enabled?: boolean
  eta?: double
  eta_growth_rate_per_tree?: double
  feature_bag_fraction?: double
  feature_processors?: MlDataframeAnalysisFeatureProcessor[]
  gamma?: double
  lambda?: double
  max_optimization_rounds_per_hyperparameter?: integer
  max_trees?: integer
  maximum_number_trees?: integer
  num_top_feature_importance_values?: integer
  prediction_field_name?: Field
  randomize_seed?: double
  soft_tree_depth_limit?: integer
  soft_tree_depth_tolerance?: double
  training_percent?: Percentage
}

export interface MlDataframeAnalysisAnalyzedFields {
  includes?: string[]
  excludes?: string[]
}

export interface MlDataframeAnalysisClassification extends MlDataframeAnalysis {
  class_assignment_objective?: string
  num_top_classes?: integer
}

export interface MlDataframeAnalysisContainer {
  classification?: MlDataframeAnalysisClassification
  outlier_detection?: MlDataframeAnalysisOutlierDetection
  regression?: MlDataframeAnalysisRegression
}

export interface MlDataframeAnalysisFeatureProcessor {
  frequency_encoding?: MlDataframeAnalysisFeatureProcessorFrequencyEncoding
  multi_encoding?: MlDataframeAnalysisFeatureProcessorMultiEncoding
  n_gram_encoding?: MlDataframeAnalysisFeatureProcessorNGramEncoding
  one_hot_encoding?: MlDataframeAnalysisFeatureProcessorOneHotEncoding
  target_mean_encoding?: MlDataframeAnalysisFeatureProcessorTargetMeanEncoding
}

export interface MlDataframeAnalysisFeatureProcessorFrequencyEncoding {
  feature_name: Name
  field: Field
  frequency_map: Record<string, double>
}

export interface MlDataframeAnalysisFeatureProcessorMultiEncoding {
  processors: integer[]
}

export interface MlDataframeAnalysisFeatureProcessorNGramEncoding {
  feature_prefix?: string
  field: Field
  length?: integer
  n_grams: integer[]
  start?: integer
  custom?: boolean
}

export interface MlDataframeAnalysisFeatureProcessorOneHotEncoding {
  field: Field
  hot_map: string
}

export interface MlDataframeAnalysisFeatureProcessorTargetMeanEncoding {
  default_value: integer
  feature_name: Name
  field: Field
  target_map: Record<string, any>
}

export interface MlDataframeAnalysisOutlierDetection {
  compute_feature_influence?: boolean
  feature_influence_threshold?: double
  method?: string
  n_neighbors?: integer
  outlier_fraction?: double
  standardization_enabled?: boolean
}

export interface MlDataframeAnalysisRegression extends MlDataframeAnalysis {
  loss_function?: string
  loss_function_parameter?: double
}

export interface MlDataframeAnalytics {
  analysis_stats?: MlDataframeAnalyticsStatsContainer
  assignment_explanation?: string
  data_counts: MlDataframeAnalyticsStatsDataCounts
  id: Id
  memory_usage: MlDataframeAnalyticsStatsMemoryUsage
  node?: NodeAttributes
  progress: MlDataframeAnalyticsStatsProgress[]
  state: MlDataframeState
}

export interface MlDataframeAnalyticsAuthorization {
  api_key?: MlApiKeyAuthorization
  roles?: string[]
  service_account?: string
}

export interface MlDataframeAnalyticsDestination {
  index: IndexName
  results_field?: Field
}

export interface MlDataframeAnalyticsFieldSelection {
  is_included: boolean
  is_required: boolean
  feature_type?: string
  mapping_types: string[]
  name: Field
  reason?: string
}

export interface MlDataframeAnalyticsMemoryEstimation {
  expected_memory_with_disk: string
  expected_memory_without_disk: string
}

export interface MlDataframeAnalyticsSource {
  index: Indices
  query?: QueryDslQueryContainer
  runtime_mappings?: MappingRuntimeFields
  _source?: MlDataframeAnalysisAnalyzedFields | string[]
}

export interface MlDataframeAnalyticsStatsContainer {
  classification_stats?: MlDataframeAnalyticsStatsHyperparameters
  outlier_detection_stats?: MlDataframeAnalyticsStatsOutlierDetection
  regression_stats?: MlDataframeAnalyticsStatsHyperparameters
}

export interface MlDataframeAnalyticsStatsDataCounts {
  skipped_docs_count: integer
  test_docs_count: integer
  training_docs_count: integer
}

export interface MlDataframeAnalyticsStatsHyperparameters {
  hyperparameters: MlHyperparameters
  iteration: integer
  timestamp: EpochTime<UnitMillis>
  timing_stats: MlTimingStats
  validation_loss: MlValidationLoss
}

export interface MlDataframeAnalyticsStatsMemoryUsage {
  memory_reestimate_bytes?: long
  peak_usage_bytes: long
  status: string
  timestamp?: EpochTime<UnitMillis>
}

export interface MlDataframeAnalyticsStatsOutlierDetection {
  parameters: MlOutlierDetectionParameters
  timestamp: EpochTime<UnitMillis>
  timing_stats: MlTimingStats
}

export interface MlDataframeAnalyticsStatsProgress {
  phase: string
  progress_percent: integer
}

export interface MlDataframeAnalyticsSummary {
  allow_lazy_start?: boolean
  analysis: MlDataframeAnalysisContainer
  analyzed_fields?: MlDataframeAnalysisAnalyzedFields | string[]
  authorization?: MlDataframeAnalyticsAuthorization
  create_time?: EpochTime<UnitMillis>
  description?: string
  dest: MlDataframeAnalyticsDestination
  id: Id
  max_num_threads?: integer
  model_memory_limit?: string
  source: MlDataframeAnalyticsSource
  version?: VersionString
  _meta?: Metadata
}

export interface MlDataframeEvaluationClassification {
  actual_field: Field
  predicted_field?: Field
  top_classes_field?: Field
  metrics?: MlDataframeEvaluationClassificationMetrics
}

export interface MlDataframeEvaluationClassificationMetrics extends MlDataframeEvaluationMetrics {
  accuracy?: Record<string, any>
  multiclass_confusion_matrix?: Record<string, any>
}

export interface MlDataframeEvaluationClassificationMetricsAucRoc {
  class_name?: Name
  include_curve?: boolean
}

export interface MlDataframeEvaluationContainer {
  classification?: MlDataframeEvaluationClassification
  outlier_detection?: MlDataframeEvaluationOutlierDetection
  regression?: MlDataframeEvaluationRegression
}

export interface MlDataframeEvaluationMetrics {
  auc_roc?: MlDataframeEvaluationClassificationMetricsAucRoc
  precision?: Record<string, any>
  recall?: Record<string, any>
}

export interface MlDataframeEvaluationOutlierDetection {
  actual_field: Field
  predicted_probability_field: Field
  metrics?: MlDataframeEvaluationOutlierDetectionMetrics
}

export interface MlDataframeEvaluationOutlierDetectionMetrics extends MlDataframeEvaluationMetrics {
  confusion_matrix?: Record<string, any>
}

export interface MlDataframeEvaluationRegression {
  actual_field: Field
  predicted_field: Field
  metrics?: MlDataframeEvaluationRegressionMetrics
}

export interface MlDataframeEvaluationRegressionMetrics {
  mse?: Record<string, any>
  msle?: MlDataframeEvaluationRegressionMetricsMsle
  huber?: MlDataframeEvaluationRegressionMetricsHuber
  r_squared?: Record<string, any>
}

export interface MlDataframeEvaluationRegressionMetricsHuber {
  delta?: double
}

export interface MlDataframeEvaluationRegressionMetricsMsle {
  offset?: double
}

export type MlDataframeState = 'started' | 'stopped' | 'starting' | 'stopping' | 'failed'

export interface MlDelayedDataCheckConfig {
  check_window?: Duration
  enabled: boolean
}

export type MlDeploymentAllocationState = 'started' | 'starting' | 'fully_allocated'

export type MlDeploymentAssignmentState = 'started' | 'starting' | 'stopping' | 'failed'

export interface MlDetectionRule {
  actions?: MlRuleAction[]
  conditions?: MlRuleCondition[]
  scope?: Record<Field, MlFilterRef>
}

export interface MlDetector {
  by_field_name?: Field
  custom_rules?: MlDetectionRule[]
  detector_description?: string
  detector_index?: integer
  exclude_frequent?: MlExcludeFrequent
  field_name?: Field
  function?: string
  over_field_name?: Field
  partition_field_name?: Field
  use_null?: boolean
}

export interface MlDetectorRead {
  by_field_name?: Field
  custom_rules?: MlDetectionRule[]
  detector_description?: string
  detector_index?: integer
  exclude_frequent?: MlExcludeFrequent
  field_name?: Field
  function: string
  over_field_name?: Field
  partition_field_name?: Field
  use_null?: boolean
}

export interface MlDetectorUpdate {
  detector_index: integer
  description?: string
  custom_rules?: MlDetectionRule[]
}

export type MlDiscoveryNode = Partial<Record<Id, MlDiscoveryNodeContent>>

export interface MlDiscoveryNodeCompact {
  name: Name
  ephemeral_id: Id
  id: Id
  transport_address: TransportAddress
  attributes: Record<string, string>
}

export interface MlDiscoveryNodeContent {
  name?: Name
  ephemeral_id: Id
  transport_address: TransportAddress
  external_id: string
  attributes: Record<string, string>
  roles: string[]
  version: VersionString
  min_index_version: integer
  max_index_version: integer
}

export type MlExcludeFrequent = 'all' | 'none' | 'by' | 'over'

export interface MlExponentialAverageCalculationContext {
  incremental_metric_value_ms: DurationValue<UnitFloatMillis>
  latest_timestamp?: EpochTime<UnitMillis>
  previous_exponential_average_ms?: DurationValue<UnitFloatMillis>
}

export interface MlFillMaskInferenceOptions {
  mask_token?: string
  num_top_classes?: integer
  tokenization?: MlTokenizationConfigContainer
  results_field?: string
  vocabulary: MlVocabulary
}

export interface MlFillMaskInferenceUpdateOptions {
  num_top_classes?: integer
  tokenization?: MlNlpTokenizationUpdateOptions
  results_field?: string
}

export interface MlFilter {
  description?: string
  filter_id: Id
  items: string[]
}

export interface MlFilterRef {
  filter_id: Id
  filter_type?: MlFilterType
}

export type MlFilterType = 'include' | 'exclude'

export interface MlGeoResults {
  actual_point?: string
  typical_point?: string
}

export interface MlHyperparameter {
  absolute_importance?: double
  name: Name
  relative_importance?: double
  supplied: boolean
  value: double
}

export interface MlHyperparameters {
  alpha?: double
  lambda?: double
  gamma?: double
  eta?: double
  eta_growth_rate_per_tree?: double
  feature_bag_fraction?: double
  downsample_factor?: double
  max_attempts_to_add_tree?: integer
  max_optimization_rounds_per_hyperparameter?: integer
  max_trees?: integer
  num_folds?: integer
  num_splits_per_feature?: integer
  soft_tree_depth_limit?: integer
  soft_tree_depth_tolerance?: double
}

export type MlInclude = 'definition' | 'feature_importance_baseline' | 'hyperparameters' | 'total_feature_importance' | 'definition_status'

export interface MlInferenceConfigCreateContainer {
  regression?: MlRegressionInferenceOptions
  classification?: MlClassificationInferenceOptions
  text_classification?: MlTextClassificationInferenceOptions
  zero_shot_classification?: MlZeroShotClassificationInferenceOptions
  fill_mask?: MlFillMaskInferenceOptions
  ner?: MlNerInferenceOptions
  pass_through?: MlPassThroughInferenceOptions
  text_embedding?: MlTextEmbeddingInferenceOptions
  text_expansion?: MlTextExpansionInferenceOptions
  question_answering?: MlQuestionAnsweringInferenceOptions
}

export interface MlInferenceConfigUpdateContainer {
  regression?: MlRegressionInferenceOptions
  classification?: MlClassificationInferenceOptions
  text_classification?: MlTextClassificationInferenceUpdateOptions
  zero_shot_classification?: MlZeroShotClassificationInferenceUpdateOptions
  fill_mask?: MlFillMaskInferenceUpdateOptions
  ner?: MlNerInferenceUpdateOptions
  pass_through?: MlPassThroughInferenceUpdateOptions
  text_embedding?: MlTextEmbeddingInferenceUpdateOptions
  text_expansion?: MlTextExpansionInferenceUpdateOptions
  question_answering?: MlQuestionAnsweringInferenceUpdateOptions
}

export interface MlInferenceResponseResult {
  entities?: MlTrainedModelEntities[]
  is_truncated?: boolean
  predicted_value?: MlPredictedValue | MlPredictedValue[]
  predicted_value_sequence?: string
  prediction_probability?: double
  prediction_score?: double
  top_classes?: MlTopClassEntry[]
  warning?: string
  feature_importance?: MlTrainedModelInferenceFeatureImportance[]
}

export interface MlInfluence {
  influencer_field_name: string
  influencer_field_values: string[]
}

export interface MlInfluencer {
  bucket_span: DurationValue<UnitSeconds>
  influencer_score: double
  influencer_field_name: Field
  influencer_field_value: string
  initial_influencer_score: double
  is_interim: boolean
  job_id: Id
  probability: double
  result_type: string
  timestamp: EpochTime<UnitMillis>
  foo?: string
}

export interface MlJob {
  allow_lazy_open: boolean
  analysis_config: MlAnalysisConfig
  analysis_limits?: MlAnalysisLimits
  background_persist_interval?: Duration
  blocked?: MlJobBlocked
  create_time?: DateTime
  custom_settings?: MlCustomSettings
  daily_model_snapshot_retention_after_days?: long
  data_description: MlDataDescription
  datafeed_config?: MlDatafeed
  deleting?: boolean
  description?: string
  finished_time?: DateTime
  groups?: string[]
  job_id: Id
  job_type?: string
  job_version?: VersionString
  model_plot_config?: MlModelPlotConfig
  model_snapshot_id?: Id
  model_snapshot_retention_days: long
  renormalization_window_days?: long
  results_index_name: IndexName
  results_retention_days?: long
}

export interface MlJobBlocked {
  reason: MlJobBlockedReason
  task_id?: TaskId
}

export type MlJobBlockedReason = 'delete' | 'reset' | 'revert'

export interface MlJobConfig {
  allow_lazy_open?: boolean
  analysis_config: MlAnalysisConfig
  analysis_limits?: MlAnalysisLimits
  background_persist_interval?: Duration
  custom_settings?: MlCustomSettings
  daily_model_snapshot_retention_after_days?: long
  data_description: MlDataDescription
  datafeed_config?: MlDatafeedConfig
  description?: string
  groups?: string[]
  job_id?: Id
  job_type?: string
  model_plot_config?: MlModelPlotConfig
  model_snapshot_retention_days?: long
  renormalization_window_days?: long
  results_index_name?: IndexName
  results_retention_days?: long
}

export interface MlJobForecastStatistics {
  memory_bytes?: MlJobStatistics
  processing_time_ms?: MlJobStatistics
  records?: MlJobStatistics
  status?: Record<string, long>
  total: long
  forecasted_jobs: integer
}

export type MlJobState = 'closing' | 'closed' | 'opened' | 'failed' | 'opening'

export interface MlJobStatistics {
  avg: double
  max: double
  min: double
  total: double
}

export interface MlJobStats {
  assignment_explanation?: string
  data_counts: MlDataCounts
  forecasts_stats: MlJobForecastStatistics
  job_id: string
  model_size_stats: MlModelSizeStats
  node?: MlDiscoveryNodeCompact
  open_time?: DateTime
  state: MlJobState
  timing_stats: MlJobTimingStats
  deleting?: boolean
}

export interface MlJobTimingStats {
  average_bucket_processing_time_ms?: DurationValue<UnitFloatMillis>
  bucket_count: long
  exponential_average_bucket_processing_time_ms?: DurationValue<UnitFloatMillis>
  exponential_average_bucket_processing_time_per_hour_ms: DurationValue<UnitFloatMillis>
  job_id: Id
  total_bucket_processing_time_ms: DurationValue<UnitFloatMillis>
  maximum_bucket_processing_time_ms?: DurationValue<UnitFloatMillis>
  minimum_bucket_processing_time_ms?: DurationValue<UnitFloatMillis>
}

export type MlMemoryStatus = 'ok' | 'soft_limit' | 'hard_limit'

export interface MlModelPackageConfig {
  create_time?: EpochTime<UnitMillis>
  description?: string
  inference_config?: Record<string, any>
  metadata?: Metadata
  minimum_version?: string
  model_repository?: string
  model_type?: string
  packaged_model_id: Id
  platform_architecture?: string
  prefix_strings?: MlTrainedModelPrefixStrings
  size?: ByteSize
  sha256?: string
  tags?: string[]
  vocabulary_file?: string
}

export interface MlModelPlotConfig {
  annotations_enabled?: boolean
  enabled?: boolean
  terms?: Field
}

export interface MlModelSizeStats {
  bucket_allocation_failures_count: long
  job_id: Id
  log_time: DateTime
  memory_status: MlMemoryStatus
  model_bytes: ByteSize
  model_bytes_exceeded?: ByteSize
  model_bytes_memory_limit?: ByteSize
  output_memory_allocator_bytes?: ByteSize
  peak_model_bytes?: ByteSize
  assignment_memory_basis?: string
  result_type: string
  total_by_field_count: long
  total_over_field_count: long
  total_partition_field_count: long
  categorization_status: MlCategorizationStatus
  categorized_doc_count: integer
  dead_category_count: integer
  failed_category_count: integer
  frequent_category_count: integer
  rare_category_count: integer
  total_category_count: integer
  timestamp?: long
}

export interface MlModelSnapshot {
  description?: string
  job_id: Id
  latest_record_time_stamp?: integer
  latest_result_time_stamp?: integer
  min_version: VersionString
  model_size_stats?: MlModelSizeStats
  retain: boolean
  snapshot_doc_count: long
  snapshot_id: Id
  timestamp: long
}

export interface MlModelSnapshotUpgrade {
  job_id: Id
  snapshot_id: Id
  state: MlSnapshotUpgradeState
  node: MlDiscoveryNode
  assignment_explanation: string
}

export interface MlNerInferenceOptions {
  tokenization?: MlTokenizationConfigContainer
  results_field?: string
  classification_labels?: string[]
  vocabulary?: MlVocabulary
}

export interface MlNerInferenceUpdateOptions {
  tokenization?: MlNlpTokenizationUpdateOptions
  results_field?: string
}

export interface MlNlpBertTokenizationConfig extends MlCommonTokenizationConfig {
}

export interface MlNlpRobertaTokenizationConfig extends MlCommonTokenizationConfig {
  add_prefix_space?: boolean
}

export interface MlNlpTokenizationUpdateOptions {
  truncate?: MlTokenizationTruncate
  span?: integer
}

export interface MlOutlierDetectionParameters {
  compute_feature_influence?: boolean
  feature_influence_threshold?: double
  method?: string
  n_neighbors?: integer
  outlier_fraction?: double
  standardization_enabled?: boolean
}

export interface MlOverallBucket {
  bucket_span: DurationValue<UnitSeconds>
  is_interim: boolean
  jobs: MlOverallBucketJob[]
  overall_score: double
  result_type: string
  timestamp: EpochTime<UnitMillis>
  timestamp_string?: DateTime
}

export interface MlOverallBucketJob {
  job_id: Id
  max_anomaly_score: double
}

export interface MlPage {
  from?: integer
  size?: integer
}

export interface MlPassThroughInferenceOptions {
  tokenization?: MlTokenizationConfigContainer
  results_field?: string
  vocabulary?: MlVocabulary
}

export interface MlPassThroughInferenceUpdateOptions {
  tokenization?: MlNlpTokenizationUpdateOptions
  results_field?: string
}

export interface MlPerPartitionCategorization {
  enabled?: boolean
  stop_on_warn?: boolean
}

export type MlPredictedValue = ScalarValue | ScalarValue[]

export interface MlQuestionAnsweringInferenceOptions {
  num_top_classes?: integer
  tokenization?: MlTokenizationConfigContainer
  results_field?: string
  max_answer_length?: integer
}

export interface MlQuestionAnsweringInferenceUpdateOptions {
  question: string
  num_top_classes?: integer
  tokenization?: MlNlpTokenizationUpdateOptions
  results_field?: string
  max_answer_length?: integer
}

export interface MlRegressionInferenceOptions {
  results_field?: Field
  num_top_feature_importance_values?: integer
}

export type MlRoutingState = 'failed' | 'started' | 'starting' | 'stopped' | 'stopping'

export type MlRuleAction = 'skip_result' | 'skip_model_update'

export interface MlRuleCondition {
  applies_to: MlAppliesTo
  operator: MlConditionOperator
  value: double
}

export interface MlRunningStateSearchInterval {
  end?: Duration
  end_ms: DurationValue<UnitMillis>
  start?: Duration
  start_ms: DurationValue<UnitMillis>
}

export type MlSnapshotUpgradeState = 'loading_old_state' | 'saving_new_state' | 'stopped' | 'failed'

export interface MlTextClassificationInferenceOptions {
  num_top_classes?: integer
  tokenization?: MlTokenizationConfigContainer
  results_field?: string
  classification_labels?: string[]
}

export interface MlTextClassificationInferenceUpdateOptions {
  num_top_classes?: integer
  tokenization?: MlNlpTokenizationUpdateOptions
  results_field?: string
  classification_labels?: string[]
}

export interface MlTextEmbeddingInferenceOptions {
  embedding_size?: integer
  tokenization?: MlTokenizationConfigContainer
  results_field?: string
  vocabulary: MlVocabulary
}

export interface MlTextEmbeddingInferenceUpdateOptions {
  tokenization?: MlNlpTokenizationUpdateOptions
  results_field?: string
}

export interface MlTextExpansionInferenceOptions {
  tokenization?: MlTokenizationConfigContainer
  results_field?: string
  vocabulary: MlVocabulary
}

export interface MlTextExpansionInferenceUpdateOptions {
  tokenization?: MlNlpTokenizationUpdateOptions
  results_field?: string
}

export interface MlTimingStats {
  elapsed_time: DurationValue<UnitMillis>
  iteration_time?: DurationValue<UnitMillis>
}

export interface MlTokenizationConfigContainer {
  bert?: MlNlpBertTokenizationConfig
  bert_ja?: MlNlpBertTokenizationConfig
  mpnet?: MlNlpBertTokenizationConfig
  roberta?: MlNlpRobertaTokenizationConfig
}

export type MlTokenizationTruncate = 'first' | 'second' | 'none'

export interface MlTopClassEntry {
  class_name: string
  class_probability: double
  class_score: double
}

export interface MlTotalFeatureImportance {
  feature_name: Name
  importance: MlTotalFeatureImportanceStatistics[]
  classes: MlTotalFeatureImportanceClass[]
}

export interface MlTotalFeatureImportanceClass {
  class_name: Name
  importance: MlTotalFeatureImportanceStatistics[]
}

export interface MlTotalFeatureImportanceStatistics {
  mean_magnitude: double
  max: integer
  min: integer
}

export interface MlTrainedModelAssignment {
  adaptive_allocations?: MlAdaptiveAllocationsSettings | null
  assignment_state: MlDeploymentAssignmentState
  max_assigned_allocations?: integer
  reason?: string
  routing_table: Record<string, MlTrainedModelAssignmentRoutingTable>
  start_time: DateTime
  task_parameters: MlTrainedModelAssignmentTaskParameters
}

export interface MlTrainedModelAssignmentRoutingTable {
  reason?: string
  routing_state: MlRoutingState
  current_allocations: integer
  target_allocations: integer
}

export interface MlTrainedModelAssignmentTaskParameters {
  model_bytes: ByteSize
  model_id: Id
  deployment_id: Id
  cache_size?: ByteSize
  number_of_allocations: integer
  priority: MlTrainingPriority
  per_deployment_memory_bytes: ByteSize
  per_allocation_memory_bytes: ByteSize
  queue_capacity: integer
  threads_per_allocation: integer
}

export interface MlTrainedModelConfig {
  model_id: Id
  model_type?: MlTrainedModelType
  tags: string[]
  version?: VersionString
  compressed_definition?: string
  created_by?: string
  create_time?: DateTime
  default_field_map?: Record<string, string>
  description?: string
  estimated_heap_memory_usage_bytes?: integer
  estimated_operations?: integer
  fully_defined?: boolean
  inference_config?: MlInferenceConfigCreateContainer
  input: MlTrainedModelConfigInput
  license_level?: string
  metadata?: MlTrainedModelConfigMetadata
  model_size_bytes?: ByteSize
  model_package?: MlModelPackageConfig
  location?: MlTrainedModelLocation
  prefix_strings?: MlTrainedModelPrefixStrings
}

export interface MlTrainedModelConfigInput {
  field_names: Field[]
}

export interface MlTrainedModelConfigMetadata {
  model_aliases?: string[]
  feature_importance_baseline?: Record<string, string>
  hyperparameters?: MlHyperparameter[]
  total_feature_importance?: MlTotalFeatureImportance[]
}

export interface MlTrainedModelDeploymentAllocationStatus {
  allocation_count: integer
  state: MlDeploymentAllocationState
  target_allocation_count: integer
}

export interface MlTrainedModelDeploymentNodesStats {
  average_inference_time_ms?: DurationValue<UnitFloatMillis>
  average_inference_time_ms_last_minute?: DurationValue<UnitFloatMillis>
  average_inference_time_ms_excluding_cache_hits?: DurationValue<UnitFloatMillis>
  error_count?: integer
  inference_count?: long
  inference_cache_hit_count?: long
  inference_cache_hit_count_last_minute?: long
  last_access?: EpochTime<UnitMillis>
  node?: MlDiscoveryNode
  number_of_allocations?: integer
  number_of_pending_requests?: integer
  peak_throughput_per_minute: long
  rejection_execution_count?: integer
  routing_state: MlTrainedModelAssignmentRoutingTable
  start_time?: EpochTime<UnitMillis>
  threads_per_allocation?: integer
  throughput_last_minute: integer
  timeout_count?: integer
}

export interface MlTrainedModelDeploymentStats {
  adaptive_allocations?: MlAdaptiveAllocationsSettings
  allocation_status?: MlTrainedModelDeploymentAllocationStatus
  cache_size?: ByteSize
  deployment_id: Id
  error_count?: integer
  inference_count?: integer
  model_id: Id
  nodes: MlTrainedModelDeploymentNodesStats[]
  number_of_allocations?: integer
  peak_throughput_per_minute: long
  priority: MlTrainingPriority
  queue_capacity?: integer
  rejected_execution_count?: integer
  reason?: string
  start_time: EpochTime<UnitMillis>
  state?: MlDeploymentAssignmentState
  threads_per_allocation?: integer
  timeout_count?: integer
}

export interface MlTrainedModelEntities {
  class_name: string
  class_probability: double
  entity: string
  start_pos: integer
  end_pos: integer
}

export interface MlTrainedModelInferenceClassImportance {
  class_name: string
  importance: double
}

export interface MlTrainedModelInferenceFeatureImportance {
  feature_name: string
  importance?: double
  classes?: MlTrainedModelInferenceClassImportance[]
}

export interface MlTrainedModelInferenceStats {
  cache_miss_count: integer
  failure_count: integer
  inference_count: integer
  missing_all_fields_count: integer
  timestamp: EpochTime<UnitMillis>
}

export interface MlTrainedModelLocation {
  index: MlTrainedModelLocationIndex
}

export interface MlTrainedModelLocationIndex {
  name: IndexName
}

export interface MlTrainedModelPrefixStrings {
  ingest?: string
  search?: string
}

export interface MlTrainedModelSizeStats {
  model_size_bytes: ByteSize
  required_native_memory_bytes: ByteSize
}

export interface MlTrainedModelStats {
  deployment_stats?: MlTrainedModelDeploymentStats
  inference_stats?: MlTrainedModelInferenceStats
  ingest?: Record<string, any>
  model_id: Id
  model_size_stats: MlTrainedModelSizeStats
  pipeline_count: integer
}

export type MlTrainedModelType = 'tree_ensemble' | 'lang_ident' | 'pytorch'

export type MlTrainingPriority = 'normal' | 'low'

export interface MlTransformAuthorization {
  api_key?: MlApiKeyAuthorization
  roles?: string[]
  service_account?: string
}

export interface MlValidationLoss {
  fold_values: string[]
  loss_type: string
}

export interface MlVocabulary {
  index: IndexName
}

export interface MlZeroShotClassificationInferenceOptions {
  tokenization?: MlTokenizationConfigContainer
  hypothesis_template?: string
  classification_labels: string[]
  results_field?: string
  multi_label?: boolean
  labels?: string[]
}

export interface MlZeroShotClassificationInferenceUpdateOptions {
  tokenization?: MlNlpTokenizationUpdateOptions
  results_field?: string
  multi_label?: boolean
  labels: string[]
}

export interface MlClearTrainedModelDeploymentCacheRequest extends RequestBase {
/** The unique identifier of the trained model. */
  model_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_id?: never }
}

export interface MlClearTrainedModelDeploymentCacheResponse {
  cleared: boolean
}

export interface MlCloseJobRequest extends RequestBase {
/** Identifier for the anomaly detection job. It can be a job identifier, a group name, or a wildcard expression. You can close multiple anomaly detection jobs in a single API request by using a group name, a comma-separated list of jobs, or a wildcard expression. You can close all jobs by using `_all` or by specifying `*` as the job identifier. */
  job_id: Id
  /** Refer to the description for the `allow_no_match` query parameter. */
  allow_no_match?: boolean
  /** Refer to the descriptiion for the `force` query parameter. */
  force?: boolean
  /** Refer to the description for the `timeout` query parameter. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, allow_no_match?: never, force?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, allow_no_match?: never, force?: never, timeout?: never }
}

export interface MlCloseJobResponse {
  closed: boolean
}

export interface MlDeleteCalendarRequest extends RequestBase {
/** A string that uniquely identifies a calendar. */
  calendar_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { calendar_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { calendar_id?: never }
}

export type MlDeleteCalendarResponse = AcknowledgedResponseBase

export interface MlDeleteCalendarEventRequest extends RequestBase {
/** A string that uniquely identifies a calendar. */
  calendar_id: Id
  /** Identifier for the scheduled event. You can obtain this identifier by using the get calendar events API. */
  event_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { calendar_id?: never, event_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { calendar_id?: never, event_id?: never }
}

export type MlDeleteCalendarEventResponse = AcknowledgedResponseBase

export interface MlDeleteCalendarJobRequest extends RequestBase {
/** A string that uniquely identifies a calendar. */
  calendar_id: Id
  /** An identifier for the anomaly detection jobs. It can be a job identifier, a group name, or a comma-separated list of jobs or groups. */
  job_id: Ids
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { calendar_id?: never, job_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { calendar_id?: never, job_id?: never }
}

export interface MlDeleteCalendarJobResponse {
  calendar_id: Id
  description?: string
  job_ids: Ids
}

export interface MlDeleteDataFrameAnalyticsRequest extends RequestBase {
/** Identifier for the data frame analytics job. */
  id: Id
  /** If `true`, it deletes a job that is not stopped; this method is quicker than stopping and deleting the job. */
  force?: boolean
  /** The time to wait for the job to be deleted. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, force?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, force?: never, timeout?: never }
}

export type MlDeleteDataFrameAnalyticsResponse = AcknowledgedResponseBase

export interface MlDeleteDatafeedRequest extends RequestBase {
/** A numerical character string that uniquely identifies the datafeed. This identifier can contain lowercase alphanumeric characters (a-z and 0-9), hyphens, and underscores. It must start and end with alphanumeric characters. */
  datafeed_id: Id
  /** Use to forcefully delete a started datafeed; this method is quicker than stopping and deleting the datafeed. */
  force?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { datafeed_id?: never, force?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { datafeed_id?: never, force?: never }
}

export type MlDeleteDatafeedResponse = AcknowledgedResponseBase

export interface MlDeleteExpiredDataRequest extends RequestBase {
/** Identifier for an anomaly detection job. It can be a job identifier, a group name, or a wildcard expression. */
  job_id?: Id
  /** The desired requests per second for the deletion processes. The default behavior is no throttling. */
  requests_per_second?: float
  /** How long can the underlying delete processes run until they are canceled. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, requests_per_second?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, requests_per_second?: never, timeout?: never }
}

export interface MlDeleteExpiredDataResponse {
  deleted: boolean
}

export interface MlDeleteFilterRequest extends RequestBase {
/** A string that uniquely identifies a filter. */
  filter_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { filter_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { filter_id?: never }
}

export type MlDeleteFilterResponse = AcknowledgedResponseBase

export interface MlDeleteForecastRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** A comma-separated list of forecast identifiers. If you do not specify this optional parameter or if you specify `_all` or `*` the API deletes all forecasts from the job. */
  forecast_id?: Id
  /** Specifies whether an error occurs when there are no forecasts. In particular, if this parameter is set to `false` and there are no forecasts associated with the job, attempts to delete all forecasts return an error. */
  allow_no_forecasts?: boolean
  /** Specifies the period of time to wait for the completion of the delete operation. When this period of time elapses, the API fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, forecast_id?: never, allow_no_forecasts?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, forecast_id?: never, allow_no_forecasts?: never, timeout?: never }
}

export type MlDeleteForecastResponse = AcknowledgedResponseBase

export interface MlDeleteJobRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** Use to forcefully delete an opened job; this method is quicker than closing and deleting the job. */
  force?: boolean
  /** Specifies whether annotations that have been added by the user should be deleted along with any auto-generated annotations when the job is reset. */
  delete_user_annotations?: boolean
  /** Specifies whether the request should return immediately or wait until the job deletion completes. */
  wait_for_completion?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, force?: never, delete_user_annotations?: never, wait_for_completion?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, force?: never, delete_user_annotations?: never, wait_for_completion?: never }
}

export type MlDeleteJobResponse = AcknowledgedResponseBase

export interface MlDeleteModelSnapshotRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** Identifier for the model snapshot. */
  snapshot_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, snapshot_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, snapshot_id?: never }
}

export type MlDeleteModelSnapshotResponse = AcknowledgedResponseBase

export interface MlDeleteTrainedModelRequest extends RequestBase {
/** The unique identifier of the trained model. */
  model_id: Id
  /** Forcefully deletes a trained model that is referenced by ingest pipelines or has a started deployment. */
  force?: boolean
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_id?: never, force?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_id?: never, force?: never, timeout?: never }
}

export type MlDeleteTrainedModelResponse = AcknowledgedResponseBase

export interface MlDeleteTrainedModelAliasRequest extends RequestBase {
/** The model alias to delete. */
  model_alias: Name
  /** The trained model ID to which the model alias refers. */
  model_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_alias?: never, model_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_alias?: never, model_id?: never }
}

export type MlDeleteTrainedModelAliasResponse = AcknowledgedResponseBase

export interface MlEstimateModelMemoryRequest extends RequestBase {
/** For a list of the properties that you can specify in the `analysis_config` component of the body of this API. */
  analysis_config?: MlAnalysisConfig
  /** Estimates of the highest cardinality in a single bucket that is observed for influencer fields over the time period that the job analyzes data. To produce a good answer, values must be provided for all influencer fields. Providing values for fields that are not listed as `influencers` has no effect on the estimation. */
  max_bucket_cardinality?: Record<Field, long>
  /** Estimates of the cardinality that is observed for fields over the whole time period that the job analyzes data. To produce a good answer, values must be provided for fields referenced in the `by_field_name`, `over_field_name` and `partition_field_name` of any detectors. Providing values for other fields has no effect on the estimation. It can be omitted from the request if no detectors have a `by_field_name`, `over_field_name` or `partition_field_name`. */
  overall_cardinality?: Record<Field, long>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { analysis_config?: never, max_bucket_cardinality?: never, overall_cardinality?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { analysis_config?: never, max_bucket_cardinality?: never, overall_cardinality?: never }
}

export interface MlEstimateModelMemoryResponse {
  model_memory_estimate: string
}

export interface MlEvaluateDataFrameConfusionMatrixItem {
  actual_class: Name
  actual_class_doc_count: integer
  predicted_classes: MlEvaluateDataFrameConfusionMatrixPrediction[]
  other_predicted_class_doc_count: integer
}

export interface MlEvaluateDataFrameConfusionMatrixPrediction {
  predicted_class: Name
  count: integer
}

export interface MlEvaluateDataFrameConfusionMatrixThreshold {
  tp: integer
  fp: integer
  tn: integer
  fn: integer
}

export interface MlEvaluateDataFrameDataframeClassificationSummary {
  auc_roc?: MlEvaluateDataFrameDataframeEvaluationSummaryAucRoc
  accuracy?: MlEvaluateDataFrameDataframeClassificationSummaryAccuracy
  multiclass_confusion_matrix?: MlEvaluateDataFrameDataframeClassificationSummaryMulticlassConfusionMatrix
  precision?: MlEvaluateDataFrameDataframeClassificationSummaryPrecision
  recall?: MlEvaluateDataFrameDataframeClassificationSummaryRecall
}

export interface MlEvaluateDataFrameDataframeClassificationSummaryAccuracy {
  classes: MlEvaluateDataFrameDataframeEvaluationClass[]
  overall_accuracy: double
}

export interface MlEvaluateDataFrameDataframeClassificationSummaryMulticlassConfusionMatrix {
  confusion_matrix: MlEvaluateDataFrameConfusionMatrixItem[]
  other_actual_class_count: integer
}

export interface MlEvaluateDataFrameDataframeClassificationSummaryPrecision {
  classes: MlEvaluateDataFrameDataframeEvaluationClass[]
  avg_precision: double
}

export interface MlEvaluateDataFrameDataframeClassificationSummaryRecall {
  classes: MlEvaluateDataFrameDataframeEvaluationClass[]
  avg_recall: double
}

export interface MlEvaluateDataFrameDataframeEvaluationClass extends MlEvaluateDataFrameDataframeEvaluationValue {
  class_name: Name
}

export interface MlEvaluateDataFrameDataframeEvaluationSummaryAucRoc extends MlEvaluateDataFrameDataframeEvaluationValue {
  curve?: MlEvaluateDataFrameDataframeEvaluationSummaryAucRocCurveItem[]
}

export interface MlEvaluateDataFrameDataframeEvaluationSummaryAucRocCurveItem {
  tpr: double
  fpr: double
  threshold: double
}

export interface MlEvaluateDataFrameDataframeEvaluationValue {
  value: double
}

export interface MlEvaluateDataFrameDataframeOutlierDetectionSummary {
  auc_roc?: MlEvaluateDataFrameDataframeEvaluationSummaryAucRoc
  precision?: Record<string, double>
  recall?: Record<string, double>
  confusion_matrix?: Record<string, MlEvaluateDataFrameConfusionMatrixThreshold>
}

export interface MlEvaluateDataFrameDataframeRegressionSummary {
  huber?: MlEvaluateDataFrameDataframeEvaluationValue
  mse?: MlEvaluateDataFrameDataframeEvaluationValue
  msle?: MlEvaluateDataFrameDataframeEvaluationValue
  r_squared?: MlEvaluateDataFrameDataframeEvaluationValue
}

export interface MlEvaluateDataFrameRequest extends RequestBase {
/** Defines the type of evaluation you want to perform. */
  evaluation: MlDataframeEvaluationContainer
  /** Defines the `index` in which the evaluation will be performed. */
  index: IndexName
  /** A query clause that retrieves a subset of data from the source index. */
  query?: QueryDslQueryContainer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { evaluation?: never, index?: never, query?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { evaluation?: never, index?: never, query?: never }
}

export interface MlEvaluateDataFrameResponse {
  classification?: MlEvaluateDataFrameDataframeClassificationSummary
  outlier_detection?: MlEvaluateDataFrameDataframeOutlierDetectionSummary
  regression?: MlEvaluateDataFrameDataframeRegressionSummary
}

export interface MlExplainDataFrameAnalyticsRequest extends RequestBase {
/** Identifier for the data frame analytics job. This identifier can contain lowercase alphanumeric characters (a-z and 0-9), hyphens, and underscores. It must start and end with alphanumeric characters. */
  id?: Id
  /** The configuration of how to source the analysis data. It requires an index. Optionally, query and _source may be specified. */
  source?: MlDataframeAnalyticsSource
  /** The destination configuration, consisting of index and optionally results_field (ml by default). */
  dest?: MlDataframeAnalyticsDestination
  /** The analysis configuration, which contains the information necessary to perform one of the following types of analysis: classification, outlier detection, or regression. */
  analysis?: MlDataframeAnalysisContainer
  /** A description of the job. */
  description?: string
  /** The approximate maximum amount of memory resources that are permitted for analytical processing. If your `elasticsearch.yml` file contains an `xpack.ml.max_model_memory_limit` setting, an error occurs when you try to create data frame analytics jobs that have `model_memory_limit` values greater than that setting. */
  model_memory_limit?: string
  /** The maximum number of threads to be used by the analysis. Using more threads may decrease the time necessary to complete the analysis at the cost of using more CPU. Note that the process may use additional threads for operational functionality other than the analysis itself. */
  max_num_threads?: integer
  /** Specify includes and/or excludes patterns to select which fields will be included in the analysis. The patterns specified in excludes are applied last, therefore excludes takes precedence. In other words, if the same field is specified in both includes and excludes, then the field will not be included in the analysis. */
  analyzed_fields?: MlDataframeAnalysisAnalyzedFields | string[]
  /** Specifies whether this job can start when there is insufficient machine learning node capacity for it to be immediately assigned to a node. */
  allow_lazy_start?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, source?: never, dest?: never, analysis?: never, description?: never, model_memory_limit?: never, max_num_threads?: never, analyzed_fields?: never, allow_lazy_start?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, source?: never, dest?: never, analysis?: never, description?: never, model_memory_limit?: never, max_num_threads?: never, analyzed_fields?: never, allow_lazy_start?: never }
}

export interface MlExplainDataFrameAnalyticsResponse {
  field_selection: MlDataframeAnalyticsFieldSelection[]
  memory_estimation: MlDataframeAnalyticsMemoryEstimation
}

export interface MlFlushJobRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** Refer to the description for the `advance_time` query parameter. */
  advance_time?: DateTime
  /** Refer to the description for the `calc_interim` query parameter. */
  calc_interim?: boolean
  /** Refer to the description for the `end` query parameter. */
  end?: DateTime
  /** Refer to the description for the `skip_time` query parameter. */
  skip_time?: DateTime
  /** Refer to the description for the `start` query parameter. */
  start?: DateTime
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, advance_time?: never, calc_interim?: never, end?: never, skip_time?: never, start?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, advance_time?: never, calc_interim?: never, end?: never, skip_time?: never, start?: never }
}

export interface MlFlushJobResponse {
  flushed: boolean
  last_finalized_bucket_end?: integer
}

export interface MlForecastRequest extends RequestBase {
/** Identifier for the anomaly detection job. The job must be open when you create a forecast; otherwise, an error occurs. */
  job_id: Id
  /** Refer to the description for the `duration` query parameter. */
  duration?: Duration
  /** Refer to the description for the `expires_in` query parameter. */
  expires_in?: Duration
  /** Refer to the description for the `max_model_memory` query parameter. */
  max_model_memory?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, duration?: never, expires_in?: never, max_model_memory?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, duration?: never, expires_in?: never, max_model_memory?: never }
}

export interface MlForecastResponse {
  acknowledged: boolean
  forecast_id: Id
}

export interface MlGetBucketsRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** The timestamp of a single bucket result. If you do not specify this parameter, the API returns information about all buckets. */
  timestamp?: DateTime
  /** Skips the specified number of buckets. */
  from?: integer
  /** Specifies the maximum number of buckets to obtain. */
  size?: integer
  /** Refer to the description for the `anomaly_score` query parameter. */
  anomaly_score?: double
  /** Refer to the description for the `desc` query parameter. */
  desc?: boolean
  /** Refer to the description for the `end` query parameter. */
  end?: DateTime
  /** Refer to the description for the `exclude_interim` query parameter. */
  exclude_interim?: boolean
  /** Refer to the description for the `expand` query parameter. */
  expand?: boolean
  page?: MlPage
  /** Refer to the desription for the `sort` query parameter. */
  sort?: Field
  /** Refer to the description for the `start` query parameter. */
  start?: DateTime
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, timestamp?: never, from?: never, size?: never, anomaly_score?: never, desc?: never, end?: never, exclude_interim?: never, expand?: never, page?: never, sort?: never, start?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, timestamp?: never, from?: never, size?: never, anomaly_score?: never, desc?: never, end?: never, exclude_interim?: never, expand?: never, page?: never, sort?: never, start?: never }
}

export interface MlGetBucketsResponse {
  buckets: MlBucketSummary[]
  count: long
}

export interface MlGetCalendarEventsRequest extends RequestBase {
/** A string that uniquely identifies a calendar. You can get information for multiple calendars by using a comma-separated list of ids or a wildcard expression. You can get information for all calendars by using `_all` or `*` or by omitting the calendar identifier. */
  calendar_id: Id
  /** Specifies to get events with timestamps earlier than this time. */
  end?: DateTime
  /** Skips the specified number of events. */
  from?: integer
  /** Specifies to get events for a specific anomaly detection job identifier or job group. It must be used with a calendar identifier of `_all` or `*`. */
  job_id?: Id
  /** Specifies the maximum number of events to obtain. */
  size?: integer
  /** Specifies to get events with timestamps after this time. */
  start?: DateTime
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { calendar_id?: never, end?: never, from?: never, job_id?: never, size?: never, start?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { calendar_id?: never, end?: never, from?: never, job_id?: never, size?: never, start?: never }
}

export interface MlGetCalendarEventsResponse {
  count: long
  events: MlCalendarEvent[]
}

export interface MlGetCalendarsCalendar {
  calendar_id: Id
  description?: string
  job_ids: Id[]
}

export interface MlGetCalendarsRequest extends RequestBase {
/** A string that uniquely identifies a calendar. You can get information for multiple calendars by using a comma-separated list of ids or a wildcard expression. You can get information for all calendars by using `_all` or `*` or by omitting the calendar identifier. */
  calendar_id?: Id
  /** Skips the specified number of calendars. This parameter is supported only when you omit the calendar identifier. */
  from?: integer
  /** Specifies the maximum number of calendars to obtain. This parameter is supported only when you omit the calendar identifier. */
  size?: integer
  /** This object is supported only when you omit the calendar identifier. */
  page?: MlPage
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { calendar_id?: never, from?: never, size?: never, page?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { calendar_id?: never, from?: never, size?: never, page?: never }
}

export interface MlGetCalendarsResponse {
  calendars: MlGetCalendarsCalendar[]
  count: long
}

export interface MlGetCategoriesRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** Identifier for the category, which is unique in the job. If you specify neither the category ID nor the partition_field_value, the API returns information about all categories. If you specify only the partition_field_value, it returns information about all categories for the specified partition. */
  category_id?: CategoryId
  /** Skips the specified number of categories. */
  from?: integer
  /** Only return categories for the specified partition. */
  partition_field_value?: string
  /** Specifies the maximum number of categories to obtain. */
  size?: integer
  /** Configures pagination. This parameter has the `from` and `size` properties. */
  page?: MlPage
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, category_id?: never, from?: never, partition_field_value?: never, size?: never, page?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, category_id?: never, from?: never, partition_field_value?: never, size?: never, page?: never }
}

export interface MlGetCategoriesResponse {
  categories: MlCategory[]
  count: long
}

export interface MlGetDataFrameAnalyticsRequest extends RequestBase {
/** Identifier for the data frame analytics job. If you do not specify this option, the API returns information for the first hundred data frame analytics jobs. */
  id?: Id
  /** Specifies what to do when the request: 1. Contains wildcard expressions and there are no data frame analytics jobs that match. 2. Contains the `_all` string or no identifiers and there are no matches. 3. Contains wildcard expressions and there are only partial matches. The default value returns an empty data_frame_analytics array when there are no matches and the subset of results when there are partial matches. If this parameter is `false`, the request returns a 404 status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** Skips the specified number of data frame analytics jobs. */
  from?: integer
  /** Specifies the maximum number of data frame analytics jobs to obtain. */
  size?: integer
  /** Indicates if certain fields should be removed from the configuration on retrieval. This allows the configuration to be in an acceptable format to be retrieved and then added to another cluster. */
  exclude_generated?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, allow_no_match?: never, from?: never, size?: never, exclude_generated?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, allow_no_match?: never, from?: never, size?: never, exclude_generated?: never }
}

export interface MlGetDataFrameAnalyticsResponse {
  count: integer
  data_frame_analytics: MlDataframeAnalyticsSummary[]
}

export interface MlGetDataFrameAnalyticsStatsRequest extends RequestBase {
/** Identifier for the data frame analytics job. If you do not specify this option, the API returns information for the first hundred data frame analytics jobs. */
  id?: Id
  /** Specifies what to do when the request: 1. Contains wildcard expressions and there are no data frame analytics jobs that match. 2. Contains the `_all` string or no identifiers and there are no matches. 3. Contains wildcard expressions and there are only partial matches. The default value returns an empty data_frame_analytics array when there are no matches and the subset of results when there are partial matches. If this parameter is `false`, the request returns a 404 status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** Skips the specified number of data frame analytics jobs. */
  from?: integer
  /** Specifies the maximum number of data frame analytics jobs to obtain. */
  size?: integer
  /** Defines whether the stats response should be verbose. */
  verbose?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, allow_no_match?: never, from?: never, size?: never, verbose?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, allow_no_match?: never, from?: never, size?: never, verbose?: never }
}

export interface MlGetDataFrameAnalyticsStatsResponse {
  count: long
  data_frame_analytics: MlDataframeAnalytics[]
}

export interface MlGetDatafeedStatsRequest extends RequestBase {
/** Identifier for the datafeed. It can be a datafeed identifier or a wildcard expression. If you do not specify one of these options, the API returns information about all datafeeds. */
  datafeed_id?: Ids
  /** Specifies what to do when the request: 1. Contains wildcard expressions and there are no datafeeds that match. 2. Contains the `_all` string or no identifiers and there are no matches. 3. Contains wildcard expressions and there are only partial matches. The default value is `true`, which returns an empty `datafeeds` array when there are no matches and the subset of results when there are partial matches. If this parameter is `false`, the request returns a `404` status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { datafeed_id?: never, allow_no_match?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { datafeed_id?: never, allow_no_match?: never }
}

export interface MlGetDatafeedStatsResponse {
  count: long
  datafeeds: MlDatafeedStats[]
}

export interface MlGetDatafeedsRequest extends RequestBase {
/** Identifier for the datafeed. It can be a datafeed identifier or a wildcard expression. If you do not specify one of these options, the API returns information about all datafeeds. */
  datafeed_id?: Ids
  /** Specifies what to do when the request: 1. Contains wildcard expressions and there are no datafeeds that match. 2. Contains the `_all` string or no identifiers and there are no matches. 3. Contains wildcard expressions and there are only partial matches. The default value is `true`, which returns an empty `datafeeds` array when there are no matches and the subset of results when there are partial matches. If this parameter is `false`, the request returns a `404` status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** Indicates if certain fields should be removed from the configuration on retrieval. This allows the configuration to be in an acceptable format to be retrieved and then added to another cluster. */
  exclude_generated?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { datafeed_id?: never, allow_no_match?: never, exclude_generated?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { datafeed_id?: never, allow_no_match?: never, exclude_generated?: never }
}

export interface MlGetDatafeedsResponse {
  count: long
  datafeeds: MlDatafeed[]
}

export interface MlGetFiltersRequest extends RequestBase {
/** A string that uniquely identifies a filter. */
  filter_id?: Ids
  /** Skips the specified number of filters. */
  from?: integer
  /** Specifies the maximum number of filters to obtain. */
  size?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { filter_id?: never, from?: never, size?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { filter_id?: never, from?: never, size?: never }
}

export interface MlGetFiltersResponse {
  count: long
  filters: MlFilter[]
}

export interface MlGetInfluencersRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** If true, the results are sorted in descending order. */
  desc?: boolean
  /** Returns influencers with timestamps earlier than this time. The default value means it is unset and results are not limited to specific timestamps. */
  end?: DateTime
  /** If true, the output excludes interim results. By default, interim results are included. */
  exclude_interim?: boolean
  /** Returns influencers with anomaly scores greater than or equal to this value. */
  influencer_score?: double
  /** Skips the specified number of influencers. */
  from?: integer
  /** Specifies the maximum number of influencers to obtain. */
  size?: integer
  /** Specifies the sort field for the requested influencers. By default, the influencers are sorted by the `influencer_score` value. */
  sort?: Field
  /** Returns influencers with timestamps after this time. The default value means it is unset and results are not limited to specific timestamps. */
  start?: DateTime
  /** Configures pagination. This parameter has the `from` and `size` properties. */
  page?: MlPage
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, desc?: never, end?: never, exclude_interim?: never, influencer_score?: never, from?: never, size?: never, sort?: never, start?: never, page?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, desc?: never, end?: never, exclude_interim?: never, influencer_score?: never, from?: never, size?: never, sort?: never, start?: never, page?: never }
}

export interface MlGetInfluencersResponse {
  count: long
  influencers: MlInfluencer[]
}

export interface MlGetJobStatsRequest extends RequestBase {
/** Identifier for the anomaly detection job. It can be a job identifier, a group name, a comma-separated list of jobs, or a wildcard expression. If you do not specify one of these options, the API returns information for all anomaly detection jobs. */
  job_id?: Id
  /** Specifies what to do when the request: 1. Contains wildcard expressions and there are no jobs that match. 2. Contains the _all string or no identifiers and there are no matches. 3. Contains wildcard expressions and there are only partial matches. If `true`, the API returns an empty `jobs` array when there are no matches and the subset of results when there are partial matches. If `false`, the API returns a `404` status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, allow_no_match?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, allow_no_match?: never }
}

export interface MlGetJobStatsResponse {
  count: long
  jobs: MlJobStats[]
}

export interface MlGetJobsRequest extends RequestBase {
/** Identifier for the anomaly detection job. It can be a job identifier, a group name, or a wildcard expression. If you do not specify one of these options, the API returns information for all anomaly detection jobs. */
  job_id?: Ids
  /** Specifies what to do when the request: 1. Contains wildcard expressions and there are no jobs that match. 2. Contains the _all string or no identifiers and there are no matches. 3. Contains wildcard expressions and there are only partial matches. The default value is `true`, which returns an empty `jobs` array when there are no matches and the subset of results when there are partial matches. If this parameter is `false`, the request returns a `404` status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** Indicates if certain fields should be removed from the configuration on retrieval. This allows the configuration to be in an acceptable format to be retrieved and then added to another cluster. */
  exclude_generated?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, allow_no_match?: never, exclude_generated?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, allow_no_match?: never, exclude_generated?: never }
}

export interface MlGetJobsResponse {
  count: long
  jobs: MlJob[]
}

export interface MlGetMemoryStatsJvmStats {
  heap_max?: ByteSize
  heap_max_in_bytes: integer
  java_inference?: ByteSize
  java_inference_in_bytes: integer
  java_inference_max?: ByteSize
  java_inference_max_in_bytes: integer
}

export interface MlGetMemoryStatsMemMlStats {
  anomaly_detectors?: ByteSize
  anomaly_detectors_in_bytes: integer
  data_frame_analytics?: ByteSize
  data_frame_analytics_in_bytes: integer
  max?: ByteSize
  max_in_bytes: integer
  native_code_overhead?: ByteSize
  native_code_overhead_in_bytes: integer
  native_inference?: ByteSize
  native_inference_in_bytes: integer
}

export interface MlGetMemoryStatsMemStats {
  adjusted_total?: ByteSize
  adjusted_total_in_bytes: integer
  total?: ByteSize
  total_in_bytes: integer
  ml: MlGetMemoryStatsMemMlStats
}

export interface MlGetMemoryStatsMemory {
  attributes: Record<string, string>
  jvm: MlGetMemoryStatsJvmStats
  mem: MlGetMemoryStatsMemStats
  name: Name
  roles: string[]
  transport_address: TransportAddress
  ephemeral_id: Id
}

export interface MlGetMemoryStatsRequest extends RequestBase {
/** The names of particular nodes in the cluster to target. For example, `nodeId1,nodeId2` or `ml:true` */
  node_id?: Id
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never, master_timeout?: never, timeout?: never }
}

export interface MlGetMemoryStatsResponse {
  _nodes: NodeStatistics
  cluster_name: Name
  nodes: Record<Id, MlGetMemoryStatsMemory>
}

export interface MlGetModelSnapshotUpgradeStatsRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** A numerical character string that uniquely identifies the model snapshot. You can get information for multiple snapshots by using a comma-separated list or a wildcard expression. You can get all snapshots by using `_all`, by specifying `*` as the snapshot ID, or by omitting the snapshot ID. */
  snapshot_id: Id
  /** Specifies what to do when the request: - Contains wildcard expressions and there are no jobs that match. - Contains the _all string or no identifiers and there are no matches. - Contains wildcard expressions and there are only partial matches. The default value is true, which returns an empty jobs array when there are no matches and the subset of results when there are partial matches. If this parameter is false, the request returns a 404 status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, snapshot_id?: never, allow_no_match?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, snapshot_id?: never, allow_no_match?: never }
}

export interface MlGetModelSnapshotUpgradeStatsResponse {
  count: long
  model_snapshot_upgrades: MlModelSnapshotUpgrade[]
}

export interface MlGetModelSnapshotsRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** A numerical character string that uniquely identifies the model snapshot. You can get information for multiple snapshots by using a comma-separated list or a wildcard expression. You can get all snapshots by using `_all`, by specifying `*` as the snapshot ID, or by omitting the snapshot ID. */
  snapshot_id?: Id
  /** Skips the specified number of snapshots. */
  from?: integer
  /** Specifies the maximum number of snapshots to obtain. */
  size?: integer
  /** Refer to the description for the `desc` query parameter. */
  desc?: boolean
  /** Refer to the description for the `end` query parameter. */
  end?: DateTime
  page?: MlPage
  /** Refer to the description for the `sort` query parameter. */
  sort?: Field
  /** Refer to the description for the `start` query parameter. */
  start?: DateTime
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, snapshot_id?: never, from?: never, size?: never, desc?: never, end?: never, page?: never, sort?: never, start?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, snapshot_id?: never, from?: never, size?: never, desc?: never, end?: never, page?: never, sort?: never, start?: never }
}

export interface MlGetModelSnapshotsResponse {
  count: long
  model_snapshots: MlModelSnapshot[]
}

export interface MlGetOverallBucketsRequest extends RequestBase {
/** Identifier for the anomaly detection job. It can be a job identifier, a group name, a comma-separated list of jobs or groups, or a wildcard expression. You can summarize the bucket results for all anomaly detection jobs by using `_all` or by specifying `*` as the `<job_id>`. */
  job_id: Id
  /** Refer to the description for the `allow_no_match` query parameter. */
  allow_no_match?: boolean
  /** Refer to the description for the `bucket_span` query parameter. */
  bucket_span?: Duration
  /** Refer to the description for the `end` query parameter. */
  end?: DateTime
  /** Refer to the description for the `exclude_interim` query parameter. */
  exclude_interim?: boolean
  /** Refer to the description for the `overall_score` query parameter. */
  overall_score?: double | string
  /** Refer to the description for the `start` query parameter. */
  start?: DateTime
  /** Refer to the description for the `top_n` query parameter. */
  top_n?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, allow_no_match?: never, bucket_span?: never, end?: never, exclude_interim?: never, overall_score?: never, start?: never, top_n?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, allow_no_match?: never, bucket_span?: never, end?: never, exclude_interim?: never, overall_score?: never, start?: never, top_n?: never }
}

export interface MlGetOverallBucketsResponse {
  count: long
  overall_buckets: MlOverallBucket[]
}

export interface MlGetRecordsRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** Skips the specified number of records. */
  from?: integer
  /** Specifies the maximum number of records to obtain. */
  size?: integer
  /** Refer to the description for the `desc` query parameter. */
  desc?: boolean
  /** Refer to the description for the `end` query parameter. */
  end?: DateTime
  /** Refer to the description for the `exclude_interim` query parameter. */
  exclude_interim?: boolean
  page?: MlPage
  /** Refer to the description for the `record_score` query parameter. */
  record_score?: double
  /** Refer to the description for the `sort` query parameter. */
  sort?: Field
  /** Refer to the description for the `start` query parameter. */
  start?: DateTime
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, from?: never, size?: never, desc?: never, end?: never, exclude_interim?: never, page?: never, record_score?: never, sort?: never, start?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, from?: never, size?: never, desc?: never, end?: never, exclude_interim?: never, page?: never, record_score?: never, sort?: never, start?: never }
}

export interface MlGetRecordsResponse {
  count: long
  records: MlAnomaly[]
}

export interface MlGetTrainedModelsRequest extends RequestBase {
/** The unique identifier of the trained model or a model alias. You can get information for multiple trained models in a single API request by using a comma-separated list of model IDs or a wildcard expression. */
  model_id?: Ids
  /** Specifies what to do when the request: - Contains wildcard expressions and there are no models that match. - Contains the _all string or no identifiers and there are no matches. - Contains wildcard expressions and there are only partial matches. If true, it returns an empty array when there are no matches and the subset of results when there are partial matches. */
  allow_no_match?: boolean
  /** Specifies whether the included model definition should be returned as a JSON map (true) or in a custom compressed format (false). */
  decompress_definition?: boolean
  /** Indicates if certain fields should be removed from the configuration on retrieval. This allows the configuration to be in an acceptable format to be retrieved and then added to another cluster. */
  exclude_generated?: boolean
  /** Skips the specified number of models. */
  from?: integer
  /** A comma delimited string of optional fields to include in the response body. */
  include?: MlInclude
  /** Specifies the maximum number of models to obtain. */
  size?: integer
  /** A comma delimited string of tags. A trained model can have many tags, or none. When supplied, only trained models that contain all the supplied tags are returned. */
  tags?: string | string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_id?: never, allow_no_match?: never, decompress_definition?: never, exclude_generated?: never, from?: never, include?: never, size?: never, tags?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_id?: never, allow_no_match?: never, decompress_definition?: never, exclude_generated?: never, from?: never, include?: never, size?: never, tags?: never }
}

export interface MlGetTrainedModelsResponse {
  count: integer
  trained_model_configs: MlTrainedModelConfig[]
}

export interface MlGetTrainedModelsStatsRequest extends RequestBase {
/** The unique identifier of the trained model or a model alias. It can be a comma-separated list or a wildcard expression. */
  model_id?: Ids
  /** Specifies what to do when the request: - Contains wildcard expressions and there are no models that match. - Contains the _all string or no identifiers and there are no matches. - Contains wildcard expressions and there are only partial matches. If true, it returns an empty array when there are no matches and the subset of results when there are partial matches. */
  allow_no_match?: boolean
  /** Skips the specified number of models. */
  from?: integer
  /** Specifies the maximum number of models to obtain. */
  size?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_id?: never, allow_no_match?: never, from?: never, size?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_id?: never, allow_no_match?: never, from?: never, size?: never }
}

export interface MlGetTrainedModelsStatsResponse {
  count: integer
  trained_model_stats: MlTrainedModelStats[]
}

export interface MlInferTrainedModelRequest extends RequestBase {
/** The unique identifier of the trained model. */
  model_id: Id
  /** Controls the amount of time to wait for inference results. */
  timeout?: Duration
  /** An array of objects to pass to the model for inference. The objects should contain a fields matching your configured trained model input. Typically, for NLP models, the field name is `text_field`. Currently, for NLP models, only a single value is allowed. */
  docs: Record<string, any>[]
  /** The inference configuration updates to apply on the API call */
  inference_config?: MlInferenceConfigUpdateContainer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_id?: never, timeout?: never, docs?: never, inference_config?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_id?: never, timeout?: never, docs?: never, inference_config?: never }
}

export interface MlInferTrainedModelResponse {
  inference_results: MlInferenceResponseResult[]
}

export interface MlInfoAnomalyDetectors {
  categorization_analyzer: MlCategorizationAnalyzer
  categorization_examples_limit: integer
  model_memory_limit: string
  model_snapshot_retention_days: integer
  daily_model_snapshot_retention_after_days: integer
}

export interface MlInfoDatafeeds {
  scroll_size: integer
}

export interface MlInfoDefaults {
  anomaly_detectors: MlInfoAnomalyDetectors
  datafeeds: MlInfoDatafeeds
}

export interface MlInfoLimits {
  max_single_ml_node_processors?: integer
  total_ml_processors?: integer
  max_model_memory_limit?: ByteSize
  effective_max_model_memory_limit?: ByteSize
  total_ml_memory: ByteSize
}

export interface MlInfoNativeCode {
  build_hash: string
  version: VersionString
}

export interface MlInfoRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface MlInfoResponse {
  defaults: MlInfoDefaults
  limits: MlInfoLimits
  upgrade_mode: boolean
  native_code: MlInfoNativeCode
}

export interface MlOpenJobRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** Refer to the description for the `timeout` query parameter. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, timeout?: never }
}

export interface MlOpenJobResponse {
  opened: boolean
  node: NodeId
}

export interface MlPostCalendarEventsRequest extends RequestBase {
/** A string that uniquely identifies a calendar. */
  calendar_id: Id
  /** A list of one of more scheduled events. The event’s start and end times can be specified as integer milliseconds since the epoch or as a string in ISO 8601 format. */
  events: MlCalendarEvent[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { calendar_id?: never, events?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { calendar_id?: never, events?: never }
}

export interface MlPostCalendarEventsResponse {
  events: MlCalendarEvent[]
}

export interface MlPostDataRequest<TData = unknown> extends RequestBase {
/** Identifier for the anomaly detection job. The job must have a state of open to receive and process the data. */
  job_id: Id
  /** Specifies the end of the bucket resetting range. */
  reset_end?: DateTime
  /** Specifies the start of the bucket resetting range. */
  reset_start?: DateTime
  data?: TData[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, reset_end?: never, reset_start?: never, data?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, reset_end?: never, reset_start?: never, data?: never }
}

export interface MlPostDataResponse {
  job_id: Id
  processed_record_count: long
  processed_field_count: long
  input_bytes: long
  input_field_count: long
  invalid_date_count: long
  missing_field_count: long
  out_of_order_timestamp_count: long
  empty_bucket_count: long
  sparse_bucket_count: long
  bucket_count: long
  earliest_record_timestamp?: EpochTime<UnitMillis>
  latest_record_timestamp?: EpochTime<UnitMillis>
  last_data_time?: EpochTime<UnitMillis>
  latest_empty_bucket_timestamp?: EpochTime<UnitMillis>
  latest_sparse_bucket_timestamp?: EpochTime<UnitMillis>
  input_record_count: long
  log_time?: EpochTime<UnitMillis>
}

export interface MlPreviewDataFrameAnalyticsDataframePreviewConfig {
  source: MlDataframeAnalyticsSource
  analysis: MlDataframeAnalysisContainer
  model_memory_limit?: string
  max_num_threads?: integer
  analyzed_fields?: MlDataframeAnalysisAnalyzedFields | string[]
}

export interface MlPreviewDataFrameAnalyticsRequest extends RequestBase {
/** Identifier for the data frame analytics job. */
  id?: Id
  /** A data frame analytics config as described in create data frame analytics jobs. Note that `id` and `dest` don’t need to be provided in the context of this API. */
  config?: MlPreviewDataFrameAnalyticsDataframePreviewConfig
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, config?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, config?: never }
}

export interface MlPreviewDataFrameAnalyticsResponse {
  feature_values: Record<Field, string>[]
}

export interface MlPreviewDatafeedRequest extends RequestBase {
/** A numerical character string that uniquely identifies the datafeed. This identifier can contain lowercase alphanumeric characters (a-z and 0-9), hyphens, and underscores. It must start and end with alphanumeric characters. NOTE: If you use this path parameter, you cannot provide datafeed or anomaly detection job configuration details in the request body. */
  datafeed_id?: Id
  /** The start time from where the datafeed preview should begin */
  start?: DateTime
  /** The end time when the datafeed preview should stop */
  end?: DateTime
  /** The datafeed definition to preview. */
  datafeed_config?: MlDatafeedConfig
  /** The configuration details for the anomaly detection job that is associated with the datafeed. If the `datafeed_config` object does not include a `job_id` that references an existing anomaly detection job, you must supply this `job_config` object. If you include both a `job_id` and a `job_config`, the latter information is used. You cannot specify a `job_config` object unless you also supply a `datafeed_config` object. */
  job_config?: MlJobConfig
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { datafeed_id?: never, start?: never, end?: never, datafeed_config?: never, job_config?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { datafeed_id?: never, start?: never, end?: never, datafeed_config?: never, job_config?: never }
}

export type MlPreviewDatafeedResponse<TDocument = unknown> = TDocument[]

export interface MlPutCalendarRequest extends RequestBase {
/** A string that uniquely identifies a calendar. */
  calendar_id: Id
  /** An array of anomaly detection job identifiers. */
  job_ids?: Id[]
  /** A description of the calendar. */
  description?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { calendar_id?: never, job_ids?: never, description?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { calendar_id?: never, job_ids?: never, description?: never }
}

export interface MlPutCalendarResponse {
  calendar_id: Id
  description?: string
  job_ids: Ids
}

export interface MlPutCalendarJobRequest extends RequestBase {
/** A string that uniquely identifies a calendar. */
  calendar_id: Id
  /** An identifier for the anomaly detection jobs. It can be a job identifier, a group name, or a comma-separated list of jobs or groups. */
  job_id: Ids
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { calendar_id?: never, job_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { calendar_id?: never, job_id?: never }
}

export interface MlPutCalendarJobResponse {
  calendar_id: Id
  description?: string
  job_ids: Ids
}

export interface MlPutDataFrameAnalyticsRequest extends RequestBase {
/** Identifier for the data frame analytics job. This identifier can contain lowercase alphanumeric characters (a-z and 0-9), hyphens, and underscores. It must start and end with alphanumeric characters. */
  id: Id
  /** Specifies whether this job can start when there is insufficient machine learning node capacity for it to be immediately assigned to a node. If set to `false` and a machine learning node with capacity to run the job cannot be immediately found, the API returns an error. If set to `true`, the API does not return an error; the job waits in the `starting` state until sufficient machine learning node capacity is available. This behavior is also affected by the cluster-wide `xpack.ml.max_lazy_ml_nodes` setting. */
  allow_lazy_start?: boolean
  /** The analysis configuration, which contains the information necessary to perform one of the following types of analysis: classification, outlier detection, or regression. */
  analysis: MlDataframeAnalysisContainer
  /** Specifies `includes` and/or `excludes` patterns to select which fields will be included in the analysis. The patterns specified in `excludes` are applied last, therefore `excludes` takes precedence. In other words, if the same field is specified in both `includes` and `excludes`, then the field will not be included in the analysis. If `analyzed_fields` is not set, only the relevant fields will be included. For example, all the numeric fields for outlier detection. The supported fields vary for each type of analysis. Outlier detection requires numeric or `boolean` data to analyze. The algorithms don’t support missing values therefore fields that have data types other than numeric or boolean are ignored. Documents where included fields contain missing values, null values, or an array are also ignored. Therefore the `dest` index may contain documents that don’t have an outlier score. Regression supports fields that are numeric, `boolean`, `text`, `keyword`, and `ip` data types. It is also tolerant of missing values. Fields that are supported are included in the analysis, other fields are ignored. Documents where included fields contain an array with two or more values are also ignored. Documents in the `dest` index that don’t contain a results field are not included in the regression analysis. Classification supports fields that are numeric, `boolean`, `text`, `keyword`, and `ip` data types. It is also tolerant of missing values. Fields that are supported are included in the analysis, other fields are ignored. Documents where included fields contain an array with two or more values are also ignored. Documents in the `dest` index that don’t contain a results field are not included in the classification analysis. Classification analysis can be improved by mapping ordinal variable values to a single number. For example, in case of age ranges, you can model the values as `0-14 = 0`, `15-24 = 1`, `25-34 = 2`, and so on. */
  analyzed_fields?: MlDataframeAnalysisAnalyzedFields | string[]
  /** A description of the job. */
  description?: string
  /** The destination configuration. */
  dest: MlDataframeAnalyticsDestination
  /** The maximum number of threads to be used by the analysis. Using more threads may decrease the time necessary to complete the analysis at the cost of using more CPU. Note that the process may use additional threads for operational functionality other than the analysis itself. */
  max_num_threads?: integer
  _meta?: Metadata
  /** The approximate maximum amount of memory resources that are permitted for analytical processing. If your `elasticsearch.yml` file contains an `xpack.ml.max_model_memory_limit` setting, an error occurs when you try to create data frame analytics jobs that have `model_memory_limit` values greater than that setting. */
  model_memory_limit?: string
  /** The configuration of how to source the analysis data. */
  source: MlDataframeAnalyticsSource
  headers?: HttpHeaders
  version?: VersionString
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, allow_lazy_start?: never, analysis?: never, analyzed_fields?: never, description?: never, dest?: never, max_num_threads?: never, _meta?: never, model_memory_limit?: never, source?: never, headers?: never, version?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, allow_lazy_start?: never, analysis?: never, analyzed_fields?: never, description?: never, dest?: never, max_num_threads?: never, _meta?: never, model_memory_limit?: never, source?: never, headers?: never, version?: never }
}

export interface MlPutDataFrameAnalyticsResponse {
  authorization?: MlDataframeAnalyticsAuthorization
  allow_lazy_start: boolean
  analysis: MlDataframeAnalysisContainer
  analyzed_fields?: MlDataframeAnalysisAnalyzedFields | string[]
  create_time: EpochTime<UnitMillis>
  description?: string
  dest: MlDataframeAnalyticsDestination
  id: Id
  max_num_threads: integer
  _meta?: Metadata
  model_memory_limit: string
  source: MlDataframeAnalyticsSource
  version: VersionString
}

export interface MlPutDatafeedRequest extends RequestBase {
/** A numerical character string that uniquely identifies the datafeed. This identifier can contain lowercase alphanumeric characters (a-z and 0-9), hyphens, and underscores. It must start and end with alphanumeric characters. */
  datafeed_id: Id
  /** If true, wildcard indices expressions that resolve into no concrete indices are ignored. This includes the `_all` string or when no indices are specified. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values. */
  expand_wildcards?: ExpandWildcards
  /** If true, concrete, expanded, or aliased indices are ignored when frozen. */
  ignore_throttled?: boolean
  /** If true, unavailable indices (missing or closed) are ignored. */
  ignore_unavailable?: boolean
  /** If set, the datafeed performs aggregation searches. Support for aggregations is limited and should be used only with low cardinality data. */
  aggregations?: Record<string, AggregationsAggregationContainer>
  /** @alias aggregations */
  /** If set, the datafeed performs aggregation searches. Support for aggregations is limited and should be used only with low cardinality data. */
  aggs?: Record<string, AggregationsAggregationContainer>
  /** Datafeeds might be required to search over long time periods, for several months or years. This search is split into time chunks in order to ensure the load on Elasticsearch is managed. Chunking configuration controls how the size of these time chunks are calculated; it is an advanced configuration option. */
  chunking_config?: MlChunkingConfig
  /** Specifies whether the datafeed checks for missing data and the size of the window. The datafeed can optionally search over indices that have already been read in an effort to determine whether any data has subsequently been added to the index. If missing data is found, it is a good indication that the `query_delay` is set too low and the data is being indexed after the datafeed has passed that moment in time. This check runs only on real-time datafeeds. */
  delayed_data_check_config?: MlDelayedDataCheckConfig
  /** The interval at which scheduled queries are made while the datafeed runs in real time. The default value is either the bucket span for short bucket spans, or, for longer bucket spans, a sensible fraction of the bucket span. When `frequency` is shorter than the bucket span, interim results for the last (partial) bucket are written then eventually overwritten by the full bucket results. If the datafeed uses aggregations, this value must be divisible by the interval of the date histogram aggregation. */
  frequency?: Duration
  /** An array of index names. Wildcards are supported. If any of the indices are in remote clusters, the master nodes and the machine learning nodes must have the `remote_cluster_client` role. */
  indices?: Indices
  /** @alias indices */
  /** An array of index names. Wildcards are supported. If any of the indices are in remote clusters, the master nodes and the machine learning nodes must have the `remote_cluster_client` role. */
  indexes?: Indices
  /** Specifies index expansion options that are used during search */
  indices_options?: IndicesOptions
  /** Identifier for the anomaly detection job. */
  job_id?: Id
  /** If a real-time datafeed has never seen any data (including during any initial training period), it automatically stops and closes the associated job after this many real-time searches return no documents. In other words, it stops after `frequency` times `max_empty_searches` of real-time operation. If not set, a datafeed with no end time that sees no data remains started until it is explicitly stopped. By default, it is not set. */
  max_empty_searches?: integer
  /** The Elasticsearch query domain-specific language (DSL). This value corresponds to the query object in an Elasticsearch search POST body. All the options that are supported by Elasticsearch can be used, as this object is passed verbatim to Elasticsearch. */
  query?: QueryDslQueryContainer
  /** The number of seconds behind real time that data is queried. For example, if data from 10:04 a.m. might not be searchable in Elasticsearch until 10:06 a.m., set this property to 120 seconds. The default value is randomly selected between `60s` and `120s`. This randomness improves the query performance when there are multiple jobs running on the same node. */
  query_delay?: Duration
  /** Specifies runtime fields for the datafeed search. */
  runtime_mappings?: MappingRuntimeFields
  /** Specifies scripts that evaluate custom expressions and returns script fields to the datafeed. The detector configuration objects in a job can contain functions that use these script fields. */
  script_fields?: Record<string, ScriptField>
  /** The size parameter that is used in Elasticsearch searches when the datafeed does not use aggregations. The maximum value is the value of `index.max_result_window`, which is 10,000 by default. */
  scroll_size?: integer
  headers?: HttpHeaders
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { datafeed_id?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, aggregations?: never, aggs?: never, chunking_config?: never, delayed_data_check_config?: never, frequency?: never, indices?: never, indexes?: never, indices_options?: never, job_id?: never, max_empty_searches?: never, query?: never, query_delay?: never, runtime_mappings?: never, script_fields?: never, scroll_size?: never, headers?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { datafeed_id?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, aggregations?: never, aggs?: never, chunking_config?: never, delayed_data_check_config?: never, frequency?: never, indices?: never, indexes?: never, indices_options?: never, job_id?: never, max_empty_searches?: never, query?: never, query_delay?: never, runtime_mappings?: never, script_fields?: never, scroll_size?: never, headers?: never }
}

export interface MlPutDatafeedResponse {
  aggregations?: Record<string, AggregationsAggregationContainer>
  authorization?: MlDatafeedAuthorization
  chunking_config: MlChunkingConfig
  delayed_data_check_config?: MlDelayedDataCheckConfig
  datafeed_id: Id
  frequency?: Duration
  indices: string[]
  job_id: Id
  indices_options?: IndicesOptions
  max_empty_searches?: integer
  query: QueryDslQueryContainer
  query_delay: Duration
  runtime_mappings?: MappingRuntimeFields
  script_fields?: Record<string, ScriptField>
  scroll_size: integer
}

export interface MlPutFilterRequest extends RequestBase {
/** A string that uniquely identifies a filter. */
  filter_id: Id
  /** A description of the filter. */
  description?: string
  /** The items of the filter. A wildcard `*` can be used at the beginning or the end of an item. Up to 10000 items are allowed in each filter. */
  items?: string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { filter_id?: never, description?: never, items?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { filter_id?: never, description?: never, items?: never }
}

export interface MlPutFilterResponse {
  description: string
  filter_id: Id
  items: string[]
}

export interface MlPutJobRequest extends RequestBase {
/** The identifier for the anomaly detection job. This identifier can contain lowercase alphanumeric characters (a-z and 0-9), hyphens, and underscores. It must start and end with alphanumeric characters. */
  job_id: Id
  /** If `true`, wildcard indices expressions that resolve into no concrete indices are ignored. This includes the `_all` string or when no indices are specified. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values. Valid values are: * `all`: Match any data stream or index, including hidden ones. * `closed`: Match closed, non-hidden indices. Also matches any non-hidden data stream. Data streams cannot be closed. * `hidden`: Match hidden data streams and hidden indices. Must be combined with `open`, `closed`, or both. * `none`: Wildcard patterns are not accepted. * `open`: Match open, non-hidden indices. Also matches any non-hidden data stream. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, concrete, expanded or aliased indices are ignored when frozen. */
  ignore_throttled?: boolean
  /** If `true`, unavailable indices (missing or closed) are ignored. */
  ignore_unavailable?: boolean
  /** Advanced configuration option. Specifies whether this job can open when there is insufficient machine learning node capacity for it to be immediately assigned to a node. By default, if a machine learning node with capacity to run the job cannot immediately be found, the open anomaly detection jobs API returns an error. However, this is also subject to the cluster-wide `xpack.ml.max_lazy_ml_nodes` setting. If this option is set to true, the open anomaly detection jobs API does not return an error and the job waits in the opening state until sufficient machine learning node capacity is available. */
  allow_lazy_open?: boolean
  /** Specifies how to analyze the data. After you create a job, you cannot change the analysis configuration; all the properties are informational. */
  analysis_config: MlAnalysisConfig
  /** Limits can be applied for the resources required to hold the mathematical models in memory. These limits are approximate and can be set per job. They do not control the memory used by other processes, for example the Elasticsearch Java processes. */
  analysis_limits?: MlAnalysisLimits
  /** Advanced configuration option. The time between each periodic persistence of the model. The default value is a randomized value between 3 to 4 hours, which avoids all jobs persisting at exactly the same time. The smallest allowed value is 1 hour. For very large models (several GB), persistence could take 10-20 minutes, so do not set the `background_persist_interval` value too low. */
  background_persist_interval?: Duration
  /** Advanced configuration option. Contains custom meta data about the job. */
  custom_settings?: MlCustomSettings
  /** Advanced configuration option, which affects the automatic removal of old model snapshots for this job. It specifies a period of time (in days) after which only the first snapshot per day is retained. This period is relative to the timestamp of the most recent snapshot for this job. Valid values range from 0 to `model_snapshot_retention_days`. */
  daily_model_snapshot_retention_after_days?: long
  /** Defines the format of the input data when you send data to the job by using the post data API. Note that when configure a datafeed, these properties are automatically set. When data is received via the post data API, it is not stored in Elasticsearch. Only the results for anomaly detection are retained. */
  data_description: MlDataDescription
  /** Defines a datafeed for the anomaly detection job. If Elasticsearch security features are enabled, your datafeed remembers which roles the user who created it had at the time of creation and runs the query using those same roles. If you provide secondary authorization headers, those credentials are used instead. */
  datafeed_config?: MlDatafeedConfig
  /** A description of the job. */
  description?: string
  /** A list of job groups. A job can belong to no groups or many. */
  groups?: string[]
  /** This advanced configuration option stores model information along with the results. It provides a more detailed view into anomaly detection. If you enable model plot it can add considerable overhead to the performance of the system; it is not feasible for jobs with many entities. Model plot provides a simplified and indicative view of the model and its bounds. It does not display complex features such as multivariate correlations or multimodal data. As such, anomalies may occasionally be reported which cannot be seen in the model plot. Model plot config can be configured when the job is created or updated later. It must be disabled if performance issues are experienced. */
  model_plot_config?: MlModelPlotConfig
  /** Advanced configuration option, which affects the automatic removal of old model snapshots for this job. It specifies the maximum period of time (in days) that snapshots are retained. This period is relative to the timestamp of the most recent snapshot for this job. By default, snapshots ten days older than the newest snapshot are deleted. */
  model_snapshot_retention_days?: long
  /** Advanced configuration option. The period over which adjustments to the score are applied, as new data is seen. The default value is the longer of 30 days or 100 bucket spans. */
  renormalization_window_days?: long
  /** A text string that affects the name of the machine learning results index. By default, the job generates an index named `.ml-anomalies-shared`. */
  results_index_name?: IndexName
  /** Advanced configuration option. The period of time (in days) that results are retained. Age is calculated relative to the timestamp of the latest bucket result. If this property has a non-null value, once per day at 00:30 (server time), results that are the specified number of days older than the latest bucket result are deleted from Elasticsearch. The default value is null, which means all results are retained. Annotations generated by the system also count as results for retention purposes; they are deleted after the same number of days as results. Annotations added by users are retained forever. */
  results_retention_days?: long
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, allow_lazy_open?: never, analysis_config?: never, analysis_limits?: never, background_persist_interval?: never, custom_settings?: never, daily_model_snapshot_retention_after_days?: never, data_description?: never, datafeed_config?: never, description?: never, groups?: never, model_plot_config?: never, model_snapshot_retention_days?: never, renormalization_window_days?: never, results_index_name?: never, results_retention_days?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, allow_lazy_open?: never, analysis_config?: never, analysis_limits?: never, background_persist_interval?: never, custom_settings?: never, daily_model_snapshot_retention_after_days?: never, data_description?: never, datafeed_config?: never, description?: never, groups?: never, model_plot_config?: never, model_snapshot_retention_days?: never, renormalization_window_days?: never, results_index_name?: never, results_retention_days?: never }
}

export interface MlPutJobResponse {
  allow_lazy_open: boolean
  analysis_config: MlAnalysisConfigRead
  analysis_limits: MlAnalysisLimits
  background_persist_interval?: Duration
  create_time: DateTime
  custom_settings?: MlCustomSettings
  daily_model_snapshot_retention_after_days: long
  data_description: MlDataDescription
  datafeed_config?: MlDatafeed
  description?: string
  groups?: string[]
  job_id: Id
  job_type: string
  job_version: string
  model_plot_config?: MlModelPlotConfig
  model_snapshot_id?: Id
  model_snapshot_retention_days: long
  renormalization_window_days?: long
  results_index_name: string
  results_retention_days?: long
}

export interface MlPutTrainedModelAggregateOutput {
  logistic_regression?: MlPutTrainedModelWeights
  weighted_sum?: MlPutTrainedModelWeights
  weighted_mode?: MlPutTrainedModelWeights
  exponent?: MlPutTrainedModelWeights
}

export interface MlPutTrainedModelDefinition {
  preprocessors?: MlPutTrainedModelPreprocessor[]
  trained_model: MlPutTrainedModelTrainedModel
}

export interface MlPutTrainedModelEnsemble {
  aggregate_output?: MlPutTrainedModelAggregateOutput
  classification_labels?: string[]
  feature_names?: string[]
  target_type?: string
  trained_models: MlPutTrainedModelTrainedModel[]
}

export interface MlPutTrainedModelFrequencyEncodingPreprocessor {
  field: string
  feature_name: string
  frequency_map: Record<string, double>
}

export interface MlPutTrainedModelInput {
  field_names: Names
}

export interface MlPutTrainedModelOneHotEncodingPreprocessor {
  field: string
  hot_map: Record<string, string>
}

export interface MlPutTrainedModelPreprocessor {
  frequency_encoding?: MlPutTrainedModelFrequencyEncodingPreprocessor
  one_hot_encoding?: MlPutTrainedModelOneHotEncodingPreprocessor
  target_mean_encoding?: MlPutTrainedModelTargetMeanEncodingPreprocessor
}

export interface MlPutTrainedModelRequest extends RequestBase {
/** The unique identifier of the trained model. */
  model_id: Id
  /** If set to `true` and a `compressed_definition` is provided, the request defers definition decompression and skips relevant validations. */
  defer_definition_decompression?: boolean
  /** Whether to wait for all child operations (e.g. model download) to complete. */
  wait_for_completion?: boolean
  /** The compressed (GZipped and Base64 encoded) inference definition of the model. If compressed_definition is specified, then definition cannot be specified. */
  compressed_definition?: string
  /** The inference definition for the model. If definition is specified, then compressed_definition cannot be specified. */
  definition?: MlPutTrainedModelDefinition
  /** A human-readable description of the inference trained model. */
  description?: string
  /** The default configuration for inference. This can be either a regression or classification configuration. It must match the underlying definition.trained_model's target_type. For pre-packaged models such as ELSER the config is not required. */
  inference_config?: MlInferenceConfigCreateContainer
  /** The input field names for the model definition. */
  input?: MlPutTrainedModelInput
  /** An object map that contains metadata about the model. */
  metadata?: any
  /** The model type. */
  model_type?: MlTrainedModelType
  /** The estimated memory usage in bytes to keep the trained model in memory. This property is supported only if defer_definition_decompression is true or the model definition is not supplied. */
  model_size_bytes?: long
  /** The platform architecture (if applicable) of the trained mode. If the model only works on one platform, because it is heavily optimized for a particular processor architecture and OS combination, then this field specifies which. The format of the string must match the platform identifiers used by Elasticsearch, so one of, `linux-x86_64`, `linux-aarch64`, `darwin-x86_64`, `darwin-aarch64`, or `windows-x86_64`. For portable models (those that work independent of processor architecture or OS features), leave this field unset. */
  platform_architecture?: string
  /** An array of tags to organize the model. */
  tags?: string[]
  /** Optional prefix strings applied at inference */
  prefix_strings?: MlTrainedModelPrefixStrings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_id?: never, defer_definition_decompression?: never, wait_for_completion?: never, compressed_definition?: never, definition?: never, description?: never, inference_config?: never, input?: never, metadata?: never, model_type?: never, model_size_bytes?: never, platform_architecture?: never, tags?: never, prefix_strings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_id?: never, defer_definition_decompression?: never, wait_for_completion?: never, compressed_definition?: never, definition?: never, description?: never, inference_config?: never, input?: never, metadata?: never, model_type?: never, model_size_bytes?: never, platform_architecture?: never, tags?: never, prefix_strings?: never }
}

export type MlPutTrainedModelResponse = MlTrainedModelConfig

export interface MlPutTrainedModelTargetMeanEncodingPreprocessor {
  field: string
  feature_name: string
  target_map: Record<string, double>
  default_value: double
}

export interface MlPutTrainedModelTrainedModel {
  tree?: MlPutTrainedModelTrainedModelTree
  tree_node?: MlPutTrainedModelTrainedModelTreeNode
  ensemble?: MlPutTrainedModelEnsemble
}

export interface MlPutTrainedModelTrainedModelTree {
  classification_labels?: string[]
  feature_names: string[]
  target_type?: string
  tree_structure: MlPutTrainedModelTrainedModelTreeNode[]
}

export interface MlPutTrainedModelTrainedModelTreeNode {
  decision_type?: string
  default_left?: boolean
  leaf_value?: double
  left_child?: integer
  node_index: integer
  right_child?: integer
  split_feature?: integer
  split_gain?: integer
  threshold?: double
}

export interface MlPutTrainedModelWeights {
  weights: double
}

export interface MlPutTrainedModelAliasRequest extends RequestBase {
/** The alias to create or update. This value cannot end in numbers. */
  model_alias: Name
  /** The identifier for the trained model that the alias refers to. */
  model_id: Id
  /** Specifies whether the alias gets reassigned to the specified trained model if it is already assigned to a different model. If the alias is already assigned and this parameter is false, the API returns an error. */
  reassign?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_alias?: never, model_id?: never, reassign?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_alias?: never, model_id?: never, reassign?: never }
}

export type MlPutTrainedModelAliasResponse = AcknowledgedResponseBase

export interface MlPutTrainedModelDefinitionPartRequest extends RequestBase {
/** The unique identifier of the trained model. */
  model_id: Id
  /** The definition part number. When the definition is loaded for inference the definition parts are streamed in the order of their part number. The first part must be `0` and the final part must be `total_parts - 1`. */
  part: integer
  /** The definition part for the model. Must be a base64 encoded string. */
  definition: string
  /** The total uncompressed definition length in bytes. Not base64 encoded. */
  total_definition_length: long
  /** The total number of parts that will be uploaded. Must be greater than 0. */
  total_parts: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_id?: never, part?: never, definition?: never, total_definition_length?: never, total_parts?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_id?: never, part?: never, definition?: never, total_definition_length?: never, total_parts?: never }
}

export type MlPutTrainedModelDefinitionPartResponse = AcknowledgedResponseBase

export interface MlPutTrainedModelVocabularyRequest extends RequestBase {
/** The unique identifier of the trained model. */
  model_id: Id
  /** The model vocabulary, which must not be empty. */
  vocabulary: string[]
  /** The optional model merges if required by the tokenizer. */
  merges?: string[]
  /** The optional vocabulary value scores if required by the tokenizer. */
  scores?: double[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_id?: never, vocabulary?: never, merges?: never, scores?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_id?: never, vocabulary?: never, merges?: never, scores?: never }
}

export type MlPutTrainedModelVocabularyResponse = AcknowledgedResponseBase

export interface MlResetJobRequest extends RequestBase {
/** The ID of the job to reset. */
  job_id: Id
  /** Should this request wait until the operation has completed before returning. */
  wait_for_completion?: boolean
  /** Specifies whether annotations that have been added by the user should be deleted along with any auto-generated annotations when the job is reset. */
  delete_user_annotations?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, wait_for_completion?: never, delete_user_annotations?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, wait_for_completion?: never, delete_user_annotations?: never }
}

export type MlResetJobResponse = AcknowledgedResponseBase

export interface MlRevertModelSnapshotRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** You can specify `empty` as the <snapshot_id>. Reverting to the empty snapshot means the anomaly detection job starts learning a new model from scratch when it is started. */
  snapshot_id: Id
  /** Refer to the description for the `delete_intervening_results` query parameter. */
  delete_intervening_results?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, snapshot_id?: never, delete_intervening_results?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, snapshot_id?: never, delete_intervening_results?: never }
}

export interface MlRevertModelSnapshotResponse {
  model: MlModelSnapshot
}

export interface MlSetUpgradeModeRequest extends RequestBase {
/** When `true`, it enables `upgrade_mode` which temporarily halts all job and datafeed tasks and prohibits new job and datafeed tasks from starting. */
  enabled?: boolean
  /** The time to wait for the request to be completed. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { enabled?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { enabled?: never, timeout?: never }
}

export type MlSetUpgradeModeResponse = AcknowledgedResponseBase

export interface MlStartDataFrameAnalyticsRequest extends RequestBase {
/** Identifier for the data frame analytics job. This identifier can contain lowercase alphanumeric characters (a-z and 0-9), hyphens, and underscores. It must start and end with alphanumeric characters. */
  id: Id
  /** Controls the amount of time to wait until the data frame analytics job starts. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, timeout?: never }
}

export interface MlStartDataFrameAnalyticsResponse {
  acknowledged: boolean
  node: NodeId
}

export interface MlStartDatafeedRequest extends RequestBase {
/** A numerical character string that uniquely identifies the datafeed. This identifier can contain lowercase alphanumeric characters (a-z and 0-9), hyphens, and underscores. It must start and end with alphanumeric characters. */
  datafeed_id: Id
  /** Refer to the description for the `end` query parameter. */
  end?: DateTime
  /** Refer to the description for the `start` query parameter. */
  start?: DateTime
  /** Refer to the description for the `timeout` query parameter. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { datafeed_id?: never, end?: never, start?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { datafeed_id?: never, end?: never, start?: never, timeout?: never }
}

export interface MlStartDatafeedResponse {
  node: NodeIds
  started: boolean
}

export interface MlStartTrainedModelDeploymentRequest extends RequestBase {
/** The unique identifier of the trained model. Currently, only PyTorch models are supported. */
  model_id: Id
  /** The inference cache size (in memory outside the JVM heap) per node for the model. The default value is the same size as the `model_size_bytes`. To disable the cache, `0b` can be provided. */
  cache_size?: ByteSize
  /** A unique identifier for the deployment of the model. */
  deployment_id?: string
  /** The number of model allocations on each node where the model is deployed. All allocations on a node share the same copy of the model in memory but use a separate set of threads to evaluate the model. Increasing this value generally increases the throughput. If this setting is greater than the number of hardware threads it will automatically be changed to a value less than the number of hardware threads. If adaptive_allocations is enabled, do not set this value, because it’s automatically set. */
  number_of_allocations?: integer
  /** The deployment priority. */
  priority?: MlTrainingPriority
  /** Specifies the number of inference requests that are allowed in the queue. After the number of requests exceeds this value, new requests are rejected with a 429 error. */
  queue_capacity?: integer
  /** Sets the number of threads used by each model allocation during inference. This generally increases the inference speed. The inference process is a compute-bound process; any number greater than the number of available hardware threads on the machine does not increase the inference speed. If this setting is greater than the number of hardware threads it will automatically be changed to a value less than the number of hardware threads. */
  threads_per_allocation?: integer
  /** Specifies the amount of time to wait for the model to deploy. */
  timeout?: Duration
  /** Specifies the allocation status to wait for before returning. */
  wait_for?: MlDeploymentAllocationState
  /** Adaptive allocations configuration. When enabled, the number of allocations is set based on the current load. If adaptive_allocations is enabled, do not set the number of allocations manually. */
  adaptive_allocations?: MlAdaptiveAllocationsSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_id?: never, cache_size?: never, deployment_id?: never, number_of_allocations?: never, priority?: never, queue_capacity?: never, threads_per_allocation?: never, timeout?: never, wait_for?: never, adaptive_allocations?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_id?: never, cache_size?: never, deployment_id?: never, number_of_allocations?: never, priority?: never, queue_capacity?: never, threads_per_allocation?: never, timeout?: never, wait_for?: never, adaptive_allocations?: never }
}

export interface MlStartTrainedModelDeploymentResponse {
  assignment: MlTrainedModelAssignment
}

export interface MlStopDataFrameAnalyticsRequest extends RequestBase {
/** Identifier for the data frame analytics job. This identifier can contain lowercase alphanumeric characters (a-z and 0-9), hyphens, and underscores. It must start and end with alphanumeric characters. */
  id: Id
  /** Specifies what to do when the request: 1. Contains wildcard expressions and there are no data frame analytics jobs that match. 2. Contains the _all string or no identifiers and there are no matches. 3. Contains wildcard expressions and there are only partial matches. The default value is true, which returns an empty data_frame_analytics array when there are no matches and the subset of results when there are partial matches. If this parameter is false, the request returns a 404 status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** If true, the data frame analytics job is stopped forcefully. */
  force?: boolean
  /** Controls the amount of time to wait until the data frame analytics job stops. Defaults to 20 seconds. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, allow_no_match?: never, force?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, allow_no_match?: never, force?: never, timeout?: never }
}

export interface MlStopDataFrameAnalyticsResponse {
  stopped: boolean
}

export interface MlStopDatafeedRequest extends RequestBase {
/** Identifier for the datafeed. You can stop multiple datafeeds in a single API request by using a comma-separated list of datafeeds or a wildcard expression. You can close all datafeeds by using `_all` or by specifying `*` as the identifier. */
  datafeed_id: Id
  /** Refer to the description for the `allow_no_match` query parameter. */
  allow_no_match?: boolean
  /** Refer to the description for the `force` query parameter. */
  force?: boolean
  /** Refer to the description for the `timeout` query parameter. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { datafeed_id?: never, allow_no_match?: never, force?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { datafeed_id?: never, allow_no_match?: never, force?: never, timeout?: never }
}

export interface MlStopDatafeedResponse {
  stopped: boolean
}

export interface MlStopTrainedModelDeploymentRequest extends RequestBase {
/** The unique identifier of the trained model. */
  model_id: Id
  /** Specifies what to do when the request: contains wildcard expressions and there are no deployments that match; contains the `_all` string or no identifiers and there are no matches; or contains wildcard expressions and there are only partial matches. By default, it returns an empty array when there are no matches and the subset of results when there are partial matches. If `false`, the request returns a 404 status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** Forcefully stops the deployment, even if it is used by ingest pipelines. You can't use these pipelines until you restart the model deployment. */
  force?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_id?: never, allow_no_match?: never, force?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_id?: never, allow_no_match?: never, force?: never }
}

export interface MlStopTrainedModelDeploymentResponse {
  stopped: boolean
}

export interface MlUpdateDataFrameAnalyticsRequest extends RequestBase {
/** Identifier for the data frame analytics job. This identifier can contain lowercase alphanumeric characters (a-z and 0-9), hyphens, and underscores. It must start and end with alphanumeric characters. */
  id: Id
  /** A description of the job. */
  description?: string
  /** The approximate maximum amount of memory resources that are permitted for analytical processing. If your `elasticsearch.yml` file contains an `xpack.ml.max_model_memory_limit` setting, an error occurs when you try to create data frame analytics jobs that have `model_memory_limit` values greater than that setting. */
  model_memory_limit?: string
  /** The maximum number of threads to be used by the analysis. Using more threads may decrease the time necessary to complete the analysis at the cost of using more CPU. Note that the process may use additional threads for operational functionality other than the analysis itself. */
  max_num_threads?: integer
  /** Specifies whether this job can start when there is insufficient machine learning node capacity for it to be immediately assigned to a node. */
  allow_lazy_start?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, description?: never, model_memory_limit?: never, max_num_threads?: never, allow_lazy_start?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, description?: never, model_memory_limit?: never, max_num_threads?: never, allow_lazy_start?: never }
}

export interface MlUpdateDataFrameAnalyticsResponse {
  authorization?: MlDataframeAnalyticsAuthorization
  allow_lazy_start: boolean
  analysis: MlDataframeAnalysisContainer
  analyzed_fields?: MlDataframeAnalysisAnalyzedFields | string[]
  create_time: long
  description?: string
  dest: MlDataframeAnalyticsDestination
  id: Id
  max_num_threads: integer
  model_memory_limit: string
  source: MlDataframeAnalyticsSource
  version: VersionString
}

export interface MlUpdateDatafeedRequest extends RequestBase {
/** A numerical character string that uniquely identifies the datafeed. This identifier can contain lowercase alphanumeric characters (a-z and 0-9), hyphens, and underscores. It must start and end with alphanumeric characters. */
  datafeed_id: Id
  /** If `true`, wildcard indices expressions that resolve into no concrete indices are ignored. This includes the `_all` string or when no indices are specified. */
  allow_no_indices?: boolean
  /** Type of index that wildcard patterns can match. If the request can target data streams, this argument determines whether wildcard expressions match hidden data streams. Supports comma-separated values. Valid values are: * `all`: Match any data stream or index, including hidden ones. * `closed`: Match closed, non-hidden indices. Also matches any non-hidden data stream. Data streams cannot be closed. * `hidden`: Match hidden data streams and hidden indices. Must be combined with `open`, `closed`, or both. * `none`: Wildcard patterns are not accepted. * `open`: Match open, non-hidden indices. Also matches any non-hidden data stream. */
  expand_wildcards?: ExpandWildcards
  /** If `true`, concrete, expanded or aliased indices are ignored when frozen. */
  ignore_throttled?: boolean
  /** If `true`, unavailable indices (missing or closed) are ignored. */
  ignore_unavailable?: boolean
  /** If set, the datafeed performs aggregation searches. Support for aggregations is limited and should be used only with low cardinality data. */
  aggregations?: Record<string, AggregationsAggregationContainer>
  /** Datafeeds might search over long time periods, for several months or years. This search is split into time chunks in order to ensure the load on Elasticsearch is managed. Chunking configuration controls how the size of these time chunks are calculated; it is an advanced configuration option. */
  chunking_config?: MlChunkingConfig
  /** Specifies whether the datafeed checks for missing data and the size of the window. The datafeed can optionally search over indices that have already been read in an effort to determine whether any data has subsequently been added to the index. If missing data is found, it is a good indication that the `query_delay` is set too low and the data is being indexed after the datafeed has passed that moment in time. This check runs only on real-time datafeeds. */
  delayed_data_check_config?: MlDelayedDataCheckConfig
  /** The interval at which scheduled queries are made while the datafeed runs in real time. The default value is either the bucket span for short bucket spans, or, for longer bucket spans, a sensible fraction of the bucket span. When `frequency` is shorter than the bucket span, interim results for the last (partial) bucket are written then eventually overwritten by the full bucket results. If the datafeed uses aggregations, this value must be divisible by the interval of the date histogram aggregation. */
  frequency?: Duration
  /** An array of index names. Wildcards are supported. If any of the indices are in remote clusters, the machine learning nodes must have the `remote_cluster_client` role. */
  indices?: string[]
  /** @alias indices */
  /** An array of index names. Wildcards are supported. If any of the indices are in remote clusters, the machine learning nodes must have the `remote_cluster_client` role. */
  indexes?: string[]
  /** Specifies index expansion options that are used during search. */
  indices_options?: IndicesOptions
  job_id?: Id
  /** If a real-time datafeed has never seen any data (including during any initial training period), it automatically stops and closes the associated job after this many real-time searches return no documents. In other words, it stops after `frequency` times `max_empty_searches` of real-time operation. If not set, a datafeed with no end time that sees no data remains started until it is explicitly stopped. By default, it is not set. */
  max_empty_searches?: integer
  /** The Elasticsearch query domain-specific language (DSL). This value corresponds to the query object in an Elasticsearch search POST body. All the options that are supported by Elasticsearch can be used, as this object is passed verbatim to Elasticsearch. Note that if you change the query, the analyzed data is also changed. Therefore, the time required to learn might be long and the understandability of the results is unpredictable. If you want to make significant changes to the source data, it is recommended that you clone the job and datafeed and make the amendments in the clone. Let both run in parallel and close one when you are satisfied with the results of the job. */
  query?: QueryDslQueryContainer
  /** The number of seconds behind real time that data is queried. For example, if data from 10:04 a.m. might not be searchable in Elasticsearch until 10:06 a.m., set this property to 120 seconds. The default value is randomly selected between `60s` and `120s`. This randomness improves the query performance when there are multiple jobs running on the same node. */
  query_delay?: Duration
  /** Specifies runtime fields for the datafeed search. */
  runtime_mappings?: MappingRuntimeFields
  /** Specifies scripts that evaluate custom expressions and returns script fields to the datafeed. The detector configuration objects in a job can contain functions that use these script fields. */
  script_fields?: Record<string, ScriptField>
  /** The size parameter that is used in Elasticsearch searches when the datafeed does not use aggregations. The maximum value is the value of `index.max_result_window`. */
  scroll_size?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { datafeed_id?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, aggregations?: never, chunking_config?: never, delayed_data_check_config?: never, frequency?: never, indices?: never, indexes?: never, indices_options?: never, job_id?: never, max_empty_searches?: never, query?: never, query_delay?: never, runtime_mappings?: never, script_fields?: never, scroll_size?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { datafeed_id?: never, allow_no_indices?: never, expand_wildcards?: never, ignore_throttled?: never, ignore_unavailable?: never, aggregations?: never, chunking_config?: never, delayed_data_check_config?: never, frequency?: never, indices?: never, indexes?: never, indices_options?: never, job_id?: never, max_empty_searches?: never, query?: never, query_delay?: never, runtime_mappings?: never, script_fields?: never, scroll_size?: never }
}

export interface MlUpdateDatafeedResponse {
  authorization?: MlDatafeedAuthorization
  aggregations?: Record<string, AggregationsAggregationContainer>
  chunking_config: MlChunkingConfig
  delayed_data_check_config?: MlDelayedDataCheckConfig
  datafeed_id: Id
  frequency?: Duration
  indices: string[]
  indices_options?: IndicesOptions
  job_id: Id
  max_empty_searches?: integer
  query: QueryDslQueryContainer
  query_delay: Duration
  runtime_mappings?: MappingRuntimeFields
  script_fields?: Record<string, ScriptField>
  scroll_size: integer
}

export interface MlUpdateFilterRequest extends RequestBase {
/** A string that uniquely identifies a filter. */
  filter_id: Id
  /** The items to add to the filter. */
  add_items?: string[]
  /** A description for the filter. */
  description?: string
  /** The items to remove from the filter. */
  remove_items?: string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { filter_id?: never, add_items?: never, description?: never, remove_items?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { filter_id?: never, add_items?: never, description?: never, remove_items?: never }
}

export interface MlUpdateFilterResponse {
  description: string
  filter_id: Id
  items: string[]
}

export interface MlUpdateJobRequest extends RequestBase {
/** Identifier for the job. */
  job_id: Id
  /** Advanced configuration option. Specifies whether this job can open when there is insufficient machine learning node capacity for it to be immediately assigned to a node. If `false` and a machine learning node with capacity to run the job cannot immediately be found, the open anomaly detection jobs API returns an error. However, this is also subject to the cluster-wide `xpack.ml.max_lazy_ml_nodes` setting. If this option is set to `true`, the open anomaly detection jobs API does not return an error and the job waits in the opening state until sufficient machine learning node capacity is available. */
  allow_lazy_open?: boolean
  analysis_limits?: MlAnalysisMemoryLimit
  /** Advanced configuration option. The time between each periodic persistence of the model. The default value is a randomized value between 3 to 4 hours, which avoids all jobs persisting at exactly the same time. The smallest allowed value is 1 hour. For very large models (several GB), persistence could take 10-20 minutes, so do not set the value too low. If the job is open when you make the update, you must stop the datafeed, close the job, then reopen the job and restart the datafeed for the changes to take effect. */
  background_persist_interval?: Duration
  /** Advanced configuration option. Contains custom meta data about the job. For example, it can contain custom URL information as shown in Adding custom URLs to machine learning results. */
  custom_settings?: Record<string, any>
  categorization_filters?: string[]
  /** A description of the job. */
  description?: string
  model_plot_config?: MlModelPlotConfig
  model_prune_window?: Duration
  /** Advanced configuration option, which affects the automatic removal of old model snapshots for this job. It specifies a period of time (in days) after which only the first snapshot per day is retained. This period is relative to the timestamp of the most recent snapshot for this job. Valid values range from 0 to `model_snapshot_retention_days`. For jobs created before version 7.8.0, the default value matches `model_snapshot_retention_days`. */
  daily_model_snapshot_retention_after_days?: long
  /** Advanced configuration option, which affects the automatic removal of old model snapshots for this job. It specifies the maximum period of time (in days) that snapshots are retained. This period is relative to the timestamp of the most recent snapshot for this job. */
  model_snapshot_retention_days?: long
  /** Advanced configuration option. The period over which adjustments to the score are applied, as new data is seen. */
  renormalization_window_days?: long
  /** Advanced configuration option. The period of time (in days) that results are retained. Age is calculated relative to the timestamp of the latest bucket result. If this property has a non-null value, once per day at 00:30 (server time), results that are the specified number of days older than the latest bucket result are deleted from Elasticsearch. The default value is null, which means all results are retained. */
  results_retention_days?: long
  /** A list of job groups. A job can belong to no groups or many. */
  groups?: string[]
  /** An array of detector update objects. */
  detectors?: MlDetectorUpdate[]
  /** Settings related to how categorization interacts with partition fields. */
  per_partition_categorization?: MlPerPartitionCategorization
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, allow_lazy_open?: never, analysis_limits?: never, background_persist_interval?: never, custom_settings?: never, categorization_filters?: never, description?: never, model_plot_config?: never, model_prune_window?: never, daily_model_snapshot_retention_after_days?: never, model_snapshot_retention_days?: never, renormalization_window_days?: never, results_retention_days?: never, groups?: never, detectors?: never, per_partition_categorization?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, allow_lazy_open?: never, analysis_limits?: never, background_persist_interval?: never, custom_settings?: never, categorization_filters?: never, description?: never, model_plot_config?: never, model_prune_window?: never, daily_model_snapshot_retention_after_days?: never, model_snapshot_retention_days?: never, renormalization_window_days?: never, results_retention_days?: never, groups?: never, detectors?: never, per_partition_categorization?: never }
}

export interface MlUpdateJobResponse {
  allow_lazy_open: boolean
  analysis_config: MlAnalysisConfigRead
  analysis_limits: MlAnalysisLimits
  background_persist_interval?: Duration
  create_time: EpochTime<UnitMillis>
  finished_time?: EpochTime<UnitMillis>
  custom_settings?: Record<string, string>
  daily_model_snapshot_retention_after_days: long
  data_description: MlDataDescription
  datafeed_config?: MlDatafeed
  description?: string
  groups?: string[]
  job_id: Id
  job_type: string
  job_version: VersionString
  model_plot_config?: MlModelPlotConfig
  model_snapshot_id?: Id
  model_snapshot_retention_days: long
  renormalization_window_days?: long
  results_index_name: IndexName
  results_retention_days?: long
}

export interface MlUpdateModelSnapshotRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** Identifier for the model snapshot. */
  snapshot_id: Id
  /** A description of the model snapshot. */
  description?: string
  /** If `true`, this snapshot will not be deleted during automatic cleanup of snapshots older than `model_snapshot_retention_days`. However, this snapshot will be deleted when the job is deleted. */
  retain?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, snapshot_id?: never, description?: never, retain?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, snapshot_id?: never, description?: never, retain?: never }
}

export interface MlUpdateModelSnapshotResponse {
  acknowledged: boolean
  model: MlModelSnapshot
}

export interface MlUpdateTrainedModelDeploymentRequest extends RequestBase {
/** The unique identifier of the trained model. Currently, only PyTorch models are supported. */
  model_id: Id
  /** The number of model allocations on each node where the model is deployed. All allocations on a node share the same copy of the model in memory but use a separate set of threads to evaluate the model. Increasing this value generally increases the throughput. If this setting is greater than the number of hardware threads it will automatically be changed to a value less than the number of hardware threads. If adaptive_allocations is enabled, do not set this value, because it’s automatically set. */
  number_of_allocations?: integer
  /** Adaptive allocations configuration. When enabled, the number of allocations is set based on the current load. If adaptive_allocations is enabled, do not set the number of allocations manually. */
  adaptive_allocations?: MlAdaptiveAllocationsSettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { model_id?: never, number_of_allocations?: never, adaptive_allocations?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { model_id?: never, number_of_allocations?: never, adaptive_allocations?: never }
}

export interface MlUpdateTrainedModelDeploymentResponse {
  assignment: MlTrainedModelAssignment
}

export interface MlUpgradeJobSnapshotRequest extends RequestBase {
/** Identifier for the anomaly detection job. */
  job_id: Id
  /** A numerical character string that uniquely identifies the model snapshot. */
  snapshot_id: Id
  /** When true, the API won’t respond until the upgrade is complete. Otherwise, it responds as soon as the upgrade task is assigned to a node. */
  wait_for_completion?: boolean
  /** Controls the time to wait for the request to complete. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, snapshot_id?: never, wait_for_completion?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, snapshot_id?: never, wait_for_completion?: never, timeout?: never }
}

export interface MlUpgradeJobSnapshotResponse {
  node: NodeId
  completed: boolean
}

export interface MlValidateRequest extends RequestBase {
  job_id?: Id
  analysis_config?: MlAnalysisConfig
  analysis_limits?: MlAnalysisLimits
  data_description?: MlDataDescription
  description?: string
  model_plot?: MlModelPlotConfig
  model_snapshot_id?: Id
  model_snapshot_retention_days?: long
  results_index_name?: IndexName
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { job_id?: never, analysis_config?: never, analysis_limits?: never, data_description?: never, description?: never, model_plot?: never, model_snapshot_id?: never, model_snapshot_retention_days?: never, results_index_name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { job_id?: never, analysis_config?: never, analysis_limits?: never, data_description?: never, description?: never, model_plot?: never, model_snapshot_id?: never, model_snapshot_retention_days?: never, results_index_name?: never }
}

export type MlValidateResponse = AcknowledgedResponseBase

export interface MlValidateDetectorRequest extends RequestBase {
  detector?: MlDetector
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { detector?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { detector?: never }
}

export type MlValidateDetectorResponse = AcknowledgedResponseBase

export interface MonitoringBulkRequest<TDocument = unknown, TPartialDocument = unknown> extends RequestBase {
/** Default document type for items which don't provide one */
  type?: string
  /** Identifier of the monitored system */
  system_id: string
  /**  */
  system_api_version: string
  /** Collection interval (e.g., '10s' or '10000ms') of the payload */
  interval: Duration
  operations?: (BulkOperationContainer | BulkUpdateAction<TDocument, TPartialDocument> | TDocument)[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { type?: never, system_id?: never, system_api_version?: never, interval?: never, operations?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { type?: never, system_id?: never, system_api_version?: never, interval?: never, operations?: never }
}

export interface MonitoringBulkResponse {
  error?: ErrorCause
  errors: boolean
  ignored: boolean
  took: long
}

export interface NodesAdaptiveSelection {
  avg_queue_size?: long
  avg_response_time?: Duration
  avg_response_time_ns?: long
  avg_service_time?: Duration
  avg_service_time_ns?: long
  outgoing_searches?: long
  rank?: string
}

export interface NodesBreaker {
  estimated_size?: string
  estimated_size_in_bytes?: long
  limit_size?: string
  limit_size_in_bytes?: long
  overhead?: float
  tripped?: float
}

export interface NodesCgroup {
  cpuacct?: NodesCpuAcct
  cpu?: NodesCgroupCpu
  memory?: NodesCgroupMemory
}

export interface NodesCgroupCpu {
  control_group?: string
  cfs_period_micros?: integer
  cfs_quota_micros?: integer
  stat?: NodesCgroupCpuStat
}

export interface NodesCgroupCpuStat {
  number_of_elapsed_periods?: long
  number_of_times_throttled?: long
  time_throttled_nanos?: DurationValue<UnitNanos>
}

export interface NodesCgroupMemory {
  control_group?: string
  limit_in_bytes?: string
  usage_in_bytes?: string
}

export interface NodesClient {
  id?: long
  agent?: string
  local_address?: string
  remote_address?: string
  last_uri?: string
  opened_time_millis?: long
  closed_time_millis?: long
  last_request_time_millis?: long
  request_count?: long
  request_size_bytes?: long
  x_opaque_id?: string
}

export interface NodesClusterAppliedStats {
  recordings?: NodesRecording[]
}

export interface NodesClusterStateQueue {
  total?: long
  pending?: long
  committed?: long
}

export interface NodesClusterStateUpdate {
  count: long
  computation_time?: Duration
  computation_time_millis?: DurationValue<UnitMillis>
  publication_time?: Duration
  publication_time_millis?: DurationValue<UnitMillis>
  context_construction_time?: Duration
  context_construction_time_millis?: DurationValue<UnitMillis>
  commit_time?: Duration
  commit_time_millis?: DurationValue<UnitMillis>
  completion_time?: Duration
  completion_time_millis?: DurationValue<UnitMillis>
  master_apply_time?: Duration
  master_apply_time_millis?: DurationValue<UnitMillis>
  notification_time?: Duration
  notification_time_millis?: DurationValue<UnitMillis>
}

export interface NodesContext {
  context?: string
  compilations?: long
  cache_evictions?: long
  compilation_limit_triggered?: long
}

export interface NodesCpu {
  percent?: integer
  sys?: Duration
  sys_in_millis?: DurationValue<UnitMillis>
  total?: Duration
  total_in_millis?: DurationValue<UnitMillis>
  user?: Duration
  user_in_millis?: DurationValue<UnitMillis>
  load_average?: Record<string, double>
}

export interface NodesCpuAcct {
  control_group?: string
  usage_nanos?: DurationValue<UnitNanos>
}

export interface NodesDataPathStats {
  available?: string
  available_in_bytes?: long
  disk_queue?: string
  disk_reads?: long
  disk_read_size?: string
  disk_read_size_in_bytes?: long
  disk_writes?: long
  disk_write_size?: string
  disk_write_size_in_bytes?: long
  free?: string
  free_in_bytes?: long
  mount?: string
  path?: string
  total?: string
  total_in_bytes?: long
  type?: string
}

export interface NodesDiscovery {
  cluster_state_queue?: NodesClusterStateQueue
  published_cluster_states?: NodesPublishedClusterStates
  cluster_state_update?: Record<string, NodesClusterStateUpdate>
  serialized_cluster_states?: NodesSerializedClusterState
  cluster_applier_stats?: NodesClusterAppliedStats
}

export interface NodesExtendedMemoryStats extends NodesMemoryStats {
  free_percent?: integer
  used_percent?: integer
}

export interface NodesFileSystem {
  data?: NodesDataPathStats[]
  timestamp?: long
  total?: NodesFileSystemTotal
  io_stats?: NodesIoStats
}

export interface NodesFileSystemTotal {
  available?: string
  available_in_bytes?: long
  free?: string
  free_in_bytes?: long
  total?: string
  total_in_bytes?: long
}

export interface NodesGarbageCollector {
  collectors?: Record<string, NodesGarbageCollectorTotal>
}

export interface NodesGarbageCollectorTotal {
  collection_count?: long
  collection_time?: string
  collection_time_in_millis?: long
}

export interface NodesHttp {
  current_open?: integer
  total_opened?: long
  clients?: NodesClient[]
  routes: Record<string, NodesHttpRoute>
}

export interface NodesHttpRoute {
  requests: NodesHttpRouteRequests
  responses: NodesHttpRouteResponses
}

export interface NodesHttpRouteRequests {
  count: long
  total_size_in_bytes: long
  size_histogram: NodesSizeHttpHistogram[]
}

export interface NodesHttpRouteResponses {
  count: long
  total_size_in_bytes: long
  handling_time_histogram: NodesTimeHttpHistogram[]
  size_histogram: NodesSizeHttpHistogram[]
}

export interface NodesIndexingPressure {
  memory?: NodesIndexingPressureMemory
}

export interface NodesIndexingPressureMemory {
  limit?: ByteSize
  limit_in_bytes?: long
  current?: NodesPressureMemory
  total?: NodesPressureMemory
}

export interface NodesIngest {
  pipelines?: Record<string, NodesIngestStats>
  total?: NodesIngestTotal
}

export interface NodesIngestStats {
  count: long
  current: long
  failed: long
  processors: Record<string, NodesKeyedProcessor>[]
  time_in_millis: DurationValue<UnitMillis>
  ingested_as_first_pipeline_in_bytes: long
  produced_as_first_pipeline_in_bytes: long
}

export interface NodesIngestTotal {
  count: long
  current: long
  failed: long
  time_in_millis: DurationValue<UnitMillis>
}

export interface NodesIoStatDevice {
  device_name?: string
  operations?: long
  read_kilobytes?: long
  read_operations?: long
  write_kilobytes?: long
  write_operations?: long
}

export interface NodesIoStats {
  devices?: NodesIoStatDevice[]
  total?: NodesIoStatDevice
}

export interface NodesJvm {
  buffer_pools?: Record<string, NodesNodeBufferPool>
  classes?: NodesJvmClasses
  gc?: NodesGarbageCollector
  mem?: NodesJvmMemoryStats
  threads?: NodesJvmThreads
  timestamp?: long
  uptime?: string
  uptime_in_millis?: long
}

export interface NodesJvmClasses {
  current_loaded_count?: long
  total_loaded_count?: long
  total_unloaded_count?: long
}

export interface NodesJvmMemoryStats {
  heap_used_in_bytes?: long
  heap_used_percent?: long
  heap_committed_in_bytes?: long
  heap_max_in_bytes?: long
  non_heap_used_in_bytes?: long
  non_heap_committed_in_bytes?: long
  pools?: Record<string, NodesPool>
}

export interface NodesJvmThreads {
  count?: long
  peak_count?: long
}

export interface NodesKeyedProcessor {
  stats?: NodesProcessor
  type?: string
}

export interface NodesMemoryStats {
  adjusted_total_in_bytes?: long
  resident?: string
  resident_in_bytes?: long
  share?: string
  share_in_bytes?: long
  total_virtual?: string
  total_virtual_in_bytes?: long
  total_in_bytes?: long
  free_in_bytes?: long
  used_in_bytes?: long
}

export interface NodesNodeBufferPool {
  count?: long
  total_capacity?: string
  total_capacity_in_bytes?: long
  used?: string
  used_in_bytes?: long
}

export interface NodesNodeReloadResult {
  name: Name
  reload_exception?: ErrorCause
}

export interface NodesNodesResponseBase {
  _nodes?: NodeStatistics
}

export interface NodesOperatingSystem {
  cpu?: NodesCpu
  mem?: NodesExtendedMemoryStats
  swap?: NodesMemoryStats
  cgroup?: NodesCgroup
  timestamp?: long
}

export interface NodesPool {
  used_in_bytes?: long
  max_in_bytes?: long
  peak_used_in_bytes?: long
  peak_max_in_bytes?: long
}

export interface NodesPressureMemory {
  all?: ByteSize
  all_in_bytes?: long
  combined_coordinating_and_primary?: ByteSize
  combined_coordinating_and_primary_in_bytes?: long
  coordinating?: ByteSize
  coordinating_in_bytes?: long
  primary?: ByteSize
  primary_in_bytes?: long
  replica?: ByteSize
  replica_in_bytes?: long
  coordinating_rejections?: long
  primary_rejections?: long
  replica_rejections?: long
}

export interface NodesProcess {
  cpu?: NodesCpu
  mem?: NodesMemoryStats
  open_file_descriptors?: integer
  max_file_descriptors?: integer
  timestamp?: long
}

export interface NodesProcessor {
  count?: long
  current?: long
  failed?: long
  time_in_millis?: DurationValue<UnitMillis>
}

export interface NodesPublishedClusterStates {
  full_states?: long
  incompatible_diffs?: long
  compatible_diffs?: long
}

export interface NodesRecording {
  name?: string
  cumulative_execution_count?: long
  cumulative_execution_time?: Duration
  cumulative_execution_time_millis?: DurationValue<UnitMillis>
}

export interface NodesRepositoryLocation {
  base_path: string
  container?: string
  bucket?: string
}

export interface NodesRepositoryMeteringInformation {
  repository_name: Name
  repository_type: string
  repository_location: NodesRepositoryLocation
  repository_ephemeral_id: Id
  repository_started_at: EpochTime<UnitMillis>
  repository_stopped_at?: EpochTime<UnitMillis>
  archived: boolean
  cluster_version?: VersionNumber
  request_counts: NodesRequestCounts
}

export interface NodesRequestCounts {
  GetBlobProperties?: long
  GetBlob?: long
  ListBlobs?: long
  PutBlob?: long
  PutBlock?: long
  PutBlockList?: long
  GetObject?: long
  ListObjects?: long
  InsertObject?: long
  PutObject?: long
  PutMultipartObject?: long
}

export interface NodesScriptCache {
  cache_evictions?: long
  compilation_limit_triggered?: long
  compilations?: long
  context?: string
}

export interface NodesScripting {
  cache_evictions?: long
  compilations?: long
  compilations_history?: Record<string, long>
  compilation_limit_triggered?: long
  contexts?: NodesContext[]
}

export interface NodesSerializedClusterState {
  full_states?: NodesSerializedClusterStateDetail
  diffs?: NodesSerializedClusterStateDetail
}

export interface NodesSerializedClusterStateDetail {
  count?: long
  uncompressed_size?: string
  uncompressed_size_in_bytes?: long
  compressed_size?: string
  compressed_size_in_bytes?: long
}

export interface NodesSizeHttpHistogram {
  count: long
  ge_bytes?: long
  lt_bytes?: long
}

export interface NodesStats {
  adaptive_selection?: Record<string, NodesAdaptiveSelection>
  breakers?: Record<string, NodesBreaker>
  fs?: NodesFileSystem
  host?: Host
  http?: NodesHttp
  ingest?: NodesIngest
  ip?: Ip | Ip[]
  jvm?: NodesJvm
  name?: Name
  os?: NodesOperatingSystem
  process?: NodesProcess
  roles?: NodeRoles
  script?: NodesScripting
  script_cache?: Record<string, NodesScriptCache | NodesScriptCache[]>
  thread_pool?: Record<string, NodesThreadCount>
  timestamp?: long
  transport?: NodesTransport
  transport_address?: TransportAddress
  attributes?: Record<Field, string>
  discovery?: NodesDiscovery
  indexing_pressure?: NodesIndexingPressure
  indices?: IndicesStatsShardStats
}

export interface NodesThreadCount {
  active?: long
  completed?: long
  largest?: long
  queue?: long
  rejected?: long
  threads?: long
}

export interface NodesTimeHttpHistogram {
  count: long
  ge_millis?: long
  lt_millis?: long
}

export interface NodesTransport {
  inbound_handling_time_histogram?: NodesTransportHistogram[]
  outbound_handling_time_histogram?: NodesTransportHistogram[]
  rx_count?: long
  rx_size?: string
  rx_size_in_bytes?: long
  server_open?: integer
  tx_count?: long
  tx_size?: string
  tx_size_in_bytes?: long
  total_outbound_connections?: long
}

export interface NodesTransportHistogram {
  count?: long
  lt_millis?: long
  ge_millis?: long
}

export interface NodesClearRepositoriesMeteringArchiveRequest extends RequestBase {
/** Comma-separated list of node IDs or names used to limit returned information. */
  node_id: NodeIds
  /** Specifies the maximum `archive_version` to be cleared from the archive. */
  max_archive_version: long
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never, max_archive_version?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never, max_archive_version?: never }
}

export type NodesClearRepositoriesMeteringArchiveResponse = NodesClearRepositoriesMeteringArchiveResponseBase

export interface NodesClearRepositoriesMeteringArchiveResponseBase extends NodesNodesResponseBase {
  cluster_name: Name
  nodes: Record<string, NodesRepositoryMeteringInformation>
}

export interface NodesGetRepositoriesMeteringInfoRequest extends RequestBase {
/** Comma-separated list of node IDs or names used to limit returned information. All the nodes selective options are explained [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster.html#cluster-nodes). */
  node_id: NodeIds
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never }
}

export type NodesGetRepositoriesMeteringInfoResponse = NodesGetRepositoriesMeteringInfoResponseBase

export interface NodesGetRepositoriesMeteringInfoResponseBase extends NodesNodesResponseBase {
  cluster_name: Name
  nodes: Record<string, NodesRepositoryMeteringInformation>
}

export interface NodesHotThreadsRequest extends RequestBase {
/** List of node IDs or names used to limit returned information. */
  node_id?: NodeIds
  /** If true, known idle threads (e.g. waiting in a socket select, or to get a task from an empty queue) are filtered out. */
  ignore_idle_threads?: boolean
  /** The interval to do the second sampling of threads. */
  interval?: Duration
  /** Number of samples of thread stacktrace. */
  snapshots?: long
  /** Specifies the number of hot threads to provide information for. */
  threads?: long
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** The type to sample. */
  type?: ThreadType
  /** The sort order for 'cpu' type (default: total) */
  sort?: ThreadType
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never, ignore_idle_threads?: never, interval?: never, snapshots?: never, threads?: never, timeout?: never, type?: never, sort?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never, ignore_idle_threads?: never, interval?: never, snapshots?: never, threads?: never, timeout?: never, type?: never, sort?: never }
}

export interface NodesHotThreadsResponse {
}

export interface NodesInfoDeprecationIndexing {
  enabled: boolean | string
}

export interface NodesInfoNodeInfo {
  attributes: Record<string, string>
  build_flavor: string
  build_hash: string
  build_type: string
  host: Host
  http?: NodesInfoNodeInfoHttp
  ip: Ip
  jvm?: NodesInfoNodeJvmInfo
  name: Name
  network?: NodesInfoNodeInfoNetwork
  os?: NodesInfoNodeOperatingSystemInfo
  plugins?: PluginStats[]
  process?: NodesInfoNodeProcessInfo
  roles: NodeRoles
  settings?: NodesInfoNodeInfoSettings
  thread_pool?: Record<string, NodesInfoNodeThreadPoolInfo>
  total_indexing_buffer?: long
  total_indexing_buffer_in_bytes?: ByteSize
  transport?: NodesInfoNodeInfoTransport
  transport_address: TransportAddress
  version: VersionString
  modules?: PluginStats[]
  ingest?: NodesInfoNodeInfoIngest
  aggregations?: Record<string, NodesInfoNodeInfoAggregation>
}

export interface NodesInfoNodeInfoAction {
  destructive_requires_name: string
}

export interface NodesInfoNodeInfoAggregation {
  types: string[]
}

export interface NodesInfoNodeInfoBootstrap {
  memory_lock: string
}

export interface NodesInfoNodeInfoClient {
  type: string
}

export interface NodesInfoNodeInfoDiscoverKeys {
  seed_hosts?: string[]
  type?: string
  seed_providers?: string[]
}
export type NodesInfoNodeInfoDiscover = NodesInfoNodeInfoDiscoverKeys
& { [property: string]: any }

export interface NodesInfoNodeInfoHttp {
  bound_address: string[]
  max_content_length?: ByteSize
  max_content_length_in_bytes: long
  publish_address: string
}

export interface NodesInfoNodeInfoIngest {
  processors: NodesInfoNodeInfoIngestProcessor[]
}

export interface NodesInfoNodeInfoIngestDownloader {
  enabled: string
}

export interface NodesInfoNodeInfoIngestInfo {
  downloader: NodesInfoNodeInfoIngestDownloader
}

export interface NodesInfoNodeInfoIngestProcessor {
  type: string
}

export interface NodesInfoNodeInfoJvmMemory {
  direct_max?: ByteSize
  direct_max_in_bytes: long
  heap_init?: ByteSize
  heap_init_in_bytes: long
  heap_max?: ByteSize
  heap_max_in_bytes: long
  non_heap_init?: ByteSize
  non_heap_init_in_bytes: long
  non_heap_max?: ByteSize
  non_heap_max_in_bytes: long
}

export interface NodesInfoNodeInfoMemory {
  total: string
  total_in_bytes: long
}

export interface NodesInfoNodeInfoNetwork {
  primary_interface: NodesInfoNodeInfoNetworkInterface
  refresh_interval: integer
}

export interface NodesInfoNodeInfoNetworkInterface {
  address: string
  mac_address: string
  name: Name
}

export interface NodesInfoNodeInfoOSCPU {
  cache_size: string
  cache_size_in_bytes: integer
  cores_per_socket: integer
  mhz: integer
  model: string
  total_cores: integer
  total_sockets: integer
  vendor: string
}

export interface NodesInfoNodeInfoPath {
  logs?: string
  home?: string
  repo?: string[]
  data?: string | string[]
}

export interface NodesInfoNodeInfoRepositories {
  url: NodesInfoNodeInfoRepositoriesUrl
}

export interface NodesInfoNodeInfoRepositoriesUrl {
  allowed_urls: string
}

export interface NodesInfoNodeInfoScript {
  allowed_types: string
  disable_max_compilations_rate?: string
}

export interface NodesInfoNodeInfoSearch {
  remote: NodesInfoNodeInfoSearchRemote
}

export interface NodesInfoNodeInfoSearchRemote {
  connect: string
}

export interface NodesInfoNodeInfoSettings {
  cluster: NodesInfoNodeInfoSettingsCluster
  node: NodesInfoNodeInfoSettingsNode
  path?: NodesInfoNodeInfoPath
  repositories?: NodesInfoNodeInfoRepositories
  discovery?: NodesInfoNodeInfoDiscover
  action?: NodesInfoNodeInfoAction
  client?: NodesInfoNodeInfoClient
  http: NodesInfoNodeInfoSettingsHttp
  bootstrap?: NodesInfoNodeInfoBootstrap
  transport: NodesInfoNodeInfoSettingsTransport
  network?: NodesInfoNodeInfoSettingsNetwork
  xpack?: NodesInfoNodeInfoXpack
  script?: NodesInfoNodeInfoScript
  search?: NodesInfoNodeInfoSearch
  ingest?: NodesInfoNodeInfoSettingsIngest
}

export interface NodesInfoNodeInfoSettingsCluster {
  name: Name
  routing?: IndicesIndexRouting
  election: NodesInfoNodeInfoSettingsClusterElection
  initial_master_nodes?: string[]
  deprecation_indexing?: NodesInfoDeprecationIndexing
}

export interface NodesInfoNodeInfoSettingsClusterElection {
  strategy: Name
}

export interface NodesInfoNodeInfoSettingsHttp {
  type: NodesInfoNodeInfoSettingsHttpType | string
  'type.default'?: string
  compression?: boolean | string
  port?: integer | string
}

export interface NodesInfoNodeInfoSettingsHttpType {
  default: string
}

export interface NodesInfoNodeInfoSettingsIngest {
  attachment?: NodesInfoNodeInfoIngestInfo
  append?: NodesInfoNodeInfoIngestInfo
  csv?: NodesInfoNodeInfoIngestInfo
  convert?: NodesInfoNodeInfoIngestInfo
  date?: NodesInfoNodeInfoIngestInfo
  date_index_name?: NodesInfoNodeInfoIngestInfo
  dot_expander?: NodesInfoNodeInfoIngestInfo
  enrich?: NodesInfoNodeInfoIngestInfo
  fail?: NodesInfoNodeInfoIngestInfo
  foreach?: NodesInfoNodeInfoIngestInfo
  json?: NodesInfoNodeInfoIngestInfo
  user_agent?: NodesInfoNodeInfoIngestInfo
  kv?: NodesInfoNodeInfoIngestInfo
  geoip?: NodesInfoNodeInfoIngestInfo
  grok?: NodesInfoNodeInfoIngestInfo
  gsub?: NodesInfoNodeInfoIngestInfo
  join?: NodesInfoNodeInfoIngestInfo
  lowercase?: NodesInfoNodeInfoIngestInfo
  remove?: NodesInfoNodeInfoIngestInfo
  rename?: NodesInfoNodeInfoIngestInfo
  script?: NodesInfoNodeInfoIngestInfo
  set?: NodesInfoNodeInfoIngestInfo
  sort?: NodesInfoNodeInfoIngestInfo
  split?: NodesInfoNodeInfoIngestInfo
  trim?: NodesInfoNodeInfoIngestInfo
  uppercase?: NodesInfoNodeInfoIngestInfo
  urldecode?: NodesInfoNodeInfoIngestInfo
  bytes?: NodesInfoNodeInfoIngestInfo
  dissect?: NodesInfoNodeInfoIngestInfo
  set_security_user?: NodesInfoNodeInfoIngestInfo
  pipeline?: NodesInfoNodeInfoIngestInfo
  drop?: NodesInfoNodeInfoIngestInfo
  circle?: NodesInfoNodeInfoIngestInfo
  inference?: NodesInfoNodeInfoIngestInfo
}

export interface NodesInfoNodeInfoSettingsNetwork {
  host?: Host | Host[]
}

export interface NodesInfoNodeInfoSettingsNode {
  name: Name
  attr: Record<string, any>
  max_local_storage_nodes?: string
}

export interface NodesInfoNodeInfoSettingsTransport {
  type: NodesInfoNodeInfoSettingsTransportType | string
  'type.default'?: string
  features?: NodesInfoNodeInfoSettingsTransportFeatures
}

export interface NodesInfoNodeInfoSettingsTransportFeatures {
  'x-pack': string
}

export interface NodesInfoNodeInfoSettingsTransportType {
  default: string
}

export interface NodesInfoNodeInfoTransport {
  bound_address: string[]
  publish_address: string
  profiles: Record<string, string>
}

export interface NodesInfoNodeInfoXpack {
  license?: NodesInfoNodeInfoXpackLicense
  security: NodesInfoNodeInfoXpackSecurity
  notification?: Record<string, any>
  ml?: NodesInfoNodeInfoXpackMl
}

export interface NodesInfoNodeInfoXpackLicense {
  self_generated: NodesInfoNodeInfoXpackLicenseType
}

export interface NodesInfoNodeInfoXpackLicenseType {
  type: string
}

export interface NodesInfoNodeInfoXpackMl {
  use_auto_machine_memory_percent?: boolean
}

export interface NodesInfoNodeInfoXpackSecurity {
  http?: NodesInfoNodeInfoXpackSecuritySsl
  enabled: string
  transport?: NodesInfoNodeInfoXpackSecuritySsl
  authc?: NodesInfoNodeInfoXpackSecurityAuthc
}

export interface NodesInfoNodeInfoXpackSecurityAuthc {
  realms?: NodesInfoNodeInfoXpackSecurityAuthcRealms
  token?: NodesInfoNodeInfoXpackSecurityAuthcToken
}

export interface NodesInfoNodeInfoXpackSecurityAuthcRealms {
  file?: Record<string, NodesInfoNodeInfoXpackSecurityAuthcRealmsStatus>
  native?: Record<string, NodesInfoNodeInfoXpackSecurityAuthcRealmsStatus>
  pki?: Record<string, NodesInfoNodeInfoXpackSecurityAuthcRealmsStatus>
}

export interface NodesInfoNodeInfoXpackSecurityAuthcRealmsStatus {
  enabled?: string
  order: string
}

export interface NodesInfoNodeInfoXpackSecurityAuthcToken {
  enabled: string
}

export interface NodesInfoNodeInfoXpackSecuritySsl {
  ssl: Record<string, string>
}

export interface NodesInfoNodeJvmInfo {
  gc_collectors: string[]
  mem: NodesInfoNodeInfoJvmMemory
  memory_pools: string[]
  pid: integer
  start_time_in_millis: EpochTime<UnitMillis>
  version: VersionString
  vm_name: Name
  vm_vendor: string
  vm_version: VersionString
  using_bundled_jdk: boolean
  bundled_jdk: boolean
  using_compressed_ordinary_object_pointers?: boolean | string
  input_arguments: string[]
}

export interface NodesInfoNodeOperatingSystemInfo {
  arch: string
  available_processors: integer
  allocated_processors?: integer
  name: Name
  pretty_name: Name
  refresh_interval_in_millis: DurationValue<UnitMillis>
  version: VersionString
  cpu?: NodesInfoNodeInfoOSCPU
  mem?: NodesInfoNodeInfoMemory
  swap?: NodesInfoNodeInfoMemory
}

export interface NodesInfoNodeProcessInfo {
  id: long
  mlockall: boolean
  refresh_interval_in_millis: DurationValue<UnitMillis>
}

export interface NodesInfoNodeThreadPoolInfo {
  core?: integer
  keep_alive?: Duration
  max?: integer
  queue_size: integer
  size?: integer
  type: string
}

export interface NodesInfoRequest extends RequestBase {
/** Comma-separated list of node IDs or names used to limit returned information. */
  node_id?: NodeIds
  /** Limits the information returned to the specific metrics. Supports a comma-separated list, such as http,ingest. */
  metric?: Metrics
  /** If true, returns settings in flat format. */
  flat_settings?: boolean
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never, metric?: never, flat_settings?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never, metric?: never, flat_settings?: never, timeout?: never }
}

export type NodesInfoResponse = NodesInfoResponseBase

export interface NodesInfoResponseBase extends NodesNodesResponseBase {
  cluster_name: Name
  nodes: Record<string, NodesInfoNodeInfo>
}

export interface NodesReloadSecureSettingsRequest extends RequestBase {
/** The names of particular nodes in the cluster to target. */
  node_id?: NodeIds
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** The password for the Elasticsearch keystore. */
  secure_settings_password?: Password
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never, timeout?: never, secure_settings_password?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never, timeout?: never, secure_settings_password?: never }
}

export type NodesReloadSecureSettingsResponse = NodesReloadSecureSettingsResponseBase

export interface NodesReloadSecureSettingsResponseBase extends NodesNodesResponseBase {
  cluster_name: Name
  nodes: Record<string, NodesNodeReloadResult>
}

export interface NodesStatsRequest extends RequestBase {
/** Comma-separated list of node IDs or names used to limit returned information. */
  node_id?: NodeIds
  /** Limit the information returned to the specified metrics */
  metric?: Metrics
  /** Limit the information returned for indices metric to the specific index metrics. It can be used only if indices (or all) metric is specified. */
  index_metric?: Metrics
  /** Comma-separated list or wildcard expressions of fields to include in fielddata and suggest statistics. */
  completion_fields?: Fields
  /** Comma-separated list or wildcard expressions of fields to include in fielddata statistics. */
  fielddata_fields?: Fields
  /** Comma-separated list or wildcard expressions of fields to include in the statistics. */
  fields?: Fields
  /** Comma-separated list of search groups to include in the search statistics. */
  groups?: boolean
  /** If true, the call reports the aggregated disk usage of each one of the Lucene index files (only applies if segment stats are requested). */
  include_segment_file_sizes?: boolean
  /** Indicates whether statistics are aggregated at the cluster, index, or shard level. */
  level?: Level
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** A comma-separated list of document types for the indexing index metric. */
  types?: string[]
  /** If `true`, the response includes information from segments that are not loaded into memory. */
  include_unloaded_segments?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never, metric?: never, index_metric?: never, completion_fields?: never, fielddata_fields?: never, fields?: never, groups?: never, include_segment_file_sizes?: never, level?: never, timeout?: never, types?: never, include_unloaded_segments?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never, metric?: never, index_metric?: never, completion_fields?: never, fielddata_fields?: never, fields?: never, groups?: never, include_segment_file_sizes?: never, level?: never, timeout?: never, types?: never, include_unloaded_segments?: never }
}

export type NodesStatsResponse = NodesStatsResponseBase

export interface NodesStatsResponseBase extends NodesNodesResponseBase {
  cluster_name?: Name
  nodes: Record<string, NodesStats>
}

export interface NodesUsageNodeUsage {
  rest_actions: Record<string, integer>
  since: EpochTime<UnitMillis>
  timestamp: EpochTime<UnitMillis>
  aggregations: Record<string, any>
}

export interface NodesUsageRequest extends RequestBase {
/** A comma-separated list of node IDs or names to limit the returned information; use `_local` to return information from the node you're connecting to, leave empty to get information from all nodes */
  node_id?: NodeIds
  /** Limits the information returned to the specific metrics. A comma-separated list of the following options: `_all`, `rest_actions`. */
  metric?: Metrics
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never, metric?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never, metric?: never, timeout?: never }
}

export type NodesUsageResponse = NodesUsageResponseBase

export interface NodesUsageResponseBase extends NodesNodesResponseBase {
  cluster_name: Name
  nodes: Record<string, NodesUsageNodeUsage>
}

export interface QueryRulesQueryRule {
  rule_id: Id
  type: QueryRulesQueryRuleType
  criteria: QueryRulesQueryRuleCriteria | QueryRulesQueryRuleCriteria[]
  actions: QueryRulesQueryRuleActions
  priority?: integer
}

export interface QueryRulesQueryRuleActions {
  ids?: Id[]
  docs?: QueryDslPinnedDoc[]
}

export interface QueryRulesQueryRuleCriteria {
  type: QueryRulesQueryRuleCriteriaType
  metadata?: string
  values?: any[]
}

export type QueryRulesQueryRuleCriteriaType = 'global' | 'exact' | 'exact_fuzzy' | 'fuzzy' | 'prefix' | 'suffix' | 'contains' | 'lt' | 'lte' | 'gt' | 'gte' | 'always'

export type QueryRulesQueryRuleType = 'pinned' | 'exclude'

export interface QueryRulesQueryRuleset {
  ruleset_id: Id
  rules: QueryRulesQueryRule[]
}

export interface QueryRulesDeleteRuleRequest extends RequestBase {
/** The unique identifier of the query ruleset containing the rule to delete */
  ruleset_id: Id
  /** The unique identifier of the query rule within the specified ruleset to delete */
  rule_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { ruleset_id?: never, rule_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { ruleset_id?: never, rule_id?: never }
}

export type QueryRulesDeleteRuleResponse = AcknowledgedResponseBase

export interface QueryRulesDeleteRulesetRequest extends RequestBase {
/** The unique identifier of the query ruleset to delete */
  ruleset_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { ruleset_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { ruleset_id?: never }
}

export type QueryRulesDeleteRulesetResponse = AcknowledgedResponseBase

export interface QueryRulesGetRuleRequest extends RequestBase {
/** The unique identifier of the query ruleset containing the rule to retrieve */
  ruleset_id: Id
  /** The unique identifier of the query rule within the specified ruleset to retrieve */
  rule_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { ruleset_id?: never, rule_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { ruleset_id?: never, rule_id?: never }
}

export type QueryRulesGetRuleResponse = QueryRulesQueryRule

export interface QueryRulesGetRulesetRequest extends RequestBase {
/** The unique identifier of the query ruleset */
  ruleset_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { ruleset_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { ruleset_id?: never }
}

export type QueryRulesGetRulesetResponse = QueryRulesQueryRuleset

export interface QueryRulesListRulesetsQueryRulesetListItem {
  ruleset_id: Id
  rule_total_count: integer
  rule_criteria_types_counts: Record<string, integer>
  rule_type_counts: Record<string, integer>
}

export interface QueryRulesListRulesetsRequest extends RequestBase {
/** The offset from the first result to fetch. */
  from?: integer
  /** The maximum number of results to retrieve. */
  size?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { from?: never, size?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { from?: never, size?: never }
}

export interface QueryRulesListRulesetsResponse {
  count: long
  results: QueryRulesListRulesetsQueryRulesetListItem[]
}

export interface QueryRulesPutRuleRequest extends RequestBase {
/** The unique identifier of the query ruleset containing the rule to be created or updated. */
  ruleset_id: Id
  /** The unique identifier of the query rule within the specified ruleset to be created or updated. */
  rule_id: Id
  /** The type of rule. */
  type: QueryRulesQueryRuleType
  /** The criteria that must be met for the rule to be applied. If multiple criteria are specified for a rule, all criteria must be met for the rule to be applied. */
  criteria: QueryRulesQueryRuleCriteria | QueryRulesQueryRuleCriteria[]
  /** The actions to take when the rule is matched. The format of this action depends on the rule type. */
  actions: QueryRulesQueryRuleActions
  priority?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { ruleset_id?: never, rule_id?: never, type?: never, criteria?: never, actions?: never, priority?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { ruleset_id?: never, rule_id?: never, type?: never, criteria?: never, actions?: never, priority?: never }
}

export interface QueryRulesPutRuleResponse {
  result: Result
}

export interface QueryRulesPutRulesetRequest extends RequestBase {
/** The unique identifier of the query ruleset to be created or updated. */
  ruleset_id: Id
  rules: QueryRulesQueryRule | QueryRulesQueryRule[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { ruleset_id?: never, rules?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { ruleset_id?: never, rules?: never }
}

export interface QueryRulesPutRulesetResponse {
  result: Result
}

export interface QueryRulesTestQueryRulesetMatchedRule {
  ruleset_id: Id
  rule_id: Id
}

export interface QueryRulesTestRequest extends RequestBase {
/** The unique identifier of the query ruleset to be created or updated */
  ruleset_id: Id
  /** The match criteria to apply to rules in the given query ruleset. Match criteria should match the keys defined in the `criteria.metadata` field of the rule. */
  match_criteria: Record<string, any>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { ruleset_id?: never, match_criteria?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { ruleset_id?: never, match_criteria?: never }
}

export interface QueryRulesTestResponse {
  total_matched_rules: integer
  matched_rules: QueryRulesTestQueryRulesetMatchedRule[]
}

export interface RollupDateHistogramGrouping {
  delay?: Duration
  field: Field
  format?: string
  interval?: Duration
  calendar_interval?: Duration
  fixed_interval?: Duration
  time_zone?: TimeZone
}

export interface RollupFieldMetric {
  field: Field
  metrics: RollupMetric[]
}

export interface RollupGroupings {
  date_histogram?: RollupDateHistogramGrouping
  histogram?: RollupHistogramGrouping
  terms?: RollupTermsGrouping
}

export interface RollupHistogramGrouping {
  fields: Fields
  interval: long
}

export type RollupMetric = 'min' | 'max' | 'sum' | 'avg' | 'value_count'

export interface RollupTermsGrouping {
  fields: Fields
}

export interface RollupDeleteJobRequest extends RequestBase {
/** Identifier for the job. */
  id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export interface RollupDeleteJobResponse {
  acknowledged: boolean
  task_failures?: TaskFailure[]
}

export type RollupGetJobsIndexingJobState = 'started' | 'indexing' | 'stopping' | 'stopped' | 'aborting'

export interface RollupGetJobsRequest extends RequestBase {
/** Identifier for the rollup job. If it is `_all` or omitted, the API returns all rollup jobs. */
  id?: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export interface RollupGetJobsResponse {
  jobs: RollupGetJobsRollupJob[]
}

export interface RollupGetJobsRollupJob {
  config: RollupGetJobsRollupJobConfiguration
  stats: RollupGetJobsRollupJobStats
  status: RollupGetJobsRollupJobStatus
}

export interface RollupGetJobsRollupJobConfiguration {
  cron: string
  groups: RollupGroupings
  id: Id
  index_pattern: string
  metrics: RollupFieldMetric[]
  page_size: long
  rollup_index: IndexName
  timeout: Duration
}

export interface RollupGetJobsRollupJobStats {
  documents_processed: long
  index_failures: long
  index_time_in_ms: DurationValue<UnitMillis>
  index_total: long
  pages_processed: long
  rollups_indexed: long
  search_failures: long
  search_time_in_ms: DurationValue<UnitMillis>
  search_total: long
  trigger_count: long
  processing_time_in_ms: DurationValue<UnitMillis>
  processing_total: long
}

export interface RollupGetJobsRollupJobStatus {
  current_position?: Record<string, any>
  job_state: RollupGetJobsIndexingJobState
  upgraded_doc_id?: boolean
}

export interface RollupGetRollupCapsRequest extends RequestBase {
/** Index, indices or index-pattern to return rollup capabilities for. `_all` may be used to fetch rollup capabilities from all jobs. */
  id?: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export type RollupGetRollupCapsResponse = Record<IndexName, RollupGetRollupCapsRollupCapabilities>

export interface RollupGetRollupCapsRollupCapabilities {
  rollup_jobs: RollupGetRollupCapsRollupCapabilitySummary[]
}

export interface RollupGetRollupCapsRollupCapabilitySummary {
  fields: Record<Field, RollupGetRollupCapsRollupFieldSummary[]>
  index_pattern: string
  job_id: string
  rollup_index: string
}

export interface RollupGetRollupCapsRollupFieldSummary {
  agg: string
  calendar_interval?: Duration
  time_zone?: TimeZone
}

export interface RollupGetRollupIndexCapsIndexCapabilities {
  rollup_jobs: RollupGetRollupIndexCapsRollupJobSummary[]
}

export interface RollupGetRollupIndexCapsRequest extends RequestBase {
/** Data stream or index to check for rollup capabilities. Wildcard (`*`) expressions are supported. */
  index: Ids
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never }
}

export type RollupGetRollupIndexCapsResponse = Record<IndexName, RollupGetRollupIndexCapsIndexCapabilities>

export interface RollupGetRollupIndexCapsRollupJobSummary {
  fields: Record<Field, RollupGetRollupIndexCapsRollupJobSummaryField[]>
  index_pattern: string
  job_id: Id
  rollup_index: IndexName
}

export interface RollupGetRollupIndexCapsRollupJobSummaryField {
  agg: string
  time_zone?: TimeZone
  calendar_interval?: Duration
}

export interface RollupPutJobRequest extends RequestBase {
/** Identifier for the rollup job. This can be any alphanumeric string and uniquely identifies the data that is associated with the rollup job. The ID is persistent; it is stored with the rolled up data. If you create a job, let it run for a while, then delete the job, the data that the job rolled up is still be associated with this job ID. You cannot create a new job with the same ID since that could lead to problems with mismatched job configurations. */
  id: Id
  /** A cron string which defines the intervals when the rollup job should be executed. When the interval triggers, the indexer attempts to rollup the data in the index pattern. The cron pattern is unrelated to the time interval of the data being rolled up. For example, you may wish to create hourly rollups of your document but to only run the indexer on a daily basis at midnight, as defined by the cron. The cron pattern is defined just like a Watcher cron schedule. */
  cron: string
  /** Defines the grouping fields and aggregations that are defined for this rollup job. These fields will then be available later for aggregating into buckets. These aggs and fields can be used in any combination. Think of the groups configuration as defining a set of tools that can later be used in aggregations to partition the data. Unlike raw data, we have to think ahead to which fields and aggregations might be used. Rollups provide enough flexibility that you simply need to determine which fields are needed, not in what order they are needed. */
  groups: RollupGroupings
  /** The index or index pattern to roll up. Supports wildcard-style patterns (`logstash-*`). The job attempts to rollup the entire index or index-pattern. */
  index_pattern: string
  /** Defines the metrics to collect for each grouping tuple. By default, only the doc_counts are collected for each group. To make rollup useful, you will often add metrics like averages, mins, maxes, etc. Metrics are defined on a per-field basis and for each field you configure which metric should be collected. */
  metrics?: RollupFieldMetric[]
  /** The number of bucket results that are processed on each iteration of the rollup indexer. A larger value tends to execute faster, but requires more memory during processing. This value has no effect on how the data is rolled up; it is merely used for tweaking the speed or memory cost of the indexer. */
  page_size: integer
  /** The index that contains the rollup results. The index can be shared with other rollup jobs. The data is stored so that it doesn’t interfere with unrelated jobs. */
  rollup_index: IndexName
  /** Time to wait for the request to complete. */
  timeout?: Duration
  headers?: HttpHeaders
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, cron?: never, groups?: never, index_pattern?: never, metrics?: never, page_size?: never, rollup_index?: never, timeout?: never, headers?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, cron?: never, groups?: never, index_pattern?: never, metrics?: never, page_size?: never, rollup_index?: never, timeout?: never, headers?: never }
}

export type RollupPutJobResponse = AcknowledgedResponseBase

export interface RollupRollupSearchRequest extends RequestBase {
/** A comma-separated list of data streams and indices used to limit the request. This parameter has the following rules: * At least one data stream, index, or wildcard expression must be specified. This target can include a rollup or non-rollup index. For data streams, the stream's backing indices can only serve as non-rollup indices. Omitting the parameter or using `_all` are not permitted. * Multiple non-rollup indices may be specified. * Only one rollup index may be specified. If more than one are supplied, an exception occurs. * Wildcard expressions (`*`) may be used. If they match more than one rollup index, an exception occurs. However, you can use an expression to match multiple non-rollup indices or data streams. */
  index: Indices
  /** Indicates whether hits.total should be rendered as an integer or an object in the rest search response */
  rest_total_hits_as_int?: boolean
  /** Specify whether aggregation and suggester names should be prefixed by their respective types in the response */
  typed_keys?: boolean
  /** Specifies aggregations. */
  aggregations?: Record<string, AggregationsAggregationContainer>
  /** @alias aggregations */
  /** Specifies aggregations. */
  aggs?: Record<string, AggregationsAggregationContainer>
  /** Specifies a DSL query that is subject to some limitations. */
  query?: QueryDslQueryContainer
  /** Must be zero if set, as rollups work on pre-aggregated data. */
  size?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, rest_total_hits_as_int?: never, typed_keys?: never, aggregations?: never, aggs?: never, query?: never, size?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, rest_total_hits_as_int?: never, typed_keys?: never, aggregations?: never, aggs?: never, query?: never, size?: never }
}

export interface RollupRollupSearchResponse<TDocument = unknown, TAggregations = Record<AggregateName, AggregationsAggregate>> {
  took: long
  timed_out: boolean
  terminated_early?: boolean
  _shards: ShardStatistics
  hits: SearchHitsMetadata<TDocument>
  aggregations?: TAggregations
}

export interface RollupStartJobRequest extends RequestBase {
/** Identifier for the rollup job. */
  id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export interface RollupStartJobResponse {
  started: boolean
}

export interface RollupStopJobRequest extends RequestBase {
/** Identifier for the rollup job. */
  id: Id
  /** If `wait_for_completion` is `true`, the API blocks for (at maximum) the specified duration while waiting for the job to stop. If more than `timeout` time has passed, the API throws a timeout exception. NOTE: Even if a timeout occurs, the stop request is still processing and eventually moves the job to STOPPED. The timeout simply means the API call itself timed out while waiting for the status change. */
  timeout?: Duration
  /** If set to `true`, causes the API to block until the indexer state completely stops. If set to `false`, the API returns immediately and the indexer is stopped asynchronously in the background. */
  wait_for_completion?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, timeout?: never, wait_for_completion?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, timeout?: never, wait_for_completion?: never }
}

export interface RollupStopJobResponse {
  stopped: boolean
}

export interface SearchApplicationAnalyticsCollection {
  event_data_stream: SearchApplicationEventDataStream
}

export interface SearchApplicationEventDataStream {
  name: IndexName
}

export type SearchApplicationEventType = 'page_view' | 'search' | 'search_click'

export interface SearchApplicationSearchApplication extends SearchApplicationSearchApplicationParameters {
  name: Name
  updated_at_millis: EpochTime<UnitMillis>
}

export interface SearchApplicationSearchApplicationParameters {
  indices: IndexName[]
  analytics_collection_name?: Name
  template?: SearchApplicationSearchApplicationTemplate
}

export interface SearchApplicationSearchApplicationTemplate {
  script: Script | string
}

export interface SearchApplicationDeleteRequest extends RequestBase {
/** The name of the search application to delete. */
  name: Name
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never }
}

export type SearchApplicationDeleteResponse = AcknowledgedResponseBase

export interface SearchApplicationDeleteBehavioralAnalyticsRequest extends RequestBase {
/** The name of the analytics collection to be deleted */
  name: Name
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never }
}

export type SearchApplicationDeleteBehavioralAnalyticsResponse = AcknowledgedResponseBase

export interface SearchApplicationGetRequest extends RequestBase {
/** The name of the search application */
  name: Name
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never }
}

export type SearchApplicationGetResponse = SearchApplicationSearchApplication

export interface SearchApplicationGetBehavioralAnalyticsRequest extends RequestBase {
/** A list of analytics collections to limit the returned information */
  name?: Name[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never }
}

export type SearchApplicationGetBehavioralAnalyticsResponse = Record<Name, SearchApplicationAnalyticsCollection>

export interface SearchApplicationListRequest extends RequestBase {
/** Query in the Lucene query string syntax. */
  q?: string
  /** Starting offset. */
  from?: integer
  /** Specifies a max number of results to get. */
  size?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { q?: never, from?: never, size?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { q?: never, from?: never, size?: never }
}

export interface SearchApplicationListResponse {
  count: long
  results: SearchApplicationSearchApplication[]
}

export interface SearchApplicationPostBehavioralAnalyticsEventRequest extends RequestBase {
/** The name of the behavioral analytics collection. */
  collection_name: Name
  /** The analytics event type. */
  event_type: SearchApplicationEventType
  /** Whether the response type has to include more details */
  debug?: boolean
  payload?: any
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { collection_name?: never, event_type?: never, debug?: never, payload?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { collection_name?: never, event_type?: never, debug?: never, payload?: never }
}

export interface SearchApplicationPostBehavioralAnalyticsEventResponse {
  accepted: boolean
  event?: any
}

export interface SearchApplicationPutRequest extends RequestBase {
/** The name of the search application to be created or updated. */
  name: Name
  /** If `true`, this request cannot replace or update existing Search Applications. */
  create?: boolean
  search_application?: SearchApplicationSearchApplicationParameters
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, create?: never, search_application?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, create?: never, search_application?: never }
}

export interface SearchApplicationPutResponse {
  result: Result
}

export interface SearchApplicationPutBehavioralAnalyticsAnalyticsAcknowledgeResponseBase extends AcknowledgedResponseBase {
  name: Name
}

export interface SearchApplicationPutBehavioralAnalyticsRequest extends RequestBase {
/** The name of the analytics collection to be created or updated. */
  name: Name
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never }
}

export type SearchApplicationPutBehavioralAnalyticsResponse = SearchApplicationPutBehavioralAnalyticsAnalyticsAcknowledgeResponseBase

export interface SearchApplicationRenderQueryRequest extends RequestBase {
/** The name of the search application to render teh query for. */
  name: Name
  params?: Record<string, any>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, params?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, params?: never }
}

export interface SearchApplicationRenderQueryResponse {
}

export interface SearchApplicationSearchRequest extends RequestBase {
/** The name of the search application to be searched. */
  name: Name
  /** Determines whether aggregation names are prefixed by their respective types in the response. */
  typed_keys?: boolean
  /** Query parameters specific to this request, which will override any defaults specified in the template. */
  params?: Record<string, any>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, typed_keys?: never, params?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, typed_keys?: never, params?: never }
}

export type SearchApplicationSearchResponse<TDocument = unknown, TAggregations = Record<AggregateName, AggregationsAggregate>> = SearchResponseBody<TDocument, TAggregations>

export type SearchableSnapshotsStatsLevel = 'cluster' | 'indices' | 'shards'

export interface SearchableSnapshotsCacheStatsNode {
  shared_cache: SearchableSnapshotsCacheStatsShared
}

export interface SearchableSnapshotsCacheStatsRequest extends RequestBase {
/** The names of the nodes in the cluster to target. */
  node_id?: NodeIds
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never, master_timeout?: never }
}

export interface SearchableSnapshotsCacheStatsResponse {
  nodes: Record<string, SearchableSnapshotsCacheStatsNode>
}

export interface SearchableSnapshotsCacheStatsShared {
  reads: long
  bytes_read_in_bytes: ByteSize
  writes: long
  bytes_written_in_bytes: ByteSize
  evictions: long
  num_regions: integer
  size_in_bytes: ByteSize
  region_size_in_bytes: ByteSize
}

export interface SearchableSnapshotsClearCacheRequest extends RequestBase {
/** A comma-separated list of data streams, indices, and aliases to clear from the cache. It supports wildcards (`*`). */
  index?: Indices
  /** Whether to expand wildcard expression to concrete indices that are open, closed or both. */
  expand_wildcards?: ExpandWildcards
  /** Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes `_all` string or when no indices have been specified) */
  allow_no_indices?: boolean
  /** Whether specified concrete indices should be ignored when unavailable (missing or closed) */
  ignore_unavailable?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, expand_wildcards?: never, allow_no_indices?: never, ignore_unavailable?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, expand_wildcards?: never, allow_no_indices?: never, ignore_unavailable?: never }
}

export type SearchableSnapshotsClearCacheResponse = any

export interface SearchableSnapshotsMountMountedSnapshot {
  snapshot: Name
  indices: Indices
  shards: ShardStatistics
}

export interface SearchableSnapshotsMountRequest extends RequestBase {
/** The name of the repository containing the snapshot of the index to mount. */
  repository: Name
  /** The name of the snapshot of the index to mount. */
  snapshot: Name
  /** The period to wait for the master node. If the master node is not available before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** If true, the request blocks until the operation is complete. */
  wait_for_completion?: boolean
  /** The mount option for the searchable snapshot index. */
  storage?: string
  /** The name of the index contained in the snapshot whose data is to be mounted. If no `renamed_index` is specified, this name will also be used to create the new index. */
  index: IndexName
  /** The name of the index that will be created. */
  renamed_index?: IndexName
  /** The settings that should be added to the index when it is mounted. */
  index_settings?: Record<string, any>
  /** The names of settings that should be removed from the index when it is mounted. */
  ignore_index_settings?: string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { repository?: never, snapshot?: never, master_timeout?: never, wait_for_completion?: never, storage?: never, index?: never, renamed_index?: never, index_settings?: never, ignore_index_settings?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { repository?: never, snapshot?: never, master_timeout?: never, wait_for_completion?: never, storage?: never, index?: never, renamed_index?: never, index_settings?: never, ignore_index_settings?: never }
}

export interface SearchableSnapshotsMountResponse {
  snapshot: SearchableSnapshotsMountMountedSnapshot
}

export interface SearchableSnapshotsStatsRequest extends RequestBase {
/** A comma-separated list of data streams and indices to retrieve statistics for. */
  index?: Indices
  /** Return stats aggregated at cluster, index or shard level */
  level?: SearchableSnapshotsStatsLevel
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, level?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, level?: never }
}

export interface SearchableSnapshotsStatsResponse {
  stats: any
  total: any
}

export interface SecurityAccess {
  replication?: SecurityReplicationAccess[]
  search?: SecuritySearchAccess[]
}

export interface SecurityApiKey {
  id: Id
  name: Name
  type: SecurityApiKeyType
  creation: EpochTime<UnitMillis>
  expiration?: EpochTime<UnitMillis>
  invalidated: boolean
  invalidation?: EpochTime<UnitMillis>
  username: Username
  realm: string
  realm_type?: string
  metadata: Metadata
  role_descriptors?: Record<string, SecurityRoleDescriptor>
  limited_by?: Record<string, SecurityRoleDescriptor>[]
  access?: SecurityAccess
  profile_uid?: string
  _sort?: SortResults
}

export type SecurityApiKeyType = 'rest' | 'cross_cluster'

export interface SecurityApplicationGlobalUserPrivileges {
  manage: SecurityManageUserPrivileges
}

export interface SecurityApplicationPrivileges {
  application: string
  privileges: string[]
  resources: string[]
}

export interface SecurityBulkError {
  count: integer
  details: Record<string, ErrorCause>
}

export interface SecurityClusterNode {
  name: Name
}

export type SecurityClusterPrivilege = 'all' | 'cancel_task' | 'create_snapshot' | 'cross_cluster_replication' | 'cross_cluster_search' | 'delegate_pki' | 'grant_api_key' | 'manage' | 'manage_api_key' | 'manage_autoscaling' | 'manage_behavioral_analytics' | 'manage_ccr' | 'manage_data_frame_transforms' | 'manage_data_stream_global_retention' | 'manage_enrich' | 'manage_ilm' | 'manage_index_templates' | 'manage_inference' | 'manage_ingest_pipelines' | 'manage_logstash_pipelines' | 'manage_ml' | 'manage_oidc' | 'manage_own_api_key' | 'manage_pipeline' | 'manage_rollup' | 'manage_saml' | 'manage_search_application' | 'manage_search_query_rules' | 'manage_search_synonyms' | 'manage_security' | 'manage_service_account' | 'manage_slm' | 'manage_token' | 'manage_transform' | 'manage_user_profile' | 'manage_watcher' | 'monitor' | 'monitor_data_frame_transforms' | 'monitor_data_stream_global_retention' | 'monitor_enrich' | 'monitor_inference' | 'monitor_ml' | 'monitor_rollup' | 'monitor_snapshot' | 'monitor_stats' | 'monitor_text_structure' | 'monitor_transform' | 'monitor_watcher' | 'none' | 'post_behavioral_analytics_event' | 'read_ccr' | 'read_fleet_secrets' | 'read_ilm' | 'read_pipeline' | 'read_security' | 'read_slm' | 'transport_client' | 'write_connector_secrets' | 'write_fleet_secrets' | string

export interface SecurityCreatedStatus {
  created: boolean
}

export interface SecurityFieldSecurity {
  except?: Fields
  grant?: Fields
}

export interface SecurityGlobalPrivilege {
  application: SecurityApplicationGlobalUserPrivileges
}

export type SecurityGrantType = 'password' | 'access_token'

export type SecurityIndexPrivilege = 'all' | 'auto_configure' | 'create' | 'create_doc' | 'create_index' | 'cross_cluster_replication' | 'cross_cluster_replication_internal' | 'delete' | 'delete_index' | 'index' | 'maintenance' | 'manage' | 'manage_data_stream_lifecycle' | 'manage_follow_index' | 'manage_ilm' | 'manage_leader_index' | 'monitor' | 'none' | 'read' | 'read_cross_cluster' | 'view_index_metadata' | 'write' | string

export interface SecurityIndicesPrivileges {
  field_security?: SecurityFieldSecurity
  names: IndexName | IndexName[]
  privileges: SecurityIndexPrivilege[]
  query?: SecurityIndicesPrivilegesQuery
  allow_restricted_indices?: boolean
}

export type SecurityIndicesPrivilegesQuery = string | QueryDslQueryContainer | SecurityRoleTemplateQuery

export interface SecurityManageUserPrivileges {
  applications: string[]
}

export interface SecurityRealmInfo {
  name: Name
  type: string
}

export type SecurityRemoteClusterPrivilege = 'monitor_enrich' | 'monitor_stats'

export interface SecurityRemoteClusterPrivileges {
  clusters: Names
  privileges: SecurityRemoteClusterPrivilege[]
}

export interface SecurityRemoteIndicesPrivileges {
  clusters: Names
  field_security?: SecurityFieldSecurity
  names: IndexName | IndexName[]
  privileges: SecurityIndexPrivilege[]
  query?: SecurityIndicesPrivilegesQuery
  allow_restricted_indices?: boolean
}

export interface SecurityRemoteUserIndicesPrivileges {
  field_security?: SecurityFieldSecurity[]
  names: IndexName | IndexName[]
  privileges: SecurityIndexPrivilege[]
  query?: SecurityIndicesPrivilegesQuery[]
  allow_restricted_indices: boolean
  clusters: string[]
}

export interface SecurityReplicationAccess {
  names: IndexName | IndexName[]
  allow_restricted_indices?: boolean
}

export interface SecurityRestriction {
  workflows: SecurityRestrictionWorkflow[]
}

export type SecurityRestrictionWorkflow = 'search_application_query' | string

export interface SecurityRoleDescriptor {
  cluster?: SecurityClusterPrivilege[]
  indices?: SecurityIndicesPrivileges[]
  index?: SecurityIndicesPrivileges[]
  remote_indices?: SecurityRemoteIndicesPrivileges[]
  remote_cluster?: SecurityRemoteClusterPrivileges[]
  global?: SecurityGlobalPrivilege[] | SecurityGlobalPrivilege
  applications?: SecurityApplicationPrivileges[]
  metadata?: Metadata
  run_as?: string[]
  description?: string
  restriction?: SecurityRestriction
  transient_metadata?: Record<string, any>
}

export interface SecurityRoleDescriptorRead {
  cluster: SecurityClusterPrivilege[]
  indices: SecurityIndicesPrivileges[]
  index: SecurityIndicesPrivileges[]
  remote_indices?: SecurityRemoteIndicesPrivileges[]
  remote_cluster?: SecurityRemoteClusterPrivileges[]
  global?: SecurityGlobalPrivilege[] | SecurityGlobalPrivilege
  applications?: SecurityApplicationPrivileges[]
  metadata?: Metadata
  run_as?: string[]
  description?: string
  restriction?: SecurityRestriction
  transient_metadata?: Record<string, any>
}

export interface SecurityRoleMapping {
  enabled: boolean
  metadata: Metadata
  roles?: string[]
  role_templates?: SecurityRoleTemplate[]
  rules: SecurityRoleMappingRule
}

export interface SecurityRoleMappingRule {
  any?: SecurityRoleMappingRule[]
  all?: SecurityRoleMappingRule[]
  field?: Partial<Record<Field, FieldValue | FieldValue[]>>
  except?: SecurityRoleMappingRule
}

export interface SecurityRoleTemplate {
  format?: SecurityTemplateFormat
  template: Script | string
}

export type SecurityRoleTemplateInlineQuery = string | QueryDslQueryContainer

export interface SecurityRoleTemplateQuery {
  template?: SecurityRoleTemplateScript | SecurityRoleTemplateInlineQuery
}

export interface SecurityRoleTemplateScript {
  source?: SecurityRoleTemplateInlineQuery
  id?: Id
  params?: Record<string, any>
  lang?: ScriptLanguage
  options?: Record<string, string>
}

export interface SecuritySearchAccess {
  field_security?: SecurityFieldSecurity
  names: IndexName | IndexName[]
  query?: SecurityIndicesPrivilegesQuery
  allow_restricted_indices?: boolean
}

export interface SecuritySecuritySettings {
  index?: IndicesIndexSettings
}

export type SecurityTemplateFormat = 'string' | 'json'

export interface SecurityUser {
  email?: string | null
  full_name?: Name | null
  metadata: Metadata
  roles: string[]
  username: Username
  enabled: boolean
  profile_uid?: SecurityUserProfileId
}

export interface SecurityUserIndicesPrivileges {
  field_security?: SecurityFieldSecurity[]
  names: IndexName | IndexName[]
  privileges: SecurityIndexPrivilege[]
  query?: SecurityIndicesPrivilegesQuery[]
  allow_restricted_indices: boolean
}

export interface SecurityUserProfile {
  uid: SecurityUserProfileId
  user: SecurityUserProfileUser
  data: Record<string, any>
  labels: Record<string, any>
  enabled?: boolean
}

export interface SecurityUserProfileHitMetadata {
  _primary_term: long
  _seq_no: SequenceNumber
}

export type SecurityUserProfileId = string

export interface SecurityUserProfileUser {
  email?: string | null
  full_name?: Name | null
  realm_name: Name
  realm_domain?: Name
  roles: string[]
  username: Username
}

export interface SecurityUserProfileWithMetadata extends SecurityUserProfile {
  last_synchronized: long
  _doc: SecurityUserProfileHitMetadata
}

export interface SecurityActivateUserProfileRequest extends RequestBase {
/** The user's Elasticsearch access token or JWT. Both `access` and `id` JWT token types are supported and they depend on the underlying JWT realm configuration. If you specify the `access_token` grant type, this parameter is required. It is not valid with other grant types. */
  access_token?: string
  /** The type of grant. */
  grant_type: SecurityGrantType
  /** The user's password. If you specify the `password` grant type, this parameter is required. It is not valid with other grant types. */
  password?: string
  /** The username that identifies the user. If you specify the `password` grant type, this parameter is required. It is not valid with other grant types. */
  username?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { access_token?: never, grant_type?: never, password?: never, username?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { access_token?: never, grant_type?: never, password?: never, username?: never }
}

export type SecurityActivateUserProfileResponse = SecurityUserProfileWithMetadata

export interface SecurityAuthenticateAuthenticateApiKey {
  id: Id
  name?: Name
}

export interface SecurityAuthenticateRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface SecurityAuthenticateResponse {
  api_key?: SecurityAuthenticateAuthenticateApiKey
  authentication_realm: SecurityRealmInfo
  email?: string | null
  full_name?: Name | null
  lookup_realm: SecurityRealmInfo
  metadata: Metadata
  roles: string[]
  username: Username
  enabled: boolean
  authentication_type: string
  token?: SecurityAuthenticateToken
}

export interface SecurityAuthenticateToken {
  name: Name
  type?: string
}

export interface SecurityBulkDeleteRoleRequest extends RequestBase {
/** If `true` (the default) then refresh the affected shards to make this operation visible to search, if `wait_for` then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** An array of role names to delete */
  names: string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { refresh?: never, names?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { refresh?: never, names?: never }
}

export interface SecurityBulkDeleteRoleResponse {
  deleted?: string[]
  not_found?: string[]
  errors?: SecurityBulkError
}

export interface SecurityBulkPutRoleRequest extends RequestBase {
/** If `true` (the default) then refresh the affected shards to make this operation visible to search, if `wait_for` then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** A dictionary of role name to RoleDescriptor objects to add or update */
  roles: Record<string, SecurityRoleDescriptor>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { refresh?: never, roles?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { refresh?: never, roles?: never }
}

export interface SecurityBulkPutRoleResponse {
  created?: string[]
  updated?: string[]
  noop?: string[]
  errors?: SecurityBulkError
}

export interface SecurityBulkUpdateApiKeysRequest extends RequestBase {
/** Expiration time for the API keys. By default, API keys never expire. This property can be omitted to leave the value unchanged. */
  expiration?: Duration
  /** The API key identifiers. */
  ids: string | string[]
  /** Arbitrary nested metadata to associate with the API keys. Within the `metadata` object, top-level keys beginning with an underscore (`_`) are reserved for system usage. Any information specified with this parameter fully replaces metadata previously associated with the API key. */
  metadata?: Metadata
  /** The role descriptors to assign to the API keys. An API key's effective permissions are an intersection of its assigned privileges and the point-in-time snapshot of permissions of the owner user. You can assign new privileges by specifying them in this parameter. To remove assigned privileges, supply the `role_descriptors` parameter as an empty object `{}`. If an API key has no assigned privileges, it inherits the owner user's full permissions. The snapshot of the owner's permissions is always updated, whether you supply the `role_descriptors` parameter. The structure of a role descriptor is the same as the request for the create API keys API. */
  role_descriptors?: Record<string, SecurityRoleDescriptor>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { expiration?: never, ids?: never, metadata?: never, role_descriptors?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { expiration?: never, ids?: never, metadata?: never, role_descriptors?: never }
}

export interface SecurityBulkUpdateApiKeysResponse {
  errors?: SecurityBulkError
  noops: string[]
  updated: string[]
}

export interface SecurityChangePasswordRequest extends RequestBase {
/** The user whose password you want to change. If you do not specify this parameter, the password is changed for the current user. */
  username?: Username
  /** If `true` (the default) then refresh the affected shards to make this operation visible to search, if `wait_for` then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** The new password value. Passwords must be at least 6 characters long. */
  password?: Password
  /** A hash of the new password value. This must be produced using the same hashing algorithm as has been configured for password storage. For more details, see the explanation of the `xpack.security.authc.password_hashing.algorithm` setting. */
  password_hash?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { username?: never, refresh?: never, password?: never, password_hash?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { username?: never, refresh?: never, password?: never, password_hash?: never }
}

export interface SecurityChangePasswordResponse {
}

export interface SecurityClearApiKeyCacheRequest extends RequestBase {
/** Comma-separated list of API key IDs to evict from the API key cache. To evict all API keys, use `*`. Does not support other wildcard patterns. */
  ids: Ids
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { ids?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { ids?: never }
}

export interface SecurityClearApiKeyCacheResponse {
  _nodes: NodeStatistics
  cluster_name: Name
  nodes: Record<string, SecurityClusterNode>
}

export interface SecurityClearCachedPrivilegesRequest extends RequestBase {
/** A comma-separated list of applications. To clear all applications, use an asterism (`*`). It does not support other wildcard patterns. */
  application: Name
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { application?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { application?: never }
}

export interface SecurityClearCachedPrivilegesResponse {
  _nodes: NodeStatistics
  cluster_name: Name
  nodes: Record<string, SecurityClusterNode>
}

export interface SecurityClearCachedRealmsRequest extends RequestBase {
/** A comma-separated list of realms. To clear all realms, use an asterisk (`*`). It does not support other wildcard patterns. */
  realms: Names
  /** A comma-separated list of the users to clear from the cache. If you do not specify this parameter, the API evicts all users from the user cache. */
  usernames?: string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { realms?: never, usernames?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { realms?: never, usernames?: never }
}

export interface SecurityClearCachedRealmsResponse {
  _nodes: NodeStatistics
  cluster_name: Name
  nodes: Record<string, SecurityClusterNode>
}

export interface SecurityClearCachedRolesRequest extends RequestBase {
/** A comma-separated list of roles to evict from the role cache. To evict all roles, use an asterisk (`*`). It does not support other wildcard patterns. */
  name: Names
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never }
}

export interface SecurityClearCachedRolesResponse {
  _nodes: NodeStatistics
  cluster_name: Name
  nodes: Record<string, SecurityClusterNode>
}

export interface SecurityClearCachedServiceTokensRequest extends RequestBase {
/** The namespace, which is a top-level grouping of service accounts. */
  namespace: Namespace
  /** The name of the service, which must be unique within its namespace. */
  service: Service
  /** A comma-separated list of token names to evict from the service account token caches. Use a wildcard (`*`) to evict all tokens that belong to a service account. It does not support other wildcard patterns. */
  name: Names
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { namespace?: never, service?: never, name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { namespace?: never, service?: never, name?: never }
}

export interface SecurityClearCachedServiceTokensResponse {
  _nodes: NodeStatistics
  cluster_name: Name
  nodes: Record<string, SecurityClusterNode>
}

export interface SecurityCreateApiKeyRequest extends RequestBase {
/** If `true` (the default) then refresh the affected shards to make this operation visible to search, if `wait_for` then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** The expiration time for the API key. By default, API keys never expire. */
  expiration?: Duration
  /** A name for the API key. */
  name?: Name
  /** An array of role descriptors for this API key. When it is not specified or it is an empty array, the API key will have a point in time snapshot of permissions of the authenticated user. If you supply role descriptors, the resultant permissions are an intersection of API keys permissions and the authenticated user's permissions thereby limiting the access scope for API keys. The structure of role descriptor is the same as the request for the create role API. For more details, refer to the create or update roles API. NOTE: Due to the way in which this permission intersection is calculated, it is not possible to create an API key that is a child of another API key, unless the derived key is created without any privileges. In this case, you must explicitly specify a role descriptor with no privileges. The derived API key can be used for authentication; it will not have authority to call Elasticsearch APIs. */
  role_descriptors?: Record<string, SecurityRoleDescriptor>
  /** Arbitrary metadata that you want to associate with the API key. It supports nested data structure. Within the metadata object, keys beginning with `_` are reserved for system usage. */
  metadata?: Metadata
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { refresh?: never, expiration?: never, name?: never, role_descriptors?: never, metadata?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { refresh?: never, expiration?: never, name?: never, role_descriptors?: never, metadata?: never }
}

export interface SecurityCreateApiKeyResponse {
  api_key: string
  expiration?: long
  id: Id
  name: Name
  encoded: string
}

export interface SecurityCreateCrossClusterApiKeyRequest extends RequestBase {
/** The access to be granted to this API key. The access is composed of permissions for cross-cluster search and cross-cluster replication. At least one of them must be specified. NOTE: No explicit privileges should be specified for either search or replication access. The creation process automatically converts the access specification to a role descriptor which has relevant privileges assigned accordingly. */
  access: SecurityAccess
  /** Expiration time for the API key. By default, API keys never expire. */
  expiration?: Duration
  /** Arbitrary metadata that you want to associate with the API key. It supports nested data structure. Within the metadata object, keys beginning with `_` are reserved for system usage. */
  metadata?: Metadata
  /** Specifies the name for this API key. */
  name: Name
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { access?: never, expiration?: never, metadata?: never, name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { access?: never, expiration?: never, metadata?: never, name?: never }
}

export interface SecurityCreateCrossClusterApiKeyResponse {
  api_key: string
  expiration?: DurationValue<UnitMillis>
  id: Id
  name: Name
  encoded: string
}

export interface SecurityCreateServiceTokenRequest extends RequestBase {
/** The name of the namespace, which is a top-level grouping of service accounts. */
  namespace: Namespace
  /** The name of the service. */
  service: Service
  /** The name for the service account token. If omitted, a random name will be generated. Token names must be at least one and no more than 256 characters. They can contain alphanumeric characters (a-z, A-Z, 0-9), dashes (`-`), and underscores (`_`), but cannot begin with an underscore. NOTE: Token names must be unique in the context of the associated service account. They must also be globally unique with their fully qualified names, which are comprised of the service account principal and token name, such as `<namespace>/<service>/<token-name>`. */
  name?: Name
  /** If `true` then refresh the affected shards to make this operation visible to search, if `wait_for` (the default) then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { namespace?: never, service?: never, name?: never, refresh?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { namespace?: never, service?: never, name?: never, refresh?: never }
}

export interface SecurityCreateServiceTokenResponse {
  created: boolean
  token: SecurityCreateServiceTokenToken
}

export interface SecurityCreateServiceTokenToken {
  name: Name
  value: string
}

export interface SecurityDelegatePkiAuthentication {
  username: string
  roles: string[]
  full_name: string | null
  email: string | null
  token?: Record<string, string>
  metadata: Metadata
  enabled: boolean
  authentication_realm: SecurityDelegatePkiAuthenticationRealm
  lookup_realm: SecurityDelegatePkiAuthenticationRealm
  authentication_type: string
  api_key?: Record<string, string>
}

export interface SecurityDelegatePkiAuthenticationRealm {
  name: string
  type: string
  domain?: string
}

export interface SecurityDelegatePkiRequest extends RequestBase {
/** The X509Certificate chain, which is represented as an ordered string array. Each string in the array is a base64-encoded (Section 4 of RFC4648 - not base64url-encoded) of the certificate's DER encoding. The first element is the target certificate that contains the subject distinguished name that is requesting access. This may be followed by additional certificates; each subsequent certificate is used to certify the previous one. */
  x509_certificate_chain: string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { x509_certificate_chain?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { x509_certificate_chain?: never }
}

export interface SecurityDelegatePkiResponse {
  access_token: string
  expires_in: long
  type: string
  authentication?: SecurityDelegatePkiAuthentication
}

export interface SecurityDeletePrivilegesFoundStatus {
  found: boolean
}

export interface SecurityDeletePrivilegesRequest extends RequestBase {
/** The name of the application. Application privileges are always associated with exactly one application. */
  application: Name
  /** The name of the privilege. */
  name: Names
  /** If `true` (the default) then refresh the affected shards to make this operation visible to search, if `wait_for` then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { application?: never, name?: never, refresh?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { application?: never, name?: never, refresh?: never }
}

export type SecurityDeletePrivilegesResponse = Record<string, Record<string, SecurityDeletePrivilegesFoundStatus>>

export interface SecurityDeleteRoleRequest extends RequestBase {
/** The name of the role. */
  name: Name
  /** If `true` (the default) then refresh the affected shards to make this operation visible to search, if `wait_for` then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, refresh?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, refresh?: never }
}

export interface SecurityDeleteRoleResponse {
  found: boolean
}

export interface SecurityDeleteRoleMappingRequest extends RequestBase {
/** The distinct name that identifies the role mapping. The name is used solely as an identifier to facilitate interaction via the API; it does not affect the behavior of the mapping in any way. */
  name: Name
  /** If `true` (the default) then refresh the affected shards to make this operation visible to search, if `wait_for` then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, refresh?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, refresh?: never }
}

export interface SecurityDeleteRoleMappingResponse {
  found: boolean
}

export interface SecurityDeleteServiceTokenRequest extends RequestBase {
/** The namespace, which is a top-level grouping of service accounts. */
  namespace: Namespace
  /** The service name. */
  service: Service
  /** The name of the service account token. */
  name: Name
  /** If `true` then refresh the affected shards to make this operation visible to search, if `wait_for` (the default) then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { namespace?: never, service?: never, name?: never, refresh?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { namespace?: never, service?: never, name?: never, refresh?: never }
}

export interface SecurityDeleteServiceTokenResponse {
  found: boolean
}

export interface SecurityDeleteUserRequest extends RequestBase {
/** An identifier for the user. */
  username: Username
  /** If `true` (the default) then refresh the affected shards to make this operation visible to search, if `wait_for` then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { username?: never, refresh?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { username?: never, refresh?: never }
}

export interface SecurityDeleteUserResponse {
  found: boolean
}

export interface SecurityDisableUserRequest extends RequestBase {
/** An identifier for the user. */
  username: Username
  /** If `true` (the default) then refresh the affected shards to make this operation visible to search, if `wait_for` then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { username?: never, refresh?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { username?: never, refresh?: never }
}

export interface SecurityDisableUserResponse {
}

export interface SecurityDisableUserProfileRequest extends RequestBase {
/** Unique identifier for the user profile. */
  uid: SecurityUserProfileId
  /** If 'true', Elasticsearch refreshes the affected shards to make this operation visible to search. If 'wait_for', it waits for a refresh to make this operation visible to search. If 'false', it does nothing with refreshes. */
  refresh?: Refresh
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { uid?: never, refresh?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { uid?: never, refresh?: never }
}

export type SecurityDisableUserProfileResponse = AcknowledgedResponseBase

export interface SecurityEnableUserRequest extends RequestBase {
/** An identifier for the user. */
  username: Username
  /** If `true` (the default) then refresh the affected shards to make this operation visible to search, if `wait_for` then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { username?: never, refresh?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { username?: never, refresh?: never }
}

export interface SecurityEnableUserResponse {
}

export interface SecurityEnableUserProfileRequest extends RequestBase {
/** A unique identifier for the user profile. */
  uid: SecurityUserProfileId
  /** If 'true', Elasticsearch refreshes the affected shards to make this operation visible to search. If 'wait_for', it waits for a refresh to make this operation visible to search. If 'false', nothing is done with refreshes. */
  refresh?: Refresh
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { uid?: never, refresh?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { uid?: never, refresh?: never }
}

export type SecurityEnableUserProfileResponse = AcknowledgedResponseBase

export interface SecurityEnrollKibanaRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface SecurityEnrollKibanaResponse {
  token: SecurityEnrollKibanaToken
  http_ca: string
}

export interface SecurityEnrollKibanaToken {
  name: string
  value: string
}

export interface SecurityEnrollNodeRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface SecurityEnrollNodeResponse {
  http_ca_key: string
  http_ca_cert: string
  transport_ca_cert: string
  transport_key: string
  transport_cert: string
  nodes_addresses: string[]
}

export interface SecurityGetApiKeyRequest extends RequestBase {
/** An API key id. This parameter cannot be used with any of `name`, `realm_name` or `username`. */
  id?: Id
  /** An API key name. This parameter cannot be used with any of `id`, `realm_name` or `username`. It supports prefix search with wildcard. */
  name?: Name
  /** A boolean flag that can be used to query API keys owned by the currently authenticated user. The `realm_name` or `username` parameters cannot be specified when this parameter is set to `true` as they are assumed to be the currently authenticated ones. */
  owner?: boolean
  /** The name of an authentication realm. This parameter cannot be used with either `id` or `name` or when `owner` flag is set to `true`. */
  realm_name?: Name
  /** The username of a user. This parameter cannot be used with either `id` or `name` or when `owner` flag is set to `true`. */
  username?: Username
  /** Return the snapshot of the owner user's role descriptors associated with the API key. An API key's actual permission is the intersection of its assigned role descriptors and the owner user's role descriptors. */
  with_limited_by?: boolean
  /** A boolean flag that can be used to query API keys that are currently active. An API key is considered active if it is neither invalidated, nor expired at query time. You can specify this together with other parameters such as `owner` or `name`. If `active_only` is false, the response will include both active and inactive (expired or invalidated) keys. */
  active_only?: boolean
  /** Determines whether to also retrieve the profile uid, for the API key owner principal, if it exists. */
  with_profile_uid?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, name?: never, owner?: never, realm_name?: never, username?: never, with_limited_by?: never, active_only?: never, with_profile_uid?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, name?: never, owner?: never, realm_name?: never, username?: never, with_limited_by?: never, active_only?: never, with_profile_uid?: never }
}

export interface SecurityGetApiKeyResponse {
  api_keys: SecurityApiKey[]
}

export interface SecurityGetBuiltinPrivilegesRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export interface SecurityGetBuiltinPrivilegesResponse {
  cluster: SecurityClusterPrivilege[]
  index: IndexName[]
  remote_cluster: SecurityRemoteClusterPrivilege[]
}

export interface SecurityGetPrivilegesRequest extends RequestBase {
/** The name of the application. Application privileges are always associated with exactly one application. If you do not specify this parameter, the API returns information about all privileges for all applications. */
  application?: Name
  /** The name of the privilege. If you do not specify this parameter, the API returns information about all privileges for the requested application. */
  name?: Names
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { application?: never, name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { application?: never, name?: never }
}

export type SecurityGetPrivilegesResponse = Record<string, Record<string, SecurityPutPrivilegesActions>>

export interface SecurityGetRoleRequest extends RequestBase {
/** The name of the role. You can specify multiple roles as a comma-separated list. If you do not specify this parameter, the API returns information about all roles. */
  name?: Names
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never }
}

export type SecurityGetRoleResponse = Record<string, SecurityGetRoleRole>

export interface SecurityGetRoleRole {
  cluster: SecurityClusterPrivilege[]
  indices: SecurityIndicesPrivileges[]
  remote_indices?: SecurityRemoteIndicesPrivileges[]
  remote_cluster?: SecurityRemoteClusterPrivileges[]
  metadata: Metadata
  description?: string
  run_as?: string[]
  transient_metadata?: Record<string, any>
  applications: SecurityApplicationPrivileges[]
  role_templates?: SecurityRoleTemplate[]
  global?: Record<string, Record<string, Record<string, string[]>>>
}

export interface SecurityGetRoleMappingRequest extends RequestBase {
/** The distinct name that identifies the role mapping. The name is used solely as an identifier to facilitate interaction via the API; it does not affect the behavior of the mapping in any way. You can specify multiple mapping names as a comma-separated list. If you do not specify this parameter, the API returns information about all role mappings. */
  name?: Names
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never }
}

export type SecurityGetRoleMappingResponse = Record<string, SecurityRoleMapping>

export interface SecurityGetServiceAccountsRequest extends RequestBase {
/** The name of the namespace. Omit this parameter to retrieve information about all service accounts. If you omit this parameter, you must also omit the `service` parameter. */
  namespace?: Namespace
  /** The service name. Omit this parameter to retrieve information about all service accounts that belong to the specified `namespace`. */
  service?: Service
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { namespace?: never, service?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { namespace?: never, service?: never }
}

export type SecurityGetServiceAccountsResponse = Record<string, SecurityGetServiceAccountsRoleDescriptorWrapper>

export interface SecurityGetServiceAccountsRoleDescriptorWrapper {
  role_descriptor: SecurityRoleDescriptorRead
}

export interface SecurityGetServiceCredentialsNodesCredentials {
  _nodes: NodeStatistics
  file_tokens: Record<string, SecurityGetServiceCredentialsNodesCredentialsFileToken>
}

export interface SecurityGetServiceCredentialsNodesCredentialsFileToken {
  nodes: string[]
}

export interface SecurityGetServiceCredentialsRequest extends RequestBase {
/** The name of the namespace. */
  namespace: Namespace
  /** The service name. */
  service: Name
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { namespace?: never, service?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { namespace?: never, service?: never }
}

export interface SecurityGetServiceCredentialsResponse {
  service_account: string
  count: integer
  tokens: Record<string, Metadata>
  nodes_credentials: SecurityGetServiceCredentialsNodesCredentials
}

export interface SecurityGetSettingsRequest extends RequestBase {
/** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never }
}

export interface SecurityGetSettingsResponse {
  security: SecuritySecuritySettings
  'security-profile': SecuritySecuritySettings
  'security-tokens': SecuritySecuritySettings
}

export type SecurityGetTokenAccessTokenGrantType = 'password' | 'client_credentials' | '_kerberos' | 'refresh_token'

export interface SecurityGetTokenAuthenticatedUser extends SecurityUser {
  authentication_realm: SecurityGetTokenUserRealm
  lookup_realm: SecurityGetTokenUserRealm
  authentication_provider?: SecurityGetTokenAuthenticationProvider
  authentication_type: string
}

export interface SecurityGetTokenAuthenticationProvider {
  type: string
  name: Name
}

export interface SecurityGetTokenRequest extends RequestBase {
/** The type of grant. Supported grant types are: `password`, `_kerberos`, `client_credentials`, and `refresh_token`. */
  grant_type?: SecurityGetTokenAccessTokenGrantType
  /** The scope of the token. Currently tokens are only issued for a scope of FULL regardless of the value sent with the request. */
  scope?: string
  /** The user's password. If you specify the `password` grant type, this parameter is required. This parameter is not valid with any other supported grant type. */
  password?: Password
  /** The base64 encoded kerberos ticket. If you specify the `_kerberos` grant type, this parameter is required. This parameter is not valid with any other supported grant type. */
  kerberos_ticket?: string
  /** The string that was returned when you created the token, which enables you to extend its life. If you specify the `refresh_token` grant type, this parameter is required. This parameter is not valid with any other supported grant type. */
  refresh_token?: string
  /** The username that identifies the user. If you specify the `password` grant type, this parameter is required. This parameter is not valid with any other supported grant type. */
  username?: Username
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { grant_type?: never, scope?: never, password?: never, kerberos_ticket?: never, refresh_token?: never, username?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { grant_type?: never, scope?: never, password?: never, kerberos_ticket?: never, refresh_token?: never, username?: never }
}

export interface SecurityGetTokenResponse {
  access_token: string
  expires_in: long
  scope?: string
  type: string
  refresh_token?: string
  kerberos_authentication_response_token?: string
  authentication: SecurityGetTokenAuthenticatedUser
}

export interface SecurityGetTokenUserRealm {
  name: Name
  type: string
}

export interface SecurityGetUserRequest extends RequestBase {
/** An identifier for the user. You can specify multiple usernames as a comma-separated list. If you omit this parameter, the API retrieves information about all users. */
  username?: Username | Username[]
  /** Determines whether to retrieve the user profile UID, if it exists, for the users. */
  with_profile_uid?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { username?: never, with_profile_uid?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { username?: never, with_profile_uid?: never }
}

export type SecurityGetUserResponse = Record<string, SecurityUser>

export interface SecurityGetUserPrivilegesRequest extends RequestBase {
/** The name of the application. Application privileges are always associated with exactly one application. If you do not specify this parameter, the API returns information about all privileges for all applications. */
  application?: Name
  /** The name of the privilege. If you do not specify this parameter, the API returns information about all privileges for the requested application. */
  priviledge?: Name
  username?: Name | null
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { application?: never, priviledge?: never, username?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { application?: never, priviledge?: never, username?: never }
}

export interface SecurityGetUserPrivilegesResponse {
  applications: SecurityApplicationPrivileges[]
  cluster: string[]
  remote_cluster?: SecurityRemoteClusterPrivileges[]
  global: SecurityGlobalPrivilege[]
  indices: SecurityUserIndicesPrivileges[]
  remote_indices?: SecurityRemoteUserIndicesPrivileges[]
  run_as: string[]
}

export interface SecurityGetUserProfileGetUserProfileErrors {
  count: long
  details: Record<SecurityUserProfileId, ErrorCause>
}

export interface SecurityGetUserProfileRequest extends RequestBase {
/** A unique identifier for the user profile. */
  uid: SecurityUserProfileId | SecurityUserProfileId[]
  /** A comma-separated list of filters for the `data` field of the profile document. To return all content use `data=*`. To return a subset of content use `data=<key>` to retrieve content nested under the specified `<key>`. By default returns no `data` content. */
  data?: string | string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { uid?: never, data?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { uid?: never, data?: never }
}

export interface SecurityGetUserProfileResponse {
  profiles: SecurityUserProfileWithMetadata[]
  errors?: SecurityGetUserProfileGetUserProfileErrors
}

export type SecurityGrantApiKeyApiKeyGrantType = 'access_token' | 'password'

export interface SecurityGrantApiKeyGrantApiKey {
  name: Name
  expiration?: DurationLarge
  role_descriptors?: Record<string, SecurityRoleDescriptor> | Record<string, SecurityRoleDescriptor>[]
  metadata?: Metadata
}

export interface SecurityGrantApiKeyRequest extends RequestBase {
/** The API key. */
  api_key: SecurityGrantApiKeyGrantApiKey
  /** The type of grant. Supported grant types are: `access_token`, `password`. */
  grant_type: SecurityGrantApiKeyApiKeyGrantType
  /** The user's access token. If you specify the `access_token` grant type, this parameter is required. It is not valid with other grant types. */
  access_token?: string
  /** The user name that identifies the user. If you specify the `password` grant type, this parameter is required. It is not valid with other grant types. */
  username?: Username
  /** The user's password. If you specify the `password` grant type, this parameter is required. It is not valid with other grant types. */
  password?: Password
  /** The name of the user to be impersonated. */
  run_as?: Username
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { api_key?: never, grant_type?: never, access_token?: never, username?: never, password?: never, run_as?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { api_key?: never, grant_type?: never, access_token?: never, username?: never, password?: never, run_as?: never }
}

export interface SecurityGrantApiKeyResponse {
  api_key: string
  id: Id
  name: Name
  expiration?: EpochTime<UnitMillis>
  encoded: string
}

export interface SecurityHasPrivilegesApplicationPrivilegesCheck {
  application: string
  privileges: string[]
  resources: string[]
}

export type SecurityHasPrivilegesApplicationsPrivileges = Record<Name, SecurityHasPrivilegesResourcePrivileges>

export interface SecurityHasPrivilegesIndexPrivilegesCheck {
  names: Indices
  privileges: SecurityIndexPrivilege[]
  allow_restricted_indices?: boolean
}

export type SecurityHasPrivilegesPrivileges = Record<string, boolean>

export interface SecurityHasPrivilegesRequest extends RequestBase {
/** Username */
  user?: Name
  application?: SecurityHasPrivilegesApplicationPrivilegesCheck[]
  /** A list of the cluster privileges that you want to check. */
  cluster?: SecurityClusterPrivilege[]
  index?: SecurityHasPrivilegesIndexPrivilegesCheck[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { user?: never, application?: never, cluster?: never, index?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { user?: never, application?: never, cluster?: never, index?: never }
}

export type SecurityHasPrivilegesResourcePrivileges = Record<Name, SecurityHasPrivilegesPrivileges>

export interface SecurityHasPrivilegesResponse {
  application: SecurityHasPrivilegesApplicationsPrivileges
  cluster: Record<string, boolean>
  has_all_requested: boolean
  index: Record<IndexName, SecurityHasPrivilegesPrivileges>
  username: Username
}

export interface SecurityHasPrivilegesUserProfileHasPrivilegesUserProfileErrors {
  count: long
  details: Record<SecurityUserProfileId, ErrorCause>
}

export interface SecurityHasPrivilegesUserProfilePrivilegesCheck {
  application?: SecurityHasPrivilegesApplicationPrivilegesCheck[]
  cluster?: SecurityClusterPrivilege[]
  index?: SecurityHasPrivilegesIndexPrivilegesCheck[]
}

export interface SecurityHasPrivilegesUserProfileRequest extends RequestBase {
/** A list of profile IDs. The privileges are checked for associated users of the profiles. */
  uids: SecurityUserProfileId[]
  /** An object containing all the privileges to be checked. */
  privileges: SecurityHasPrivilegesUserProfilePrivilegesCheck
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { uids?: never, privileges?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { uids?: never, privileges?: never }
}

export interface SecurityHasPrivilegesUserProfileResponse {
  has_privilege_uids: SecurityUserProfileId[]
  errors?: SecurityHasPrivilegesUserProfileHasPrivilegesUserProfileErrors
}

export interface SecurityInvalidateApiKeyRequest extends RequestBase {
  id?: Id
  /** A list of API key ids. This parameter cannot be used with any of `name`, `realm_name`, or `username`. */
  ids?: Id[]
  /** An API key name. This parameter cannot be used with any of `ids`, `realm_name` or `username`. */
  name?: Name
  /** Query API keys owned by the currently authenticated user. The `realm_name` or `username` parameters cannot be specified when this parameter is set to `true` as they are assumed to be the currently authenticated ones. NOTE: At least one of `ids`, `name`, `username`, and `realm_name` must be specified if `owner` is `false`. */
  owner?: boolean
  /** The name of an authentication realm. This parameter cannot be used with either `ids` or `name`, or when `owner` flag is set to `true`. */
  realm_name?: string
  /** The username of a user. This parameter cannot be used with either `ids` or `name` or when `owner` flag is set to `true`. */
  username?: Username
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, ids?: never, name?: never, owner?: never, realm_name?: never, username?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, ids?: never, name?: never, owner?: never, realm_name?: never, username?: never }
}

export interface SecurityInvalidateApiKeyResponse {
  error_count: integer
  error_details?: ErrorCause[]
  invalidated_api_keys: string[]
  previously_invalidated_api_keys: string[]
}

export interface SecurityInvalidateTokenRequest extends RequestBase {
/** An access token. This parameter cannot be used if any of `refresh_token`, `realm_name`, or `username` are used. */
  token?: string
  /** A refresh token. This parameter cannot be used if any of `refresh_token`, `realm_name`, or `username` are used. */
  refresh_token?: string
  /** The name of an authentication realm. This parameter cannot be used with either `refresh_token` or `token`. */
  realm_name?: Name
  /** The username of a user. This parameter cannot be used with either `refresh_token` or `token`. */
  username?: Username
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { token?: never, refresh_token?: never, realm_name?: never, username?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { token?: never, refresh_token?: never, realm_name?: never, username?: never }
}

export interface SecurityInvalidateTokenResponse {
  error_count: long
  error_details?: ErrorCause[]
  invalidated_tokens: long
  previously_invalidated_tokens: long
}

export interface SecurityOidcAuthenticateRequest extends RequestBase {
/** Associate a client session with an ID token and mitigate replay attacks. This value needs to be the same as the one that was provided to the `/_security/oidc/prepare` API or the one that was generated by Elasticsearch and included in the response to that call. */
  nonce: string
  /** The name of the OpenID Connect realm. This property is useful in cases where multiple realms are defined. */
  realm?: string
  /** The URL to which the OpenID Connect Provider redirected the User Agent in response to an authentication request after a successful authentication. This URL must be provided as-is (URL encoded), taken from the body of the response or as the value of a location header in the response from the OpenID Connect Provider. */
  redirect_uri: string
  /** Maintain state between the authentication request and the response. This value needs to be the same as the one that was provided to the `/_security/oidc/prepare` API or the one that was generated by Elasticsearch and included in the response to that call. */
  state: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { nonce?: never, realm?: never, redirect_uri?: never, state?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { nonce?: never, realm?: never, redirect_uri?: never, state?: never }
}

export interface SecurityOidcAuthenticateResponse {
  access_token: string
  expires_in: integer
  refresh_token: string
  type: string
}

export interface SecurityOidcLogoutRequest extends RequestBase {
/** The access token to be invalidated. */
  token: string
  /** The refresh token to be invalidated. */
  refresh_token?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { token?: never, refresh_token?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { token?: never, refresh_token?: never }
}

export interface SecurityOidcLogoutResponse {
  redirect: string
}

export interface SecurityOidcPrepareAuthenticationRequest extends RequestBase {
/** In the case of a third party initiated single sign on, this is the issuer identifier for the OP that the RP is to send the authentication request to. It cannot be specified when *realm* is specified. One of *realm* or *iss* is required. */
  iss?: string
  /** In the case of a third party initiated single sign on, it is a string value that is included in the authentication request as the *login_hint* parameter. This parameter is not valid when *realm* is specified. */
  login_hint?: string
  /** The value used to associate a client session with an ID token and to mitigate replay attacks. If the caller of the API does not provide a value, Elasticsearch will generate one with sufficient entropy and return it in the response. */
  nonce?: string
  /** The name of the OpenID Connect realm in Elasticsearch the configuration of which should be used in order to generate the authentication request. It cannot be specified when *iss* is specified. One of *realm* or *iss* is required. */
  realm?: string
  /** The value used to maintain state between the authentication request and the response, typically used as a Cross-Site Request Forgery mitigation. If the caller of the API does not provide a value, Elasticsearch will generate one with sufficient entropy and return it in the response. */
  state?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { iss?: never, login_hint?: never, nonce?: never, realm?: never, state?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { iss?: never, login_hint?: never, nonce?: never, realm?: never, state?: never }
}

export interface SecurityOidcPrepareAuthenticationResponse {
  nonce: string
  realm: string
  redirect: string
  state: string
}

export interface SecurityPutPrivilegesActions {
  actions: string[]
  application?: string
  name?: Name
  metadata?: Metadata
}

export interface SecurityPutPrivilegesRequest extends RequestBase {
/** If `true` (the default) then refresh the affected shards to make this operation visible to search, if `wait_for` then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  privileges?: Record<string, Record<string, SecurityPutPrivilegesActions>>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { refresh?: never, privileges?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { refresh?: never, privileges?: never }
}

export type SecurityPutPrivilegesResponse = Record<string, Record<string, SecurityCreatedStatus>>

export interface SecurityPutRoleRequest extends RequestBase {
/** The name of the role that is being created or updated. On Elasticsearch Serverless, the role name must begin with a letter or digit and can only contain letters, digits and the characters '_', '-', and '.'. Each role must have a unique name, as this will serve as the identifier for that role. */
  name: Name
  /** If `true` (the default) then refresh the affected shards to make this operation visible to search, if `wait_for` then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** A list of application privilege entries. */
  applications?: SecurityApplicationPrivileges[]
  /** A list of cluster privileges. These privileges define the cluster-level actions for users with this role. */
  cluster?: SecurityClusterPrivilege[]
  /** An object defining global privileges. A global privilege is a form of cluster privilege that is request-aware. Support for global privileges is currently limited to the management of application privileges. */
  global?: Record<string, any>
  /** A list of indices permissions entries. */
  indices?: SecurityIndicesPrivileges[]
  /** A list of remote indices permissions entries. NOTE: Remote indices are effective for remote clusters configured with the API key based model. They have no effect for remote clusters configured with the certificate based model. */
  remote_indices?: SecurityRemoteIndicesPrivileges[]
  /** A list of remote cluster permissions entries. */
  remote_cluster?: SecurityRemoteClusterPrivileges[]
  /** Optional metadata. Within the metadata object, keys that begin with an underscore (`_`) are reserved for system use. */
  metadata?: Metadata
  /** A list of users that the owners of this role can impersonate. *Note*: in Serverless, the run-as feature is disabled. For API compatibility, you can still specify an empty `run_as` field, but a non-empty list will be rejected. */
  run_as?: string[]
  /** Optional description of the role descriptor */
  description?: string
  /** Indicates roles that might be incompatible with the current cluster license, specifically roles with document and field level security. When the cluster license doesn’t allow certain features for a given role, this parameter is updated dynamically to list the incompatible features. If `enabled` is `false`, the role is ignored, but is still listed in the response from the authenticate API. */
  transient_metadata?: Record<string, any>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, refresh?: never, applications?: never, cluster?: never, global?: never, indices?: never, remote_indices?: never, remote_cluster?: never, metadata?: never, run_as?: never, description?: never, transient_metadata?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, refresh?: never, applications?: never, cluster?: never, global?: never, indices?: never, remote_indices?: never, remote_cluster?: never, metadata?: never, run_as?: never, description?: never, transient_metadata?: never }
}

export interface SecurityPutRoleResponse {
  role: SecurityCreatedStatus
}

export interface SecurityPutRoleMappingRequest extends RequestBase {
/** The distinct name that identifies the role mapping. The name is used solely as an identifier to facilitate interaction via the API; it does not affect the behavior of the mapping in any way. */
  name: Name
  /** If `true` (the default) then refresh the affected shards to make this operation visible to search, if `wait_for` then wait for a refresh to make this operation visible to search, if `false` then do nothing with refreshes. */
  refresh?: Refresh
  /** Mappings that have `enabled` set to `false` are ignored when role mapping is performed. */
  enabled?: boolean
  /** Additional metadata that helps define which roles are assigned to each user. Within the metadata object, keys beginning with `_` are reserved for system usage. */
  metadata?: Metadata
  /** A list of role names that are granted to the users that match the role mapping rules. Exactly one of `roles` or `role_templates` must be specified. */
  roles?: string[]
  /** A list of Mustache templates that will be evaluated to determine the roles names that should granted to the users that match the role mapping rules. Exactly one of `roles` or `role_templates` must be specified. */
  role_templates?: SecurityRoleTemplate[]
  /** The rules that determine which users should be matched by the mapping. A rule is a logical condition that is expressed by using a JSON DSL. */
  rules?: SecurityRoleMappingRule
  run_as?: string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, refresh?: never, enabled?: never, metadata?: never, roles?: never, role_templates?: never, rules?: never, run_as?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, refresh?: never, enabled?: never, metadata?: never, roles?: never, role_templates?: never, rules?: never, run_as?: never }
}

export interface SecurityPutRoleMappingResponse {
  created?: boolean
  role_mapping: SecurityCreatedStatus
}

export interface SecurityPutUserRequest extends RequestBase {
/** An identifier for the user. NOTE: Usernames must be at least 1 and no more than 507 characters. They can contain alphanumeric characters (a-z, A-Z, 0-9), spaces, punctuation, and printable symbols in the Basic Latin (ASCII) block. Leading or trailing whitespace is not allowed. */
  username: Username
  /** Valid values are `true`, `false`, and `wait_for`. These values have the same meaning as in the index API, but the default value for this API is true. */
  refresh?: Refresh
  /** The email of the user. */
  email?: string | null
  /** The full name of the user. */
  full_name?: string | null
  /** Arbitrary metadata that you want to associate with the user. */
  metadata?: Metadata
  /** The user's password. Passwords must be at least 6 characters long. When adding a user, one of `password` or `password_hash` is required. When updating an existing user, the password is optional, so that other fields on the user (such as their roles) may be updated without modifying the user's password */
  password?: Password
  /** A hash of the user's password. This must be produced using the same hashing algorithm as has been configured for password storage. For more details, see the explanation of the `xpack.security.authc.password_hashing.algorithm` setting in the user cache and password hash algorithm documentation. Using this parameter allows the client to pre-hash the password for performance and/or confidentiality reasons. The `password` parameter and the `password_hash` parameter cannot be used in the same request. */
  password_hash?: string
  /** A set of roles the user has. The roles determine the user's access permissions. To create a user without any roles, specify an empty list (`[]`). */
  roles?: string[]
  /** Specifies whether the user is enabled. */
  enabled?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { username?: never, refresh?: never, email?: never, full_name?: never, metadata?: never, password?: never, password_hash?: never, roles?: never, enabled?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { username?: never, refresh?: never, email?: never, full_name?: never, metadata?: never, password?: never, password_hash?: never, roles?: never, enabled?: never }
}

export interface SecurityPutUserResponse {
  created: boolean
}

export type SecurityQueryApiKeysApiKeyAggregate = AggregationsCardinalityAggregate | AggregationsValueCountAggregate | AggregationsStringTermsAggregate | AggregationsLongTermsAggregate | AggregationsDoubleTermsAggregate | AggregationsUnmappedTermsAggregate | AggregationsMultiTermsAggregate | AggregationsMissingAggregate | AggregationsFilterAggregate | AggregationsFiltersAggregate | AggregationsRangeAggregate | AggregationsDateRangeAggregate | AggregationsCompositeAggregate

export interface SecurityQueryApiKeysApiKeyAggregationContainer {
  aggregations?: Record<string, SecurityQueryApiKeysApiKeyAggregationContainer>
  aggs?: Record<string, SecurityQueryApiKeysApiKeyAggregationContainer>
  meta?: Metadata
  cardinality?: AggregationsCardinalityAggregation
  composite?: AggregationsCompositeAggregation
  date_range?: AggregationsDateRangeAggregation
  filter?: SecurityQueryApiKeysApiKeyQueryContainer
  filters?: SecurityQueryApiKeysApiKeyFiltersAggregation
  missing?: AggregationsMissingAggregation
  range?: AggregationsRangeAggregation
  terms?: AggregationsTermsAggregation
  value_count?: AggregationsValueCountAggregation
}

export interface SecurityQueryApiKeysApiKeyFiltersAggregation extends AggregationsBucketAggregationBase {
  filters?: AggregationsBuckets<SecurityQueryApiKeysApiKeyQueryContainer>
  other_bucket?: boolean
  other_bucket_key?: string
  keyed?: boolean
}

export interface SecurityQueryApiKeysApiKeyQueryContainer {
  bool?: QueryDslBoolQuery
  exists?: QueryDslExistsQuery
  ids?: QueryDslIdsQuery
  match?: Partial<Record<Field, QueryDslMatchQuery | string | float | boolean>>
  match_all?: QueryDslMatchAllQuery
  prefix?: Partial<Record<Field, QueryDslPrefixQuery | string>>
  range?: Partial<Record<Field, QueryDslRangeQuery>>
  simple_query_string?: QueryDslSimpleQueryStringQuery
  term?: Partial<Record<Field, QueryDslTermQuery | FieldValue>>
  terms?: QueryDslTermsQuery
  wildcard?: Partial<Record<Field, QueryDslWildcardQuery | string>>
}

export interface SecurityQueryApiKeysRequest extends RequestBase {
/** Return the snapshot of the owner user's role descriptors associated with the API key. An API key's actual permission is the intersection of its assigned role descriptors and the owner user's role descriptors (effectively limited by it). An API key cannot retrieve any API key’s limited-by role descriptors (including itself) unless it has `manage_api_key` or higher privileges. */
  with_limited_by?: boolean
  /** Determines whether to also retrieve the profile UID for the API key owner principal. If it exists, the profile UID is returned under the `profile_uid` response field for each API key. */
  with_profile_uid?: boolean
  /** Determines whether aggregation names are prefixed by their respective types in the response. */
  typed_keys?: boolean
  /** Any aggregations to run over the corpus of returned API keys. Aggregations and queries work together. Aggregations are computed only on the API keys that match the query. This supports only a subset of aggregation types, namely: `terms`, `range`, `date_range`, `missing`, `cardinality`, `value_count`, `composite`, `filter`, and `filters`. Additionally, aggregations only run over the same subset of fields that query works with. */
  aggregations?: Record<string, SecurityQueryApiKeysApiKeyAggregationContainer>
  /** @alias aggregations */
  /** Any aggregations to run over the corpus of returned API keys. Aggregations and queries work together. Aggregations are computed only on the API keys that match the query. This supports only a subset of aggregation types, namely: `terms`, `range`, `date_range`, `missing`, `cardinality`, `value_count`, `composite`, `filter`, and `filters`. Additionally, aggregations only run over the same subset of fields that query works with. */
  aggs?: Record<string, SecurityQueryApiKeysApiKeyAggregationContainer>
  /** A query to filter which API keys to return. If the query parameter is missing, it is equivalent to a `match_all` query. The query supports a subset of query types, including `match_all`, `bool`, `term`, `terms`, `match`, `ids`, `prefix`, `wildcard`, `exists`, `range`, and `simple_query_string`. You can query the following public information associated with an API key: `id`, `type`, `name`, `creation`, `expiration`, `invalidated`, `invalidation`, `username`, `realm`, and `metadata`. NOTE: The queryable string values associated with API keys are internally mapped as keywords. Consequently, if no `analyzer` parameter is specified for a `match` query, then the provided match query string is interpreted as a single keyword value. Such a match query is hence equivalent to a `term` query. */
  query?: SecurityQueryApiKeysApiKeyQueryContainer
  /** The starting document offset. It must not be negative. By default, you cannot page through more than 10,000 hits using the `from` and `size` parameters. To page through more hits, use the `search_after` parameter. */
  from?: integer
  /** The sort definition. Other than `id`, all public fields of an API key are eligible for sorting. In addition, sort can also be applied to the `_doc` field to sort by index order. */
  sort?: Sort
  /** The number of hits to return. It must not be negative. The `size` parameter can be set to `0`, in which case no API key matches are returned, only the aggregation results. By default, you cannot page through more than 10,000 hits using the `from` and `size` parameters. To page through more hits, use the `search_after` parameter. */
  size?: integer
  /** The search after definition. */
  search_after?: SortResults
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { with_limited_by?: never, with_profile_uid?: never, typed_keys?: never, aggregations?: never, aggs?: never, query?: never, from?: never, sort?: never, size?: never, search_after?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { with_limited_by?: never, with_profile_uid?: never, typed_keys?: never, aggregations?: never, aggs?: never, query?: never, from?: never, sort?: never, size?: never, search_after?: never }
}

export interface SecurityQueryApiKeysResponse {
  total: integer
  count: integer
  api_keys: SecurityApiKey[]
  aggregations?: Record<AggregateName, SecurityQueryApiKeysApiKeyAggregate>
}

export interface SecurityQueryRoleQueryRole extends SecurityRoleDescriptor {
  _sort?: SortResults
  name: string
}

export interface SecurityQueryRoleRequest extends RequestBase {
/** A query to filter which roles to return. If the query parameter is missing, it is equivalent to a `match_all` query. The query supports a subset of query types, including `match_all`, `bool`, `term`, `terms`, `match`, `ids`, `prefix`, `wildcard`, `exists`, `range`, and `simple_query_string`. You can query the following information associated with roles: `name`, `description`, `metadata`, `applications.application`, `applications.privileges`, and `applications.resources`. */
  query?: SecurityQueryRoleRoleQueryContainer
  /** The starting document offset. It must not be negative. By default, you cannot page through more than 10,000 hits using the `from` and `size` parameters. To page through more hits, use the `search_after` parameter. */
  from?: integer
  /** The sort definition. You can sort on `username`, `roles`, or `enabled`. In addition, sort can also be applied to the `_doc` field to sort by index order. */
  sort?: Sort
  /** The number of hits to return. It must not be negative. By default, you cannot page through more than 10,000 hits using the `from` and `size` parameters. To page through more hits, use the `search_after` parameter. */
  size?: integer
  /** The search after definition. */
  search_after?: SortResults
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { query?: never, from?: never, sort?: never, size?: never, search_after?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { query?: never, from?: never, sort?: never, size?: never, search_after?: never }
}

export interface SecurityQueryRoleResponse {
  total: integer
  count: integer
  roles: SecurityQueryRoleQueryRole[]
}

export interface SecurityQueryRoleRoleQueryContainer {
  bool?: QueryDslBoolQuery
  exists?: QueryDslExistsQuery
  ids?: QueryDslIdsQuery
  match?: Partial<Record<Field, QueryDslMatchQuery | string | float | boolean>>
  match_all?: QueryDslMatchAllQuery
  prefix?: Partial<Record<Field, QueryDslPrefixQuery | string>>
  range?: Partial<Record<Field, QueryDslRangeQuery>>
  simple_query_string?: QueryDslSimpleQueryStringQuery
  term?: Partial<Record<Field, QueryDslTermQuery | FieldValue>>
  terms?: QueryDslTermsQuery
  wildcard?: Partial<Record<Field, QueryDslWildcardQuery | string>>
}

export interface SecurityQueryUserQueryUser extends SecurityUser {
  _sort?: SortResults
}

export interface SecurityQueryUserRequest extends RequestBase {
/** Determines whether to retrieve the user profile UID, if it exists, for the users. */
  with_profile_uid?: boolean
  /** A query to filter which users to return. If the query parameter is missing, it is equivalent to a `match_all` query. The query supports a subset of query types, including `match_all`, `bool`, `term`, `terms`, `match`, `ids`, `prefix`, `wildcard`, `exists`, `range`, and `simple_query_string`. You can query the following information associated with user: `username`, `roles`, `enabled`, `full_name`, and `email`. */
  query?: SecurityQueryUserUserQueryContainer
  /** The starting document offset. It must not be negative. By default, you cannot page through more than 10,000 hits using the `from` and `size` parameters. To page through more hits, use the `search_after` parameter. */
  from?: integer
  /** The sort definition. Fields eligible for sorting are: `username`, `roles`, `enabled`. In addition, sort can also be applied to the `_doc` field to sort by index order. */
  sort?: Sort
  /** The number of hits to return. It must not be negative. By default, you cannot page through more than 10,000 hits using the `from` and `size` parameters. To page through more hits, use the `search_after` parameter. */
  size?: integer
  /** The search after definition */
  search_after?: SortResults
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { with_profile_uid?: never, query?: never, from?: never, sort?: never, size?: never, search_after?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { with_profile_uid?: never, query?: never, from?: never, sort?: never, size?: never, search_after?: never }
}

export interface SecurityQueryUserResponse {
  total: integer
  count: integer
  users: SecurityQueryUserQueryUser[]
}

export interface SecurityQueryUserUserQueryContainer {
  ids?: QueryDslIdsQuery
  bool?: QueryDslBoolQuery
  exists?: QueryDslExistsQuery
  match?: Partial<Record<Field, QueryDslMatchQuery | string | float | boolean>>
  match_all?: QueryDslMatchAllQuery
  prefix?: Partial<Record<Field, QueryDslPrefixQuery | string>>
  range?: Partial<Record<Field, QueryDslRangeQuery>>
  simple_query_string?: QueryDslSimpleQueryStringQuery
  term?: Partial<Record<Field, QueryDslTermQuery | FieldValue>>
  terms?: QueryDslTermsQuery
  wildcard?: Partial<Record<Field, QueryDslWildcardQuery | string>>
}

export interface SecuritySamlAuthenticateRequest extends RequestBase {
/** The SAML response as it was sent by the user's browser, usually a Base64 encoded XML document. */
  content: string
  /** A JSON array with all the valid SAML Request Ids that the caller of the API has for the current user. */
  ids: Ids
  /** The name of the realm that should authenticate the SAML response. Useful in cases where many SAML realms are defined. */
  realm?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { content?: never, ids?: never, realm?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { content?: never, ids?: never, realm?: never }
}

export interface SecuritySamlAuthenticateResponse {
  access_token: string
  username: string
  expires_in: integer
  refresh_token: string
  realm: string
}

export interface SecuritySamlCompleteLogoutRequest extends RequestBase {
/** The name of the SAML realm in Elasticsearch for which the configuration is used to verify the logout response. */
  realm: string
  /** A JSON array with all the valid SAML Request Ids that the caller of the API has for the current user. */
  ids: Ids
  /** If the SAML IdP sends the logout response with the HTTP-Redirect binding, this field must be set to the query string of the redirect URI. */
  query_string?: string
  /** If the SAML IdP sends the logout response with the HTTP-Post binding, this field must be set to the value of the SAMLResponse form parameter from the logout response. */
  content?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { realm?: never, ids?: never, query_string?: never, content?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { realm?: never, ids?: never, query_string?: never, content?: never }
}

export type SecuritySamlCompleteLogoutResponse = boolean

export interface SecuritySamlInvalidateRequest extends RequestBase {
/** The Assertion Consumer Service URL that matches the one of the SAML realm in Elasticsearch that should be used. You must specify either this parameter or the `realm` parameter. */
  acs?: string
  /** The query part of the URL that the user was redirected to by the SAML IdP to initiate the Single Logout. This query should include a single parameter named `SAMLRequest` that contains a SAML logout request that is deflated and Base64 encoded. If the SAML IdP has signed the logout request, the URL should include two extra parameters named `SigAlg` and `Signature` that contain the algorithm used for the signature and the signature value itself. In order for Elasticsearch to be able to verify the IdP's signature, the value of the `query_string` field must be an exact match to the string provided by the browser. The client application must not attempt to parse or process the string in any way. */
  query_string: string
  /** The name of the SAML realm in Elasticsearch the configuration. You must specify either this parameter or the `acs` parameter. */
  realm?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { acs?: never, query_string?: never, realm?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { acs?: never, query_string?: never, realm?: never }
}

export interface SecuritySamlInvalidateResponse {
  invalidated: integer
  realm: string
  redirect: string
}

export interface SecuritySamlLogoutRequest extends RequestBase {
/** The access token that was returned as a response to calling the SAML authenticate API. Alternatively, the most recent token that was received after refreshing the original one by using a `refresh_token`. */
  token: string
  /** The refresh token that was returned as a response to calling the SAML authenticate API. Alternatively, the most recent refresh token that was received after refreshing the original access token. */
  refresh_token?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { token?: never, refresh_token?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { token?: never, refresh_token?: never }
}

export interface SecuritySamlLogoutResponse {
  redirect: string
}

export interface SecuritySamlPrepareAuthenticationRequest extends RequestBase {
/** The Assertion Consumer Service URL that matches the one of the SAML realms in Elasticsearch. The realm is used to generate the authentication request. You must specify either this parameter or the `realm` parameter. */
  acs?: string
  /** The name of the SAML realm in Elasticsearch for which the configuration is used to generate the authentication request. You must specify either this parameter or the `acs` parameter. */
  realm?: string
  /** A string that will be included in the redirect URL that this API returns as the `RelayState` query parameter. If the Authentication Request is signed, this value is used as part of the signature computation. */
  relay_state?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { acs?: never, realm?: never, relay_state?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { acs?: never, realm?: never, relay_state?: never }
}

export interface SecuritySamlPrepareAuthenticationResponse {
  id: Id
  realm: string
  redirect: string
}

export interface SecuritySamlServiceProviderMetadataRequest extends RequestBase {
/** The name of the SAML realm in Elasticsearch. */
  realm_name: Name
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { realm_name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { realm_name?: never }
}

export interface SecuritySamlServiceProviderMetadataResponse {
  metadata: string
}

export interface SecuritySuggestUserProfilesHint {
  uids?: SecurityUserProfileId[]
  labels?: Record<string, string | string[]>
}

export interface SecuritySuggestUserProfilesRequest extends RequestBase {
/** A query string used to match name-related fields in user profile documents. Name-related fields are the user's `username`, `full_name`, and `email`. */
  name?: string
  /** The number of profiles to return. */
  size?: long
  /** A comma-separated list of filters for the `data` field of the profile document. To return all content use `data=*`. To return a subset of content, use `data=<key>` to retrieve content nested under the specified `<key>`. By default, the API returns no `data` content. It is an error to specify `data` as both the query parameter and the request body field. */
  data?: string | string[]
  /** Extra search criteria to improve relevance of the suggestion result. Profiles matching the spcified hint are ranked higher in the response. Profiles not matching the hint aren't excluded from the response as long as the profile matches the `name` field query. */
  hint?: SecuritySuggestUserProfilesHint
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, size?: never, data?: never, hint?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, size?: never, data?: never, hint?: never }
}

export interface SecuritySuggestUserProfilesResponse {
  total: SecuritySuggestUserProfilesTotalUserProfiles
  took: long
  profiles: SecurityUserProfile[]
}

export interface SecuritySuggestUserProfilesTotalUserProfiles {
  value: long
  relation: RelationName
}

export interface SecurityUpdateApiKeyRequest extends RequestBase {
/** The ID of the API key to update. */
  id: Id
  /** The role descriptors to assign to this API key. The API key's effective permissions are an intersection of its assigned privileges and the point in time snapshot of permissions of the owner user. You can assign new privileges by specifying them in this parameter. To remove assigned privileges, you can supply an empty `role_descriptors` parameter, that is to say, an empty object `{}`. If an API key has no assigned privileges, it inherits the owner user's full permissions. The snapshot of the owner's permissions is always updated, whether you supply the `role_descriptors` parameter or not. The structure of a role descriptor is the same as the request for the create API keys API. */
  role_descriptors?: Record<string, SecurityRoleDescriptor>
  /** Arbitrary metadata that you want to associate with the API key. It supports a nested data structure. Within the metadata object, keys beginning with `_` are reserved for system usage. When specified, this value fully replaces the metadata previously associated with the API key. */
  metadata?: Metadata
  /** The expiration time for the API key. By default, API keys never expire. This property can be omitted to leave the expiration unchanged. */
  expiration?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, role_descriptors?: never, metadata?: never, expiration?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, role_descriptors?: never, metadata?: never, expiration?: never }
}

export interface SecurityUpdateApiKeyResponse {
  updated: boolean
}

export interface SecurityUpdateCrossClusterApiKeyRequest extends RequestBase {
/** The ID of the cross-cluster API key to update. */
  id: Id
  /** The access to be granted to this API key. The access is composed of permissions for cross cluster search and cross cluster replication. At least one of them must be specified. When specified, the new access assignment fully replaces the previously assigned access. */
  access: SecurityAccess
  /** The expiration time for the API key. By default, API keys never expire. This property can be omitted to leave the value unchanged. */
  expiration?: Duration
  /** Arbitrary metadata that you want to associate with the API key. It supports nested data structure. Within the metadata object, keys beginning with `_` are reserved for system usage. When specified, this information fully replaces metadata previously associated with the API key. */
  metadata?: Metadata
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, access?: never, expiration?: never, metadata?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, access?: never, expiration?: never, metadata?: never }
}

export interface SecurityUpdateCrossClusterApiKeyResponse {
  updated: boolean
}

export interface SecurityUpdateSettingsRequest extends RequestBase {
/** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** Settings for the index used for most security configuration, including native realm users and roles configured with the API. */
  security?: SecuritySecuritySettings
  /** Settings for the index used to store profile information. */
  'security-profile'?: SecuritySecuritySettings
  /** Settings for the index used to store tokens. */
  'security-tokens'?: SecuritySecuritySettings
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never, timeout?: never, security?: never, 'security-profile'?: never, 'security-tokens'?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never, timeout?: never, security?: never, 'security-profile'?: never, 'security-tokens'?: never }
}

export interface SecurityUpdateSettingsResponse {
  acknowledged: boolean
}

export interface SecurityUpdateUserProfileDataRequest extends RequestBase {
/** A unique identifier for the user profile. */
  uid: SecurityUserProfileId
  /** Only perform the operation if the document has this sequence number. */
  if_seq_no?: SequenceNumber
  /** Only perform the operation if the document has this primary term. */
  if_primary_term?: long
  /** If 'true', Elasticsearch refreshes the affected shards to make this operation visible to search. If 'wait_for', it waits for a refresh to make this operation visible to search. If 'false', nothing is done with refreshes. */
  refresh?: Refresh
  /** Searchable data that you want to associate with the user profile. This field supports a nested data structure. Within the labels object, top-level keys cannot begin with an underscore (`_`) or contain a period (`.`). */
  labels?: Record<string, any>
  /** Non-searchable data that you want to associate with the user profile. This field supports a nested data structure. Within the `data` object, top-level keys cannot begin with an underscore (`_`) or contain a period (`.`). The data object is not searchable, but can be retrieved with the get user profile API. */
  data?: Record<string, any>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { uid?: never, if_seq_no?: never, if_primary_term?: never, refresh?: never, labels?: never, data?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { uid?: never, if_seq_no?: never, if_primary_term?: never, refresh?: never, labels?: never, data?: never }
}

export type SecurityUpdateUserProfileDataResponse = AcknowledgedResponseBase

export type ShutdownType = 'restart' | 'remove' | 'replace'

export interface ShutdownDeleteNodeRequest extends RequestBase {
/** The node id of node to be removed from the shutdown state */
  node_id: NodeId
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: TimeUnit
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: TimeUnit
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never, master_timeout?: never, timeout?: never }
}

export type ShutdownDeleteNodeResponse = AcknowledgedResponseBase

export interface ShutdownGetNodeNodeShutdownStatus {
  node_id: NodeId
  type: ShutdownGetNodeShutdownType
  reason: string
  shutdown_startedmillis: EpochTime<UnitMillis>
  status: ShutdownGetNodeShutdownStatus
  shard_migration: ShutdownGetNodeShardMigrationStatus
  persistent_tasks: ShutdownGetNodePersistentTaskStatus
  plugins: ShutdownGetNodePluginsStatus
}

export interface ShutdownGetNodePersistentTaskStatus {
  status: ShutdownGetNodeShutdownStatus
}

export interface ShutdownGetNodePluginsStatus {
  status: ShutdownGetNodeShutdownStatus
}

export interface ShutdownGetNodeRequest extends RequestBase {
/** Which node for which to retrieve the shutdown status */
  node_id?: NodeIds
  /** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: TimeUnit
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never, master_timeout?: never }
}

export interface ShutdownGetNodeResponse {
  nodes: ShutdownGetNodeNodeShutdownStatus[]
}

export interface ShutdownGetNodeShardMigrationStatus {
  status: ShutdownGetNodeShutdownStatus
}

export type ShutdownGetNodeShutdownStatus = 'not_started' | 'in_progress' | 'stalled' | 'complete'

export type ShutdownGetNodeShutdownType = 'remove' | 'restart'

export interface ShutdownPutNodeRequest extends RequestBase {
/** The node identifier. This parameter is not validated against the cluster's active nodes. This enables you to register a node for shut down while it is offline. No error is thrown if you specify an invalid node ID. */
  node_id: NodeId
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: TimeUnit
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: TimeUnit
  /** Valid values are restart, remove, or replace. Use restart when you need to temporarily shut down a node to perform an upgrade, make configuration changes, or perform other maintenance. Because the node is expected to rejoin the cluster, data is not migrated off of the node. Use remove when you need to permanently remove a node from the cluster. The node is not marked ready for shutdown until data is migrated off of the node Use replace to do a 1:1 replacement of a node with another node. Certain allocation decisions will be ignored (such as disk watermarks) in the interest of true replacement of the source node with the target node. During a replace-type shutdown, rollover and index creation may result in unassigned shards, and shrink may fail until the replacement is complete. */
  type: ShutdownType
  /** A human-readable reason that the node is being shut down. This field provides information for other cluster operators; it does not affect the shut down process. */
  reason: string
  /** Only valid if type is restart. Controls how long Elasticsearch will wait for the node to restart and join the cluster before reassigning its shards to other nodes. This works the same as delaying allocation with the index.unassigned.node_left.delayed_timeout setting. If you specify both a restart allocation delay and an index-level allocation delay, the longer of the two is used. */
  allocation_delay?: string
  /** Only valid if type is replace. Specifies the name of the node that is replacing the node being shut down. Shards from the shut down node are only allowed to be allocated to the target node, and no other data will be allocated to the target node. During relocation of data certain allocation rules are ignored, such as disk watermarks or user attribute filtering rules. */
  target_node_name?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { node_id?: never, master_timeout?: never, timeout?: never, type?: never, reason?: never, allocation_delay?: never, target_node_name?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { node_id?: never, master_timeout?: never, timeout?: never, type?: never, reason?: never, allocation_delay?: never, target_node_name?: never }
}

export type ShutdownPutNodeResponse = AcknowledgedResponseBase

export interface SimulateIngestIngestDocumentSimulationKeys {
  _id: Id
  _index: IndexName
  _source: Record<string, any>
  _version: SpecUtilsStringified<VersionNumber>
  executed_pipelines: string[]
  ignored_fields?: Record<string, string>[]
  error?: ErrorCause
}
export type SimulateIngestIngestDocumentSimulation = SimulateIngestIngestDocumentSimulationKeys
& { [property: string]: string | Id | IndexName | Record<string, any> | SpecUtilsStringified<VersionNumber> | string[] | Record<string, string>[] | ErrorCause }

export interface SimulateIngestRequest extends RequestBase {
/** The index to simulate ingesting into. This value can be overridden by specifying an index on each document. If you specify this parameter in the request path, it is used for any documents that do not explicitly specify an index argument. */
  index?: IndexName
  /** The pipeline to use as the default pipeline. This value can be used to override the default pipeline of the index. */
  pipeline?: PipelineName
  /** Sample documents to test in the pipeline. */
  docs: IngestDocument[]
  /** A map of component template names to substitute component template definition objects. */
  component_template_substitutions?: Record<string, ClusterComponentTemplateNode>
  /** A map of index template names to substitute index template definition objects. */
  index_template_substitutions?: Record<string, IndicesIndexTemplate>
  mapping_addition?: MappingTypeMapping
  /** Pipelines to test. If you don’t specify the `pipeline` request path parameter, this parameter is required. If you specify both this and the request path parameter, the API only uses the request path parameter. */
  pipeline_substitutions?: Record<string, IngestPipeline>
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { index?: never, pipeline?: never, docs?: never, component_template_substitutions?: never, index_template_substitutions?: never, mapping_addition?: never, pipeline_substitutions?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { index?: never, pipeline?: never, docs?: never, component_template_substitutions?: never, index_template_substitutions?: never, mapping_addition?: never, pipeline_substitutions?: never }
}

export interface SimulateIngestResponse {
  docs: SimulateIngestSimulateIngestDocumentResult[]
}

export interface SimulateIngestSimulateIngestDocumentResult {
  doc?: SimulateIngestIngestDocumentSimulation
}

export interface SlmConfiguration {
  ignore_unavailable?: boolean
  indices?: Indices
  include_global_state?: boolean
  feature_states?: string[]
  metadata?: Metadata
  partial?: boolean
}

export interface SlmInProgress {
  name: Name
  start_time_millis: EpochTime<UnitMillis>
  state: string
  uuid: Uuid
}

export interface SlmInvocation {
  snapshot_name: Name
  time: DateTime
}

export interface SlmPolicy {
  config?: SlmConfiguration
  name: Name
  repository: string
  retention?: SlmRetention
  schedule: WatcherCronExpression
}

export interface SlmRetention {
  expire_after: Duration
  max_count: integer
  min_count: integer
}

export interface SlmSnapshotLifecycle {
  in_progress?: SlmInProgress
  last_failure?: SlmInvocation
  last_success?: SlmInvocation
  modified_date?: DateTime
  modified_date_millis: EpochTime<UnitMillis>
  next_execution?: DateTime
  next_execution_millis: EpochTime<UnitMillis>
  policy: SlmPolicy
  version: VersionNumber
  stats: SlmStatistics
}

export interface SlmStatistics {
  retention_deletion_time?: Duration
  retention_deletion_time_millis?: DurationValue<UnitMillis>
  retention_failed?: long
  retention_runs?: long
  retention_timed_out?: long
  policy?: Id
  total_snapshots_deleted?: long
  snapshots_deleted?: long
  total_snapshot_deletion_failures?: long
  snapshot_deletion_failures?: long
  total_snapshots_failed?: long
  snapshots_failed?: long
  total_snapshots_taken?: long
  snapshots_taken?: long
}

export interface SlmDeleteLifecycleRequest extends RequestBase {
/** The id of the snapshot lifecycle policy to remove */
  policy_id: Name
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { policy_id?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { policy_id?: never, master_timeout?: never, timeout?: never }
}

export type SlmDeleteLifecycleResponse = AcknowledgedResponseBase

export interface SlmExecuteLifecycleRequest extends RequestBase {
/** The id of the snapshot lifecycle policy to be executed */
  policy_id: Name
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { policy_id?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { policy_id?: never, master_timeout?: never, timeout?: never }
}

export interface SlmExecuteLifecycleResponse {
  snapshot_name: Name
}

export interface SlmExecuteRetentionRequest extends RequestBase {
/** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never, timeout?: never }
}

export type SlmExecuteRetentionResponse = AcknowledgedResponseBase

export interface SlmGetLifecycleRequest extends RequestBase {
/** Comma-separated list of snapshot lifecycle policies to retrieve */
  policy_id?: Names
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { policy_id?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { policy_id?: never, master_timeout?: never, timeout?: never }
}

export type SlmGetLifecycleResponse = Record<Id, SlmSnapshotLifecycle>

export interface SlmGetStatsRequest extends RequestBase {
/** Period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never, timeout?: never }
}

export interface SlmGetStatsResponse {
  retention_deletion_time: Duration
  retention_deletion_time_millis: DurationValue<UnitMillis>
  retention_failed: long
  retention_runs: long
  retention_timed_out: long
  total_snapshots_deleted: long
  total_snapshot_deletion_failures: long
  total_snapshots_failed: long
  total_snapshots_taken: long
  policy_stats: string[]
}

export interface SlmGetStatusRequest extends RequestBase {
/** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never, timeout?: never }
}

export interface SlmGetStatusResponse {
  operation_mode: LifecycleOperationMode
}

export interface SlmPutLifecycleRequest extends RequestBase {
/** The identifier for the snapshot lifecycle policy you want to create or update. */
  policy_id: Name
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  timeout?: Duration
  /** Configuration for each snapshot created by the policy. */
  config?: SlmConfiguration
  /** Name automatically assigned to each snapshot created by the policy. Date math is supported. To prevent conflicting snapshot names, a UUID is automatically appended to each snapshot name. */
  name?: Name
  /** Repository used to store snapshots created by this policy. This repository must exist prior to the policy’s creation. You can create a repository using the snapshot repository API. */
  repository?: string
  /** Retention rules used to retain and delete snapshots created by the policy. */
  retention?: SlmRetention
  /** Periodic or absolute schedule at which the policy creates snapshots. SLM applies schedule changes immediately. */
  schedule?: WatcherCronExpression
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { policy_id?: never, master_timeout?: never, timeout?: never, config?: never, name?: never, repository?: never, retention?: never, schedule?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { policy_id?: never, master_timeout?: never, timeout?: never, config?: never, name?: never, repository?: never, retention?: never, schedule?: never }
}

export type SlmPutLifecycleResponse = AcknowledgedResponseBase

export interface SlmStartRequest extends RequestBase {
/** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never, timeout?: never }
}

export type SlmStartResponse = AcknowledgedResponseBase

export interface SlmStopRequest extends RequestBase {
/** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never, timeout?: never }
}

export type SlmStopResponse = AcknowledgedResponseBase

export interface SnapshotAzureRepository extends SnapshotRepositoryBase {
  type: 'azure'
  settings?: SnapshotAzureRepositorySettings
}

export interface SnapshotAzureRepositorySettings extends SnapshotRepositorySettingsBase {
  base_path?: string
  client?: string
  container?: string
  delete_objects_max_size?: integer
  location_mode?: string
  max_concurrent_batch_deletes?: integer
  readonly?: boolean
}

export interface SnapshotFileCountSnapshotStats {
  file_count: integer
  size_in_bytes: long
}

export interface SnapshotGcsRepository extends SnapshotRepositoryBase {
  type: 'gcs'
  settings: SnapshotGcsRepositorySettings
}

export interface SnapshotGcsRepositorySettings extends SnapshotRepositorySettingsBase {
  bucket: string
  application_name?: string
  base_path?: string
  client?: string
  readonly?: boolean
}

export interface SnapshotIndexDetails {
  shard_count: integer
  size?: ByteSize
  size_in_bytes: long
  max_segments_per_shard: long
}

export interface SnapshotInfoFeatureState {
  feature_name: string
  indices: Indices
}

export interface SnapshotReadOnlyUrlRepository extends SnapshotRepositoryBase {
  type: 'url'
  settings: SnapshotReadOnlyUrlRepositorySettings
}

export interface SnapshotReadOnlyUrlRepositorySettings extends SnapshotRepositorySettingsBase {
  http_max_retries?: integer
  http_socket_timeout?: Duration
  max_number_of_snapshots?: integer
  url: string
}

export type SnapshotRepository = SnapshotAzureRepository | SnapshotGcsRepository | SnapshotS3Repository | SnapshotSharedFileSystemRepository | SnapshotReadOnlyUrlRepository | SnapshotSourceOnlyRepository

export interface SnapshotRepositoryBase {
  uuid?: Uuid
}

export interface SnapshotRepositorySettingsBase {
  chunk_size?: ByteSize
  compress?: boolean
  max_restore_bytes_per_sec?: ByteSize
  max_snapshot_bytes_per_sec?: ByteSize
}

export interface SnapshotS3Repository extends SnapshotRepositoryBase {
  type: 's3'
  settings: SnapshotS3RepositorySettings
}

export interface SnapshotS3RepositorySettings extends SnapshotRepositorySettingsBase {
  bucket: string
  base_path?: string
  buffer_size?: ByteSize
  canned_acl?: string
  client?: string
  delete_objects_max_size?: integer
  get_register_retry_delay?: Duration
  max_multipart_parts?: integer
  max_multipart_upload_cleanup_size?: integer
  readonly?: boolean
  server_side_encryption?: boolean
  storage_class?: string
  'throttled_delete_retry.delay_increment'?: Duration
  'throttled_delete_retry.maximum_delay'?: Duration
  'throttled_delete_retry.maximum_number_of_retries'?: integer
}

export interface SnapshotShardsStats {
  done: long
  failed: long
  finalizing: long
  initializing: long
  started: long
  total: long
}

export type SnapshotShardsStatsStage = 'DONE' | 'FAILURE' | 'FINALIZE' | 'INIT' | 'STARTED'

export interface SnapshotShardsStatsSummary {
  incremental: SnapshotShardsStatsSummaryItem
  total: SnapshotShardsStatsSummaryItem
  start_time_in_millis: EpochTime<UnitMillis>
  time?: Duration
  time_in_millis: DurationValue<UnitMillis>
}

export interface SnapshotShardsStatsSummaryItem {
  file_count: long
  size_in_bytes: long
}

export interface SnapshotSharedFileSystemRepository extends SnapshotRepositoryBase {
  type: 'fs'
  settings: SnapshotSharedFileSystemRepositorySettings
}

export interface SnapshotSharedFileSystemRepositorySettings extends SnapshotRepositorySettingsBase {
  location: string
  max_number_of_snapshots?: integer
  readonly?: boolean
}

export interface SnapshotSnapshotIndexStats {
  shards: Record<string, SnapshotSnapshotShardsStatus>
  shards_stats: SnapshotShardsStats
  stats: SnapshotSnapshotStats
}

export interface SnapshotSnapshotInfo {
  data_streams: string[]
  duration?: Duration
  duration_in_millis?: DurationValue<UnitMillis>
  end_time?: DateTime
  end_time_in_millis?: EpochTime<UnitMillis>
  failures?: SnapshotSnapshotShardFailure[]
  include_global_state?: boolean
  indices?: IndexName[]
  index_details?: Record<IndexName, SnapshotIndexDetails>
  metadata?: Metadata
  reason?: string
  repository?: Name
  snapshot: Name
  shards?: ShardStatistics
  start_time?: DateTime
  start_time_in_millis?: EpochTime<UnitMillis>
  state?: string
  uuid: Uuid
  version?: VersionString
  version_id?: VersionNumber
  feature_states?: SnapshotInfoFeatureState[]
}

export interface SnapshotSnapshotShardFailure {
  index: IndexName
  node_id?: Id
  reason: string
  shard_id: Id
  index_uuid: Id
  status: string
}

export interface SnapshotSnapshotShardsStatus {
  stage: SnapshotShardsStatsStage
  stats: SnapshotShardsStatsSummary
}

export type SnapshotSnapshotSort = 'start_time' | 'duration' | 'name' | 'index_count' | 'repository' | 'shard_count' | 'failed_shard_count'

export interface SnapshotSnapshotStats {
  incremental: SnapshotFileCountSnapshotStats
  start_time_in_millis: EpochTime<UnitMillis>
  time?: Duration
  time_in_millis: DurationValue<UnitMillis>
  total: SnapshotFileCountSnapshotStats
}

export interface SnapshotSourceOnlyRepository extends SnapshotRepositoryBase {
  type: 'source'
  settings: SnapshotSourceOnlyRepositorySettings
}

export interface SnapshotSourceOnlyRepositorySettings extends SnapshotRepositorySettingsBase {
  delegate_type?: string
  max_number_of_snapshots?: integer
  read_only?: boolean
  readonly?: boolean
}

export interface SnapshotStatus {
  include_global_state: boolean
  indices: Record<string, SnapshotSnapshotIndexStats>
  repository: string
  shards_stats: SnapshotShardsStats
  snapshot: string
  state: string
  stats: SnapshotSnapshotStats
  uuid: Uuid
}

export interface SnapshotCleanupRepositoryCleanupRepositoryResults {
  deleted_blobs: long
  deleted_bytes: long
}

export interface SnapshotCleanupRepositoryRequest extends RequestBase {
/** The name of the snapshot repository to clean up. */
  name: Name
  /** The period to wait for a connection to the master node. If the master node is not available before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1` */
  master_timeout?: Duration
  /** The period to wait for a response from all relevant nodes in the cluster after updating the cluster metadata. If no response is received before the timeout expires, the cluster metadata update still applies but the response will indicate that it was not completely acknowledged. To indicate that the request should never timeout, set it to `-1`. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
}

export interface SnapshotCleanupRepositoryResponse {
  results: SnapshotCleanupRepositoryCleanupRepositoryResults
}

export interface SnapshotCloneRequest extends RequestBase {
/** The name of the snapshot repository that both source and target snapshot belong to. */
  repository: Name
  /** The source snapshot name. */
  snapshot: Name
  /** The target snapshot name. */
  target_snapshot: Name
  /** The period to wait for the master node. If the master node is not available before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** The period of time to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** A comma-separated list of indices to include in the snapshot. Multi-target syntax is supported. */
  indices: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { repository?: never, snapshot?: never, target_snapshot?: never, master_timeout?: never, timeout?: never, indices?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { repository?: never, snapshot?: never, target_snapshot?: never, master_timeout?: never, timeout?: never, indices?: never }
}

export type SnapshotCloneResponse = AcknowledgedResponseBase

export interface SnapshotCreateRequest extends RequestBase {
/** The name of the repository for the snapshot. */
  repository: Name
  /** The name of the snapshot. It supportes date math. It must be unique in the repository. */
  snapshot: Name
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** If `true`, the request returns a response when the snapshot is complete. If `false`, the request returns a response when the snapshot initializes. */
  wait_for_completion?: boolean
  /** Determines how wildcard patterns in the `indices` parameter match data streams and indices. It supports comma-separated values such as `open,hidden`. */
  expand_wildcards?: ExpandWildcards
  /** The feature states to include in the snapshot. Each feature state includes one or more system indices containing related data. You can view a list of eligible features using the get features API. If `include_global_state` is `true`, all current feature states are included by default. If `include_global_state` is `false`, no feature states are included by default. Note that specifying an empty array will result in the default behavior. To exclude all feature states, regardless of the `include_global_state` value, specify an array with only the value `none` (`["none"]`). */
  feature_states?: string[]
  /** If `true`, the request ignores data streams and indices in `indices` that are missing or closed. If `false`, the request returns an error for any data stream or index that is missing or closed. */
  ignore_unavailable?: boolean
  /** If `true`, the current cluster state is included in the snapshot. The cluster state includes persistent cluster settings, composable index templates, legacy index templates, ingest pipelines, and ILM policies. It also includes data stored in system indices, such as Watches and task records (configurable via `feature_states`). */
  include_global_state?: boolean
  /** A comma-separated list of data streams and indices to include in the snapshot. It supports a multi-target syntax. The default is an empty array (`[]`), which includes all regular data streams and regular indices. To exclude all data streams and indices, use `-*`. You can't use this parameter to include or exclude system indices or system data streams from a snapshot. Use `feature_states` instead. */
  indices?: Indices
  /** Arbitrary metadata to the snapshot, such as a record of who took the snapshot, why it was taken, or any other useful data. It can have any contents but it must be less than 1024 bytes. This information is not automatically generated by Elasticsearch. */
  metadata?: Metadata
  /** If `true`, it enables you to restore a partial snapshot of indices with unavailable shards. Only shards that were successfully included in the snapshot will be restored. All missing shards will be recreated as empty. If `false`, the entire restore operation will fail if one or more indices included in the snapshot do not have all primary shards available. */
  partial?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { repository?: never, snapshot?: never, master_timeout?: never, wait_for_completion?: never, expand_wildcards?: never, feature_states?: never, ignore_unavailable?: never, include_global_state?: never, indices?: never, metadata?: never, partial?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { repository?: never, snapshot?: never, master_timeout?: never, wait_for_completion?: never, expand_wildcards?: never, feature_states?: never, ignore_unavailable?: never, include_global_state?: never, indices?: never, metadata?: never, partial?: never }
}

export interface SnapshotCreateResponse {
  accepted?: boolean
  snapshot?: SnapshotSnapshotInfo
}

export interface SnapshotCreateRepositoryRequest extends RequestBase {
/** The name of the snapshot repository to register or update. */
  name: Name
  /** The period to wait for the master node. If the master node is not available before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** The period to wait for a response from all relevant nodes in the cluster after updating the cluster metadata. If no response is received before the timeout expires, the cluster metadata update still applies but the response will indicate that it was not completely acknowledged. To indicate that the request should never timeout, set it to `-1`. */
  timeout?: Duration
  /** If `true`, the request verifies the repository is functional on all master and data nodes in the cluster. If `false`, this verification is skipped. You can also perform this verification with the verify snapshot repository API. */
  verify?: boolean
  repository?: SnapshotRepository
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never, verify?: never, repository?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never, verify?: never, repository?: never }
}

export type SnapshotCreateRepositoryResponse = AcknowledgedResponseBase

export interface SnapshotDeleteRequest extends RequestBase {
/** The name of the repository to delete a snapshot from. */
  repository: Name
  /** A comma-separated list of snapshot names to delete. It also accepts wildcards (`*`). */
  snapshot: Name
  /** The period to wait for the master node. If the master node is not available before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { repository?: never, snapshot?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { repository?: never, snapshot?: never, master_timeout?: never }
}

export type SnapshotDeleteResponse = AcknowledgedResponseBase

export interface SnapshotDeleteRepositoryRequest extends RequestBase {
/** The ame of the snapshot repositories to unregister. Wildcard (`*`) patterns are supported. */
  name: Names
  /** The period to wait for the master node. If the master node is not available before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** The period to wait for a response from all relevant nodes in the cluster after updating the cluster metadata. If no response is received before the timeout expires, the cluster metadata update still applies but the response will indicate that it was not completely acknowledged. To indicate that the request should never timeout, set it to `-1`. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
}

export type SnapshotDeleteRepositoryResponse = AcknowledgedResponseBase

export interface SnapshotGetRequest extends RequestBase {
/** A comma-separated list of snapshot repository names used to limit the request. Wildcard (`*`) expressions are supported. */
  repository: Name
  /** A comma-separated list of snapshot names to retrieve Wildcards (`*`) are supported. * To get information about all snapshots in a registered repository, use a wildcard (`*`) or `_all`. * To get information about any snapshots that are currently running, use `_current`. */
  snapshot: Names
  /** An offset identifier to start pagination from as returned by the next field in the response body. */
  after?: string
  /** The value of the current sort column at which to start retrieval. It can be a string `snapshot-` or a repository name when sorting by snapshot or repository name. It can be a millisecond time value or a number when sorting by `index-` or shard count. */
  from_sort_value?: string
  /** If `false`, the request returns an error for any snapshots that are unavailable. */
  ignore_unavailable?: boolean
  /** If `true`, the response includes additional information about each index in the snapshot comprising the number of shards in the index, the total size of the index in bytes, and the maximum number of segments per shard in the index. The default is `false`, meaning that this information is omitted. */
  index_details?: boolean
  /** If `true`, the response includes the name of each index in each snapshot. */
  index_names?: boolean
  /** If `true`, the response includes the repository name in each snapshot. */
  include_repository?: boolean
  /** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** The sort order. Valid values are `asc` for ascending and `desc` for descending order. The default behavior is ascending order. */
  order?: SortOrder
  /** Numeric offset to start pagination from based on the snapshots matching this request. Using a non-zero value for this parameter is mutually exclusive with using the after parameter. Defaults to 0. */
  offset?: integer
  /** The maximum number of snapshots to return. The default is 0, which means to return all that match the request without limit. */
  size?: integer
  /** Filter snapshots by a comma-separated list of snapshot lifecycle management (SLM) policy names that snapshots belong to. You can use wildcards (`*`) and combinations of wildcards followed by exclude patterns starting with `-`. For example, the pattern `*,-policy-a-\*` will return all snapshots except for those that were created by an SLM policy with a name starting with `policy-a-`. Note that the wildcard pattern `*` matches all snapshots created by an SLM policy but not those snapshots that were not created by an SLM policy. To include snapshots that were not created by an SLM policy, you can use the special pattern `_none` that will match all snapshots without an SLM policy. */
  slm_policy_filter?: Name
  /** The sort order for the result. The default behavior is sorting by snapshot start time stamp. */
  sort?: SnapshotSnapshotSort
  /** If `true`, returns additional information about each snapshot such as the version of Elasticsearch which took the snapshot, the start and end times of the snapshot, and the number of shards snapshotted. NOTE: The parameters `size`, `order`, `after`, `from_sort_value`, `offset`, `slm_policy_filter`, and `sort` are not supported when you set `verbose=false` and the sort order for requests with `verbose=false` is undefined. */
  verbose?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { repository?: never, snapshot?: never, after?: never, from_sort_value?: never, ignore_unavailable?: never, index_details?: never, index_names?: never, include_repository?: never, master_timeout?: never, order?: never, offset?: never, size?: never, slm_policy_filter?: never, sort?: never, verbose?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { repository?: never, snapshot?: never, after?: never, from_sort_value?: never, ignore_unavailable?: never, index_details?: never, index_names?: never, include_repository?: never, master_timeout?: never, order?: never, offset?: never, size?: never, slm_policy_filter?: never, sort?: never, verbose?: never }
}

export interface SnapshotGetResponse {
  remaining: integer
  total: integer
  next?: string
  responses?: SnapshotGetSnapshotResponseItem[]
  snapshots?: SnapshotSnapshotInfo[]
}

export interface SnapshotGetSnapshotResponseItem {
  repository: Name
  snapshots?: SnapshotSnapshotInfo[]
  error?: ErrorCause
}

export interface SnapshotGetRepositoryRequest extends RequestBase {
/** A comma-separated list of snapshot repository names used to limit the request. Wildcard (`*`) expressions are supported including combining wildcards with exclude patterns starting with `-`. To get information about all snapshot repositories registered in the cluster, omit this parameter or use `*` or `_all`. */
  name?: Names
  /** If `true`, the request gets information from the local node only. If `false`, the request gets information from the master node. */
  local?: boolean
  /** The period to wait for the master node. If the master node is not available before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, local?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, local?: never, master_timeout?: never }
}

export type SnapshotGetRepositoryResponse = Record<string, SnapshotRepository>

export interface SnapshotRepositoryAnalyzeBlobDetails {
  name: string
  overwritten: boolean
  read_early: boolean
  read_end: long
  read_start: long
  reads: SnapshotRepositoryAnalyzeReadBlobDetails
  size: ByteSize
  size_bytes: long
}

export interface SnapshotRepositoryAnalyzeDetailsInfo {
  blob: SnapshotRepositoryAnalyzeBlobDetails
  overwrite_elapsed?: Duration
  overwrite_elapsed_nanos?: DurationValue<UnitNanos>
  write_elapsed: Duration
  write_elapsed_nanos: DurationValue<UnitNanos>
  write_throttled: Duration
  write_throttled_nanos: DurationValue<UnitNanos>
  writer_node: SnapshotRepositoryAnalyzeSnapshotNodeInfo
}

export interface SnapshotRepositoryAnalyzeReadBlobDetails {
  before_write_complete?: boolean
  elapsed?: Duration
  elapsed_nanos?: DurationValue<UnitNanos>
  first_byte_time?: Duration
  first_byte_time_nanos: DurationValue<UnitNanos>
  found: boolean
  node: SnapshotRepositoryAnalyzeSnapshotNodeInfo
  throttled?: Duration
  throttled_nanos?: DurationValue<UnitNanos>
}

export interface SnapshotRepositoryAnalyzeReadSummaryInfo {
  count: integer
  max_wait: Duration
  max_wait_nanos: DurationValue<UnitNanos>
  total_elapsed: Duration
  total_elapsed_nanos: DurationValue<UnitNanos>
  total_size: ByteSize
  total_size_bytes: long
  total_throttled: Duration
  total_throttled_nanos: DurationValue<UnitNanos>
  total_wait: Duration
  total_wait_nanos: DurationValue<UnitNanos>
}

export interface SnapshotRepositoryAnalyzeRequest extends RequestBase {
/** The name of the repository. */
  name: Name
  /** The total number of blobs to write to the repository during the test. For realistic experiments, you should set it to at least `2000`. */
  blob_count?: integer
  /** The number of operations to run concurrently during the test. */
  concurrency?: integer
  /** Indicates whether to return detailed results, including timing information for every operation performed during the analysis. If false, it returns only a summary of the analysis. */
  detailed?: boolean
  /** The number of nodes on which to perform an early read operation while writing each blob. Early read operations are only rarely performed. */
  early_read_node_count?: integer
  /** The maximum size of a blob to be written during the test. For realistic experiments, you should set it to at least `2gb`. */
  max_blob_size?: ByteSize
  /** An upper limit on the total size of all the blobs written during the test. For realistic experiments, you should set it to at least `1tb`. */
  max_total_data_size?: ByteSize
  /** The probability of performing a rare action such as an early read, an overwrite, or an aborted write on each blob. */
  rare_action_probability?: double
  /** Indicates whether to rarely cancel writes before they complete. */
  rarely_abort_writes?: boolean
  /** The number of nodes on which to read a blob after writing. */
  read_node_count?: integer
  /** The minimum number of linearizable register operations to perform in total. For realistic experiments, you should set it to at least `100`. */
  register_operation_count?: integer
  /** The seed for the pseudo-random number generator used to generate the list of operations performed during the test. To repeat the same set of operations in multiple experiments, use the same seed in each experiment. Note that the operations are performed concurrently so might not always happen in the same order on each run. */
  seed?: integer
  /** The period of time to wait for the test to complete. If no response is received before the timeout expires, the test is cancelled and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, blob_count?: never, concurrency?: never, detailed?: never, early_read_node_count?: never, max_blob_size?: never, max_total_data_size?: never, rare_action_probability?: never, rarely_abort_writes?: never, read_node_count?: never, register_operation_count?: never, seed?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, blob_count?: never, concurrency?: never, detailed?: never, early_read_node_count?: never, max_blob_size?: never, max_total_data_size?: never, rare_action_probability?: never, rarely_abort_writes?: never, read_node_count?: never, register_operation_count?: never, seed?: never, timeout?: never }
}

export interface SnapshotRepositoryAnalyzeResponse {
  blob_count: integer
  blob_path: string
  concurrency: integer
  coordinating_node: SnapshotRepositoryAnalyzeSnapshotNodeInfo
  delete_elapsed: Duration
  delete_elapsed_nanos: DurationValue<UnitNanos>
  details: SnapshotRepositoryAnalyzeDetailsInfo
  early_read_node_count: integer
  issues_detected: string[]
  listing_elapsed: Duration
  listing_elapsed_nanos: DurationValue<UnitNanos>
  max_blob_size: ByteSize
  max_blob_size_bytes: long
  max_total_data_size: ByteSize
  max_total_data_size_bytes: long
  rare_action_probability: double
  read_node_count: integer
  repository: string
  seed: long
  summary: SnapshotRepositoryAnalyzeSummaryInfo
}

export interface SnapshotRepositoryAnalyzeSnapshotNodeInfo {
  id: Id
  name: Name
}

export interface SnapshotRepositoryAnalyzeSummaryInfo {
  read: SnapshotRepositoryAnalyzeReadSummaryInfo
  write: SnapshotRepositoryAnalyzeWriteSummaryInfo
}

export interface SnapshotRepositoryAnalyzeWriteSummaryInfo {
  count: integer
  total_elapsed: Duration
  total_elapsed_nanos: DurationValue<UnitNanos>
  total_size: ByteSize
  total_size_bytes: long
  total_throttled: Duration
  total_throttled_nanos: long
}

export interface SnapshotRepositoryVerifyIntegrityRequest extends RequestBase {
/** The name of the snapshot repository. */
  name: Names
  /** If `verify_blob_contents` is `true`, this parameter specifies how many blobs to verify at once. */
  blob_thread_pool_concurrency?: integer
  /** The maximum number of index snapshots to verify concurrently within each index verification. */
  index_snapshot_verification_concurrency?: integer
  /** The number of indices to verify concurrently. The default behavior is to use the entire `snapshot_meta` thread pool. */
  index_verification_concurrency?: integer
  /** If `verify_blob_contents` is `true`, this parameter specifies the maximum amount of data that Elasticsearch will read from the repository every second. */
  max_bytes_per_sec?: string
  /** The number of shard snapshot failures to track during integrity verification, in order to avoid excessive resource usage. If your repository contains more than this number of shard snapshot failures, the verification will fail. */
  max_failed_shard_snapshots?: integer
  /** The maximum number of snapshot metadata operations to run concurrently. The default behavior is to use at most half of the `snapshot_meta` thread pool at once. */
  meta_thread_pool_concurrency?: integer
  /** The number of snapshots to verify concurrently. The default behavior is to use at most half of the `snapshot_meta` thread pool at once. */
  snapshot_verification_concurrency?: integer
  /** Indicates whether to verify the checksum of every data blob in the repository. If this feature is enabled, Elasticsearch will read the entire repository contents, which may be extremely slow and expensive. */
  verify_blob_contents?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, blob_thread_pool_concurrency?: never, index_snapshot_verification_concurrency?: never, index_verification_concurrency?: never, max_bytes_per_sec?: never, max_failed_shard_snapshots?: never, meta_thread_pool_concurrency?: never, snapshot_verification_concurrency?: never, verify_blob_contents?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, blob_thread_pool_concurrency?: never, index_snapshot_verification_concurrency?: never, index_verification_concurrency?: never, max_bytes_per_sec?: never, max_failed_shard_snapshots?: never, meta_thread_pool_concurrency?: never, snapshot_verification_concurrency?: never, verify_blob_contents?: never }
}

export type SnapshotRepositoryVerifyIntegrityResponse = any

export interface SnapshotRestoreRequest extends RequestBase {
/** The name of the repository to restore a snapshot from. */
  repository: Name
  /** The name of the snapshot to restore. */
  snapshot: Name
  /** The period to wait for the master node. If the master node is not available before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** If `true`, the request returns a response when the restore operation completes. The operation is complete when it finishes all attempts to recover primary shards for restored indices. This applies even if one or more of the recovery attempts fail. If `false`, the request returns a response when the restore operation initializes. */
  wait_for_completion?: boolean
  /** The feature states to restore. If `include_global_state` is `true`, the request restores all feature states in the snapshot by default. If `include_global_state` is `false`, the request restores no feature states by default. Note that specifying an empty array will result in the default behavior. To restore no feature states, regardless of the `include_global_state` value, specify an array containing only the value `none` (`["none"]`). */
  feature_states?: string[]
  /** The index settings to not restore from the snapshot. You can't use this option to ignore `index.number_of_shards`. For data streams, this option applies only to restored backing indices. New backing indices are configured using the data stream's matching index template. */
  ignore_index_settings?: string[]
  /** If `true`, the request ignores any index or data stream in indices that's missing from the snapshot. If `false`, the request returns an error for any missing index or data stream. */
  ignore_unavailable?: boolean
  /** If `true`, the request restores aliases for any restored data streams and indices. If `false`, the request doesn’t restore aliases. */
  include_aliases?: boolean
  /** If `true`, restore the cluster state. The cluster state includes: * Persistent cluster settings * Index templates * Legacy index templates * Ingest pipelines * Index lifecycle management (ILM) policies * Stored scripts * For snapshots taken after 7.12.0, feature states If `include_global_state` is `true`, the restore operation merges the legacy index templates in your cluster with the templates contained in the snapshot, replacing any existing ones whose name matches one in the snapshot. It completely removes all persistent settings, non-legacy index templates, ingest pipelines, and ILM lifecycle policies that exist in your cluster and replaces them with the corresponding items from the snapshot. Use the `feature_states` parameter to configure how feature states are restored. If `include_global_state` is `true` and a snapshot was created without a global state then the restore request will fail. */
  include_global_state?: boolean
  /** Index settings to add or change in restored indices, including backing indices. You can't use this option to change `index.number_of_shards`. For data streams, this option applies only to restored backing indices. New backing indices are configured using the data stream's matching index template. */
  index_settings?: IndicesIndexSettings
  /** A comma-separated list of indices and data streams to restore. It supports a multi-target syntax. The default behavior is all regular indices and regular data streams in the snapshot. You can't use this parameter to restore system indices or system data streams. Use `feature_states` instead. */
  indices?: Indices
  /** If `false`, the entire restore operation will fail if one or more indices included in the snapshot do not have all primary shards available. If true, it allows restoring a partial snapshot of indices with unavailable shards. Only shards that were successfully included in the snapshot will be restored. All missing shards will be recreated as empty. */
  partial?: boolean
  /** A rename pattern to apply to restored data streams and indices. Data streams and indices matching the rename pattern will be renamed according to `rename_replacement`. The rename pattern is applied as defined by the regular expression that supports referencing the original text, according to the `appendReplacement` logic. */
  rename_pattern?: string
  /** The rename replacement string that is used with the `rename_pattern`. */
  rename_replacement?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { repository?: never, snapshot?: never, master_timeout?: never, wait_for_completion?: never, feature_states?: never, ignore_index_settings?: never, ignore_unavailable?: never, include_aliases?: never, include_global_state?: never, index_settings?: never, indices?: never, partial?: never, rename_pattern?: never, rename_replacement?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { repository?: never, snapshot?: never, master_timeout?: never, wait_for_completion?: never, feature_states?: never, ignore_index_settings?: never, ignore_unavailable?: never, include_aliases?: never, include_global_state?: never, index_settings?: never, indices?: never, partial?: never, rename_pattern?: never, rename_replacement?: never }
}

export interface SnapshotRestoreResponse {
  accepted?: boolean
  snapshot?: SnapshotRestoreSnapshotRestore
}

export interface SnapshotRestoreSnapshotRestore {
  indices: IndexName[]
  snapshot: string
  shards: ShardStatistics
}

export interface SnapshotStatusRequest extends RequestBase {
/** The snapshot repository name used to limit the request. It supports wildcards (`*`) if `<snapshot>` isn't specified. */
  repository?: Name
  /** A comma-separated list of snapshots to retrieve status for. The default is currently running snapshots. Wildcards (`*`) are not supported. */
  snapshot?: Names
  /** If `false`, the request returns an error for any snapshots that are unavailable. If `true`, the request ignores snapshots that are unavailable, such as those that are corrupted or temporarily cannot be returned. */
  ignore_unavailable?: boolean
  /** The period to wait for the master node. If the master node is not available before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { repository?: never, snapshot?: never, ignore_unavailable?: never, master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { repository?: never, snapshot?: never, ignore_unavailable?: never, master_timeout?: never }
}

export interface SnapshotStatusResponse {
  snapshots: SnapshotStatus[]
}

export interface SnapshotVerifyRepositoryCompactNodeInfo {
  name: Name
}

export interface SnapshotVerifyRepositoryRequest extends RequestBase {
/** The name of the snapshot repository to verify. */
  name: Name
  /** The period to wait for the master node. If the master node is not available before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** The period to wait for a response from all relevant nodes in the cluster after updating the cluster metadata. If no response is received before the timeout expires, the cluster metadata update still applies but the response will indicate that it was not completely acknowledged. To indicate that the request should never timeout, set it to `-1`. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { name?: never, master_timeout?: never, timeout?: never }
}

export interface SnapshotVerifyRepositoryResponse {
  nodes: Record<string, SnapshotVerifyRepositoryCompactNodeInfo>
}

export interface SqlColumn {
  name: Name
  type: string
}

export type SqlRow = any[]

export interface SqlClearCursorRequest extends RequestBase {
/** Cursor to clear. */
  cursor: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { cursor?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { cursor?: never }
}

export interface SqlClearCursorResponse {
  succeeded: boolean
}

export interface SqlDeleteAsyncRequest extends RequestBase {
/** The identifier for the search. */
  id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export type SqlDeleteAsyncResponse = AcknowledgedResponseBase

export interface SqlGetAsyncRequest extends RequestBase {
/** The identifier for the search. */
  id: Id
  /** The separator for CSV results. The API supports this parameter only for CSV responses. */
  delimiter?: string
  /** The format for the response. You must specify a format using this parameter or the `Accept` HTTP header. If you specify both, the API uses this parameter. */
  format?: string
  /** The retention period for the search and its results. It defaults to the `keep_alive` period for the original SQL search. */
  keep_alive?: Duration
  /** The period to wait for complete results. It defaults to no timeout, meaning the request waits for complete search results. */
  wait_for_completion_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, delimiter?: never, format?: never, keep_alive?: never, wait_for_completion_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, delimiter?: never, format?: never, keep_alive?: never, wait_for_completion_timeout?: never }
}

export interface SqlGetAsyncResponse {
  id: Id
  is_running: boolean
  is_partial: boolean
  columns?: SqlColumn[]
  cursor?: string
  rows: SqlRow[]
}

export interface SqlGetAsyncStatusRequest extends RequestBase {
/** The identifier for the search. */
  id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export interface SqlGetAsyncStatusResponse {
  expiration_time_in_millis: EpochTime<UnitMillis>
  id: string
  is_running: boolean
  is_partial: boolean
  start_time_in_millis: EpochTime<UnitMillis>
  completion_status?: uint
}

export interface SqlQueryRequest extends RequestBase {
/** The format for the response. You can also specify a format using the `Accept` HTTP header. If you specify both this parameter and the `Accept` HTTP header, this parameter takes precedence. */
  format?: SqlQuerySqlFormat
  /** If `true`, the response has partial results when there are shard request timeouts or shard failures. If `false`, the API returns an error with no partial results. */
  allow_partial_search_results?: boolean
  /** The default catalog (cluster) for queries. If unspecified, the queries execute on the data in the local cluster only. */
  catalog?: string
  /** If `true`, the results are in a columnar fashion: one row represents all the values of a certain column from the current page of results. The API supports this parameter only for CBOR, JSON, SMILE, and YAML responses. */
  columnar?: boolean
  /** The cursor used to retrieve a set of paginated results. If you specify a cursor, the API only uses the `columnar` and `time_zone` request body parameters. It ignores other request body parameters. */
  cursor?: string
  /** The maximum number of rows (or entries) to return in one response. */
  fetch_size?: integer
  /** If `false`, the API returns an exception when encountering multiple values for a field. If `true`, the API is lenient and returns the first value from the array with no guarantee of consistent results. */
  field_multi_value_leniency?: boolean
  /** The Elasticsearch query DSL for additional filtering. */
  filter?: QueryDslQueryContainer
  /** If `true`, the search can run on frozen indices. */
  index_using_frozen?: boolean
  /** The retention period for an async or saved synchronous search. */
  keep_alive?: Duration
  /** If `true`, Elasticsearch stores synchronous searches if you also specify the `wait_for_completion_timeout` parameter. If `false`, Elasticsearch only stores async searches that don't finish before the `wait_for_completion_timeout`. */
  keep_on_completion?: boolean
  /** The minimum retention period for the scroll cursor. After this time period, a pagination request might fail because the scroll cursor is no longer available. Subsequent scroll requests prolong the lifetime of the scroll cursor by the duration of `page_timeout` in the scroll request. */
  page_timeout?: Duration
  /** The values for parameters in the query. */
  params?: Record<string, any>
  /** The SQL query to run. */
  query?: string
  /** The timeout before the request fails. */
  request_timeout?: Duration
  /** One or more runtime fields for the search request. These fields take precedence over mapped fields with the same name. */
  runtime_mappings?: MappingRuntimeFields
  /** The ISO-8601 time zone ID for the search. */
  time_zone?: TimeZone
  /** The period to wait for complete results. It defaults to no timeout, meaning the request waits for complete search results. If the search doesn't finish within this period, the search becomes async. To save a synchronous search, you must specify this parameter and the `keep_on_completion` parameter. */
  wait_for_completion_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { format?: never, allow_partial_search_results?: never, catalog?: never, columnar?: never, cursor?: never, fetch_size?: never, field_multi_value_leniency?: never, filter?: never, index_using_frozen?: never, keep_alive?: never, keep_on_completion?: never, page_timeout?: never, params?: never, query?: never, request_timeout?: never, runtime_mappings?: never, time_zone?: never, wait_for_completion_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { format?: never, allow_partial_search_results?: never, catalog?: never, columnar?: never, cursor?: never, fetch_size?: never, field_multi_value_leniency?: never, filter?: never, index_using_frozen?: never, keep_alive?: never, keep_on_completion?: never, page_timeout?: never, params?: never, query?: never, request_timeout?: never, runtime_mappings?: never, time_zone?: never, wait_for_completion_timeout?: never }
}

export interface SqlQueryResponse {
  columns?: SqlColumn[]
  cursor?: string
  id?: Id
  is_running?: boolean
  is_partial?: boolean
  rows: SqlRow[]
}

export type SqlQuerySqlFormat = 'csv' | 'json' | 'tsv' | 'txt' | 'yaml' | 'cbor' | 'smile'

export interface SqlTranslateRequest extends RequestBase {
/** The maximum number of rows (or entries) to return in one response. */
  fetch_size?: integer
  /** The Elasticsearch query DSL for additional filtering. */
  filter?: QueryDslQueryContainer
  /** The SQL query to run. */
  query: string
  /** The ISO-8601 time zone ID for the search. */
  time_zone?: TimeZone
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { fetch_size?: never, filter?: never, query?: never, time_zone?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { fetch_size?: never, filter?: never, query?: never, time_zone?: never }
}

export interface SqlTranslateResponse {
  aggregations?: Record<string, AggregationsAggregationContainer>
  size?: long
  _source?: SearchSourceConfig
  fields?: (QueryDslFieldAndFormat | Field)[]
  query?: QueryDslQueryContainer
  sort?: Sort
}

export interface SslCertificatesCertificateInformation {
  alias: string | null
  expiry: DateTime
  format: string
  has_private_key: boolean
  issuer?: string
  path: string
  serial_number: string
  subject_dn: string
}

export interface SslCertificatesRequest extends RequestBase {
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any }
}

export type SslCertificatesResponse = SslCertificatesCertificateInformation[]

export interface SynonymsSynonymRule {
  id?: Id
  synonyms: SynonymsSynonymString
}

export interface SynonymsSynonymRuleRead {
  id: Id
  synonyms: SynonymsSynonymString
}

export type SynonymsSynonymString = string

export interface SynonymsSynonymsUpdateResult {
  result: Result
  reload_analyzers_details: IndicesReloadSearchAnalyzersReloadResult
}

export interface SynonymsDeleteSynonymRequest extends RequestBase {
/** The synonyms set identifier to delete. */
  id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export type SynonymsDeleteSynonymResponse = AcknowledgedResponseBase

export interface SynonymsDeleteSynonymRuleRequest extends RequestBase {
/** The ID of the synonym set to update. */
  set_id: Id
  /** The ID of the synonym rule to delete. */
  rule_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { set_id?: never, rule_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { set_id?: never, rule_id?: never }
}

export type SynonymsDeleteSynonymRuleResponse = SynonymsSynonymsUpdateResult

export interface SynonymsGetSynonymRequest extends RequestBase {
/** The synonyms set identifier to retrieve. */
  id: Id
  /** The starting offset for query rules to retrieve. */
  from?: integer
  /** The max number of query rules to retrieve. */
  size?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, from?: never, size?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, from?: never, size?: never }
}

export interface SynonymsGetSynonymResponse {
  count: integer
  synonyms_set: SynonymsSynonymRuleRead[]
}

export interface SynonymsGetSynonymRuleRequest extends RequestBase {
/** The ID of the synonym set to retrieve the synonym rule from. */
  set_id: Id
  /** The ID of the synonym rule to retrieve. */
  rule_id: Id
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { set_id?: never, rule_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { set_id?: never, rule_id?: never }
}

export type SynonymsGetSynonymRuleResponse = SynonymsSynonymRuleRead

export interface SynonymsGetSynonymsSetsRequest extends RequestBase {
/** The starting offset for synonyms sets to retrieve. */
  from?: integer
  /** The maximum number of synonyms sets to retrieve. */
  size?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { from?: never, size?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { from?: never, size?: never }
}

export interface SynonymsGetSynonymsSetsResponse {
  count: integer
  results: SynonymsGetSynonymsSetsSynonymsSetItem[]
}

export interface SynonymsGetSynonymsSetsSynonymsSetItem {
  synonyms_set: Id
  count: integer
}

export interface SynonymsPutSynonymRequest extends RequestBase {
/** The ID of the synonyms set to be created or updated. */
  id: Id
  /** The synonym rules definitions for the synonyms set. */
  synonyms_set: SynonymsSynonymRule | SynonymsSynonymRule[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, synonyms_set?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, synonyms_set?: never }
}

export interface SynonymsPutSynonymResponse {
  result: Result
  reload_analyzers_details: IndicesReloadSearchAnalyzersReloadResult
}

export interface SynonymsPutSynonymRuleRequest extends RequestBase {
/** The ID of the synonym set. */
  set_id: Id
  /** The ID of the synonym rule to be updated or created. */
  rule_id: Id
  /** The synonym rule information definition, which must be in Solr format. */
  synonyms: SynonymsSynonymString
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { set_id?: never, rule_id?: never, synonyms?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { set_id?: never, rule_id?: never, synonyms?: never }
}

export type SynonymsPutSynonymRuleResponse = SynonymsSynonymsUpdateResult

export type TasksGroupBy = 'nodes' | 'parents' | 'none'

export interface TasksNodeTasks {
  name?: NodeId
  transport_address?: TransportAddress
  host?: Host
  ip?: Ip
  roles?: string[]
  attributes?: Record<string, string>
  tasks: Record<TaskId, TasksTaskInfo>
}

export interface TasksParentTaskInfo extends TasksTaskInfo {
  children?: TasksTaskInfo[]
}

export interface TasksTaskInfo {
  action: string
  cancelled?: boolean
  cancellable: boolean
  description?: string
  headers: Record<string, string>
  id: long
  node: NodeId
  running_time?: Duration
  running_time_in_nanos: DurationValue<UnitNanos>
  start_time_in_millis: EpochTime<UnitMillis>
  status?: any
  type: string
  parent_task_id?: TaskId
}

export type TasksTaskInfos = TasksTaskInfo[] | Record<string, TasksParentTaskInfo>

export interface TasksTaskListResponseBase {
  node_failures?: ErrorCause[]
  task_failures?: TaskFailure[]
  nodes?: Record<string, TasksNodeTasks>
  tasks?: TasksTaskInfos
}

export interface TasksCancelRequest extends RequestBase {
/** The task identifier. */
  task_id?: TaskId
  /** A comma-separated list or wildcard expression of actions that is used to limit the request. */
  actions?: string | string[]
  /** A comma-separated list of node IDs or names that is used to limit the request. */
  nodes?: string[]
  /** A parent task ID that is used to limit the tasks. */
  parent_task_id?: string
  /** If true, the request blocks until all found tasks are complete. */
  wait_for_completion?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { task_id?: never, actions?: never, nodes?: never, parent_task_id?: never, wait_for_completion?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { task_id?: never, actions?: never, nodes?: never, parent_task_id?: never, wait_for_completion?: never }
}

export type TasksCancelResponse = TasksTaskListResponseBase

export interface TasksGetRequest extends RequestBase {
/** The task identifier. */
  task_id: Id
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** If `true`, the request blocks until the task has completed. */
  wait_for_completion?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { task_id?: never, timeout?: never, wait_for_completion?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { task_id?: never, timeout?: never, wait_for_completion?: never }
}

export interface TasksGetResponse {
  completed: boolean
  task: TasksTaskInfo
  response?: any
  error?: ErrorCause
}

export interface TasksListRequest extends RequestBase {
/** A comma-separated list or wildcard expression of actions used to limit the request. For example, you can use `cluser:*` to retrieve all cluster-related tasks. */
  actions?: string | string[]
  /** If `true`, the response includes detailed information about the running tasks. This information is useful to distinguish tasks from each other but is more costly to run. */
  detailed?: boolean
  /** A key that is used to group tasks in the response. The task lists can be grouped either by nodes or by parent tasks. */
  group_by?: TasksGroupBy
  /** A comma-separated list of node IDs or names that is used to limit the returned information. */
  nodes?: NodeIds
  /** A parent task identifier that is used to limit returned information. To return all tasks, omit this parameter or use a value of `-1`. If the parent task is not found, the API does not return a 404 response code. */
  parent_task_id?: Id
  /** The period to wait for each node to respond. If a node does not respond before its timeout expires, the response does not include its information. However, timed out nodes are included in the `node_failures` property. */
  timeout?: Duration
  /** If `true`, the request blocks until the operation is complete. */
  wait_for_completion?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { actions?: never, detailed?: never, group_by?: never, nodes?: never, parent_task_id?: never, timeout?: never, wait_for_completion?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { actions?: never, detailed?: never, group_by?: never, nodes?: never, parent_task_id?: never, timeout?: never, wait_for_completion?: never }
}

export type TasksListResponse = TasksTaskListResponseBase

export type TextStructureEcsCompatibilityType = 'disabled' | 'v1'

export interface TextStructureFieldStat {
  count: integer
  cardinality: integer
  top_hits: TextStructureTopHit[]
  mean_value?: integer
  median_value?: integer
  max_value?: integer
  min_value?: integer
  earliest?: string
  latest?: string
}

export type TextStructureFormatType = 'delimited' | 'ndjson' | 'semi_structured_text' | 'xml'

export interface TextStructureTopHit {
  count: long
  value: any
}

export interface TextStructureFindFieldStructureRequest extends RequestBase {
/** If `format` is set to `delimited`, you can specify the column names in a comma-separated list. If this parameter is not specified, the structure finder uses the column names from the header row of the text. If the text does not have a header row, columns are named "column1", "column2", "column3", for example. */
  column_names?: string
  /** If you have set `format` to `delimited`, you can specify the character used to delimit the values in each row. Only a single character is supported; the delimiter cannot have multiple characters. By default, the API considers the following possibilities: comma, tab, semi-colon, and pipe (`|`). In this default scenario, all rows must have the same number of fields for the delimited format to be detected. If you specify a delimiter, up to 10% of the rows can have a different number of columns than the first row. */
  delimiter?: string
  /** The number of documents to include in the structural analysis. The minimum value is 2. */
  documents_to_sample?: uint
  /** The mode of compatibility with ECS compliant Grok patterns. Use this parameter to specify whether to use ECS Grok patterns instead of legacy ones when the structure finder creates a Grok pattern. This setting primarily has an impact when a whole message Grok pattern such as `%{CATALINALOG}` matches the input. If the structure finder identifies a common structure but has no idea of the meaning then generic field names such as `path`, `ipaddress`, `field1`, and `field2` are used in the `grok_pattern` output. The intention in that situation is that a user who knows the meanings will rename the fields before using them. */
  ecs_compatibility?: TextStructureEcsCompatibilityType
  /** If `true`, the response includes a field named `explanation`, which is an array of strings that indicate how the structure finder produced its result. */
  explain?: boolean
  /** The field that should be analyzed. */
  field: Field
  /** The high level structure of the text. By default, the API chooses the format. In this default scenario, all rows must have the same number of fields for a delimited format to be detected. If the format is set to delimited and the delimiter is not set, however, the API tolerates up to 5% of rows that have a different number of columns than the first row. */
  format?: TextStructureFormatType
  /** If the format is `semi_structured_text`, you can specify a Grok pattern that is used to extract fields from every message in the text. The name of the timestamp field in the Grok pattern must match what is specified in the `timestamp_field` parameter. If that parameter is not specified, the name of the timestamp field in the Grok pattern must match "timestamp". If `grok_pattern` is not specified, the structure finder creates a Grok pattern. */
  grok_pattern?: GrokPattern
  /** The name of the index that contains the analyzed field. */
  index: IndexName
  /** If the format is `delimited`, you can specify the character used to quote the values in each row if they contain newlines or the delimiter character. Only a single character is supported. If this parameter is not specified, the default value is a double quote (`"`). If your delimited text format does not use quoting, a workaround is to set this argument to a character that does not appear anywhere in the sample. */
  quote?: string
  /** If the format is `delimited`, you can specify whether values between delimiters should have whitespace trimmed from them. If this parameter is not specified and the delimiter is pipe (`|`), the default value is true. Otherwise, the default value is `false`. */
  should_trim_fields?: boolean
  /** The maximum amount of time that the structure analysis can take. If the analysis is still running when the timeout expires, it will be stopped. */
  timeout?: Duration
  /** The name of the field that contains the primary timestamp of each record in the text. In particular, if the text was ingested into an index, this is the field that would be used to populate the `@timestamp` field. If the format is `semi_structured_text`, this field must match the name of the appropriate extraction in the `grok_pattern`. Therefore, for semi-structured text, it is best not to specify this parameter unless `grok_pattern` is also specified. For structured text, if you specify this parameter, the field must exist within the text. If this parameter is not specified, the structure finder makes a decision about which field (if any) is the primary timestamp field. For structured text, it is not compulsory to have a timestamp in the text. */
  timestamp_field?: Field
  /** The Java time format of the timestamp field in the text. Only a subset of Java time format letter groups are supported: * `a` * `d` * `dd` * `EEE` * `EEEE` * `H` * `HH` * `h` * `M` * `MM` * `MMM` * `MMMM` * `mm` * `ss` * `XX` * `XXX` * `yy` * `yyyy` * `zzz` Additionally `S` letter groups (fractional seconds) of length one to nine are supported providing they occur after `ss` and are separated from the `ss` by a period (`.`), comma (`,`), or colon (`:`). Spacing and punctuation is also permitted with the exception a question mark (`?`), newline, and carriage return, together with literal text enclosed in single quotes. For example, `MM/dd HH.mm.ss,SSSSSS 'in' yyyy` is a valid override format. One valuable use case for this parameter is when the format is semi-structured text, there are multiple timestamp formats in the text, and you know which format corresponds to the primary timestamp, but you do not want to specify the full `grok_pattern`. Another is when the timestamp format is one that the structure finder does not consider by default. If this parameter is not specified, the structure finder chooses the best format from a built-in set. If the special value `null` is specified, the structure finder will not look for a primary timestamp in the text. When the format is semi-structured text, this will result in the structure finder treating the text as single-line messages. */
  timestamp_format?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { column_names?: never, delimiter?: never, documents_to_sample?: never, ecs_compatibility?: never, explain?: never, field?: never, format?: never, grok_pattern?: never, index?: never, quote?: never, should_trim_fields?: never, timeout?: never, timestamp_field?: never, timestamp_format?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { column_names?: never, delimiter?: never, documents_to_sample?: never, ecs_compatibility?: never, explain?: never, field?: never, format?: never, grok_pattern?: never, index?: never, quote?: never, should_trim_fields?: never, timeout?: never, timestamp_field?: never, timestamp_format?: never }
}

export interface TextStructureFindFieldStructureResponse {
  charset: string
  ecs_compatibility?: TextStructureEcsCompatibilityType
  field_stats: Record<Field, TextStructureFieldStat>
  format: TextStructureFormatType
  grok_pattern?: GrokPattern
  java_timestamp_formats?: string[]
  joda_timestamp_formats?: string[]
  ingest_pipeline: IngestPipelineConfig
  mappings: MappingTypeMapping
  multiline_start_pattern?: string
  need_client_timezone: boolean
  num_lines_analyzed: integer
  num_messages_analyzed: integer
  sample_start: string
  timestamp_field?: Field
}

export interface TextStructureFindMessageStructureRequest extends RequestBase {
/** If the format is `delimited`, you can specify the column names in a comma-separated list. If this parameter is not specified, the structure finder uses the column names from the header row of the text. If the text does not have a header role, columns are named "column1", "column2", "column3", for example. */
  column_names?: string
  /** If you the format is `delimited`, you can specify the character used to delimit the values in each row. Only a single character is supported; the delimiter cannot have multiple characters. By default, the API considers the following possibilities: comma, tab, semi-colon, and pipe (`|`). In this default scenario, all rows must have the same number of fields for the delimited format to be detected. If you specify a delimiter, up to 10% of the rows can have a different number of columns than the first row. */
  delimiter?: string
  /** The mode of compatibility with ECS compliant Grok patterns. Use this parameter to specify whether to use ECS Grok patterns instead of legacy ones when the structure finder creates a Grok pattern. This setting primarily has an impact when a whole message Grok pattern such as `%{CATALINALOG}` matches the input. If the structure finder identifies a common structure but has no idea of meaning then generic field names such as `path`, `ipaddress`, `field1`, and `field2` are used in the `grok_pattern` output, with the intention that a user who knows the meanings rename these fields before using it. */
  ecs_compatibility?: TextStructureEcsCompatibilityType
  /** If this parameter is set to true, the response includes a field named `explanation`, which is an array of strings that indicate how the structure finder produced its result. */
  explain?: boolean
  /** The high level structure of the text. By default, the API chooses the format. In this default scenario, all rows must have the same number of fields for a delimited format to be detected. If the format is `delimited` and the delimiter is not set, however, the API tolerates up to 5% of rows that have a different number of columns than the first row. */
  format?: TextStructureFormatType
  /** If the format is `semi_structured_text`, you can specify a Grok pattern that is used to extract fields from every message in the text. The name of the timestamp field in the Grok pattern must match what is specified in the `timestamp_field` parameter. If that parameter is not specified, the name of the timestamp field in the Grok pattern must match "timestamp". If `grok_pattern` is not specified, the structure finder creates a Grok pattern. */
  grok_pattern?: GrokPattern
  /** If the format is `delimited`, you can specify the character used to quote the values in each row if they contain newlines or the delimiter character. Only a single character is supported. If this parameter is not specified, the default value is a double quote (`"`). If your delimited text format does not use quoting, a workaround is to set this argument to a character that does not appear anywhere in the sample. */
  quote?: string
  /** If the format is `delimited`, you can specify whether values between delimiters should have whitespace trimmed from them. If this parameter is not specified and the delimiter is pipe (`|`), the default value is true. Otherwise, the default value is `false`. */
  should_trim_fields?: boolean
  /** The maximum amount of time that the structure analysis can take. If the analysis is still running when the timeout expires, it will be stopped. */
  timeout?: Duration
  /** The name of the field that contains the primary timestamp of each record in the text. In particular, if the text was ingested into an index, this is the field that would be used to populate the `@timestamp` field. If the format is `semi_structured_text`, this field must match the name of the appropriate extraction in the `grok_pattern`. Therefore, for semi-structured text, it is best not to specify this parameter unless `grok_pattern` is also specified. For structured text, if you specify this parameter, the field must exist within the text. If this parameter is not specified, the structure finder makes a decision about which field (if any) is the primary timestamp field. For structured text, it is not compulsory to have a timestamp in the text. */
  timestamp_field?: Field
  /** The Java time format of the timestamp field in the text. Only a subset of Java time format letter groups are supported: * `a` * `d` * `dd` * `EEE` * `EEEE` * `H` * `HH` * `h` * `M` * `MM` * `MMM` * `MMMM` * `mm` * `ss` * `XX` * `XXX` * `yy` * `yyyy` * `zzz` Additionally `S` letter groups (fractional seconds) of length one to nine are supported providing they occur after `ss` and are separated from the `ss` by a period (`.`), comma (`,`), or colon (`:`). Spacing and punctuation is also permitted with the exception a question mark (`?`), newline, and carriage return, together with literal text enclosed in single quotes. For example, `MM/dd HH.mm.ss,SSSSSS 'in' yyyy` is a valid override format. One valuable use case for this parameter is when the format is semi-structured text, there are multiple timestamp formats in the text, and you know which format corresponds to the primary timestamp, but you do not want to specify the full `grok_pattern`. Another is when the timestamp format is one that the structure finder does not consider by default. If this parameter is not specified, the structure finder chooses the best format from a built-in set. If the special value `null` is specified, the structure finder will not look for a primary timestamp in the text. When the format is semi-structured text, this will result in the structure finder treating the text as single-line messages. */
  timestamp_format?: string
  /** The list of messages you want to analyze. */
  messages: string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { column_names?: never, delimiter?: never, ecs_compatibility?: never, explain?: never, format?: never, grok_pattern?: never, quote?: never, should_trim_fields?: never, timeout?: never, timestamp_field?: never, timestamp_format?: never, messages?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { column_names?: never, delimiter?: never, ecs_compatibility?: never, explain?: never, format?: never, grok_pattern?: never, quote?: never, should_trim_fields?: never, timeout?: never, timestamp_field?: never, timestamp_format?: never, messages?: never }
}

export interface TextStructureFindMessageStructureResponse {
  charset: string
  ecs_compatibility?: TextStructureEcsCompatibilityType
  field_stats: Record<Field, TextStructureFieldStat>
  format: TextStructureFormatType
  grok_pattern?: GrokPattern
  java_timestamp_formats?: string[]
  joda_timestamp_formats?: string[]
  ingest_pipeline: IngestPipelineConfig
  mappings: MappingTypeMapping
  multiline_start_pattern?: string
  need_client_timezone: boolean
  num_lines_analyzed: integer
  num_messages_analyzed: integer
  sample_start: string
  timestamp_field?: Field
}

export interface TextStructureFindStructureRequest<TJsonDocument = unknown> {
/** The text's character set. It must be a character set that is supported by the JVM that Elasticsearch uses. For example, `UTF-8`, `UTF-16LE`, `windows-1252`, or `EUC-JP`. If this parameter is not specified, the structure finder chooses an appropriate character set. */
  charset?: string
  /** If you have set format to `delimited`, you can specify the column names in a comma-separated list. If this parameter is not specified, the structure finder uses the column names from the header row of the text. If the text does not have a header role, columns are named "column1", "column2", "column3", for example. */
  column_names?: string
  /** If you have set `format` to `delimited`, you can specify the character used to delimit the values in each row. Only a single character is supported; the delimiter cannot have multiple characters. By default, the API considers the following possibilities: comma, tab, semi-colon, and pipe (`|`). In this default scenario, all rows must have the same number of fields for the delimited format to be detected. If you specify a delimiter, up to 10% of the rows can have a different number of columns than the first row. */
  delimiter?: string
  /** The mode of compatibility with ECS compliant Grok patterns. Use this parameter to specify whether to use ECS Grok patterns instead of legacy ones when the structure finder creates a Grok pattern. Valid values are `disabled` and `v1`. This setting primarily has an impact when a whole message Grok pattern such as `%{CATALINALOG}` matches the input. If the structure finder identifies a common structure but has no idea of meaning then generic field names such as `path`, `ipaddress`, `field1`, and `field2` are used in the `grok_pattern` output, with the intention that a user who knows the meanings rename these fields before using it. */
  ecs_compatibility?: string
  /** If this parameter is set to `true`, the response includes a field named explanation, which is an array of strings that indicate how the structure finder produced its result. If the structure finder produces unexpected results for some text, use this query parameter to help you determine why the returned structure was chosen. */
  explain?: boolean
  /** The high level structure of the text. Valid values are `ndjson`, `xml`, `delimited`, and `semi_structured_text`. By default, the API chooses the format. In this default scenario, all rows must have the same number of fields for a delimited format to be detected. If the format is set to `delimited` and the delimiter is not set, however, the API tolerates up to 5% of rows that have a different number of columns than the first row. */
  format?: string
  /** If you have set `format` to `semi_structured_text`, you can specify a Grok pattern that is used to extract fields from every message in the text. The name of the timestamp field in the Grok pattern must match what is specified in the `timestamp_field` parameter. If that parameter is not specified, the name of the timestamp field in the Grok pattern must match "timestamp". If `grok_pattern` is not specified, the structure finder creates a Grok pattern. */
  grok_pattern?: GrokPattern
  /** If you have set `format` to `delimited`, you can use this parameter to indicate whether the column names are in the first row of the text. If this parameter is not specified, the structure finder guesses based on the similarity of the first row of the text to other rows. */
  has_header_row?: boolean
  /** The maximum number of characters in a message when lines are merged to form messages while analyzing semi-structured text. If you have extremely long messages you may need to increase this, but be aware that this may lead to very long processing times if the way to group lines into messages is misdetected. */
  line_merge_size_limit?: uint
  /** The number of lines to include in the structural analysis, starting from the beginning of the text. The minimum is 2. If the value of this parameter is greater than the number of lines in the text, the analysis proceeds (as long as there are at least two lines in the text) for all of the lines. NOTE: The number of lines and the variation of the lines affects the speed of the analysis. For example, if you upload text where the first 1000 lines are all variations on the same message, the analysis will find more commonality than would be seen with a bigger sample. If possible, however, it is more efficient to upload sample text with more variety in the first 1000 lines than to request analysis of 100000 lines to achieve some variety. */
  lines_to_sample?: uint
  /** If you have set `format` to `delimited`, you can specify the character used to quote the values in each row if they contain newlines or the delimiter character. Only a single character is supported. If this parameter is not specified, the default value is a double quote (`"`). If your delimited text format does not use quoting, a workaround is to set this argument to a character that does not appear anywhere in the sample. */
  quote?: string
  /** If you have set `format` to `delimited`, you can specify whether values between delimiters should have whitespace trimmed from them. If this parameter is not specified and the delimiter is pipe (`|`), the default value is `true`. Otherwise, the default value is `false`. */
  should_trim_fields?: boolean
  /** The maximum amount of time that the structure analysis can take. If the analysis is still running when the timeout expires then it will be stopped. */
  timeout?: Duration
  /** The name of the field that contains the primary timestamp of each record in the text. In particular, if the text were ingested into an index, this is the field that would be used to populate the `@timestamp` field. If the `format` is `semi_structured_text`, this field must match the name of the appropriate extraction in the `grok_pattern`. Therefore, for semi-structured text, it is best not to specify this parameter unless `grok_pattern` is also specified. For structured text, if you specify this parameter, the field must exist within the text. If this parameter is not specified, the structure finder makes a decision about which field (if any) is the primary timestamp field. For structured text, it is not compulsory to have a timestamp in the text. */
  timestamp_field?: Field
  /** The Java time format of the timestamp field in the text. Only a subset of Java time format letter groups are supported: * `a` * `d` * `dd` * `EEE` * `EEEE` * `H` * `HH` * `h` * `M` * `MM` * `MMM` * `MMMM` * `mm` * `ss` * `XX` * `XXX` * `yy` * `yyyy` * `zzz` Additionally `S` letter groups (fractional seconds) of length one to nine are supported providing they occur after `ss` and separated from the `ss` by a `.`, `,` or `:`. Spacing and punctuation is also permitted with the exception of `?`, newline and carriage return, together with literal text enclosed in single quotes. For example, `MM/dd HH.mm.ss,SSSSSS 'in' yyyy` is a valid override format. One valuable use case for this parameter is when the format is semi-structured text, there are multiple timestamp formats in the text, and you know which format corresponds to the primary timestamp, but you do not want to specify the full `grok_pattern`. Another is when the timestamp format is one that the structure finder does not consider by default. If this parameter is not specified, the structure finder chooses the best format from a built-in set. If the special value `null` is specified the structure finder will not look for a primary timestamp in the text. When the format is semi-structured text this will result in the structure finder treating the text as single-line messages. */
  timestamp_format?: string
  text_files?: TJsonDocument[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { charset?: never, column_names?: never, delimiter?: never, ecs_compatibility?: never, explain?: never, format?: never, grok_pattern?: never, has_header_row?: never, line_merge_size_limit?: never, lines_to_sample?: never, quote?: never, should_trim_fields?: never, timeout?: never, timestamp_field?: never, timestamp_format?: never, text_files?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { charset?: never, column_names?: never, delimiter?: never, ecs_compatibility?: never, explain?: never, format?: never, grok_pattern?: never, has_header_row?: never, line_merge_size_limit?: never, lines_to_sample?: never, quote?: never, should_trim_fields?: never, timeout?: never, timestamp_field?: never, timestamp_format?: never, text_files?: never }
}

export interface TextStructureFindStructureResponse {
  charset: string
  has_header_row?: boolean
  has_byte_order_marker: boolean
  format: string
  field_stats: Record<Field, TextStructureFieldStat>
  sample_start: string
  num_messages_analyzed: integer
  mappings: MappingTypeMapping
  quote?: string
  delimiter?: string
  need_client_timezone: boolean
  num_lines_analyzed: integer
  column_names?: string[]
  explanation?: string[]
  grok_pattern?: GrokPattern
  multiline_start_pattern?: string
  exclude_lines_pattern?: string
  java_timestamp_formats?: string[]
  joda_timestamp_formats?: string[]
  timestamp_field?: Field
  should_trim_fields?: boolean
  ingest_pipeline: IngestPipelineConfig
}

export interface TextStructureTestGrokPatternMatchedField {
  match: string
  offset: integer
  length: integer
}

export interface TextStructureTestGrokPatternMatchedText {
  matched: boolean
  fields?: Record<string, TextStructureTestGrokPatternMatchedField[]>
}

export interface TextStructureTestGrokPatternRequest extends RequestBase {
/** The mode of compatibility with ECS compliant Grok patterns. Use this parameter to specify whether to use ECS Grok patterns instead of legacy ones when the structure finder creates a Grok pattern. Valid values are `disabled` and `v1`. */
  ecs_compatibility?: string
  /** The Grok pattern to run on the text. */
  grok_pattern: GrokPattern
  /** The lines of text to run the Grok pattern on. */
  text: string[]
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { ecs_compatibility?: never, grok_pattern?: never, text?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { ecs_compatibility?: never, grok_pattern?: never, text?: never }
}

export interface TextStructureTestGrokPatternResponse {
  matches: TextStructureTestGrokPatternMatchedText[]
}

export interface TransformDestination {
  index?: IndexName
  pipeline?: string
}

export interface TransformLatest {
  sort: Field
  unique_key: Field[]
}

export interface TransformPivot {
  aggregations?: Record<string, AggregationsAggregationContainer>
  aggs?: Record<string, AggregationsAggregationContainer>
  group_by?: Record<string, TransformPivotGroupByContainer>
}

export interface TransformPivotGroupByContainer {
  date_histogram?: AggregationsDateHistogramAggregation
  geotile_grid?: AggregationsGeoTileGridAggregation
  histogram?: AggregationsHistogramAggregation
  terms?: AggregationsTermsAggregation
}

export interface TransformRetentionPolicy {
  field: Field
  max_age: Duration
}

export interface TransformRetentionPolicyContainer {
  time?: TransformRetentionPolicy
}

export interface TransformSettings {
  align_checkpoints?: boolean
  dates_as_epoch_millis?: boolean
  deduce_mappings?: boolean
  docs_per_second?: float
  max_page_search_size?: integer
  unattended?: boolean
}

export interface TransformSource {
  index: Indices
  query?: QueryDslQueryContainer
  runtime_mappings?: MappingRuntimeFields
}

export interface TransformSyncContainer {
  time?: TransformTimeSync
}

export interface TransformTimeSync {
  delay?: Duration
  field: Field
}

export interface TransformDeleteTransformRequest extends RequestBase {
/** Identifier for the transform. */
  transform_id: Id
  /** If this value is false, the transform must be stopped before it can be deleted. If true, the transform is deleted regardless of its current state. */
  force?: boolean
  /** If this value is true, the destination index is deleted together with the transform. If false, the destination index will not be deleted */
  delete_dest_index?: boolean
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { transform_id?: never, force?: never, delete_dest_index?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { transform_id?: never, force?: never, delete_dest_index?: never, timeout?: never }
}

export type TransformDeleteTransformResponse = AcknowledgedResponseBase

export interface TransformGetTransformRequest extends RequestBase {
/** Identifier for the transform. It can be a transform identifier or a wildcard expression. You can get information for all transforms by using `_all`, by specifying `*` as the `<transform_id>`, or by omitting the `<transform_id>`. */
  transform_id?: Names
  /** Specifies what to do when the request: 1. Contains wildcard expressions and there are no transforms that match. 2. Contains the _all string or no identifiers and there are no matches. 3. Contains wildcard expressions and there are only partial matches. If this parameter is false, the request returns a 404 status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** Skips the specified number of transforms. */
  from?: integer
  /** Specifies the maximum number of transforms to obtain. */
  size?: integer
  /** Excludes fields that were automatically added when creating the transform. This allows the configuration to be in an acceptable format to be retrieved and then added to another cluster. */
  exclude_generated?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { transform_id?: never, allow_no_match?: never, from?: never, size?: never, exclude_generated?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { transform_id?: never, allow_no_match?: never, from?: never, size?: never, exclude_generated?: never }
}

export interface TransformGetTransformResponse {
  count: long
  transforms: TransformGetTransformTransformSummary[]
}

export interface TransformGetTransformTransformSummary {
  authorization?: MlTransformAuthorization
  create_time?: EpochTime<UnitMillis>
  description?: string
  dest: ReindexDestination
  frequency?: Duration
  id: Id
  latest?: TransformLatest
  pivot?: TransformPivot
  retention_policy?: TransformRetentionPolicyContainer
  settings?: TransformSettings
  source: TransformSource
  sync?: TransformSyncContainer
  version?: VersionString
  _meta?: Metadata
}

export interface TransformGetTransformStatsCheckpointStats {
  checkpoint: long
  checkpoint_progress?: TransformGetTransformStatsTransformProgress
  timestamp?: DateTime
  timestamp_millis?: EpochTime<UnitMillis>
  time_upper_bound?: DateTime
  time_upper_bound_millis?: EpochTime<UnitMillis>
}

export interface TransformGetTransformStatsCheckpointing {
  changes_last_detected_at?: long
  changes_last_detected_at_date_time?: DateTime
  last: TransformGetTransformStatsCheckpointStats
  next?: TransformGetTransformStatsCheckpointStats
  operations_behind?: long
  last_search_time?: long
}

export interface TransformGetTransformStatsRequest extends RequestBase {
/** Identifier for the transform. It can be a transform identifier or a wildcard expression. You can get information for all transforms by using `_all`, by specifying `*` as the `<transform_id>`, or by omitting the `<transform_id>`. */
  transform_id: Names
  /** Specifies what to do when the request: 1. Contains wildcard expressions and there are no transforms that match. 2. Contains the _all string or no identifiers and there are no matches. 3. Contains wildcard expressions and there are only partial matches. If this parameter is false, the request returns a 404 status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** Skips the specified number of transforms. */
  from?: long
  /** Specifies the maximum number of transforms to obtain. */
  size?: long
  /** Controls the time to wait for the stats */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { transform_id?: never, allow_no_match?: never, from?: never, size?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { transform_id?: never, allow_no_match?: never, from?: never, size?: never, timeout?: never }
}

export interface TransformGetTransformStatsResponse {
  count: long
  transforms: TransformGetTransformStatsTransformStats[]
}

export interface TransformGetTransformStatsTransformIndexerStats {
  delete_time_in_ms?: EpochTime<UnitMillis>
  documents_indexed: long
  documents_deleted?: long
  documents_processed: long
  exponential_avg_checkpoint_duration_ms: DurationValue<UnitFloatMillis>
  exponential_avg_documents_indexed: double
  exponential_avg_documents_processed: double
  index_failures: long
  index_time_in_ms: DurationValue<UnitMillis>
  index_total: long
  pages_processed: long
  processing_time_in_ms: DurationValue<UnitMillis>
  processing_total: long
  search_failures: long
  search_time_in_ms: DurationValue<UnitMillis>
  search_total: long
  trigger_count: long
}

export interface TransformGetTransformStatsTransformProgress {
  docs_indexed: long
  docs_processed: long
  docs_remaining?: long
  percent_complete?: double
  total_docs?: long
}

export interface TransformGetTransformStatsTransformStats {
  checkpointing: TransformGetTransformStatsCheckpointing
  health?: TransformGetTransformStatsTransformStatsHealth
  id: Id
  node?: NodeAttributes
  reason?: string
  state: string
  stats: TransformGetTransformStatsTransformIndexerStats
}

export interface TransformGetTransformStatsTransformStatsHealth {
  status: HealthStatus
}

export interface TransformPreviewTransformRequest extends RequestBase {
/** Identifier for the transform to preview. If you specify this path parameter, you cannot provide transform configuration details in the request body. */
  transform_id?: Id
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** The destination for the transform. */
  dest?: TransformDestination
  /** Free text description of the transform. */
  description?: string
  /** The interval between checks for changes in the source indices when the transform is running continuously. Also determines the retry interval in the event of transient failures while the transform is searching or indexing. The minimum value is 1s and the maximum is 1h. */
  frequency?: Duration
  /** The pivot method transforms the data by aggregating and grouping it. These objects define the group by fields and the aggregation to reduce the data. */
  pivot?: TransformPivot
  /** The source of the data for the transform. */
  source?: TransformSource
  /** Defines optional transform settings. */
  settings?: TransformSettings
  /** Defines the properties transforms require to run continuously. */
  sync?: TransformSyncContainer
  /** Defines a retention policy for the transform. Data that meets the defined criteria is deleted from the destination index. */
  retention_policy?: TransformRetentionPolicyContainer
  /** The latest method transforms the data by finding the latest document for each unique key. */
  latest?: TransformLatest
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { transform_id?: never, timeout?: never, dest?: never, description?: never, frequency?: never, pivot?: never, source?: never, settings?: never, sync?: never, retention_policy?: never, latest?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { transform_id?: never, timeout?: never, dest?: never, description?: never, frequency?: never, pivot?: never, source?: never, settings?: never, sync?: never, retention_policy?: never, latest?: never }
}

export interface TransformPreviewTransformResponse<TTransform = unknown> {
  generated_dest_index: IndicesIndexState
  preview: TTransform[]
}

export interface TransformPutTransformRequest extends RequestBase {
/** Identifier for the transform. This identifier can contain lowercase alphanumeric characters (a-z and 0-9), hyphens, and underscores. It has a 64 character limit and must start and end with alphanumeric characters. */
  transform_id: Id
  /** When the transform is created, a series of validations occur to ensure its success. For example, there is a check for the existence of the source indices and a check that the destination index is not part of the source index pattern. You can use this parameter to skip the checks, for example when the source index does not exist until after the transform is created. The validations are always run when you start the transform, however, with the exception of privilege checks. */
  defer_validation?: boolean
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** The destination for the transform. */
  dest: TransformDestination
  /** Free text description of the transform. */
  description?: string
  /** The interval between checks for changes in the source indices when the transform is running continuously. Also determines the retry interval in the event of transient failures while the transform is searching or indexing. The minimum value is `1s` and the maximum is `1h`. */
  frequency?: Duration
  /** The latest method transforms the data by finding the latest document for each unique key. */
  latest?: TransformLatest
  /** Defines optional transform metadata. */
  _meta?: Metadata
  /** The pivot method transforms the data by aggregating and grouping it. These objects define the group by fields and the aggregation to reduce the data. */
  pivot?: TransformPivot
  /** Defines a retention policy for the transform. Data that meets the defined criteria is deleted from the destination index. */
  retention_policy?: TransformRetentionPolicyContainer
  /** Defines optional transform settings. */
  settings?: TransformSettings
  /** The source of the data for the transform. */
  source: TransformSource
  /** Defines the properties transforms require to run continuously. */
  sync?: TransformSyncContainer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { transform_id?: never, defer_validation?: never, timeout?: never, dest?: never, description?: never, frequency?: never, latest?: never, _meta?: never, pivot?: never, retention_policy?: never, settings?: never, source?: never, sync?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { transform_id?: never, defer_validation?: never, timeout?: never, dest?: never, description?: never, frequency?: never, latest?: never, _meta?: never, pivot?: never, retention_policy?: never, settings?: never, source?: never, sync?: never }
}

export type TransformPutTransformResponse = AcknowledgedResponseBase

export interface TransformResetTransformRequest extends RequestBase {
/** Identifier for the transform. This identifier can contain lowercase alphanumeric characters (a-z and 0-9), hyphens, and underscores. It has a 64 character limit and must start and end with alphanumeric characters. */
  transform_id: Id
  /** If this value is `true`, the transform is reset regardless of its current state. If it's `false`, the transform must be stopped before it can be reset. */
  force?: boolean
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { transform_id?: never, force?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { transform_id?: never, force?: never, timeout?: never }
}

export type TransformResetTransformResponse = AcknowledgedResponseBase

export interface TransformScheduleNowTransformRequest extends RequestBase {
/** Identifier for the transform. */
  transform_id: Id
  /** Controls the time to wait for the scheduling to take place */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { transform_id?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { transform_id?: never, timeout?: never }
}

export type TransformScheduleNowTransformResponse = AcknowledgedResponseBase

export interface TransformStartTransformRequest extends RequestBase {
/** Identifier for the transform. */
  transform_id: Id
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** Restricts the set of transformed entities to those changed after this time. Relative times like now-30d are supported. Only applicable for continuous transforms. */
  from?: string
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { transform_id?: never, timeout?: never, from?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { transform_id?: never, timeout?: never, from?: never }
}

export type TransformStartTransformResponse = AcknowledgedResponseBase

export interface TransformStopTransformRequest extends RequestBase {
/** Identifier for the transform. To stop multiple transforms, use a comma-separated list or a wildcard expression. To stop all transforms, use `_all` or `*` as the identifier. */
  transform_id: Name
  /** Specifies what to do when the request: contains wildcard expressions and there are no transforms that match; contains the `_all` string or no identifiers and there are no matches; contains wildcard expressions and there are only partial matches. If it is true, the API returns a successful acknowledgement message when there are no matches. When there are only partial matches, the API stops the appropriate transforms. If it is false, the request returns a 404 status code when there are no matches or only partial matches. */
  allow_no_match?: boolean
  /** If it is true, the API forcefully stops the transforms. */
  force?: boolean
  /** Period to wait for a response when `wait_for_completion` is `true`. If no response is received before the timeout expires, the request returns a timeout exception. However, the request continues processing and eventually moves the transform to a STOPPED state. */
  timeout?: Duration
  /** If it is true, the transform does not completely stop until the current checkpoint is completed. If it is false, the transform stops as soon as possible. */
  wait_for_checkpoint?: boolean
  /** If it is true, the API blocks until the indexer state completely stops. If it is false, the API returns immediately and the indexer is stopped asynchronously in the background. */
  wait_for_completion?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { transform_id?: never, allow_no_match?: never, force?: never, timeout?: never, wait_for_checkpoint?: never, wait_for_completion?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { transform_id?: never, allow_no_match?: never, force?: never, timeout?: never, wait_for_checkpoint?: never, wait_for_completion?: never }
}

export type TransformStopTransformResponse = AcknowledgedResponseBase

export interface TransformUpdateTransformRequest extends RequestBase {
/** Identifier for the transform. */
  transform_id: Id
  /** When true, deferrable validations are not run. This behavior may be desired if the source index does not exist until after the transform is created. */
  defer_validation?: boolean
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** The destination for the transform. */
  dest?: TransformDestination
  /** Free text description of the transform. */
  description?: string
  /** The interval between checks for changes in the source indices when the transform is running continuously. Also determines the retry interval in the event of transient failures while the transform is searching or indexing. The minimum value is 1s and the maximum is 1h. */
  frequency?: Duration
  /** Defines optional transform metadata. */
  _meta?: Metadata
  /** The source of the data for the transform. */
  source?: TransformSource
  /** Defines optional transform settings. */
  settings?: TransformSettings
  /** Defines the properties transforms require to run continuously. */
  sync?: TransformSyncContainer
  /** Defines a retention policy for the transform. Data that meets the defined criteria is deleted from the destination index. */
  retention_policy?: TransformRetentionPolicyContainer | null
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { transform_id?: never, defer_validation?: never, timeout?: never, dest?: never, description?: never, frequency?: never, _meta?: never, source?: never, settings?: never, sync?: never, retention_policy?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { transform_id?: never, defer_validation?: never, timeout?: never, dest?: never, description?: never, frequency?: never, _meta?: never, source?: never, settings?: never, sync?: never, retention_policy?: never }
}

export interface TransformUpdateTransformResponse {
  authorization?: MlTransformAuthorization
  create_time: long
  description: string
  dest: ReindexDestination
  frequency?: Duration
  id: Id
  latest?: TransformLatest
  pivot?: TransformPivot
  retention_policy?: TransformRetentionPolicyContainer
  settings: TransformSettings
  source: ReindexSource
  sync?: TransformSyncContainer
  version: VersionString
  _meta?: Metadata
}

export interface TransformUpgradeTransformsRequest extends RequestBase {
/** When true, the request checks for updates but does not run them. */
  dry_run?: boolean
  /** Period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { dry_run?: never, timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { dry_run?: never, timeout?: never }
}

export interface TransformUpgradeTransformsResponse {
  needs_update: integer
  no_action: integer
  updated: integer
}

export interface WatcherAcknowledgeState {
  state: WatcherAcknowledgementOptions
  timestamp: DateTime
}

export type WatcherAcknowledgementOptions = 'awaits_successful_execution' | 'ackable' | 'acked'

export interface WatcherAction {
  action_type?: WatcherActionType
  condition?: WatcherConditionContainer
  foreach?: string
  max_iterations?: integer
  name?: Name
  throttle_period?: Duration
  throttle_period_in_millis?: DurationValue<UnitMillis>
  transform?: TransformContainer
  index?: WatcherIndexAction
  logging?: WatcherLoggingAction
  email?: WatcherEmailAction
  pagerduty?: WatcherPagerDutyAction
  slack?: WatcherSlackAction
  webhook?: WatcherWebhookAction
}

export type WatcherActionExecutionMode = 'simulate' | 'force_simulate' | 'execute' | 'force_execute' | 'skip'

export interface WatcherActionStatus {
  ack: WatcherAcknowledgeState
  last_execution?: WatcherExecutionState
  last_successful_execution?: WatcherExecutionState
  last_throttle?: WatcherThrottleState
}

export type WatcherActionStatusOptions = 'success' | 'failure' | 'simulated' | 'throttled'

export type WatcherActionType = 'email' | 'webhook' | 'index' | 'logging' | 'slack' | 'pagerduty'

export type WatcherActions = Record<IndexName, WatcherActionStatus>

export interface WatcherActivationState {
  active: boolean
  timestamp: DateTime
}

export interface WatcherActivationStatus {
  actions: WatcherActions
  state: WatcherActivationState
  version: VersionNumber
}

export interface WatcherAlwaysCondition {
}

export interface WatcherArrayCompareConditionKeys {
  path: string
}
export type WatcherArrayCompareCondition = WatcherArrayCompareConditionKeys
& { [property: string]: WatcherArrayCompareOpParams | string }

export interface WatcherArrayCompareOpParams {
  quantifier: WatcherQuantifier
  value: FieldValue
}

export interface WatcherChainInput {
  inputs: Partial<Record<string, WatcherInputContainer>>[]
}

export interface WatcherConditionContainer {
  always?: WatcherAlwaysCondition
  array_compare?: Partial<Record<string, WatcherArrayCompareCondition>>
  compare?: Partial<Record<string, Partial<Record<WatcherConditionOp, FieldValue>>>>
  never?: WatcherNeverCondition
  script?: WatcherScriptCondition
}

export type WatcherConditionOp = 'not_eq' | 'eq' | 'lt' | 'gt' | 'lte' | 'gte'

export type WatcherConditionType = 'always' | 'never' | 'script' | 'compare' | 'array_compare'

export type WatcherConnectionScheme = 'http' | 'https'

export type WatcherCronExpression = string

export interface WatcherDailySchedule {
  at: WatcherScheduleTimeOfDay[]
}

export type WatcherDataAttachmentFormat = 'json' | 'yaml'

export interface WatcherDataEmailAttachment {
  format?: WatcherDataAttachmentFormat
}

export type WatcherDay = 'sunday' | 'monday' | 'tuesday' | 'wednesday' | 'thursday' | 'friday' | 'saturday'

export interface WatcherEmail {
  id?: Id
  bcc?: string | string[]
  body?: WatcherEmailBody
  cc?: string | string[]
  from?: string
  priority?: WatcherEmailPriority
  reply_to?: string | string[]
  sent_date?: DateTime
  subject: string
  to: string | string[]
  attachments?: Record<string, WatcherEmailAttachmentContainer>
}

export interface WatcherEmailAction extends WatcherEmail {
}

export interface WatcherEmailAttachmentContainer {
  http?: WatcherHttpEmailAttachment
  reporting?: WatcherReportingEmailAttachment
  data?: WatcherDataEmailAttachment
}

export interface WatcherEmailBody {
  html?: string
  text?: string
}

export type WatcherEmailPriority = 'lowest' | 'low' | 'normal' | 'high' | 'highest'

export interface WatcherEmailResult {
  account?: string
  message: WatcherEmail
  reason?: string
}

export type WatcherExecutionPhase = 'awaits_execution' | 'started' | 'input' | 'condition' | 'actions' | 'watch_transform' | 'aborted' | 'finished'

export interface WatcherExecutionResult {
  actions: WatcherExecutionResultAction[]
  condition: WatcherExecutionResultCondition
  execution_duration: DurationValue<UnitMillis>
  execution_time: DateTime
  input: WatcherExecutionResultInput
}

export interface WatcherExecutionResultAction {
  email?: WatcherEmailResult
  id: Id
  index?: WatcherIndexResult
  logging?: WatcherLoggingResult
  pagerduty?: WatcherPagerDutyResult
  reason?: string
  slack?: WatcherSlackResult
  status: WatcherActionStatusOptions
  type: WatcherActionType
  webhook?: WatcherWebhookResult
  error?: ErrorCause
}

export interface WatcherExecutionResultCondition {
  met: boolean
  status: WatcherActionStatusOptions
  type: WatcherConditionType
}

export interface WatcherExecutionResultInput {
  payload: Record<string, any>
  status: WatcherActionStatusOptions
  type: WatcherInputType
}

export interface WatcherExecutionState {
  successful: boolean
  timestamp: DateTime
  reason?: string
}

export type WatcherExecutionStatus = 'awaits_execution' | 'checking' | 'execution_not_needed' | 'throttled' | 'executed' | 'failed' | 'deleted_while_queued' | 'not_executed_already_queued'

export interface WatcherExecutionThreadPool {
  max_size: long
  queue_size: long
}

export interface WatcherHourAndMinute {
  hour: integer[]
  minute: integer[]
}

export interface WatcherHourlySchedule {
  minute: integer[]
}

export interface WatcherHttpEmailAttachment {
  content_type?: string
  inline?: boolean
  request?: WatcherHttpInputRequestDefinition
}

export interface WatcherHttpInput {
  extract?: string[]
  request?: WatcherHttpInputRequestDefinition
  response_content_type?: WatcherResponseContentType
}

export interface WatcherHttpInputAuthentication {
  basic: WatcherHttpInputBasicAuthentication
}

export interface WatcherHttpInputBasicAuthentication {
  password: Password
  username: Username
}

export type WatcherHttpInputMethod = 'head' | 'get' | 'post' | 'put' | 'delete'

export interface WatcherHttpInputProxy {
  host: Host
  port: uint
}

export interface WatcherHttpInputRequestDefinition {
  auth?: WatcherHttpInputAuthentication
  body?: string
  connection_timeout?: Duration
  headers?: Record<string, string>
  host?: Host
  method?: WatcherHttpInputMethod
  params?: Record<string, string>
  path?: string
  port?: uint
  proxy?: WatcherHttpInputProxy
  read_timeout?: Duration
  scheme?: WatcherConnectionScheme
  url?: string
}

export interface WatcherHttpInputRequestResult extends WatcherHttpInputRequestDefinition {
}

export interface WatcherHttpInputResponseResult {
  body: string
  headers: HttpHeaders
  status: integer
}

export interface WatcherIndexAction {
  index: IndexName
  doc_id?: Id
  refresh?: Refresh
  op_type?: OpType
  timeout?: Duration
  execution_time_field?: Field
}

export interface WatcherIndexResult {
  response: WatcherIndexResultSummary
}

export interface WatcherIndexResultSummary {
  created: boolean
  id: Id
  index: IndexName
  result: Result
  version: VersionNumber
}

export interface WatcherInputContainer {
  chain?: WatcherChainInput
  http?: WatcherHttpInput
  search?: WatcherSearchInput
  simple?: Record<string, any>
}

export type WatcherInputType = 'http' | 'search' | 'simple'

export interface WatcherLoggingAction {
  level?: string
  text: string
  category?: string
}

export interface WatcherLoggingResult {
  logged_text: string
}

export type WatcherMonth = 'january' | 'february' | 'march' | 'april' | 'may' | 'june' | 'july' | 'august' | 'september' | 'october' | 'november' | 'december'

export interface WatcherNeverCondition {
}

export interface WatcherPagerDutyAction extends WatcherPagerDutyEvent {
}

export interface WatcherPagerDutyContext {
  href?: string
  src?: string
  type: WatcherPagerDutyContextType
}

export type WatcherPagerDutyContextType = 'link' | 'image'

export interface WatcherPagerDutyEvent {
  account?: string
  attach_payload: boolean
  client?: string
  client_url?: string
  contexts?: WatcherPagerDutyContext[]
  context?: WatcherPagerDutyContext[]
  description: string
  event_type?: WatcherPagerDutyEventType
  incident_key: string
  proxy?: WatcherPagerDutyEventProxy
}

export interface WatcherPagerDutyEventProxy {
  host?: Host
  port?: integer
}

export type WatcherPagerDutyEventType = 'trigger' | 'resolve' | 'acknowledge'

export interface WatcherPagerDutyResult {
  event: WatcherPagerDutyEvent
  reason?: string
  request?: WatcherHttpInputRequestResult
  response?: WatcherHttpInputResponseResult
}

export type WatcherQuantifier = 'some' | 'all'

export interface WatcherQueryWatch {
  _id: Id
  status?: WatcherWatchStatus
  watch?: WatcherWatch
  _primary_term?: integer
  _seq_no?: SequenceNumber
}

export interface WatcherReportingEmailAttachment {
  url: string
  inline?: boolean
  retries?: integer
  interval?: Duration
  request?: WatcherHttpInputRequestDefinition
}

export type WatcherResponseContentType = 'json' | 'yaml' | 'text'

export interface WatcherScheduleContainer {
  timezone?: string
  cron?: WatcherCronExpression
  daily?: WatcherDailySchedule
  hourly?: WatcherHourlySchedule
  interval?: Duration
  monthly?: WatcherTimeOfMonth | WatcherTimeOfMonth[]
  weekly?: WatcherTimeOfWeek | WatcherTimeOfWeek[]
  yearly?: WatcherTimeOfYear | WatcherTimeOfYear[]
}

export type WatcherScheduleTimeOfDay = string | WatcherHourAndMinute

export interface WatcherScheduleTriggerEvent {
  scheduled_time: DateTime
  triggered_time?: DateTime
}

export interface WatcherScriptCondition {
  lang?: string
  params?: Record<string, any>
  source?: string
  id?: string
}

export interface WatcherSearchInput {
  extract?: string[]
  request: WatcherSearchInputRequestDefinition
  timeout?: Duration
}

export interface WatcherSearchInputRequestBody {
  query: QueryDslQueryContainer
}

export interface WatcherSearchInputRequestDefinition {
  body?: WatcherSearchInputRequestBody
  indices?: IndexName[]
  indices_options?: IndicesOptions
  search_type?: SearchType
  template?: WatcherSearchTemplateRequestBody
  rest_total_hits_as_int?: boolean
}

export interface WatcherSearchTemplateRequestBody {
  explain?: boolean
  id?: Id
  params?: Record<string, any>
  profile?: boolean
  source?: string
}

export interface WatcherSimulatedActions {
  actions: string[]
  all: WatcherSimulatedActions
  use_all: boolean
}

export interface WatcherSlackAction {
  account?: string
  message: WatcherSlackMessage
}

export interface WatcherSlackAttachment {
  author_icon?: string
  author_link?: string
  author_name: string
  color?: string
  fallback?: string
  fields?: WatcherSlackAttachmentField[]
  footer?: string
  footer_icon?: string
  image_url?: string
  pretext?: string
  text?: string
  thumb_url?: string
  title: string
  title_link?: string
  ts?: EpochTime<UnitSeconds>
}

export interface WatcherSlackAttachmentField {
  short: boolean
  title: string
  value: string
}

export interface WatcherSlackDynamicAttachment {
  attachment_template: WatcherSlackAttachment
  list_path: string
}

export interface WatcherSlackMessage {
  attachments: WatcherSlackAttachment[]
  dynamic_attachments?: WatcherSlackDynamicAttachment
  from: string
  icon?: string
  text: string
  to: string[]
}

export interface WatcherSlackResult {
  account?: string
  message: WatcherSlackMessage
}

export interface WatcherThrottleState {
  reason: string
  timestamp: DateTime
}

export interface WatcherTimeOfMonth {
  at: string[]
  on: integer[]
}

export interface WatcherTimeOfWeek {
  at: string[]
  on: WatcherDay[]
}

export interface WatcherTimeOfYear {
  at: string[]
  int: WatcherMonth[]
  on: integer[]
}

export interface WatcherTriggerContainer {
  schedule?: WatcherScheduleContainer
}

export interface WatcherTriggerEventContainer {
  schedule?: WatcherScheduleTriggerEvent
}

export interface WatcherTriggerEventResult {
  manual: WatcherTriggerEventContainer
  triggered_time: DateTime
  type: string
}

export interface WatcherWatch {
  actions: Record<IndexName, WatcherAction>
  condition: WatcherConditionContainer
  input: WatcherInputContainer
  metadata?: Metadata
  status?: WatcherWatchStatus
  throttle_period?: Duration
  throttle_period_in_millis?: DurationValue<UnitMillis>
  transform?: TransformContainer
  trigger: WatcherTriggerContainer
}

export interface WatcherWatchStatus {
  actions: WatcherActions
  last_checked?: DateTime
  last_met_condition?: DateTime
  state: WatcherActivationState
  version: VersionNumber
  execution_state?: string
}

export interface WatcherWebhookAction extends WatcherHttpInputRequestDefinition {
}

export interface WatcherWebhookResult {
  request: WatcherHttpInputRequestResult
  response?: WatcherHttpInputResponseResult
}

export interface WatcherAckWatchRequest extends RequestBase {
/** The watch identifier. */
  watch_id: Name
  /** A comma-separated list of the action identifiers to acknowledge. If you omit this parameter, all of the actions of the watch are acknowledged. */
  action_id?: Names
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { watch_id?: never, action_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { watch_id?: never, action_id?: never }
}

export interface WatcherAckWatchResponse {
  status: WatcherWatchStatus
}

export interface WatcherActivateWatchRequest extends RequestBase {
/** The watch identifier. */
  watch_id: Name
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { watch_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { watch_id?: never }
}

export interface WatcherActivateWatchResponse {
  status: WatcherActivationStatus
}

export interface WatcherDeactivateWatchRequest extends RequestBase {
/** The watch identifier. */
  watch_id: Name
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { watch_id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { watch_id?: never }
}

export interface WatcherDeactivateWatchResponse {
  status: WatcherActivationStatus
}

export interface WatcherDeleteWatchRequest extends RequestBase {
/** The watch identifier. */
  id: Name
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export interface WatcherDeleteWatchResponse {
  found: boolean
  _id: Id
  _version: VersionNumber
}

export interface WatcherExecuteWatchRequest extends RequestBase {
/** The watch identifier. */
  id?: Id
  /** Defines whether the watch runs in debug mode. */
  debug?: boolean
  /** Determines how to handle the watch actions as part of the watch execution. */
  action_modes?: Record<string, WatcherActionExecutionMode>
  /** When present, the watch uses this object as a payload instead of executing its own input. */
  alternative_input?: Record<string, any>
  /** When set to `true`, the watch execution uses the always condition. This can also be specified as an HTTP parameter. */
  ignore_condition?: boolean
  /** When set to `true`, the watch record representing the watch execution result is persisted to the `.watcher-history` index for the current time. In addition, the status of the watch is updated, possibly throttling subsequent runs. This can also be specified as an HTTP parameter. */
  record_execution?: boolean
  simulated_actions?: WatcherSimulatedActions
  /** This structure is parsed as the data of the trigger event that will be used during the watch execution. */
  trigger_data?: WatcherScheduleTriggerEvent
  /** When present, this watch is used instead of the one specified in the request. This watch is not persisted to the index and `record_execution` cannot be set. */
  watch?: WatcherWatch
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, debug?: never, action_modes?: never, alternative_input?: never, ignore_condition?: never, record_execution?: never, simulated_actions?: never, trigger_data?: never, watch?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, debug?: never, action_modes?: never, alternative_input?: never, ignore_condition?: never, record_execution?: never, simulated_actions?: never, trigger_data?: never, watch?: never }
}

export interface WatcherExecuteWatchResponse {
  _id: Id
  watch_record: WatcherExecuteWatchWatchRecord
}

export interface WatcherExecuteWatchWatchRecord {
  condition: WatcherConditionContainer
  input: WatcherInputContainer
  messages: string[]
  metadata?: Metadata
  node: string
  result: WatcherExecutionResult
  state: WatcherExecutionStatus
  trigger_event: WatcherTriggerEventResult
  user: Username
  watch_id: Id
  status?: WatcherWatchStatus
}

export interface WatcherGetSettingsRequest extends RequestBase {
/** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never }
}

export interface WatcherGetSettingsResponse {
  index: IndicesIndexSettings
}

export interface WatcherGetWatchRequest extends RequestBase {
/** The watch identifier. */
  id: Name
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never }
}

export interface WatcherGetWatchResponse {
  found: boolean
  _id: Id
  status?: WatcherWatchStatus
  watch?: WatcherWatch
  _primary_term?: integer
  _seq_no?: SequenceNumber
  _version?: VersionNumber
}

export interface WatcherPutWatchRequest extends RequestBase {
/** The identifier for the watch. */
  id: Id
  /** The initial state of the watch. The default value is `true`, which means the watch is active by default. */
  active?: boolean
  /** only update the watch if the last operation that has changed the watch has the specified primary term */
  if_primary_term?: long
  /** only update the watch if the last operation that has changed the watch has the specified sequence number */
  if_seq_no?: SequenceNumber
  /** Explicit version number for concurrency control */
  version?: VersionNumber
  /** The list of actions that will be run if the condition matches. */
  actions?: Record<string, WatcherAction>
  /** The condition that defines if the actions should be run. */
  condition?: WatcherConditionContainer
  /** The input that defines the input that loads the data for the watch. */
  input?: WatcherInputContainer
  /** Metadata JSON that will be copied into the history entries. */
  metadata?: Metadata
  /** The minimum time between actions being run. The default is 5 seconds. This default can be changed in the config file with the setting `xpack.watcher.throttle.period.default_period`. If both this value and the `throttle_period_in_millis` parameter are specified, Watcher uses the last parameter included in the request. */
  throttle_period?: Duration
  /** Minimum time in milliseconds between actions being run. Defaults to 5000. If both this value and the throttle_period parameter are specified, Watcher uses the last parameter included in the request. */
  throttle_period_in_millis?: DurationValue<UnitMillis>
  /** The transform that processes the watch payload to prepare it for the watch actions. */
  transform?: TransformContainer
  /** The trigger that defines when the watch should run. */
  trigger?: WatcherTriggerContainer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { id?: never, active?: never, if_primary_term?: never, if_seq_no?: never, version?: never, actions?: never, condition?: never, input?: never, metadata?: never, throttle_period?: never, throttle_period_in_millis?: never, transform?: never, trigger?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { id?: never, active?: never, if_primary_term?: never, if_seq_no?: never, version?: never, actions?: never, condition?: never, input?: never, metadata?: never, throttle_period?: never, throttle_period_in_millis?: never, transform?: never, trigger?: never }
}

export interface WatcherPutWatchResponse {
  created: boolean
  _id: Id
  _primary_term: long
  _seq_no: SequenceNumber
  _version: VersionNumber
}

export interface WatcherQueryWatchesRequest extends RequestBase {
/** The offset from the first result to fetch. It must be non-negative. */
  from?: integer
  /** The number of hits to return. It must be non-negative. */
  size?: integer
  /** A query that filters the watches to be returned. */
  query?: QueryDslQueryContainer
  /** One or more fields used to sort the search results. */
  sort?: Sort
  /** Retrieve the next page of hits using a set of sort values from the previous page. */
  search_after?: SortResults
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { from?: never, size?: never, query?: never, sort?: never, search_after?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { from?: never, size?: never, query?: never, sort?: never, search_after?: never }
}

export interface WatcherQueryWatchesResponse {
  count: integer
  watches: WatcherQueryWatch[]
}

export interface WatcherStartRequest extends RequestBase {
/** Period to wait for a connection to the master node. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never }
}

export type WatcherStartResponse = AcknowledgedResponseBase

export interface WatcherStatsRequest extends RequestBase {
/** Defines which additional metrics are included in the response. */
  metric?: WatcherStatsWatcherMetric | WatcherStatsWatcherMetric[]
  /** Defines whether stack traces are generated for each watch that is running. */
  emit_stacktraces?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { metric?: never, emit_stacktraces?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { metric?: never, emit_stacktraces?: never }
}

export interface WatcherStatsResponse {
  _nodes: NodeStatistics
  cluster_name: Name
  manually_stopped: boolean
  stats: WatcherStatsWatcherNodeStats[]
}

export interface WatcherStatsWatchRecordQueuedStats {
  execution_time: DateTime
}

export interface WatcherStatsWatchRecordStats extends WatcherStatsWatchRecordQueuedStats {
  execution_phase: WatcherExecutionPhase
  triggered_time: DateTime
  executed_actions?: string[]
  watch_id: Id
  watch_record_id: Id
}

export type WatcherStatsWatcherMetric = '_all' | 'all' | 'queued_watches' | 'current_watches' | 'pending_watches'

export interface WatcherStatsWatcherNodeStats {
  current_watches?: WatcherStatsWatchRecordStats[]
  execution_thread_pool: WatcherExecutionThreadPool
  queued_watches?: WatcherStatsWatchRecordQueuedStats[]
  watch_count: long
  watcher_state: WatcherStatsWatcherState
  node_id: Id
}

export type WatcherStatsWatcherState = 'stopped' | 'starting' | 'started' | 'stopping'

export interface WatcherStopRequest extends RequestBase {
/** The period to wait for the master node. If the master node is not available before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never }
}

export type WatcherStopResponse = AcknowledgedResponseBase

export interface WatcherUpdateSettingsRequest extends RequestBase {
/** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. */
  master_timeout?: Duration
  /** The period to wait for a response. If no response is received before the timeout expires, the request fails and returns an error. */
  timeout?: Duration
  'index.auto_expand_replicas'?: string
  'index.number_of_replicas'?: integer
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never, timeout?: never, 'index.auto_expand_replicas'?: never, 'index.number_of_replicas'?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never, timeout?: never, 'index.auto_expand_replicas'?: never, 'index.number_of_replicas'?: never }
}

export interface WatcherUpdateSettingsResponse {
  acknowledged: boolean
}

export interface XpackInfoBuildInformation {
  date: DateTime
  hash: string
}

export interface XpackInfoFeature {
  available: boolean
  description?: string
  enabled: boolean
  native_code_info?: XpackInfoNativeCodeInformation
}

export interface XpackInfoFeatures {
  aggregate_metric: XpackInfoFeature
  analytics: XpackInfoFeature
  ccr: XpackInfoFeature
  data_streams: XpackInfoFeature
  data_tiers: XpackInfoFeature
  enrich: XpackInfoFeature
  enterprise_search: XpackInfoFeature
  eql: XpackInfoFeature
  esql: XpackInfoFeature
  graph: XpackInfoFeature
  ilm: XpackInfoFeature
  logstash: XpackInfoFeature
  logsdb: XpackInfoFeature
  ml: XpackInfoFeature
  monitoring: XpackInfoFeature
  rollup: XpackInfoFeature
  runtime_fields?: XpackInfoFeature
  searchable_snapshots: XpackInfoFeature
  security: XpackInfoFeature
  slm: XpackInfoFeature
  spatial: XpackInfoFeature
  sql: XpackInfoFeature
  transform: XpackInfoFeature
  universal_profiling: XpackInfoFeature
  voting_only: XpackInfoFeature
  watcher: XpackInfoFeature
  archive: XpackInfoFeature
}

export interface XpackInfoMinimalLicenseInformation {
  expiry_date_in_millis: EpochTime<UnitMillis>
  mode: LicenseLicenseType
  status: LicenseLicenseStatus
  type: LicenseLicenseType
  uid: string
}

export interface XpackInfoNativeCodeInformation {
  build_hash: string
  version: VersionString
}

export interface XpackInfoRequest extends RequestBase {
/** A comma-separated list of the information categories to include in the response. For example, `build,license,features`. */
  categories?: XpackInfoXPackCategory[]
  /** If this param is used it must be set to true */
  accept_enterprise?: boolean
  /** Defines whether additional human-readable information is included in the response. In particular, it adds descriptions and a tag line. */
  human?: boolean
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { categories?: never, accept_enterprise?: never, human?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { categories?: never, accept_enterprise?: never, human?: never }
}

export interface XpackInfoResponse {
  build: XpackInfoBuildInformation
  features: XpackInfoFeatures
  license: XpackInfoMinimalLicenseInformation
  tagline: string
}

export type XpackInfoXPackCategory = 'build' | 'features' | 'license'

export interface XpackUsageAnalytics extends XpackUsageBase {
  stats: XpackUsageAnalyticsStatistics
}

export interface XpackUsageAnalyticsStatistics {
  boxplot_usage: long
  cumulative_cardinality_usage: long
  string_stats_usage: long
  top_metrics_usage: long
  t_test_usage: long
  moving_percentiles_usage: long
  normalize_usage: long
  rate_usage: long
  multi_terms_usage?: long
}

export interface XpackUsageArchive extends XpackUsageBase {
  indices_count: long
}

export interface XpackUsageAudit extends XpackUsageFeatureToggle {
  outputs?: string[]
}

export interface XpackUsageBase {
  available: boolean
  enabled: boolean
}

export interface XpackUsageCcr extends XpackUsageBase {
  auto_follow_patterns_count: integer
  follower_indices_count: integer
}

export interface XpackUsageCounter {
  active: long
  total: long
}

export interface XpackUsageDataStreams extends XpackUsageBase {
  data_streams: long
  indices_count: long
}

export interface XpackUsageDataTierPhaseStatistics {
  node_count: long
  index_count: long
  total_shard_count: long
  primary_shard_count: long
  doc_count: long
  total_size_bytes: long
  primary_size_bytes: long
  primary_shard_size_avg_bytes: long
  primary_shard_size_median_bytes: long
  primary_shard_size_mad_bytes: long
}

export interface XpackUsageDataTiers extends XpackUsageBase {
  data_warm: XpackUsageDataTierPhaseStatistics
  data_frozen?: XpackUsageDataTierPhaseStatistics
  data_cold: XpackUsageDataTierPhaseStatistics
  data_content: XpackUsageDataTierPhaseStatistics
  data_hot: XpackUsageDataTierPhaseStatistics
}

export interface XpackUsageDatafeed {
  count: long
}

export interface XpackUsageEql extends XpackUsageBase {
  features: XpackUsageEqlFeatures
  queries: Record<string, XpackUsageQuery>
}

export interface XpackUsageEqlFeatures {
  join: uint
  joins: XpackUsageEqlFeaturesJoin
  keys: XpackUsageEqlFeaturesKeys
  event: uint
  pipes: XpackUsageEqlFeaturesPipes
  sequence: uint
  sequences: XpackUsageEqlFeaturesSequences
}

export interface XpackUsageEqlFeaturesJoin {
  join_queries_two: uint
  join_queries_three: uint
  join_until: uint
  join_queries_five_or_more: uint
  join_queries_four: uint
}

export interface XpackUsageEqlFeaturesKeys {
  join_keys_two: uint
  join_keys_one: uint
  join_keys_three: uint
  join_keys_five_or_more: uint
  join_keys_four: uint
}

export interface XpackUsageEqlFeaturesPipes {
  pipe_tail: uint
  pipe_head: uint
}

export interface XpackUsageEqlFeaturesSequences {
  sequence_queries_three: uint
  sequence_queries_four: uint
  sequence_queries_two: uint
  sequence_until: uint
  sequence_queries_five_or_more: uint
  sequence_maxspan: uint
}

export interface XpackUsageFeatureToggle {
  enabled: boolean
}

export interface XpackUsageFlattened extends XpackUsageBase {
  field_count: integer
}

export interface XpackUsageHealthStatistics extends XpackUsageBase {
  invocations: XpackUsageInvocations
}

export interface XpackUsageIlm {
  policy_count: integer
  policy_stats: XpackUsageIlmPolicyStatistics[]
}

export interface XpackUsageIlmPolicyStatistics {
  indices_managed: integer
  phases: XpackUsagePhases
}

export interface XpackUsageInvocations {
  total: long
}

export interface XpackUsageIpFilter {
  http: boolean
  transport: boolean
}

export interface XpackUsageJobUsage {
  count: integer
  created_by: Record<string, long>
  detectors: MlJobStatistics
  forecasts: XpackUsageMlJobForecasts
  model_size: MlJobStatistics
}

export interface XpackUsageMachineLearning extends XpackUsageBase {
  datafeeds: Record<string, XpackUsageDatafeed>
  jobs: Record<string, XpackUsageJobUsage>
  node_count: integer
  data_frame_analytics_jobs: XpackUsageMlDataFrameAnalyticsJobs
  inference: XpackUsageMlInference
}

export interface XpackUsageMlCounter {
  count: long
}

export interface XpackUsageMlDataFrameAnalyticsJobs {
  memory_usage?: XpackUsageMlDataFrameAnalyticsJobsMemory
  _all: XpackUsageMlDataFrameAnalyticsJobsCount
  analysis_counts?: XpackUsageMlDataFrameAnalyticsJobsAnalysis
  stopped?: XpackUsageMlDataFrameAnalyticsJobsCount
}

export interface XpackUsageMlDataFrameAnalyticsJobsAnalysis {
  classification?: integer
  outlier_detection?: integer
  regression?: integer
}

export interface XpackUsageMlDataFrameAnalyticsJobsCount {
  count: long
}

export interface XpackUsageMlDataFrameAnalyticsJobsMemory {
  peak_usage_bytes: MlJobStatistics
}

export interface XpackUsageMlInference {
  ingest_processors: Record<string, XpackUsageMlInferenceIngestProcessor>
  trained_models: XpackUsageMlInferenceTrainedModels
  deployments?: XpackUsageMlInferenceDeployments
}

export interface XpackUsageMlInferenceDeployments {
  count: integer
  inference_counts: MlJobStatistics
  model_sizes_bytes: MlJobStatistics
  time_ms: XpackUsageMlInferenceDeploymentsTimeMs
}

export interface XpackUsageMlInferenceDeploymentsTimeMs {
  avg: double
}

export interface XpackUsageMlInferenceIngestProcessor {
  num_docs_processed: XpackUsageMlInferenceIngestProcessorCount
  pipelines: XpackUsageMlCounter
  num_failures: XpackUsageMlInferenceIngestProcessorCount
  time_ms: XpackUsageMlInferenceIngestProcessorCount
}

export interface XpackUsageMlInferenceIngestProcessorCount {
  max: long
  sum: long
  min: long
}

export interface XpackUsageMlInferenceTrainedModels {
  estimated_operations?: MlJobStatistics
  estimated_heap_memory_usage_bytes?: MlJobStatistics
  count?: XpackUsageMlInferenceTrainedModelsCount
  _all: XpackUsageMlCounter
  model_size_bytes?: MlJobStatistics
}

export interface XpackUsageMlInferenceTrainedModelsCount {
  total: long
  prepackaged: long
  other: long
  pass_through?: long
  regression?: long
  classification?: long
  ner?: long
  text_embedding?: long
}

export interface XpackUsageMlJobForecasts {
  total: long
  forecasted_jobs: long
}

export interface XpackUsageMonitoring extends XpackUsageBase {
  collection_enabled: boolean
  enabled_exporters: Record<string, long>
}

export interface XpackUsagePhase {
  actions: string[]
  min_age: DurationValue<UnitMillis>
}

export interface XpackUsagePhases {
  cold?: XpackUsagePhase
  delete?: XpackUsagePhase
  frozen?: XpackUsagePhase
  hot?: XpackUsagePhase
  warm?: XpackUsagePhase
}

export interface XpackUsageQuery {
  count?: integer
  failed?: integer
  paging?: integer
  total?: integer
}

export interface XpackUsageRealm extends XpackUsageBase {
  name?: string[]
  order?: long[]
  size?: long[]
  cache?: XpackUsageRealmCache[]
  has_authorization_realms?: boolean[]
  has_default_username_pattern?: boolean[]
  has_truststore?: boolean[]
  is_authentication_delegated?: boolean[]
}

export interface XpackUsageRealmCache {
  size: long
}

export interface XpackUsageRequest extends RequestBase {
/** The period to wait for a connection to the master node. If no response is received before the timeout expires, the request fails and returns an error. To indicate that the request should never timeout, set it to `-1`. */
  master_timeout?: Duration
  /** All values in `body` will be added to the request body. */
  body?: string | { [key: string]: any } & { master_timeout?: never }
  /** All values in `querystring` will be added to the request querystring. */
  querystring?: { [key: string]: any } & { master_timeout?: never }
}

export interface XpackUsageResponse {
  aggregate_metric: XpackUsageBase
  analytics: XpackUsageAnalytics
  archive: XpackUsageArchive
  watcher: XpackUsageWatcher
  ccr: XpackUsageCcr
  data_frame?: XpackUsageBase
  data_science?: XpackUsageBase
  data_streams?: XpackUsageDataStreams
  data_tiers: XpackUsageDataTiers
  enrich?: XpackUsageBase
  eql: XpackUsageEql
  flattened?: XpackUsageFlattened
  graph: XpackUsageBase
  health_api?: XpackUsageHealthStatistics
  ilm: XpackUsageIlm
  logstash: XpackUsageBase
  ml: XpackUsageMachineLearning
  monitoring: XpackUsageMonitoring
  rollup: XpackUsageBase
  runtime_fields?: XpackUsageRuntimeFieldTypes
  spatial: XpackUsageBase
  searchable_snapshots: XpackUsageSearchableSnapshots
  security: XpackUsageSecurity
  slm: XpackUsageSlm
  sql: XpackUsageSql
  transform: XpackUsageBase
  vectors?: XpackUsageVector
  voting_only: XpackUsageBase
}

export interface XpackUsageRoleMapping {
  enabled: integer
  size: integer
}

export interface XpackUsageRuntimeFieldTypes extends XpackUsageBase {
  field_types: XpackUsageRuntimeFieldsType[]
}

export interface XpackUsageRuntimeFieldsType {
  chars_max: long
  chars_total: long
  count: long
  doc_max: long
  doc_total: long
  index_count: long
  lang: string[]
  lines_max: long
  lines_total: long
  name: Field
  scriptless_count: long
  shadowed_count: long
  source_max: long
  source_total: long
}

export interface XpackUsageSearchableSnapshots extends XpackUsageBase {
  indices_count: integer
  full_copy_indices_count?: integer
  shared_cache_indices_count?: integer
}

export interface XpackUsageSecurity extends XpackUsageBase {
  api_key_service: XpackUsageFeatureToggle
  anonymous: XpackUsageFeatureToggle
  audit: XpackUsageAudit
  fips_140: XpackUsageFeatureToggle
  ipfilter: XpackUsageIpFilter
  realms: Record<string, XpackUsageRealm>
  role_mapping: Record<string, XpackUsageRoleMapping>
  roles: XpackUsageSecurityRoles
  ssl: XpackUsageSsl
  system_key?: XpackUsageFeatureToggle
  token_service: XpackUsageFeatureToggle
  operator_privileges: XpackUsageBase
}

export interface XpackUsageSecurityRoles {
  native: XpackUsageSecurityRolesNative
  dls: XpackUsageSecurityRolesDls
  file: XpackUsageSecurityRolesFile
}

export interface XpackUsageSecurityRolesDls {
  bit_set_cache: XpackUsageSecurityRolesDlsBitSetCache
}

export interface XpackUsageSecurityRolesDlsBitSetCache {
  count: integer
  memory?: ByteSize
  memory_in_bytes: ulong
}

export interface XpackUsageSecurityRolesFile {
  dls: boolean
  fls: boolean
  size: long
}

export interface XpackUsageSecurityRolesNative {
  dls: boolean
  fls: boolean
  size: long
}

export interface XpackUsageSlm extends XpackUsageBase {
  policy_count?: integer
  policy_stats?: SlmStatistics
}

export interface XpackUsageSql extends XpackUsageBase {
  features: Record<string, integer>
  queries: Record<string, XpackUsageQuery>
}

export interface XpackUsageSsl {
  http: XpackUsageFeatureToggle
  transport: XpackUsageFeatureToggle
}

export interface XpackUsageVector extends XpackUsageBase {
  dense_vector_dims_avg_count: integer
  dense_vector_fields_count: integer
  sparse_vector_fields_count?: integer
}

export interface XpackUsageWatcher extends XpackUsageBase {
  execution: XpackUsageWatcherActions
  watch: XpackUsageWatcherWatch
  count: XpackUsageCounter
}

export interface XpackUsageWatcherActionTotals {
  total: Duration
  total_time_in_ms: DurationValue<UnitMillis>
}

export interface XpackUsageWatcherActions {
  actions: Record<Name, XpackUsageWatcherActionTotals>
}

export interface XpackUsageWatcherWatch {
  input: Record<Name, XpackUsageCounter>
  condition?: Record<Name, XpackUsageCounter>
  action?: Record<Name, XpackUsageCounter>
  trigger: XpackUsageWatcherWatchTrigger
}

export interface XpackUsageWatcherWatchTrigger {
  schedule?: XpackUsageWatcherWatchTriggerSchedule
  _all: XpackUsageCounter
}

export interface XpackUsageWatcherWatchTriggerSchedule extends XpackUsageCounter {
  cron: XpackUsageCounter
  _all: XpackUsageCounter
}

export interface SpecUtilsAdditionalProperties<TKey = unknown, TValue = unknown> {
}

export interface SpecUtilsAdditionalProperty<TKey = unknown, TValue = unknown> {
}

export interface SpecUtilsCommonQueryParameters {
  error_trace?: boolean
  filter_path?: string | string[]
  human?: boolean
  pretty?: boolean
}

export interface SpecUtilsCommonCatQueryParameters {
  format?: string
  help?: boolean
  v?: boolean
}

export interface SpecUtilsOverloadOf<TDefinition = unknown> {
}
